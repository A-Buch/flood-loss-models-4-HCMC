{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"Add floor numbers to HCMC dataset\"\"\"\n",
    "\n",
    "__author__ = \"Anna Buch, Heidelberg University\"\n",
    "__email__ = \"anna.buch@uni-heidelberg.de\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Floor numbers and geolocations\n",
    "\n",
    "**Aim**: \\\n",
    "Try to get the number of floors per shophouse and the rather exact geolocations of the shophouses, in which the surveyed microbusinesses are located in.\n",
    "Due that the GPS coordinates in the HCMC dataset are unprecise, the matching has to be done based on the building addresses.\n",
    "\n",
    "First examine if the shophouse addresses from the HCMC dataet matches with the addresses from a second dataset comprising housing information and geolocation.\n",
    "Update the HCMC dataset for the addresses which occur in both datasets. By doing this the floor number and geolocation can be obtained for at least some records.\n",
    "For the remaining records (shophouses for which no floor number exist) assume a two-storey building, based on the findings from Moon et al. 2009."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "UTILS_PATH = os.path.join(os.path.abspath(''), '../', 'utils')\n",
    "sys.path.append(UTILS_PATH)\n",
    "import figures as f\n",
    "import preprocessing as pp\n",
    "import feature_selection as fs\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geoinformations = gpd.read_file(\"../input_survey_data/Buildings_HCMC/HCMC_buildings_survey_TUEB_addresses.shp\")  # Dataset in vietnamese characters\n",
    "\n",
    "## data cleaning and repair\n",
    "geoinformations.Nr_Floors = geoinformations.Nr_Floors.replace({10:1, 20:2, 30:3, 40:4}).astype(\"Int64\")  ## fix floor numbers. 10-->1, 20-->2\n",
    "geoinformations[\"Street\"] = geoinformations[\"Street\"].str.lower().replace(\",\", \"\")\n",
    "\n",
    "geoinformations.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load survey data\n",
    "raw_data = pd.read_excel(\"../input_survey_data/all-attributes_shophouses.xlsx\")  # Niveditas dataset\n",
    "\n",
    "## vietnamese version of survey data\n",
    "vietnamese_data = pd.read_excel(\"../input_survey_data/Data DECIDER shophouse.xlsx\")  # Dataset in vietnamese characters\n",
    "vietnamese_data.head(3)\n",
    "\n",
    "## data cleaning and repair\n",
    "raw_data[\"Q0.3\"] = raw_data[\"Q0.3\"].str.lower().replace(\",\", \"\")\n",
    "vietnamese_data[\"Q0.3\"] = vietnamese_data[\"Q0.3\"].str.lower().replace(\",\", \"\")\n",
    "raw_data\n",
    "## Fix erroneous coordinate pair by removing second decimal point\n",
    "raw_data.GPS = raw_data.GPS.astype(str).replace({\"10.722.546,106.62888\":\"10.722546,106.62888\",\n",
    "                                     \"10797626106701100\":\"10.797626,106.701100\",  # idx 24\n",
    "                                     \"10722187106.63\":\"10.722187,106.63\"})  # idx 152"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### update dataset with vietnamese addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(raw_data.shape)\n",
    "#t = FuzzyMerge(left=raw_data, right=vietnamese_data, left_on=\"GPS\", right_on=\"GPS\").main()\n",
    "raw_data[\"id\"] = raw_data.index\n",
    "raw_data.insert(0, \"id\", raw_data.pop(\"id\"))  # use key to identify doublicates after merged with vietnamese df\n",
    "\n",
    "raw_data[\"Q0.3\"] =  raw_data[\"Q0.3\"].str.strip()\n",
    "vietnamese_data[\"Q0.3\"] = vietnamese_data[\"Q0.3\"].str.strip()\n",
    "vietnamese_data[\"Housenumber_street\"] = vietnamese_data[\"Q0.3\"]\n",
    "print(len(vietnamese_data[\"Housenumber_street\"].unique()))\n",
    "raw_data[\"housenumber_street\"] = raw_data[\"Q0.3\"]\n",
    "print(len(raw_data[\"housenumber_street\"].unique()))\n",
    "\n",
    "raw_data_vietnamese = pp.FuzzyMerge(left=raw_data, right=vietnamese_data[[\"Housenumber_street\",\"Q0.2.District\", \"Q0.2.Ward\", \"Q0.3\"]], left_on=\"Q0.3\", right_on=\"Q0.3\").main()\n",
    "#raw_data_vietnamese = pp.FuzzyMerge(left=raw_data, right=vietnamese_data[[\"Housenumber_street\",\"Q0.2.District\", \"Q0.2.Ward\", \"Q0.3\", \"Q0.5\"]], left_on=\"Q0.3\", right_on=\"Q0.3\").main()\n",
    "print(raw_data_vietnamese.shape)\n",
    "print(len(raw_data_vietnamese[\"housenumber_street\"].unique()))\n",
    "print(len(raw_data_vietnamese[\"Housenumber_street\"].unique()))  # all ientmaese adresses matched with its corresponding address from Niveditas dataset\n",
    "\n",
    "## TODO robustify by replacing all columns ending with \"_x\" by columns ending with \"_y\"\n",
    "raw_data_vietnamese[\"housenumber_street\"] = raw_data_vietnamese[\"Housenumber_street\"]\n",
    "raw_data_vietnamese[\"Q0.2.District_x\"] = raw_data_vietnamese[\"Q0.2.District_y\"]\n",
    "raw_data_vietnamese[\"Q0.2.Ward_x\"] = raw_data_vietnamese[\"Q0.2.Ward_y\"]\n",
    "#raw_data_vietnamese[\"Q0.5_x\"] = raw_data_vietnamese[\"Q0.5_y\"]\n",
    "raw_data_vietnamese.drop([\"Housenumber_street\", \"Q0.2.District_y\",\"Q0.2.Ward_y\"], axis=1, inplace=True)\n",
    "#raw_data_vietnamese.drop([\"Housenumber_street\", \"Q0.2.District_y\",\"Q0.2.Ward_y\", \"Q0.5_y\"], axis=1, inplace=True)\n",
    "raw_data_vietnamese.columns = raw_data_vietnamese.columns.str.rstrip('_x')\n",
    "print(raw_data_vietnamese.shape)\n",
    "raw_data_vietnamese\n",
    "\n",
    "## 10 records are dublicates in columns which are from raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_vietnamese[raw_data_vietnamese.id.duplicated(keep=False)]  # show all dublicates\n",
    "#(raw_data_vietnamese.loc[[147]].values == raw_data_vietnamese.loc[148].values).all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## remove dublicated records\n",
    "raw_data_vietnamese = raw_data_vietnamese[~raw_data_vietnamese.duplicated(keep=\"last\")]\n",
    "print(raw_data_vietnamese.shape)\n",
    "raw_data_vietnamese.drop(\"id\",axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get coords in readable format for gpd\n",
    "raw_data_vietnamese = gpd.GeoDataFrame(raw_data_vietnamese,  \n",
    "            geometry=gpd.points_from_xy( \n",
    "                    raw_data_vietnamese[\"GPS\"].str.split(\",\").str[1], # lon\n",
    "                    raw_data_vietnamese[\"GPS\"].str.split(\",\").str[0],  # lat\n",
    "            )\n",
    "        )\n",
    "print(raw_data_vietnamese.shape)\n",
    "\n",
    "## save shp locations to disk, \n",
    "# extract elevation based on shop locations in datapoints_vars_bui.shp via QGIS due to loading size and process with gdal\n",
    "print(raw_data_vietnamese.crs)\n",
    "raw_data_vietnamese = raw_data_vietnamese.set_crs(4326) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_vietnamese[~raw_data_vietnamese.is_empty].geometry.info()\n",
    "# raw_data_vietnamese.geometry.info(9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## visual check of SMEs locations\n",
    "import folium\n",
    "\n",
    "glimpse = raw_data_vietnamese[~ raw_data_vietnamese.is_empty]   # drop emtpy geoms\n",
    "glimpse_geolocations = geoinformations[~ geoinformations.is_empty]   # drop emtpy geoms\n",
    "m = glimpse.geometry.explore(name=\"survey ds\", color=\"red\", k=6)  \n",
    "m = glimpse_geolocations.explode(ignore_index=True).explore(\n",
    "    m=m, \n",
    "    name=\"geolocations\",\n",
    "    column=\"Nr_Floors\", \n",
    "    popup=True, \n",
    "    #tooltip=\"Nr_Floors\", \n",
    "    #cmap=\"winter\"\n",
    "    cmap=\"Set1\"\n",
    ")    # BT_Moon BT_TUEB_2\n",
    "\n",
    "folium.LayerControl().add_to(m)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Distribution of floor numbers\n",
    " \n",
    "t = geoinformations.groupby([\"BT_Moon\", \"Nr_Floors\"]).size().unstack(0)\n",
    "t.plot.bar(stacked=True)\n",
    "\n",
    "#plt.hist(stacked=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Join adresses\n",
    "Add geolocations and building information based on common street and house numbers to the updated survey dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_vietnamese[\"housenumber_street\"] = raw_data_vietnamese[\"housenumber_street\"].str.strip()\n",
    "#raw_data_vietnamese[\"street_housenumber\"].isna().sum()\n",
    "geoinformations['Housenumber_street'] = geoinformations['HouseNumbe'] + \" \" + geoinformations['Street']\n",
    "\n",
    "## drop unknown adresses \n",
    "print(f\"Removing {geoinformations.Housenumber_street.isna().sum()} records with missing address\")\n",
    "geoinformations = geoinformations.loc[~geoinformations.Housenumber_street.isna(),:]\n",
    "#geoinformations.street_housenumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## make street names more similar, due that Tuebingen group only used first two words of each street name, but in Niveidtas dtataset the entire street names are used\n",
    "raw_data_vietnamese.housenumber_street = raw_data_vietnamese.housenumber_street.astype(str)\n",
    "for idx, street in enumerate(raw_data_vietnamese.housenumber_street):\n",
    "    if street != \"nan\":\n",
    "        print(street)\n",
    "        raw_data_vietnamese.housenumber_street[idx] = ' '.join([x if index != 3 else \"\" for index, x in enumerate(street.split())]).strip()\n",
    "\n",
    "#raw_data_vietnamese_geolocations.housenumber_street.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note:* Housenumber how to read: e.g. “25/1/10” means “house No.10 in niche 1 of alley 25”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_vietnamese[\"housenumber_street\"].unique()  # --> 62 records with adrresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geoinformations[\"id\"] = geoinformations.index  # get unique key to access number of matches\n",
    "raw_data_vietnamese[\"id_x\"] = raw_data_vietnamese.index\n",
    "raw_data_vietnamese.insert(0, \"id_x\", raw_data_vietnamese.pop(\"id_x\"))\n",
    "\n",
    "geoinformations['updated_geometry'] = geoinformations[\"geometry\"]\n",
    "\n",
    "## NOTE test to repair\n",
    "raw_data_vietnamese_geolocations = pd.merge(\n",
    "    left=raw_data_vietnamese, #[\"housenumber_street\"], \n",
    "    right=geoinformations[['BT_Moon', 'Nr_Floors', 'BT_TUEB_2','Housenumber_street', 'id', 'updated_geometry']], \n",
    "    left_on=\"housenumber_street\", right_on=\"Housenumber_street\",\n",
    "    how=\"left\")\n",
    "\n",
    "\n",
    "print(raw_data_vietnamese.shape)\n",
    "print(geoinformations.shape)\n",
    "print(raw_data_vietnamese_geolocations.shape)\n",
    "print(len(geoinformations.id.unique()))\n",
    "print(len(raw_data_vietnamese_geolocations.id.unique()))  # records with improved geolocations\n",
    "\n",
    "## count records which didnt match with any of the geolocations , = missing ids after joined adresses\n",
    "print(raw_data_vietnamese_geolocations.id.isna().sum())  # cutoff: 0.9 :177 , 0.8: 133 (477 records), 0.7:130 (531 records)\n",
    "\n",
    "raw_data_vietnamese_geolocations.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(geoinformations.Nr_Floors) - geoinformations.Nr_Floors.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geoinformations.Nr_Floors.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## update geometries \n",
    "Replace GPS location of records in survey dataset where a imporved geolocation from Tuebingen exists\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_vietnamese_geolocations.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_vietnamese_geolocations.updated_geometry = raw_data_vietnamese_geolocations.updated_geometry.representative_point()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_vietnamese_geolocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "raw_data_vietnamese_geolocations['geometry'] = np.where(\n",
    "    ~raw_data_vietnamese_geolocations['updated_geometry'].isnull(), \n",
    "    raw_data_vietnamese_geolocations['updated_geometry'],\n",
    "    raw_data_vietnamese_geolocations['geometry']\n",
    ")\n",
    "# raw_data_vietnamese_geolocations['geometry']\n",
    "raw_data_vietnamese_geolocations[\"P4Q4.2.1\"] = raw_data_vietnamese_geolocations[\"P4Q4.2.1\"].astype(str)\n",
    "raw_data_vietnamese_geolocations.drop([\"GPS\", \"Q0.10\", \"P4Q4.2.2\",\"updated_geometry\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## prepare for saving as shp\n",
    "datetime_col = raw_data_vietnamese_geolocations.select_dtypes(include=['datetime64']).columns.to_list()\n",
    "raw_data_vietnamese_geolocations[datetime_col] = raw_data_vietnamese_geolocations[datetime_col].astype(str)\n",
    "raw_data_vietnamese_geolocations[[\"Q0.6\",\"P1Q2.1.1\", \"P1Q2.2.1\" ,\"P1Q2.1.2\",\"P1Q2.2.2\", \"P4Q4.2.1\"]] = raw_data_vietnamese_geolocations[[\"Q0.6\",\"P1Q2.1.1\", \"P1Q2.2.1\" ,\"P1Q2.1.2\",\"P1Q2.2.2\", \"P4Q4.2.1\"]].astype(str)\n",
    "\n",
    "print(raw_data_vietnamese_geolocations.crs)\n",
    "raw_data_vietnamese_geolocations = raw_data_vietnamese_geolocations.set_crs(4326) \n",
    "\n",
    "## save shp locations to disk\n",
    "raw_data_vietnamese_geolocations.loc[:, \"P1Q2.2.2\":\"geometry\"].to_file('../input_survey_data/DEM_LiDAR/datapoints_vars_bui_tueb.shp')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## all dublicate columns which need to be corrected\n",
    "\n",
    "raw_v_g_dubl = pd.concat(g for _, g in raw_data_vietnamese_geolocations.groupby(\"id_x\") if len(g) > 1)\n",
    "raw_v_g_dubl[[\"id_x\" ,\"Q0.14\", \"housenumber_street\", \"geometry\",\t\"BT_Moon\",\t\"Nr_Floors\", \"BT_TUEB_2\", \"Housenumber_street\", \"id\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## write to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save updated HCMC survey ds (with corrrect adresses, and partly improved geolocations)\n",
    "\n",
    "## save shp locations to disk\n",
    "raw_data_vietnamese_geolocations_sm = gpd.GeoDataFrame(\n",
    "    pd.concat(  # TODO add columns numbers of candidate predictors + \"BT_Moon\",\t\"Nr_Floors\",\t\"BT_TUEB_2\"\n",
    "        [raw_data_vietnamese_geolocations[[\"id_x\"]], raw_data_vietnamese_geolocations.loc[:, \"P1Q2.2.2\":\"geometry\"]]\n",
    "        , axis=1))\n",
    "raw_data_vietnamese_geolocations_sm.to_file('../input_survey_data/DEM_LiDAR/datapoints_vars_bui_tueb_tst2.shp')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_vietnamese_geolocations[raw_data_vietnamese_geolocations.duplicated(subset=[\"id_x\"],keep=False)].sort_values(\"id_x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_vietnamese_geolocations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## record number with missing imporved geolocation info\n",
    "raw_data_vietnamese_geolocations.Housenumber_street.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_vietnamese_geolocations.housenumber_street.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual postprocessing\n",
    "for a quicker processing all samples are written to excel, these samples are comprissed out of the survey shophouses and can occure one or more times depending how often a match with similar or identical addresses form the tuebing dataset ws found. \n",
    "\n",
    "*raw_data_vietnamese_geolocations_incl_dublicates.xlsx* is processed manually by keeping only records which have idnetical addresses or if addresses slightly differ a visual comparison of the adresses is done. If both addresses describe buildings next to each other than it is assumed that building tye and especially floor number is similar \n",
    "\n",
    "Manual created output: **raw_data_vietnamese_geolocations_no_dublicates.xlsx** which contains all records from Niveditas dataset, some of theses 252 shops (ie. records) contain improved geoinformation and building information such as floor number \n",
    "\n",
    "\n",
    "**TODO** \n",
    "make this in python e.g. by creating new column with same number for each group of dublicates and select out of each group the record with the fewest missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## all dublicate columns which need to be corrected\n",
    "\n",
    "raw_v_g_dubl = pd.concat(g for _, g in raw_data_vietnamese_geolocations.groupby(\"id_x\") if len(g) > 1)\n",
    "raw_v_g_dubl[[\"id_x\" ,\"Q0.14\", \"housenumber_street\", \"geometry\",\t\"BT_Moon\",\t\"Nr_Floors\", \"BT_TUEB_2\", \"Housenumber_street\", \"id\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_data\n",
    "raw_data_vietnamese_geolocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py396_c3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
