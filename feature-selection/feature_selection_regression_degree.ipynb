{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created  ..\\..\\model_results\\selected_features\\degree_of_rcloss\n",
      "Created  ..\\..\\models_trained\\final_models\\degree_of_rcloss\n",
      "Created  ..\\..\\models_trained\\nested_cv_models\\degree_of_rcloss\n",
      "Created  ..\\..\\model_results\\models_evaluation\\degree_of_rcloss\n",
      "..\\..\\model_results\\selected_features\\degree_of_rcloss ..\\..\\models_trained\\final_models\\degree_of_rcloss ..\\..\\models_trained\\nested_cv_models\\degree_of_rcloss ..\\..\\model_results\\models_evaluation\\degree_of_rcloss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05-16-2024 12:27:26 - __feature_extraction_degreee__ - INFO - (317, 20)\n",
      "05-16-2024 12:27:26 - __feature_extraction_degreee__ - INFO - \n",
      "\n",
      "############ Applying ElasticNet on rcloss ############\n",
      " \n",
      "05-16-2024 12:27:26 - __feature_extraction_degreee__ - INFO - Removing 0 records from entire dataset due that these values are nan in target variable\n",
      "05-16-2024 12:27:26 - __feature_extraction_degreee__ - INFO - Finally use 276 records for feature extraction, from those are 169 cases with zero-loss or zero-reduction\n",
      "05-16-2024 12:27:26 - __feature_extraction_degreee__ - INFO - Use for feature extraction 17 features to predict degree of rcloss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['rcloss', 'closs', 'inundation duration', 'water depth inside',\n",
      "       'contaminations', 'flow velocity', 'flood experience', 'building age',\n",
      "       'building area', 'geometry', 'shp_business_limitation', 'shp_sector',\n",
      "       'mthly. income', 'emergency measures', 'no. employees',\n",
      "       'non-structural measures', 'structural measures', 'resilience',\n",
      "       'shp_content_value_euro', 'mthly. sales'],\n",
      "      dtype='object')\n",
      "Dropping records with missing values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05-16-2024 12:27:49 - __feature_extraction_degreee__ - INFO - Parameter sets of best estimators outer test-sets:\n",
      "05-16-2024 12:27:49 - __feature_extraction_degreee__ - INFO - Params of best model: {'model__tol': 0.3, 'model__selection': 'random', 'model__random_state': 42, 'model__max_iter': 6, 'model__l1_ratio': 0.1, 'model__alpha': 0.5}\n",
      "05-16-2024 12:27:49 - __feature_extraction_degreee__ - INFO - Performance of best estimator\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElasticNet:  {'model__tol': 0.3, 'model__selection': 'random', 'model__random_state': 42, 'model__max_iter': 6, 'model__l1_ratio': 0.1, 'model__alpha': 0.5}\n",
      "ElasticNet:  {'model__tol': 0.3, 'model__selection': 'random', 'model__random_state': 42, 'model__max_iter': 6, 'model__l1_ratio': 0.1, 'model__alpha': 0.5}\n",
      "ElasticNet:  {'model__tol': 0.3, 'model__selection': 'random', 'model__random_state': 42, 'model__max_iter': 6, 'model__l1_ratio': 0.1, 'model__alpha': 0.5}\n",
      "ElasticNet:  {'model__tol': 0.3, 'model__selection': 'random', 'model__random_state': 42, 'model__max_iter': 6, 'model__l1_ratio': 0.1, 'model__alpha': 0.5}\n",
      "ElasticNet:  {'model__tol': 0.3, 'model__selection': 'random', 'model__random_state': 42, 'model__max_iter': 6, 'model__l1_ratio': 0.1, 'model__alpha': 0.5}\n",
      "\n",
      "\n",
      "test_MAE 6.400267280153487\n",
      "test_RMSE 11.437692179373881\n",
      "test_MBE 1.3250381469285644\n",
      "test_SMAPE 82.32913728150537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05-16-2024 12:27:53 - __feature_extraction_degreee__ - INFO - \n",
      "Select features based on permutation feature importance\n",
      "05-16-2024 12:27:53 - __feature_extraction_degreee__ - INFO - 5 most important features: ['closs', 'flow velocity', 'shp_business_limitation', 'non-structural measures', 'water depth inside']\n",
      "05-16-2024 12:27:53 - __feature_extraction_degreee__ - INFO - \n",
      "Training and evaluation of ElasticNet took 0.44549153333333336 minutes\n",
      "\n",
      "05-16-2024 12:27:53 - __feature_extraction_degreee__ - INFO - \n",
      "\n",
      "############ Applying cforest on rcloss ############\n",
      " \n",
      "05-16-2024 12:27:53 - __feature_extraction_degreee__ - INFO - Removing 0 records from entire dataset due that these values are nan in target variable\n",
      "05-16-2024 12:27:53 - __feature_extraction_degreee__ - INFO - Finally use 276 records for feature extraction, from those are 169 cases with zero-loss or zero-reduction\n",
      "05-16-2024 12:27:53 - __feature_extraction_degreee__ - INFO - Use for feature extraction 17 features to predict degree of rcloss\n",
      "R[write to console]: Fitting final model using CV on whole data\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefs_intercept = np.append(model_intercept, list(model_coefs)) [ 3.75184241  3.1088422   0.          0.77797721 -0.          1.76679071\n",
      "  0.0073245  -0.48975601 -0.02131454  1.58617685 -0.33252285  0.22750083\n",
      "  0.68615811 -0.08435724 -0.46184777 -0.00508614  0.          0.48038337]\n",
      "Dropping records with missing values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Performing 5-fold outer CV, using 1 core\n",
      "\n",
      "R[write to console]: Duration: 6.499602 mins\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nested cross-validation with caret\n",
      "Method:  cforest \n",
      "No filter\n",
      "Outer loop:  5-fold cv\n",
      "Inner loop:  5-fold repeatedcv\n",
      "276 observations, 17 predictors\n",
      "\n",
      "        mtry  n.filter\n",
      "Fold 1    14        17\n",
      "Fold 2    14        17\n",
      "Fold 3    14        17\n",
      "Fold 4    14        17\n",
      "Fold 5    14        17\n",
      "\n",
      "Final parameters:\n",
      "  mtry\n",
      "    14\n",
      "\n",
      "Result:\n",
      "    RMSE   Rsquared        MAE   \n",
      "  9.9334     0.5072     3.3678   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05-16-2024 12:34:23 - __model_training__ - INFO - \n",
      "Summary CRF \n",
      " $dimx\n",
      "[1] 276  17\n",
      "\n",
      "$folds\n",
      "       mtry n.filter\n",
      "Fold 1   14       17\n",
      "Fold 2   14       17\n",
      "Fold 3   14       17\n",
      "Fold 4   14       17\n",
      "Fold 5   14       17\n",
      "\n",
      "$final_param\n",
      "  mtry\n",
      "7   14\n",
      "\n",
      "$result\n",
      "    RMSE   Rsquared        MAE   \n",
      "  9.9334     0.5072     3.3678   \n",
      "\n",
      "\n",
      "05-16-2024 12:34:30 - __feature_extraction_degreee__ - INFO - Performance of best CRF model: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_MAE: 2.300448573602632\n",
      "test_RMSE: 5.842672925471902\n",
      "test_MBE: 0.5929492750226636\n",
      "test_SMAPE: 72.23715505179793\n",
      "  |||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||| 100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05-16-2024 12:36:09 - __feature_extraction_degreee__ - INFO - \n",
      "Select features based on permutation feature importance\n",
      "05-16-2024 12:36:09 - __feature_extraction_degreee__ - INFO - 5 most important features: ['closs', 'shp_business_limitation', 'mthly. income', 'flow velocity', 'mthly. sales']\n",
      "05-16-2024 12:36:09 - __feature_extraction_degreee__ - INFO - \n",
      "Training and evaluation of cforest took 8.263085666666667 minutes\n",
      "\n",
      "05-16-2024 12:36:09 - __feature_extraction_degreee__ - INFO - \n",
      "\n",
      "############ Applying XGBRegressor on rcloss ############\n",
      " \n",
      "05-16-2024 12:36:09 - __feature_extraction_degreee__ - INFO - Removing 0 records from entire dataset due that these values are nan in target variable\n",
      "05-16-2024 12:36:09 - __feature_extraction_degreee__ - INFO - Finally use 317 records for feature extraction, from those are 191 cases with zero-loss or zero-reduction\n",
      "05-16-2024 12:36:09 - __feature_extraction_degreee__ - INFO - Use for feature extraction 17 features to predict degree of rcloss\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [1], line 258\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;66;03m## evaluate model    \u001b[39;00m\n\u001b[0;32m    249\u001b[0m me \u001b[38;5;241m=\u001b[39m e\u001b[38;5;241m.\u001b[39mModelEvaluation(\n\u001b[0;32m    250\u001b[0m     models_trained_ncv\u001b[38;5;241m=\u001b[39mmodels_trained_ncv, \n\u001b[0;32m    251\u001b[0m     Xy\u001b[38;5;241m=\u001b[39mdf_Xy,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    256\u001b[0m     seed\u001b[38;5;241m=\u001b[39mseed,\n\u001b[0;32m    257\u001b[0m )\n\u001b[1;32m--> 258\u001b[0m model_evaluation_results \u001b[38;5;241m=\u001b[39m \u001b[43mme\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_evaluate_ncv\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;66;03m## reverse sklearn.cross_validate() outputted regression scores (e.g. MAE, RMSE, SMAPE, R2)\u001b[39;00m\n\u001b[0;32m    261\u001b[0m model_evaluation_results \u001b[38;5;241m=\u001b[39m me\u001b[38;5;241m.\u001b[39mnegate_scores_from_sklearn_cross_valdiate(  \u001b[38;5;66;03m# TODO impl directly as method in ModelEvalaution()\u001b[39;00m\n\u001b[0;32m    262\u001b[0m     model_evaluation_results, \n\u001b[0;32m    263\u001b[0m     metric_names\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_MAE\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_MBE\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_RMSE\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_SMAPE\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\Anna\\Documents\\UNI\\MA_topic\\master thesis\\flood-loss-models-4-HCMC-remote\\improve-project\\feature-selection\\../../utils\\evaluation.py:81\u001b[0m, in \u001b[0;36mModelEvaluation.model_evaluate_ncv\u001b[1;34m(self, sample_weights, prediction_method)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;124;03m\"\"\"  \u001b[39;00m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;124;03mRun and Evaluate sklearn model by nested cross-validation [outer folds]\u001b[39;00m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;124;03mprediction_method (str): \"predict\" or \"predict_proba\"\u001b[39;00m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;124;03mreturn: predict y and return model generalization perfromance\u001b[39;00m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m    \n\u001b[0;32m     79\u001b[0m \u001b[38;5;66;03m## predict y of each outer folds by using the estimator from the respecitve inner fold \u001b[39;00m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;66;03m## NOTE dont use cross_val_predict() to access generalization performance\u001b[39;00m\n\u001b[1;32m---> 81\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_pred \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_predict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels_trained_ncv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# estimators from inner cv\u001b[39;49;00m\n\u001b[0;32m     83\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     84\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mk_folds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# KFold without repeats to have for each sample one predicted value \u001b[39;49;00m\n\u001b[0;32m     85\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprediction_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     86\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     87\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;66;03m## Probability predictions (self.y_pred is 2-dimensional: predicted probabilities and respective predictions)\u001b[39;00m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prediction_method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict_proba\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\py396_c3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:1036\u001b[0m, in \u001b[0;36mcross_val_predict\u001b[1;34m(estimator, X, y, groups, cv, n_jobs, verbose, fit_params, pre_dispatch, method)\u001b[0m\n\u001b[0;32m   1033\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m   1034\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m   1035\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[1;32m-> 1036\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1037\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_predict\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1038\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\n\u001b[0;32m   1039\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1040\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msplits\u001b[49m\n\u001b[0;32m   1041\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1043\u001b[0m inv_test_indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(\u001b[38;5;28mlen\u001b[39m(test_indices), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m   1044\u001b[0m inv_test_indices[test_indices] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mlen\u001b[39m(test_indices))\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\py396_c3\\lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\py396_c3\\lib\\site-packages\\joblib\\parallel.py:1855\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1853\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1854\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1855\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1857\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1858\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1860\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1861\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1862\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\py396_c3\\lib\\site-packages\\joblib\\parallel.py:1784\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1782\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1783\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1784\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1785\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1786\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\py396_c3\\lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\py396_c3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:1118\u001b[0m, in \u001b[0;36m_fit_and_predict\u001b[1;34m(estimator, X, y, train, test, verbose, fit_params, method)\u001b[0m\n\u001b[0;32m   1116\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m   1117\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1118\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m   1119\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(estimator, method)\n\u001b[0;32m   1120\u001b[0m predictions \u001b[38;5;241m=\u001b[39m func(X_test)\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\py396_c3\\lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\py396_c3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    894\u001b[0m     )\n\u001b[0;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 898\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\py396_c3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1806\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1805\u001b[0m     \u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1806\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1807\u001b[0m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1808\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\n\u001b[0;32m   1809\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1810\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\py396_c3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    838\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    839\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    842\u001b[0m         )\n\u001b[0;32m    843\u001b[0m     )\n\u001b[1;32m--> 845\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    849\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    850\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    852\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    854\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    855\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    858\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    865\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    866\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    867\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\py396_c3\\lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\py396_c3\\lib\\site-packages\\joblib\\parallel.py:1855\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1853\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1854\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1855\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1857\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1858\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1860\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1861\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1862\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\py396_c3\\lib\\site-packages\\joblib\\parallel.py:1784\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1782\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1783\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1784\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1785\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1786\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\py396_c3\\lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\py396_c3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:732\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    730\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    731\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 732\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    734\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    735\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    736\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\py396_c3\\lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\py396_c3\\lib\\site-packages\\sklearn\\pipeline.py:420\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    419\u001b[0m         fit_params_last_step \u001b[38;5;241m=\u001b[39m fit_params_steps[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[1;32m--> 420\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator\u001b[38;5;241m.\u001b[39mfit(Xt, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params_last_step)\n\u001b[0;32m    422\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\py396_c3\\lib\\site-packages\\xgboost\\core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    619\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 620\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\py396_c3\\lib\\site-packages\\xgboost\\sklearn.py:1025\u001b[0m, in \u001b[0;36mXGBModel.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1014\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1016\u001b[0m (\n\u001b[0;32m   1017\u001b[0m     model,\n\u001b[0;32m   1018\u001b[0m     metric,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1023\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[0;32m   1024\u001b[0m )\n\u001b[1;32m-> 1025\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1026\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1027\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1028\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1029\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1030\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1031\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1032\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1033\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1034\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1035\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1036\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1037\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1039\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_evaluation_result(evals_result)\n\u001b[0;32m   1040\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\py396_c3\\lib\\site-packages\\xgboost\\core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    619\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 620\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\py396_c3\\lib\\site-packages\\xgboost\\training.py:189\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    187\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 189\u001b[0m bst \u001b[38;5;241m=\u001b[39m \u001b[43mcb_container\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mafter_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m evals_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    192\u001b[0m     evals_result\u001b[38;5;241m.\u001b[39mupdate(cb_container\u001b[38;5;241m.\u001b[39mhistory)\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\py396_c3\\lib\\site-packages\\xgboost\\callback.py:167\u001b[0m, in \u001b[0;36mCallbackContainer.after_training\u001b[1;34m(self, model)\u001b[0m\n\u001b[0;32m    164\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, Booster), msg\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_cv:\n\u001b[1;32m--> 167\u001b[0m     num_parallel_tree, _ \u001b[38;5;241m=\u001b[39m \u001b[43m_get_booster_layer_trees\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m model\u001b[38;5;241m.\u001b[39mattr(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_score\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    169\u001b[0m         model\u001b[38;5;241m.\u001b[39mbest_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(cast(\u001b[38;5;28mstr\u001b[39m, model\u001b[38;5;241m.\u001b[39mattr(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_score\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\py396_c3\\lib\\site-packages\\xgboost\\core.py:1475\u001b[0m, in \u001b[0;36m_get_booster_layer_trees\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_booster_layer_trees\u001b[39m(model: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBooster\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m]:\n\u001b[0;32m   1470\u001b[0m     \u001b[38;5;124;03m\"\"\"Get number of trees added to booster per-iteration.  This function will be removed\u001b[39;00m\n\u001b[0;32m   1471\u001b[0m \u001b[38;5;124;03m    once `best_ntree_limit` is dropped in favor of `best_iteration`.  Returns\u001b[39;00m\n\u001b[0;32m   1472\u001b[0m \u001b[38;5;124;03m    `num_parallel_tree` and `num_groups`.\u001b[39;00m\n\u001b[0;32m   1473\u001b[0m \n\u001b[0;32m   1474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1475\u001b[0m     config \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1476\u001b[0m     booster \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlearner\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgradient_booster\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1477\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m booster \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgblinear\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\py396_c3\\lib\\site-packages\\xgboost\\core.py:1732\u001b[0m, in \u001b[0;36mBooster.save_config\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1730\u001b[0m json_string \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mc_char_p()\n\u001b[0;32m   1731\u001b[0m length \u001b[38;5;241m=\u001b[39m c_bst_ulong()\n\u001b[1;32m-> 1732\u001b[0m _check_call(\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterSaveJsonConfig\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1733\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1734\u001b[0m \u001b[43m    \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlength\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1735\u001b[0m \u001b[43m    \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_string\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1736\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m json_string\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1737\u001b[0m result \u001b[38;5;241m=\u001b[39m json_string\u001b[38;5;241m.\u001b[39mvalue\u001b[38;5;241m.\u001b[39mdecode()  \u001b[38;5;66;03m# pylint: disable=no-member\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\py396_c3\\lib\\site-packages\\rpy2\\rinterface.py:107\u001b[0m, in \u001b[0;36m_sigint_handler\u001b[1;34m(sig, frame)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sigint_handler\u001b[39m(sig, frame):\n\u001b[1;32m--> 107\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"Featue selection with ML models for HCMC survey dataset\"\"\"\n",
    "\n",
    "__author__ = \"Anna Buch, Heidelberg University\"\n",
    "__email__ = \"a.buch@stud.uni-heidelberg.de\"\n",
    "\n",
    "\n",
    "# ## Feature selection \n",
    "# Enitre workflow with all models for the target variables relative content loss and business reduction as well for the binary version of relative content loss (chance of loss)\n",
    "# \n",
    "# Due to the small survey dataset size a nested CV is used to assess the predicitve performance of the tested ML-models.\n",
    "# In the inner CV the best hyperaparamters based on k-fold are selected; in the outer cv the generalization error across all tested models is evaluated. \n",
    "# Nested CV is computationally intensive but this limitation can be mitigated by the samll sample size and \n",
    "# a well chosen a predefined range of hyperparameter values.\n",
    "# \n",
    "# Classification for chance of rcloss: \n",
    "# - Probablistic Logistic Regression\n",
    "\n",
    "# Regression for degree of rcloss or rbred:\n",
    "# - Elastic Net (EN)\n",
    "# - eXtreme Gradient Boosting (XGB)\n",
    "# - Conditional Random Forest (CRF)\n",
    "\n",
    "\n",
    "import sys, os\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.metrics import make_scorer, mean_absolute_error\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "UTILS_PATH = os.path.join(os.path.abspath(\"\"), \"../\", \"utils\")\n",
    "sys.path.append(UTILS_PATH)\n",
    "\n",
    "import feature_selection as fs\n",
    "import training as t\n",
    "import evaluation as e\n",
    "import evaluation_utils as eu\n",
    "import figures as f\n",
    "import settings as s\n",
    "import pipelines as p\n",
    "import preprocessing as pp\n",
    "\n",
    "# p.main()  # create/update model settings\n",
    "seed = s.seed\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "import contextlib\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#### Load R packages to process Conditional Random Forest in python\n",
    "# *NOTE 1: all needed R packages have to be previously loaded in R*\n",
    "# *NOTE 2: Make sure that caret package version >= 6.0-81, otherwise caret.train() throws an error*\n",
    "import rpy2.robjects as robjects\n",
    "from rpy2.robjects import pandas2ri\n",
    "from rpy2.robjects.packages import importr\n",
    "\n",
    "\n",
    "# get basic R packages\n",
    "utils = importr(\"utils\")\n",
    "base = importr(\"base\")\n",
    "dplyr = importr(\"dplyr\")\n",
    "stats_r = importr(\"stats\")  # rename due to similar python package\n",
    "\n",
    "# pandas.DataFrames to R dataframes \n",
    "pandas2ri.activate()\n",
    "\n",
    "# print r df in html\n",
    "import rpy2.ipython.html\n",
    "rpy2.ipython.html.init_printing()\n",
    "\n",
    "# get libraries for CRF processing, ctree_controls etc\n",
    "party = importr(\"party\")        # Random Forest with Conditional Inference Trees (Conditional Random Forest)\n",
    "permimp = importr(\"permimp\")  # conditional permutation feature importance\n",
    "caret = importr(\"caret\") # package version needs to be higher than  >=  6.0-90\n",
    "nestedcv = importr(\"nestedcv\")\n",
    "tdr = importr(\"tdr\")\n",
    "\n",
    "\n",
    "\n",
    "targets = [(\"rcloss\", \"degree of rcloss\"), (\"rbred\", \"rbred\")]\n",
    "target, target_plot = targets[0] # <- change here: flood loss variable to process\n",
    "pred_target = f\"pred_{target}\"\n",
    "\n",
    "\n",
    "# Get logger  # test: init application\n",
    "main_logger = \"__feature_extraction_degree__\"\n",
    "logger = s.init_logger(main_logger)\n",
    "\n",
    "## settings for cv\n",
    "kfolds_and_repeats = 5, 5 # 3, 1  # <k-folds, repeats> for nested cv\n",
    "inner_cv = RepeatedKFold(n_splits=kfolds_and_repeats[0], n_repeats=kfolds_and_repeats[1], random_state=seed)\n",
    "outer_cv = RepeatedKFold(n_splits=kfolds_and_repeats[0], n_repeats=1, random_state=seed) # make same as for R nestedcv.train()\n",
    "\n",
    "\n",
    "## save models and their evaluation in following folders:\n",
    "INPATH_DATA = Path(s.INPATH_DATA) # input path\n",
    "OUTPATH_FEATURES, OUTPATH_FINALMODELS, OUTPATH_ESTIMATORS_NCV, OUTPATH_RESULTS = [ # create output paths\n",
    "    pp.create_output_dir(Path(d) / \"degree_of_rcloss\") for d in  \n",
    "    [s.OUTPATH_FEATURES, s.OUTPATH_FINALMODELS, s.OUTPATH_ESTIMATORS_NCV, s.OUTPATH_EVAL]\n",
    "]\n",
    "print(OUTPATH_FEATURES, OUTPATH_FINALMODELS, OUTPATH_ESTIMATORS_NCV, OUTPATH_RESULTS)\n",
    "\n",
    "\n",
    "\n",
    "## preprocessed HCMC survey data for rcloss\n",
    "df_candidates = pd.read_excel(f\"{INPATH_DATA}/input_data_contentloss_tueb.xlsx\")\n",
    "\n",
    "##  use nice feature names\n",
    "df_candidates.rename(columns=s.feature_names_plot, inplace=True)\n",
    "\n",
    "print(df_candidates.columns)\n",
    "# with contextlib.suppress(Exception):\n",
    "#     df_candidates.drop([\"hh_monthly_income_euro\", \"shp_content_value_euro\"], axis=1, inplace=True)\n",
    "\n",
    " \n",
    "logger.info(df_candidates.shape)\n",
    "\n",
    "## Evaluation metrics \n",
    "score_metrics = {\n",
    "    \"MAE\": make_scorer(mean_absolute_error, greater_is_better=False),\n",
    "    \"RMSE\": make_scorer(eu.root_mean_squared_error, greater_is_better=False),\n",
    "    \"MBE\": make_scorer(eu.mean_bias_error, greater_is_better=False),\n",
    "    # \"R2\": \"r2\",\n",
    "    \"SMAPE\": make_scorer(eu.symmetric_mean_absolute_percentage_error, greater_is_better=False)\n",
    "}\n",
    "\n",
    "\n",
    "## Load set of hyperparameters\n",
    "hyperparams_set = pp.load_config(f\"{UTILS_PATH}/hyperparameter_sets.json\")\n",
    "\n",
    "\n",
    "## iterate over piplines. Each pipline contains a scaler and regressor (and optionally a bagging method) \n",
    "pipelines = [\"pipe_en\", \"pipe_crf\", \"pipe_xgb\"]  \n",
    "\n",
    "\n",
    "## empty variables to store model outputs\n",
    "eval_sets = {}\n",
    "models_trained = {}\n",
    "final_models_trained = {}\n",
    "models_coef = {}\n",
    "predicted_values = {}\n",
    "df_feature_importances = pd.DataFrame(index=df_candidates.drop(target, axis=1).columns.to_list())\n",
    "models_scores = {}\n",
    "\n",
    "\n",
    "\n",
    "for pipe_name in pipelines:\n",
    "\n",
    "    TIME0 = datetime.now()\n",
    "\n",
    "    ## load model pipelines\n",
    "    pipe = joblib.load(f\"{UTILS_PATH}/pipelines/{pipe_name}.pkl\")\n",
    " \n",
    "    try:\n",
    "        model_name = re.findall(\"[a-zA-Z]+\", str(pipe.steps[1][1].__class__).split(\".\")[-1])[0] # get model name for python models  \n",
    "    except AttributeError:\n",
    "        model_name = pipe # get R model name\n",
    "    \n",
    "    ## load respective hyperparameter space\n",
    "    param_space = hyperparams_set[f\"{model_name}_hyperparameters\"]\n",
    "\n",
    "    ## if bagging fro model training is used , rename hyperparmeters\n",
    "    if \"bag\" in pipe_name.split(\"_\"):\n",
    "        logger.info(f\"Testing {model_name} with bagging\")\n",
    "        param_space = { k.replace(\"model\", \"bagging__estimator\") : v for (k, v) in param_space.items()}\n",
    "\n",
    "\n",
    "    logger.info( f\"\\n\\n############ Applying {model_name} on {target} ############\\n \")\n",
    "\n",
    "    # save original df for later\n",
    "    df_Xy = df_candidates\n",
    "\n",
    "    # rm geometry column which only needed for visualization\n",
    "    df_Xy = df_Xy.drop(\"geometry\", axis=1)\n",
    "\n",
    "    ## drop content value var due its only needed to recalculate losses after BN\n",
    "    with contextlib.suppress(Exception):\n",
    "        df_Xy.drop([\"shp_content_value_euro\"], axis=1, inplace=True)\n",
    "   \n",
    "  \n",
    "    # get predictor names\n",
    "    X_names = df_Xy.drop(target, axis=1).columns.to_list()\n",
    "\n",
    "    ## remove zero-loss records only for combined dataset\n",
    "    if target == \"Target_relative_contentloss_euro\":\n",
    "        logger.info(f\"Removing {df_Xy.loc[df_Xy[target]==0.0,:].shape[0]} zero loss records\")\n",
    "        df_Xy = df_Xy.loc[df_Xy[target]!=0.0,:]\n",
    "\n",
    "\n",
    "    ## drop samples where target is nan\n",
    "    logger.info(f\"Removing {df_Xy[target].isna().sum()} records from entire dataset due that these values are nan in target variable\")\n",
    "    df_Xy = df_Xy[ ~df_Xy[target].isna()]\n",
    "\n",
    "    ## Elastic Net and Random Forest: drop samples where any value is nan\n",
    "    if (model_name == \"ElasticNet\") | (model_name == \"cforest\"):\n",
    "        print(\"Dropping records with missing values\")\n",
    "        df_Xy.dropna(inplace=True)\n",
    "        #df_Xy = df_Xy.apply(lambda x: x.fillna(x.median()), axis=0)\n",
    "        # print(\"Impute records with missing values for Elastic Net or cforest\",\n",
    "        #        f\"keeping {df_Xy.shape} damage cases for model training and evaluation\")\n",
    "\n",
    "\n",
    "    logger.info(\n",
    "        f\"Finally use {df_Xy.shape[0]} records for feature extraction, from those are {(df_Xy[target][df_Xy[target] == 0.0]).count()} cases with zero-loss or zero-reduction\",\n",
    "    )\n",
    "\n",
    "    X = df_Xy[X_names]\n",
    "    y = df_Xy[target]\n",
    "\n",
    "    logger.info( f\"Use for feature extraction {X.shape[1]} features to predict {target_plot}\")\n",
    "\n",
    "\n",
    "    ## run sklearn model\n",
    "    if model_name != \"cforest\":\n",
    "\n",
    "\n",
    "        ## fit model for unbiased model evaluation and for final model used for Feature importance, Partial Dependence etc.\n",
    "        mf = t.ModelFitting(\n",
    "            model=pipe, \n",
    "            Xy=df_Xy,\n",
    "            target_name=target,\n",
    "            param_space=param_space,\n",
    "            tuning_score=score_metrics[\"MAE\"], # tune by getting reducing MAE\n",
    "            cv=inner_cv,\n",
    "            kfolds_and_repeats=kfolds_and_repeats,\n",
    "            seed=seed,\n",
    "        )\n",
    "        models_trained_ncv = mf.model_fit_ncv()\n",
    "\n",
    "        # save models from nested cv and final model on entire ds\n",
    "        joblib.dump(models_trained_ncv, f\"{OUTPATH_ESTIMATORS_NCV}/{model_name}_{target}.joblib\")\n",
    "\n",
    "        ## evaluate model    \n",
    "        me = e.ModelEvaluation(\n",
    "            models_trained_ncv=models_trained_ncv, \n",
    "            Xy=df_Xy,\n",
    "            target_name=target,\n",
    "            score_metrics=score_metrics,\n",
    "            cv=outer_cv,\n",
    "            kfolds=kfolds_and_repeats[0],\n",
    "            seed=seed,\n",
    "        )\n",
    "        model_evaluation_results = me.model_evaluate_ncv()\n",
    "\n",
    "        ## reverse sklearn.cross_validate() outputted regression scores (e.g. MAE, RMSE, SMAPE, R2)\n",
    "        model_evaluation_results = me.negate_scores_from_sklearn_cross_valdiate(  # TODO impl directly as method in ModelEvalaution()\n",
    "            model_evaluation_results, \n",
    "            metric_names=(\"test_MAE\", \"test_MBE\", \"test_RMSE\", \"test_SMAPE\"))\n",
    "\n",
    "  \n",
    "        ## visual check if hyperparameter ranges are good or need to be adapted\n",
    "        logger.info(f\"Parameter sets of best estimators outer test-sets:\") \n",
    "        for i in range(len(model_evaluation_results[\"estimator\"])):\n",
    "            print(f\"{model_name}: \", model_evaluation_results[\"estimator\"][i].best_params_)\n",
    "        print(\"\\n\")\n",
    "\n",
    "        ## store models evaluation \n",
    "        models_scores[model_name] =  {\n",
    "            k: model_evaluation_results[k] for k in tuple(\"test_\" + s for s in list(score_metrics.keys()))\n",
    "        } # get evaluation scores, metric names start with \"test_<metricname>\"\n",
    "\n",
    "  \n",
    "  \n",
    "        ## Final model\n",
    "\n",
    "        ## get  and save final model based on best MAE score during outer cv\n",
    "        best_idx = list(models_scores[model_name][\"test_MAE\"]).index(min(models_scores[model_name][\"test_MAE\"]))\n",
    "        final_model = model_evaluation_results[\"estimator\"][best_idx]\n",
    "        logger.info(f\"Params of best model: {final_model.best_params_}\") \n",
    "        final_model = final_model.best_estimator_\n",
    "\n",
    "         \n",
    "        ## print performance of best estimator   \n",
    "        logger.info(f\"Performance of best estimator\") \n",
    "        for metric in models_scores[model_name].keys():\n",
    "            print(metric, models_scores[model_name][metric][best_idx])\n",
    "         \n",
    "\n",
    "        final_models_trained[model_name] = final_model \n",
    "        joblib.dump(final_model, f\"{OUTPATH_FINALMODELS}/{model_name}_{target}.joblib\")\n",
    "\n",
    "\n",
    "        ## get predictions of final model from respective outer test set\n",
    "        test_set_best = df_Xy.iloc[model_evaluation_results[\"indices\"][\"test\"][best_idx], :]\n",
    "        finalmodel_X_test = test_set_best.drop(target, axis=1)\n",
    "        finalmodel_y_test = test_set_best[target]\n",
    "        finalmodel_y_pred = final_model.predict(finalmodel_X_test)  # get predictions from final model for its test-set (should be the same as done during model evluation with ncv)\n",
    "\n",
    "\n",
    "        ## Learning curve of train and test set of final model\n",
    "        train_set_best = df_Xy.iloc[model_evaluation_results[\"indices\"][\"train\"][best_idx], :]\n",
    "        f.plot_learning_curves(\n",
    "            final_model, train_set_best, test_set_best, target,\n",
    "            f\"{OUTPATH_RESULTS}/learning_curves{target}_{model_name}.png\", \n",
    "            model_name)\n",
    "        \n",
    "        \n",
    "        ## Feature importance of best model on its test set\n",
    "        importances = me.permutation_feature_importance(\n",
    "            final_model, \n",
    "            finalmodel_X_test, finalmodel_y_test, \n",
    "            repeats=5)\n",
    "\n",
    "\n",
    "        ## regression coefficients for linear models from best estimator\n",
    "        with contextlib.suppress(Exception):\n",
    "\n",
    "            models_coef[model_name] = me.calc_regression_coefficients(final_model, finalmodel_y_test, finalmodel_y_pred)\n",
    "\n",
    "            outfile = f\"{OUTPATH_RESULTS}/regression_coefficients_{model_name}_{target}.xlsx\"\n",
    "            models_coef[model_name].round(3).to_excel(outfile, index=True)\n",
    "            logger.info(f\"Regression Coefficients:\\n {models_coef[model_name].sort_values('probabilities', ascending=False)} \\n .. saved to {outfile}\")\n",
    "            \n",
    "            ## check if any regression coefficient is significant \n",
    "            if np.min(models_coef[model_name][\"probabilities\"]) >= 0.05:\n",
    "                ## non permanent decorator, extending with creation of log file for warnings\n",
    "                logger = s.decorate_init_logger(s.init_logger)(\"__warning_coefs__\") \n",
    "                logger.info(\"non of the regression coefficients is significant\")\n",
    "                logger = s.init_logger(main_logger)  # reset to previous state\n",
    "\n",
    "\n",
    "    ## run R model\n",
    "    else:\n",
    "         ## define model settings\n",
    "        mf = t.ModelFitting(\n",
    "            model=pipe,  # pipe contains only name of applied R algorithm \n",
    "            Xy=df_Xy,\n",
    "            target_name=target,\n",
    "            param_space=param_space,\n",
    "            tuning_score=score_metrics[\"MAE\"],\n",
    "            cv=inner_cv,\n",
    "            kfolds_and_repeats=kfolds_and_repeats,\n",
    "            seed=s.seed\n",
    "        )\n",
    "        # NOTE: normalization is not mandatory for decision-trees but might decrease processing time\n",
    "        models_trained_ncv = mf.r_model_fit_ncv()  # pipe\n",
    "        joblib.dump(models_trained_ncv, f\"{OUTPATH_ESTIMATORS_NCV}/{model_name}_{target}.joblib\")\n",
    "\n",
    "\n",
    "        me = e.ModelEvaluation(\n",
    "            models_trained_ncv=models_trained_ncv, \n",
    "            Xy=df_Xy,\n",
    "            target_name=target,\n",
    "            score_metrics=score_metrics,  # make optional in ModelEvlaution() class\n",
    "            cv=outer_cv,\n",
    "            kfolds=kfolds_and_repeats[0],\n",
    "            seed=s.seed\n",
    "        )\n",
    "        model_evaluation_results = me.r_model_evaluate_ncv()\n",
    "\n",
    "\n",
    "        ## get std of CRF from inner folds\n",
    "        ## TODO shorter name for r_model_evaluation_dict        \n",
    "        r_model_evaluation_dict =  {a : [] for a in [\"test_MAE\", \"test_RMSE\", \"test_MBE\", \"test_SMAPE\"]}\n",
    "        # r_model_evaluation_dict =  {a : [] for a in [\"test_MAE\", \"test_RMSE\", \"test_MBE\", \"test_R2\", \"test_SMAPE\"]}\n",
    "        for idx in range(1, kfolds_and_repeats[0]+1):  # number of estimators , R counts starting from 1\n",
    "            df = me.r_models_cv_predictions(idx)  # get all crf estimators from outer cv\n",
    "            r_model_evaluation_dict[\"test_MAE\"].append(mean_absolute_error(df.testy, df.predy))\n",
    "            r_model_evaluation_dict[\"test_RMSE\"].append(eu.root_mean_squared_error(df.testy,df.predy)) #(df.testy, df.predy)\n",
    "            r_model_evaluation_dict[\"test_MBE\"].append(eu.mean_bias_error(df.testy, df.predy))\n",
    "            # r_model_evaluation_dict[\"test_R2\"].append(eu.r2_score(df.testy, df.predy))\n",
    "            r_model_evaluation_dict[\"test_SMAPE\"].append(eu.symmetric_mean_absolute_percentage_error(df.testy, df.predy))\n",
    "      \n",
    "      \n",
    "        ## Final CRF model\n",
    "        robjects.r(\"\"\"\n",
    "            r_final_model <- function(model, verbose=FALSE) {\n",
    "                model$final_fit$finalModel\n",
    "            }\n",
    "        \"\"\")\n",
    "        r_final_model = robjects.globalenv[\"r_final_model\"] \n",
    "        final_model = r_final_model(models_trained_ncv)\n",
    "        # final_model = mf.r_final_model()  # select final model from models_trained_ncv\n",
    "        best_idx = list(r_model_evaluation_dict[\"test_MAE\"]).index(min(r_model_evaluation_dict[\"test_MAE\"]))\n",
    "\n",
    "        ## performance of final CRF model \n",
    "        logger.info(f\"Performance of best CRF model: \")\n",
    "        for metric in r_model_evaluation_dict.keys():\n",
    "            print(f\"{metric}: {r_model_evaluation_dict[metric][best_idx]}\")\n",
    "        \n",
    "        ## plot cforest learning curve        \n",
    "        f.plot_r_learning_curve(\n",
    "            df_Xy, target, \n",
    "            f\"{OUTPATH_RESULTS}/learning_curves{target}_{model_name}.png\")\n",
    "\n",
    "        ## Feature importance of best model\n",
    "        importances = me.r_permutation_feature_importance(final_model)\n",
    "\n",
    "        ## store model evaluation and final model\n",
    "        models_scores[model_name] = r_model_evaluation_dict ## store performance scores from R estimators        \n",
    "        final_models_trained[model_name] = final_model\n",
    "        joblib.dump(final_model, f\"{OUTPATH_FINALMODELS}/{model_name}_{target}.joblib\")\n",
    "\n",
    "\n",
    "\n",
    "    # ## Collect all models and their evaluation\n",
    "\n",
    "    ## store fitted models and their evaluation results for later \n",
    "    eval_sets[model_name] = df_Xy\n",
    "    models_trained[f\"{model_name}\"] = models_trained_ncv\n",
    "    predicted_values[model_name] = me.residuals  # y_true, y_pred and residual from outer cv\n",
    "\n",
    "    ## store Feature Importances of each model\n",
    "    logger.info(\"\\nSelect features based on permutation feature importance\")\n",
    "    df_importance = pd.DataFrame(\n",
    "        {\n",
    "            f\"{model_name}_importances\" : importances[0],   # averaged importnace scores across repeats\n",
    "            f\"{model_name}_importances_std\" : importances[1]\n",
    "        },\n",
    "        index=X_names,\n",
    "    )\n",
    "    df_feature_importances = df_feature_importances.merge(\n",
    "        df_importance[f\"{model_name}_importances\"],   # only use mean FI, drop std of FI\n",
    "        left_index=True, right_index=True, how=\"outer\")\n",
    "    df_feature_importances = df_feature_importances.sort_values(f\"{model_name}_importances\", ascending=False)  # get most important features to the top\n",
    "    logger.info(f\"5 most important features: {df_feature_importances.iloc[:5].index.to_list()}\")\n",
    "\n",
    "\n",
    "    logger.info(\n",
    "    f\"\\nTraining and evaluation of {model_name} took {(datetime.now() - TIME0).total_seconds() / 60} minutes\\n\"\n",
    "    )\n",
    "            \n",
    "\n",
    "\n",
    "## Plot performance ranges of all evaluated estimators from outer cross-validation \n",
    "logger.info(\"Creating boxplots for range of performane scores from outer folds of nested cross-validation\")\n",
    "f.boxplot_outer_scores_ncv(\n",
    "    models_scores,\n",
    "    outfile=f\"{OUTPATH_FINALMODELS}/boxplot_scores4ncv_{target}.png\",\n",
    "    target_name=target_plot)\n",
    "\n",
    "\n",
    "# store avergaed scores and std for later usage\n",
    "## TODO remove overhead  -> store avergaed scores and std during loop\n",
    "xgb_model_evaluation = pd.DataFrame(models_scores[\"XGBRegressor\"]).mean(axis=0)  # get mean of outer cv metrics (negative MAE and neg RMSE, pos. R2, pos MBE, posSMAPE)\n",
    "xgb_model_evaluation_std = pd.DataFrame(models_scores[\"XGBRegressor\"]).std(axis=0)   # get respective standard deviations\n",
    "crf__model_evaluation = pd.DataFrame(models_scores[\"cforest\"]).mean(axis=0)\n",
    "crf_model_evaluation_std = pd.DataFrame(models_scores[\"cforest\"]).std(axis=0)\n",
    "en_model_evaluation = pd.DataFrame(models_scores[\"ElasticNet\"]).mean(axis=0)\n",
    "en_model_evaluation_std = pd.DataFrame(models_scores[\"ElasticNet\"]).std(axis=0)\n",
    "\n",
    "\n",
    "model_evaluation = pd.concat([en_model_evaluation, en_model_evaluation_std, crf__model_evaluation, crf_model_evaluation_std, xgb_model_evaluation, xgb_model_evaluation_std], axis=1)\n",
    "model_evaluation.columns = [\"ElasticNet_score\", \"ElasticNet_score_std\", \"cforest_score\", \"cforest_score_std\", \"XGBRegressor_score\", \"XGBRegressor_score_std\"]\n",
    "\n",
    "\n",
    "## rename metrics\n",
    "model_evaluation.index = model_evaluation.index.str.replace(\"test_\", \"\")\n",
    "\n",
    "outfile = f\"{OUTPATH_RESULTS}/performance_{target}.xlsx\"\n",
    "model_evaluation.round(3).to_excel(outfile, index=True)\n",
    "logger.info(f\"Outer evaluation scores of nested cross-validation (mean) :\\n {model_evaluation.round(3)} \\n.. saved to {outfile}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Feature Importances \n",
    "\n",
    "#### prepare Feature Importances \n",
    "## Have the same feature importance method across all applied ML models\n",
    "## Weight Importances by model performance on outer loop (mean MAE)\n",
    "## **Overall FI ranking (procedure similar to Rözer et al 2019; Brill 2022)**\n",
    "\n",
    "## weight FI scores based on performance ; weigth importances from better performed models stronger\n",
    "model_weights =  {\n",
    "    \"XGBRegressor_importances\" : np.mean(models_scores[\"XGBRegressor\"][\"test_MAE\"]),\n",
    "    \"ElasticNet_importances\" : np.mean(models_scores[\"ElasticNet\"][\"test_MAE\"]),\n",
    "    \"cforest_importances\" : np.mean(models_scores[\"cforest\"][\"test_MAE\"]),\n",
    "}\n",
    "df_feature_importances_w = fs.calc_weighted_sum_feature_importances(df_feature_importances, model_weights)\n",
    "\n",
    "\n",
    "####  Plot Feature importances\n",
    "\n",
    "## the best model has the highest weighted feature importance value\n",
    "df_feature_importances_plot = df_feature_importances_w\n",
    "\n",
    "## drop features which dont reduce the loss\n",
    "df_feature_importances_plot = df_feature_importances_plot.loc[df_feature_importances_plot.weighted_sum_importances > 0.0, : ] \n",
    "\n",
    "## plot stacked FI\n",
    "f.plot_stacked_feature_importances(\n",
    "    df_feature_importances_plot[[\"ElasticNet_importances_weighted\", \"cforest_importances_weighted\", \"XGBRegressor_importances_weighted\",]],\n",
    "    target_name=target_plot,\n",
    "    model_names_plot = (\"Elastic Net\", \"Conditional Random Forest\", \"XGBRegressor\"),\n",
    "    outfile=f\"{OUTPATH_RESULTS}/feature_importances_{target}.png\"\n",
    ")\n",
    "\n",
    "\n",
    "## Save final feature space \n",
    "### The final selection of features is used later for the non-parametric Bayesian Network\n",
    "\n",
    "## drop records with missing target values\n",
    "logger.info(f\"Dropping {df_candidates[f'{target}'].isna().sum()} records from entire dataset due that these values are nan in target variable\")\n",
    "df_candidates = df_candidates[ ~df_candidates[target].isna()]\n",
    "logger.info(f\"Keeping {df_candidates.shape[0]} records and {df_candidates.shape[1]} features\")\n",
    "\n",
    "\n",
    "## sort features by their overall importance (weighted sum across across all features) \n",
    "final_feature_names = df_feature_importances_w[\"weighted_sum_importances\"].sort_values(ascending=False).index##[:10]\n",
    "\n",
    "## save important features, first column contains target variable\n",
    "fs.save_selected_features(\n",
    "    df_candidates.drop(target, axis=1), # TODO adpat function that target is only once added\n",
    "    pd.DataFrame(df_candidates, columns=[target]), \n",
    "    final_feature_names,\n",
    "    filename=f\"{OUTPATH_FEATURES}/final_predictors_{target}.xlsx\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "## Partial dependence\n",
    "\n",
    "## PDP shows the marginal effect that one or two features have on the predicted outcome.\n",
    "\n",
    "## store partial dependences for each model\n",
    "pdp_features = {a : {} for a in [\"ElasticNet\", \"XGBRegressor\", \"cforest\"]}\n",
    "\n",
    "\n",
    "for model_name in [\"ElasticNet\", \"cforest\", \"XGBRegressor\"]:\n",
    "\n",
    "    Xy_pdp = eval_sets[model_name].dropna() #  solve bug on sklearn.partial_dependece() which can not deal with NAN values\n",
    "    X_pdp, y_pdp = Xy_pdp[Xy_pdp.columns.drop(target)], Xy_pdp[target]\n",
    "\n",
    "    ## NOTE scaling mandatory for cforest model (which dont accepts the rescaled values for R PDPs function)\n",
    "    ## all PDs are based on only complete records - therefore XGB, EN needs \"scale\":True , and CRF is scaled directly \n",
    "    if model_name == \"cforest\": \n",
    "        scaler = MinMaxScaler()\n",
    "        X_pdp = pd.DataFrame(\n",
    "                scaler.fit_transform(X_pdp), # for same x-axis scaled pd plots across models\n",
    "                columns=X.columns\n",
    "                )\n",
    "    Xy_pdp = pd.concat([y_pdp, X_pdp], axis=1)\n",
    "\n",
    "    for predictor_name in X.columns.to_list(): \n",
    "        features_info =  {\n",
    "            \"model\" : final_models_trained[model_name], \n",
    "            \"Xy\" : Xy_pdp, \n",
    "            \"y_name\" : target, \n",
    "            \"feature_name\" : predictor_name, \n",
    "            # \"percentiles\" : (0.05, .95), # causes NAN for some variables for XGB if (0, 1)\n",
    "            \"scale\"  : True\n",
    "        }  \n",
    "        # get Partial dependences for sklearn models      \n",
    "        if model_name != \"cforest\": \n",
    "            partial_dep = me.get_partial_dependence(**features_info)\n",
    "        # get Partial dependences for R models      \n",
    "        else:  \n",
    "            #  change function only temporary to process R model instead of sklearn models\n",
    "            # features_info.pop(\"percentiles\")\n",
    "            partial_dep = me.decorator_func(**features_info) (me.get_partial_dependence)()  \n",
    "            # R partial func scales predictor values differenctly (maybe R standarized them?), therefore rescale them back to range between 0 and 1\n",
    "            scaler = MinMaxScaler()\n",
    "            partial_dep[predictor_name] = scaler.fit_transform(partial_dep[[predictor_name]])\n",
    "          \n",
    "        pdp_features[model_name][predictor_name] = partial_dep\n",
    "\n",
    "\n",
    "\n",
    "## Plot PDP\n",
    "\n",
    "most_important_features = df_feature_importances_plot.sort_values(\"weighted_sum_importances\", ascending=False).index\n",
    "categorical = [] # [\"flowvelocity\", \"further_variables ..\"]\n",
    "ncols = 3\n",
    "nrows = len(most_important_features[:9])\n",
    "idx = 0\n",
    "\n",
    "plt.figure(figsize=(10, 25))\n",
    "plt.suptitle(f\"Partial Dependences for {target_plot}\", fontsize=16, fontweight=\"bold\", y=.99)\n",
    "# plt.subplots_adjust(top=0.97)\n",
    "\n",
    "## legend\n",
    "top_bar = mpatches.Patch(color=\"steelblue\", label=\"Elastic Net\", alpha=.7)  #TODO update with s.color_palette_models from settings\n",
    "middle_bar = mpatches.Patch(color=\"darkblue\", label=\"Conditional Random Forest\", alpha=.7)\n",
    "bottom_bar = mpatches.Patch(color=\"grey\", label=\"XGBRegressor\", alpha=.7)\n",
    "plt.tick_params(axis='x', which='major', labelsize=12)\n",
    "plt.tick_params(axis='y', which='major', labelsize=12)\n",
    "plt.legend(handles=[top_bar, middle_bar, bottom_bar], loc=\"lower right\")\n",
    "plt.tight_layout()\n",
    "\n",
    "## create PDP for all three models\n",
    "for feature in most_important_features[:9]:\n",
    "    for model_name, color, idx_col in zip([\"ElasticNet\", \"cforest\", \"XGBRegressor\"], [\"steelblue\", \"darkblue\", \"grey\"], [0, 0, 0]):\n",
    "\n",
    "        # idx position of subplot and plot settings\n",
    "        sns.set_style(\"whitegrid\", {\"grid.linestyle\": \":\"})\n",
    "        ax = plt.subplot(nrows, ncols, idx + 1 + idx_col)\n",
    "        feature_info = {\"color\" : color, \"ax\" : ax} \n",
    "\n",
    "        ## partial dependence of one feature for one model to plot\n",
    "        df_pd_feature = pdp_features[model_name][feature]  \n",
    "        \n",
    "        # plot\n",
    "        p = f.plot_partial_dependence(\n",
    "            df_pd_feature, \n",
    "            feature_name=feature, \n",
    "            partial_dependence_name=\"yhat\", \n",
    "            categorical=[],\n",
    "            outfile=f\"{OUTPATH_RESULTS}/pdp_{target}.png\",\n",
    "            **feature_info\n",
    "            )\n",
    "        p\n",
    "        plt.ylim(0,30)\n",
    "        # plt.title(feature)\n",
    "        visible_ticks = {\"top\": False, \"right\": False}\n",
    "        plt.tick_params(axis=\"x\", which=\"both\", **visible_ticks)\n",
    "        \n",
    "    sns.rugplot(df_pd_feature, x=feature, height=.02, color=\"black\")\n",
    "    idx = idx + 1\n",
    "\n",
    "\n",
    "\n",
    "### Empirical ~ predicted\n",
    "## use y_pred cross-valdiated from outer folds, mulitplied by 100 for more readable output\n",
    "for k,v in predicted_values.items():\n",
    "    print(f\"\\n{k} predicted target from cross-valdiated outer folds:\")\n",
    "    print(eu.empirical_vs_predicted(predicted_values[k][\"y_true\"], predicted_values[k][\"y_pred\"]))\n",
    "\n",
    "\n",
    "# ### Plot prediction error from outer cv\n",
    "f.plot_residuals(\n",
    "    df_residuals=predicted_values, \n",
    "    model_names_abbreviation=[\"ElasticNet\", \"cforest\", \"XGBRegressor\"],  \n",
    "    model_names_plot=[\"Elastic Net\", \"Conditional Random Forest\", \"XGBoost\"],\n",
    "    outfile=f\"{OUTPATH_RESULTS}/residuals_{target}.png\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rcloss'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py396_c3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
