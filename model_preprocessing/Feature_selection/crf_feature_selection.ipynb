{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"Data preprocessing for HCMC survey dataset\"\"\"\n",
    "\n",
    "__author__ = \"Anna Buch, Heidelberg University\"\n",
    "__email__ = \"a.buch@stud.uni-heidelberg.de\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection done by Conditional Inference Trees and its Random Forest adaption\n",
    "\n",
    "CIT uses p-value as one-a-split criterion instead of using homogeneity. The algorithm will pick the feature with the least p-value and will start splitting from it. Then it will keep going until it no longer finds statistically significant p-value or some other criteria have met such as minimum node size or max split. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda\\envs\\py396_c3\\lib\\site-packages\\rpy2\\robjects\\packages.py:367: UserWarning: The symbol 'quartz' is not in this R namespace/package.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, confusion_matrix, mean_absolute_error\n",
    "from sklearn.preprocessing import QuantileTransformer, quantile_transform, PowerTransformer, power_transform\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, train_test_split, StratifiedKFold, RepeatedStratifiedKFold, RepeatedKFold, cross_val_score, cross_validate\n",
    "from sklearn.metrics import r2_score, mean_squared_error, median_absolute_error\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.metrics import PredictionErrorDisplay \n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.preprocessing import quantile_transform\n",
    "from scipy import stats \n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.insert(0, \"../../../\")\n",
    "import utils.utils_feature_selection as fs\n",
    "import utils.settings as s\n",
    "import utils.utils_evaluation as e\n",
    "\n",
    "s.init()\n",
    "seed = s.seed\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "transformation = True ##False\n",
    "targets = [\"Target_contentloss_euro\", \"Target_relative_contentloss_euro\", \"Target_businessreduction\"]\n",
    "target = targets[0]\n",
    "# ruff check ./model_preprocessing/Feature_selection/utils_feature_selection.py --fix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load R packages to process Conditional Random Forest in python\n",
    "*Note 1: all needed R packages have to be previously loaded in R*\n",
    "\n",
    "*Note 2: Make sure that caret package version >= 6.0-81, otherwise caret.train() throws an error*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rpy2\n",
    "import rpy2.robjects as robjects\n",
    "from rpy2.robjects.packages import importr, data\n",
    "import rpy2.robjects.packages as rpackages\n",
    "\n",
    "\n",
    "# get basic R packages\n",
    "utils = importr('utils')\n",
    "base = importr('base')\n",
    "dplyr = importr('dplyr')\n",
    "stats_r = importr(\"stats\")  # rename due to similar python package\n",
    "# pandas.DataFrames to R dataframes \n",
    "from rpy2.robjects import pandas2ri, Formula\n",
    "pandas2ri.activate()\n",
    "\n",
    "# print r df in html\n",
    "import rpy2.ipython.html\n",
    "rpy2.ipython.html.init_printing()\n",
    "\n",
    "\n",
    "# get libraries for CRF processing, ctree_controls etc\n",
    "partykit = importr('partykit')\n",
    "party = importr('party')\n",
    "caret = importr('caret') # package version >=\n",
    "nestedcv = importr(\"nestedcv\")\n",
    "#stablelearner = importr('stablelearner')\n",
    "ggplot2 = importr('ggplot2')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       382.000000\n",
       "mean        915.749476\n",
       "std       11673.198952\n",
       "min           0.000000\n",
       "25%           0.000000\n",
       "50%           0.000000\n",
       "75%          78.600000\n",
       "max      224190.400000\n",
       "Name: Target_contentloss_euro, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_candidates = pd.read_excel(\"../../../input_survey_data/input_data_contentloss_tueb.xlsx\")\n",
    "#df_candidates = pd.read_excel(\"../../../input_survey_data/input_data_businessreduction_tueb.xlsx\")\n",
    "\n",
    "\n",
    "#df_candidates = pd.read_excel(\"../../../input_survey_data/input_data_contentloss.xlsx\")\n",
    "#df_candidates = pd.read_excel(\"../../../input_survey_data/input_data_businessreduction_tueb.xlsx\")\n",
    "\n",
    "# ### use only relative loss as target or only absolute loss as target\n",
    "#df_candidates = df_candidates.drop([\"Target_contentloss_euro\", \"shp_content_value_euro\"], axis=1)\n",
    "df_candidates = df_candidates.drop([\"Target_relative_contentloss_euro\"], axis=1)\n",
    "\n",
    "df_candidates[target].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(397, 33)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## TODO make this shorter\n",
    "\n",
    "try:\n",
    "    #if target==\"Target_relative_contentloss_euro\": \n",
    "    df_candidates = df_candidates.drop(\"floors\", axis=1 )  # remove if still in ds due that it's used for shp_content_value and relative content loss\n",
    "    df_candidates = df_candidates.drop(\"resilience_govern_careing_increases\", axis=1)\n",
    "    df_candidates = df_candidates.drop(\"buildingtype_moon\", axis=1)  # remove due to 64 % missing values   \n",
    "except:\n",
    "    pass\n",
    "\n",
    "df_candidates.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of missing values per feature [%]\n",
      " elevation_building_height_cm           15.869018\n",
      "shp_content_value_euro                 15.617128\n",
      "resilience_govern_careing_increases    13.602015\n",
      "shp_registered_capital_euro            11.838791\n",
      "bage                                    6.801008\n",
      "hh_monthly_income_cat                   6.045340\n",
      "Target_contentloss_euro                 3.778338\n",
      "inundation_duration_h                   2.267003\n",
      "b_area                                  0.503778\n",
      "water_depth_cm                          0.251889\n",
      "emergency_measures.3                    0.000000\n",
      "emergency_measures.1                    0.000000\n",
      "contaminations_heavy                    0.000000\n",
      "contaminations_light                    0.000000\n",
      "contaminations.0                        0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Percentage of missing values per feature [%]\\n\", df_candidates.isna().mean().sort_values(ascending=False)[:15]  * 100) \n",
    "#df_candidates = df_candidates[df_candidates.columns[df_candidates.isna().mean() < 0.10]]  # drop feautres with more than 10% missing values\n",
    "#print(df_candidates.isna().sum(axis=0).sort_values(ascending=False))\n",
    "## --> drops content values if threshold == 15%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model performance without zero-loss records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing 226 zero loss records\n",
      "Keeping (171, 33) damage cases for model training and evaluation\n"
     ]
    }
   ],
   "source": [
    "print(f\"Removing {df_candidates.loc[df_candidates[target]==0.0,:].shape[0]} zero loss records\")\n",
    "df_candidates = df_candidates.loc[df_candidates[target]!=0.0,:]\n",
    "\n",
    "print(f\"Keeping {df_candidates.shape} damage cases for model training and evaluation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test remove further features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(171, 31)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_candidates = df_candidates.drop([\n",
    "        \"contaminations_light\", \"contaminations_heavy\", \n",
    "     ], axis=1\n",
    ")\n",
    "df_candidates.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## remove records where target information is missing\n",
    "#df_candidates = df_candidates[ ~df_candidates[f\"{target}\"].isna()]\n",
    "#print(df_candidates.shape)\n",
    "\n",
    "## Handle nan values in X and target\n",
    "df_candidates = df_candidates.dropna()\n",
    "\n",
    "X = df_candidates.drop(target, axis=1)\n",
    "y = df_candidates[target]\n",
    "\n",
    "\n",
    "# # TEST: replace nan with median of each variable\n",
    "# for c in X.columns:\n",
    "#    X[c].fillna(X[c].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Fitting final model using CV on whole data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Performing 2-fold outer CV, using 1 core\n",
      "\n",
      "R[write to console]: Duration: 26.14808 secs\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$call\n",
      "(function (y, x, method = \"rf\", filterFUN = NULL, filter_options = NULL, \n",
      "    weights = NULL, balance = NULL, balance_options = NULL, outer_method = c(\"cv\", \n",
      "        \"LOOCV\"), n_outer_folds = 10, n_inner_folds = 10, outer_folds = NULL, \n",
      "    inner_folds = NULL, pass_outer_folds = FALSE, cv.cores = 1, \n",
      "    multicore_fork = (Sys.info()[\"sysname\"] != \"Windows\"), metric = ifelse(is.factor(y), \n",
      "        \"logLoss\", \"RMSE\"), trControl = NULL, tuneGrid = NULL, \n",
      "    savePredictions = \"final\", outer_train_predict = FALSE, finalCV = TRUE, \n",
      "    na.option = \"pass\", verbose = TRUE, ...) \n",
      "{\n",
      "    start <- Sys.time()\n",
      "    nestcv.call <- match.call(expand.dots = TRUE)\n",
      "    outer_method <- match.arg(outer_method)\n",
      "    if (is.character(y)) \n",
      "        y <- factor(y)\n",
      "    if (!is.null(balance) & is.numeric(y)) {\n",
      "        stop(\"`balance` can only be used for classification\")\n",
      "    }\n",
      "    ok <- checkxy(y, x, na.option, weights)\n",
      "    y <- y[ok$r]\n",
      "    x <- x[ok$r, ok$c]\n",
      "    weights <- weights[ok$r]\n",
      "    if (!is.null(balance) & !is.null(weights)) {\n",
      "        stop(\"`balance` and `weights` cannot be used at the same time\")\n",
      "    }\n",
      "    if (is.null(outer_folds)) {\n",
      "        outer_folds <- switch(outer_method, cv = createFolds(y, \n",
      "            k = n_outer_folds), LOOCV = 1:length(y))\n",
      "    }\n",
      "    else {\n",
      "        if (\"n_outer_folds\" %in% names(nestcv.call)) {\n",
      "            if (n_outer_folds != length(outer_folds)) \n",
      "                stop(\"Mismatch between n_outer_folds and length(outer_folds)\")\n",
      "        }\n",
      "        n_outer_folds <- length(outer_folds)\n",
      "    }\n",
      "    if (!is.null(inner_folds)) {\n",
      "        if (length(inner_folds) != length(outer_folds)) \n",
      "            stop(\"Mismatch in length(outer_folds) and length(inner_folds)\")\n",
      "        if (\"n_inner_folds\" %in% names(nestcv.call)) {\n",
      "            if (n_inner_folds != length(inner_folds)) \n",
      "                stop(\"Mismatch between n_inner_folds and length(inner_folds)\")\n",
      "        }\n",
      "        n_inner_folds <- length(inner_folds[[1]])\n",
      "        outer_train_size <- sapply(swapFoldIndex(outer_folds), \n",
      "            length)\n",
      "        chk <- vapply(seq_along(outer_train_size), function(i) {\n",
      "            max(unlist(inner_folds[[i]])) > outer_train_size[i]\n",
      "        }, logical(1))\n",
      "        if (any(chk)) \n",
      "            stop(\"inner_folds contains index out of range\")\n",
      "        if (!is.null(balance)) \n",
      "            stop(\"`balance` cannot be used if `inner_folds` is specified\")\n",
      "        inner_train_folds <- lapply(inner_folds, swapFoldIndex)\n",
      "    }\n",
      "    else inner_train_folds <- NULL\n",
      "    if (is.null(trControl)) {\n",
      "        trControl <- if (is.factor(y)) {\n",
      "            trainControl(method = \"cv\", number = n_inner_folds, \n",
      "                classProbs = TRUE, savePredictions = savePredictions, \n",
      "                summaryFunction = mnLogLoss)\n",
      "        }\n",
      "        else trainControl(method = \"cv\", number = n_inner_folds, \n",
      "            savePredictions = savePredictions)\n",
      "    }\n",
      "    if (!is.null(tuneGrid)) {\n",
      "        if (nrow(tuneGrid) == 1) {\n",
      "            trControl <- trainControl(method = \"none\", classProbs = TRUE)\n",
      "            inner_train_folds <- NULL\n",
      "        }\n",
      "    }\n",
      "    if (is.na(finalCV)) {\n",
      "        final_fit <- finalTune <- filtx <- yfinal <- xsub <- NA\n",
      "    }\n",
      "    else {\n",
      "        if (verbose) \n",
      "            message(\"Fitting final model using CV on whole data\")\n",
      "        dat <- nest_filt_bal(NULL, y, x, filterFUN, filter_options, \n",
      "            balance, balance_options)\n",
      "        yfinal <- dat$ytrain\n",
      "        filtx <- dat$filt_xtrain\n",
      "        if (finalCV) {\n",
      "            trControlFinal <- trControl\n",
      "            if (pass_outer_folds) {\n",
      "                if (n_outer_folds == trControl$number && trControl$method == \n",
      "                  \"cv\" && is.null(balance)) {\n",
      "                  train_folds <- swapFoldIndex(outer_folds, length(y))\n",
      "                  trControlFinal$index <- train_folds\n",
      "                  trControlFinal$indexOut <- outer_folds\n",
      "                }\n",
      "                else message(\"Cannot pass `outer_folds` to final CV\")\n",
      "            }\n",
      "            if (cv.cores >= 2) {\n",
      "                if (Sys.info()[\"sysname\"] == \"Windows\") {\n",
      "                  cl <- makeCluster(cv.cores)\n",
      "                  registerDoParallel(cl)\n",
      "                }\n",
      "                else {\n",
      "                  registerDoParallel(cores = cv.cores)\n",
      "                }\n",
      "            }\n",
      "            printlog <- capture.output({\n",
      "                final_fit <- caret::train(x = filtx, y = yfinal, \n",
      "                  method = method, weights = weights, metric = metric, \n",
      "                  trControl = trControlFinal, tuneGrid = tuneGrid, \n",
      "                  ...)\n",
      "            })\n",
      "            finalTune <- final_fit$bestTune\n",
      "            if (cv.cores >= 2) {\n",
      "                if (Sys.info()[\"sysname\"] == \"Windows\") \n",
      "                  stopCluster(cl)\n",
      "                foreach::registerDoSEQ()\n",
      "            }\n",
      "        }\n",
      "    }\n",
      "    if (verbose && (!multicore_fork || Sys.getenv(\"RSTUDIO\") == \n",
      "        \"1\")) {\n",
      "        message(\"Performing \", n_outer_folds, \"-fold outer CV, using \", \n",
      "            plural(cv.cores, \"core(s)\"))\n",
      "    }\n",
      "    if (!multicore_fork && cv.cores >= 2) {\n",
      "        cl <- makeCluster(cv.cores)\n",
      "        dots <- list(...)\n",
      "        varlist <- c(\"outer_folds\", \"inner_train_folds\", \"y\", \n",
      "            \"x\", \"method\", \"filterFUN\", \"filter_options\", \"weights\", \n",
      "            \"balance\", \"balance_options\", \"metric\", \"trControl\", \n",
      "            \"tuneGrid\", \"outer_train_predict\", \"nestcv.trainCore\", \n",
      "            \"dots\")\n",
      "        clusterExport(cl, varlist = varlist, envir = environment())\n",
      "        if (verbose) {\n",
      "            if (!requireNamespace(\"pbapply\", quietly = TRUE)) {\n",
      "                stop(\"Package 'pbapply' must be installed\", call. = FALSE)\n",
      "            }\n",
      "            outer_res <- pbapply::pblapply(seq_along(outer_folds), \n",
      "                function(i) {\n",
      "                  args <- c(list(i = i, y = y, x = x, outer_folds = outer_folds, \n",
      "                    inner_train_folds = inner_train_folds, method = method, \n",
      "                    filterFUN = filterFUN, filter_options = filter_options, \n",
      "                    weights = weights, balance = balance, balance_options = balance_options, \n",
      "                    metric = metric, trControl = trControl, tuneGrid = tuneGrid, \n",
      "                    outer_train_predict = outer_train_predict), \n",
      "                    dots)\n",
      "                  do.call(nestcv.trainCore, args)\n",
      "                }, cl = cl)\n",
      "        }\n",
      "        else {\n",
      "            outer_res <- parLapply(cl = cl, seq_along(outer_folds), \n",
      "                function(i) {\n",
      "                  args <- c(list(i = i, y = y, x = x, outer_folds = outer_folds, \n",
      "                    inner_train_folds = inner_train_folds, method = method, \n",
      "                    filterFUN = filterFUN, filter_options = filter_options, \n",
      "                    weights = weights, balance = balance, balance_options = balance_options, \n",
      "                    metric = metric, trControl = trControl, tuneGrid = tuneGrid, \n",
      "                    outer_train_predict = outer_train_predict), \n",
      "                    dots)\n",
      "                  do.call(nestcv.trainCore, args)\n",
      "                })\n",
      "        }\n",
      "        stopCluster(cl)\n",
      "    }\n",
      "    else {\n",
      "        outer_res <- mclapply(seq_along(outer_folds), function(i) {\n",
      "            nestcv.trainCore(i, y, x, outer_folds, inner_train_folds, \n",
      "                method, filterFUN, filter_options, weights, balance, \n",
      "                balance_options, metric, trControl, tuneGrid, \n",
      "                outer_train_predict, verbose, ...)\n",
      "        }, mc.cores = cv.cores, mc.allow.recursive = FALSE)\n",
      "    }\n",
      "    predslist <- lapply(outer_res, \"[[\", \"preds\")\n",
      "    output <- data.table::rbindlist(predslist)\n",
      "    output <- as.data.frame(output)\n",
      "    if (!is.null(rownames(x))) {\n",
      "        rownames(output) <- unlist(lapply(predslist, rownames))\n",
      "    }\n",
      "    summary <- predSummary(output)\n",
      "    caret.roc <- NULL\n",
      "    if (is.factor(y) & nlevels(y) == 2) {\n",
      "        caret.roc <- pROC::roc(output$testy, output$predyp, direction = \"<\", \n",
      "            quiet = TRUE)\n",
      "    }\n",
      "    bestTunes <- lapply(outer_res, function(i) i$fit$bestTune)\n",
      "    bestTunes <- as.data.frame(data.table::rbindlist(bestTunes))\n",
      "    rownames(bestTunes) <- paste(\"Fold\", seq_len(nrow(bestTunes)))\n",
      "    if (!is.na(finalCV) && !finalCV) {\n",
      "        if (verbose) \n",
      "            message(\"Fitting single final model\")\n",
      "        finalTune <- finaliseTune(bestTunes)\n",
      "        fitControl <- trainControl(method = \"none\", classProbs = is.factor(y))\n",
      "        final_fit <- caret::train(x = filtx, y = yfinal, method = method, \n",
      "            weights = weights, trControl = fitControl, tuneGrid = finalTune, \n",
      "            ...)\n",
      "    }\n",
      "    if (!is.na(finalCV)) {\n",
      "        all_vars <- unlist(lapply(outer_res, function(i) {\n",
      "            colnames(i$fit$trainingData)\n",
      "        }))\n",
      "        all_vars <- unique(c(all_vars, colnames(filtx)))\n",
      "        all_vars <- all_vars[all_vars %in% colnames(x)]\n",
      "        xsub <- x[, all_vars]\n",
      "    }\n",
      "    end <- Sys.time()\n",
      "    if (verbose) \n",
      "        message(\"Duration: \", format(end - start))\n",
      "    out <- list(call = nestcv.call, output = output, outer_result = outer_res, \n",
      "        outer_method = outer_method, outer_folds = outer_folds, \n",
      "        dimx = dim(x), xsub = xsub, y = y, yfinal = yfinal, final_fit = final_fit, \n",
      "        final_vars = colnames(filtx), roc = caret.roc, trControl = trControl, \n",
      "        bestTunes = bestTunes, finalTune = finalTune, summary = summary)\n",
      "    class(out) <- \"nestcv.train\"\n",
      "    out\n",
      "})(y = c(`7` = 29.5, `10` = 18.4, `11` = 18.4, `20` = 1473, `22` = 268.1, \n",
      "`24` = 7.4, `28` = 76.5, `29` = 168.6, `47` = 1494.6, `53` = 55.2, \n",
      "`62` = 18.7, `64` = 55.2, `68` = 73.7, `79` = 36.8, `87` = 267.9, \n",
      "`96` = 1288.5, `103` = 119, `105` = 79.3, `110` = 1189.8, `113` = 224.2, \n",
      "`114` = 36.8, `117` = 19.8, `118` = 119, `129` = 153.1, `132` = 26.2, \n",
      "`136` = 37.4, `141` = 74.7, `143` = 44.8, `150` = 2615.6, `151` = 224190.4, \n",
      "`152` = 37.4, `162` = 373.7, `163` = 73.7, `164` = 84.3, `165` = 421.4, \n",
      "`173` = 1473, `175` = 11, `177` = 34120, `183` = 793.2, `184` = 368.3, \n",
      "`185` = 44.7, `186` = 186.8, `193` = 1868.3, `194` = 1121, `195` = 405.1, \n",
      "`202` = 112.1, `203` = 37.4, `204` = 76.5, `207` = 76.5, `209` = 124.2, \n",
      "`210` = 82.8, `232` = 149.5, `237` = 149.5, `241` = 37.4, `244` = 110.5, \n",
      "`250` = 74.7, `257` = 38.3, `264` = 268.1, `266` = 39.7, `274` = 38.3, \n",
      "`275` = 39.7, `280` = 3624.4, `283` = 82.8, `290` = 38.3, `291` = 56, \n",
      "`295` = 382.7, `296` = 74.7, `302` = 178.5, `303` = 224.2, `305` = 37.4, \n",
      "`318` = 373.7, `323` = 1189.8, `327` = 632.1, `330` = 214.8, \n",
      "`339` = 4552.9, `340` = 165.6, `341` = 650.6, `345` = 74.7, `347` = 24851.1, \n",
      "`355` = 126.4, `361` = 1473, `363` = 36.8, `364` = 268.1, `365` = 448.4, \n",
      "`366` = 82.8, `372` = 1121, `373` = 368.3, `376` = 76.5, `377` = 214.8, \n",
      "`386` = 248.3), x = list(inundation_duration_h = c(12, 2, 0.5, \n",
      "7, 2, 9, 3, 3, 4, 1, 5, 3, 10, 3, 600, 3, 2, 2, 48, 9, 2, 2, \n",
      "5, 1, 3, 2, 10, 3, 72, 70, 70, 3, 2, 2, 5, 4, 1, 3, 2, 3, 4, \n",
      "2, 4, 4, 2, 0.5, 3, 2, 2, 3, 3, 3, 2, 0.5, 2, 3, 10, 2, 2, 8, \n",
      "3, 4, 4, 9, 12, 15, 2, 1, 3, 33, 5, 48, 12, 10, 5, 7, 5, 10, \n",
      "5, 2, 4, 6, 2, 3, 2, 4, 3, 3, 3, 3), water_depth_cm = c(20, 3, \n",
      "10, 21, 30, 20, 30, 40, 80, 5, 20, 10, 20, 40, 30, 100, 20, 50, \n",
      "120, 50, 10, 10, 5, 10, 20, 20, 40, 7, 45, 100, 75, 5, 20, 30, \n",
      "80, 20, 10, 70, 20, 10, 20, 2, 60, 50, 40, 20, 10, 20, 30, 80, \n",
      "10, 20, 30, 10, 30, 5, 50, 30, 40, 100, 20, 90, 5, 50, 20, 50, \n",
      "20, 50, 70, 50, 40, 120, 50, 20, 15, 40, 40, 40, 20, 40, 20, \n",
      "50, 20, 15, 10, 50, 60, 30, 30, 40), contaminations.0 = c(0L, \n",
      "1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n",
      "0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n",
      "0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, \n",
      "0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n",
      "0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n",
      "0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L), flowvelocity = c(2L, 4L, \n",
      "2L, 5L, 2L, 4L, 2L, 2L, 5L, 1L, 4L, 4L, 5L, 5L, 4L, 4L, 2L, 4L, \n",
      "5L, 4L, 4L, 3L, 3L, 2L, 2L, 3L, 5L, 3L, 5L, 5L, 5L, 2L, 1L, 2L, \n",
      "4L, 4L, 4L, 3L, 2L, 3L, 2L, 3L, 4L, 3L, 3L, 3L, 1L, 2L, 3L, 4L, \n",
      "1L, 4L, 3L, 1L, 2L, 2L, 4L, 4L, 5L, 5L, 3L, 5L, 4L, 4L, 5L, 5L, \n",
      "4L, 5L, 2L, 5L, 4L, 5L, 5L, 4L, 2L, 3L, 3L, 5L, 5L, 3L, 4L, 5L, \n",
      "5L, 4L, 2L, 3L, 4L, 1L, 3L, 5L), emergency_measures.1 = c(1L, \n",
      "0L, 0L, 1L, 1L, 0L, 0L, 1L, 1L, 0L, 0L, 0L, 1L, 1L, 0L, 1L, 1L, \n",
      "0L, 0L, 1L, 1L, 0L, 0L, 0L, 1L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 1L, \n",
      "1L, 1L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 1L, 1L, 1L, 0L, 0L, 0L, 1L, \n",
      "1L, 1L, 0L, 1L, 0L, 1L, 1L, 0L, 1L, 1L, 0L, 1L, 1L, 0L, 0L, 0L, \n",
      "1L, 1L, 0L, 0L, 1L, 1L, 0L, 1L, 1L, 1L, 0L, 0L, 0L, 0L, 1L, 0L, \n",
      "0L, 1L, 1L, 0L, 1L, 1L, 0L, 0L, 0L), emergency_measures.2 = c(0L, \n",
      "0L, 0L, 0L, 1L, 0L, 0L, 0L, 1L, 1L, 0L, 0L, 1L, 0L, 0L, 1L, 0L, \n",
      "0L, 0L, 1L, 1L, 1L, 1L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n",
      "0L, 0L, 1L, 1L, 1L, 0L, 1L, 0L, 1L, 1L, 1L, 1L, 0L, 0L, 1L, 1L, \n",
      "1L, 1L, 0L, 1L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 0L, 0L, 1L, 0L, 0L, \n",
      "1L, 1L, 0L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 0L, 1L, 0L, 0L, 0L, 1L, \n",
      "1L, 1L, 1L, 0L, 1L, 1L, 0L, 1L, 0L), emergency_measures.3 = c(1L, \n",
      "0L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n",
      "1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 1L, \n",
      "1L, 1L, 1L, 1L, 1L, 0L, 1L, 0L, 0L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, \n",
      "1L, 1L, 0L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n",
      "1L, 1L, 0L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 0L, 0L, 1L, 1L, \n",
      "1L, 0L, 1L, 1L, 1L, 1L, 0L, 1L, 0L), emergency_measures.4 = c(0L, \n",
      "1L, 0L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, \n",
      "1L, 0L, 1L, 1L, 0L, 1L, 0L, 1L, 0L, 1L, 1L, 0L, 0L, 0L, 0L, 1L, \n",
      "1L, 0L, 1L, 1L, 1L, 0L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, \n",
      "1L, 1L, 0L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, \n",
      "1L, 1L, 0L, 0L, 0L, 1L, 0L, 1L, 1L, 1L, 0L, 0L, 0L, 1L, 1L, 1L, \n",
      "1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 0L), emergency_measures.7 = c(0L, \n",
      "0L, 0L, 0L, 1L, 0L, 1L, 0L, 0L, 0L, 0L, 1L, 1L, 0L, 0L, 1L, 1L, \n",
      "1L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 1L, 0L, 1L, \n",
      "1L, 1L, 0L, 0L, 1L, 0L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, \n",
      "1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, \n",
      "0L, 0L, 0L, 1L, 1L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, \n",
      "0L, 0L, 1L, 1L, 1L, 1L, 1L, 0L, 1L), emergency_measures.8 = c(0L, \n",
      "0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, \n",
      "0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 1L, 0L, \n",
      "0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n",
      "0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n",
      "0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, \n",
      "0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L), overall_problem_house = c(1L, \n",
      "0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n",
      "1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n",
      "1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n",
      "1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n",
      "1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n",
      "1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L), protect_valuables_impl = c(1L, \n",
      "5L, 5L, 5L, 1L, 1L, 1L, 4L, 5L, 5L, 1L, 1L, 1L, 4L, 5L, 5L, 5L, \n",
      "1L, 1L, 1L, 1L, 1L, 1L, 5L, 1L, 5L, 5L, 1L, 5L, 5L, 5L, 5L, 5L, \n",
      "5L, 5L, 1L, 1L, 1L, 5L, 4L, 1L, 1L, 4L, 4L, 4L, 5L, 4L, 5L, 1L, \n",
      "5L, 5L, 1L, 1L, 1L, 1L, 5L, 5L, 2L, 1L, 5L, 5L, 5L, 5L, 1L, 1L, \n",
      "1L, 1L, 4L, 4L, 1L, 2L, 1L, 2L, 1L, 5L, 5L, 5L, 5L, 1L, 5L, 1L, \n",
      "1L, 1L, 4L, 1L, 4L, 4L, 4L, 5L, 2L), water_barriers_impl = c(5L, \n",
      "1L, 5L, 5L, 1L, 5L, 5L, 5L, 5L, 1L, 1L, 1L, 1L, 5L, 5L, 5L, 1L, \n",
      "1L, 1L, 1L, 1L, 1L, 5L, 5L, 5L, 5L, 5L, 5L, 4L, 5L, 4L, 1L, 1L, \n",
      "1L, 4L, 1L, 5L, 5L, 5L, 4L, 4L, 5L, 4L, 4L, 4L, 5L, 5L, 5L, 1L, \n",
      "1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 5L, 1L, 5L, 1L, 4L, 1L, \n",
      "1L, 5L, 5L, 5L, 5L, 2L, 1L, 1L, 5L, 5L, 5L, 5L, 5L, 5L, 1L, 1L, \n",
      "5L, 1L, 4L, 4L, 4L, 4L, 5L, 5L, 2L), pumping_equipment_impl = c(5L, \n",
      "5L, 5L, 5L, 5L, 5L, 5L, 5L, 1L, 1L, 1L, 5L, 5L, 1L, 5L, 5L, 5L, \n",
      "5L, 5L, 1L, 5L, 1L, 1L, 5L, 5L, 5L, 5L, 1L, 1L, 1L, 5L, 5L, 5L, \n",
      "1L, 4L, 5L, 5L, 4L, 5L, 4L, 4L, 5L, 5L, 4L, 5L, 4L, 1L, 1L, 5L, \n",
      "1L, 1L, 1L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 1L, 5L, 1L, 5L, 5L, \n",
      "5L, 1L, 5L, 2L, 1L, 2L, 5L, 5L, 1L, 1L, 1L, 5L, 5L, 1L, 1L, 5L, \n",
      "5L, 5L, 4L, 4L, 4L, 5L, 1L, 1L, 1L), elevation_building_impl = c(1L, \n",
      "1L, 1L, 1L, 4L, 1L, 4L, 4L, 4L, 1L, 4L, 1L, 1L, 4L, 4L, 4L, 1L, \n",
      "1L, 4L, 4L, 4L, 4L, 4L, 4L, 1L, 4L, 4L, 1L, 1L, 4L, 1L, 4L, 1L, \n",
      "4L, 1L, 1L, 1L, 4L, 5L, 5L, 5L, 1L, 4L, 4L, 1L, 4L, 4L, 1L, 4L, \n",
      "4L, 1L, 1L, 4L, 1L, 1L, 4L, 1L, 4L, 2L, 1L, 2L, 2L, 2L, 2L, 1L, \n",
      "1L, 1L, 2L, 4L, 2L, 1L, 4L, 2L, 4L, 1L, 1L, 4L, 4L, 1L, 4L, 1L, \n",
      "1L, 4L, 5L, 5L, 4L, 2L, 4L, 1L, 1L), resistant_material_building_impl = c(5L, \n",
      "5L, 5L, 5L, 5L, 5L, 5L, 4L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, \n",
      "5L, 5L, 5L, 5L, 5L, 4L, 5L, 5L, 5L, 5L, 4L, 5L, 5L, 5L, 5L, 5L, \n",
      "5L, 5L, 5L, 5L, 5L, 5L, 5L, 4L, 1L, 5L, 5L, 5L, 5L, 4L, 1L, 5L, \n",
      "5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, \n",
      "5L, 1L, 5L, 5L, 5L, 5L, 5L, 5L, 4L, 5L, 5L, 5L, 5L, 4L, 5L, 5L, \n",
      "5L, 5L, 5L, 4L, 5L, 5L, 4L, 1L, 5L), electricity_higher_impl = c(5L, \n",
      "5L, 5L, 5L, 4L, 1L, 5L, 4L, 5L, 1L, 5L, 5L, 1L, 4L, 1L, 5L, 5L, \n",
      "5L, 4L, 1L, 1L, 4L, 4L, 5L, 1L, 5L, 5L, 5L, 1L, 1L, 1L, 4L, 5L, \n",
      "5L, 5L, 5L, 5L, 5L, 5L, 1L, 4L, 5L, 4L, 4L, 1L, 5L, 4L, 5L, 1L, \n",
      "5L, 1L, 5L, 5L, 5L, 1L, 5L, 5L, 4L, 5L, 1L, 5L, 5L, 1L, 5L, 5L, \n",
      "1L, 5L, 2L, 4L, 5L, 2L, 4L, 5L, 4L, 5L, 1L, 5L, 5L, 5L, 5L, 5L, \n",
      "5L, 1L, 1L, 4L, 4L, 2L, 4L, 5L, 5L), flood_protections_impl = c(5L, \n",
      "5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, \n",
      "5L, 5L, 5L, 1L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, \n",
      "5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 4L, 5L, 5L, 5L, 5L, 1L, 5L, \n",
      "5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, \n",
      "5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, \n",
      "5L, 5L, 5L, 5L, 5L, 5L, 5L, 1L, 5L), flood_experience = c(4L, \n",
      "4L, 1L, 2L, 4L, 5L, 4L, 5L, 2L, 5L, 3L, 5L, 5L, 5L, 6L, 6L, 5L, \n",
      "3L, 5L, 6L, 6L, 6L, 6L, 5L, 6L, 6L, 2L, 5L, 4L, 5L, 5L, 4L, 5L, \n",
      "4L, 4L, 6L, 5L, 4L, 3L, 6L, 6L, 4L, 6L, 6L, 5L, 5L, 6L, 6L, 6L, \n",
      "4L, 5L, 5L, 6L, 2L, 6L, 4L, 4L, 4L, 6L, 5L, 4L, 6L, 5L, 4L, 5L, \n",
      "5L, 4L, 6L, 5L, 6L, 5L, 5L, 6L, 6L, 6L, 5L, 5L, 2L, 5L, 4L, 6L, \n",
      "5L, 5L, 6L, 6L, 6L, 5L, 6L, 6L, 5L), elevation_building_height_cm = c(20, \n",
      "30, 20, 200, 100, 70, 40, 20, 110, 80, 70, 40, 100, 100, 110, \n",
      "150, 80, 100, 150, 30, 50, 100, 120, 120, 70, 100, 30, 70, 40, \n",
      "110, 100, 20, 50, 110, 120, 40, 70, 100, 60, 40, 150, 50, 60, \n",
      "150, 60, 80, 100, 80, 50, 150, 120, 80, 60, 20, 60, 50, 30, 100, \n",
      "50, 60, 60, 100, 80, 60, 40, 100, 50, 150, 100, 40, 40, 150, \n",
      "30, 120, 70, 150, 120, 30, 70, 110, 40, 70, 80, 40, 150, 150, \n",
      "60, 100, 80, 80), bage = c(21, 22, 45, 33, 0, 45, 17, 14, 6, \n",
      "30, 19, 18, 30, 21, 19, 5, 12, 12, 13, 31, 25, 19, 7, 20, 3, \n",
      "51, 62, 47, 10, 14, 17, 24, 20, 16, 35, 12, 15, 8, 21, 57, 12, \n",
      "23, 10, 20, 0, 23, 19, 16, 6, 28, 9, 6, 14, 24, 33, 5, 20, 0, \n",
      "27, 24, 17, 22, 26, 18, 17, 28, 19, 42, 20, 5, 23, 13, 18, 3, \n",
      "46, 19, 20, 62, 42, 16, 12, 15, 12, 56, 14, 20, 0, 18, 11, 3), \n",
      "    b_area = c(54, 45, 35, 90, 45, 55, 50, 20, 140, 90, 120, \n",
      "    16, 35, 98, 74, 87, 115, 15, 50, 200, 40, 40, 40, 118, 20, \n",
      "    50, 36, 50, 90, 1000, 80, 120, 40, 50, 20, 43, 15, 850, 72, \n",
      "    56, 48, 125, 50, 120, 28, 150, 50, 48, 35, 240, 92.8, 80, \n",
      "    90, 120, 120, 60, 45, 45, 40, 65, 50, 160, 90, 80, 16, 35, \n",
      "    80, 156, 98, 80, 56, 50, 80, 40, 110, 84, 118, 36, 50, 50, \n",
      "    43, 15, 40, 56, 48, 120, 28, 50, 48, 80), hh_monthly_income_cat = c(7, \n",
      "    3, 3, 4, 3, 3, 4, 3, 5, 2, 4, 4, 2, 3, 4, 5, 3, 3, 3, 4, \n",
      "    3, 4, 3, 4, 3, 2, 2, 3, 3, 8, 2, 3, 3, 2, 2, 4, 3, 3, 3, \n",
      "    3, 5, 3, 5, 6, 5, 4, 4, 4, 3, 3, 3, 3, 3, 4, 3, 4, 3, 3, \n",
      "    3, 4, 5, 7, 2, 3, 4, 2, 4, 3, 3, 3, 4, 3, 2, 3, 4, 3, 4, \n",
      "    2, 3, 2, 4, 3, 3, 3, 5, 6, 5, 4, 4, 3), shp_owner = c(1L, \n",
      "    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 1L, 1L, 1L, 1L, 3L, 2L, 3L, \n",
      "    3L, 1L, 1L, 1L, 1L, 88L, 1L, 3L, 1L, 1L, 3L, 3L, 3L, 2L, \n",
      "    3L, 3L, 3L, 3L, 3L, 1L, 1L, 1L, 3L, 3L, 3L, 1L, 3L, 3L, 3L, \n",
      "    1L, 3L, 1L, 3L, 3L, 3L, 3L, 3L, 3L, 1L, 3L, 3L, 3L, 3L, 1L, \n",
      "    1L, 3L, 1L, 1L, 1L, 1L, 1L, 3L, 3L, 3L, 3L, 1L, 1L, 1L, 3L, \n",
      "    3L, 3L, 3L, 3L, 3L, 1L, 1L, 1L, 3L, 3L, 3L, 3L, 3L, 1L, 3L\n",
      "    ), shp_sector = c(17L, 17L, 12L, 17L, 11L, 31L, 31L, 17L, \n",
      "    21L, 11L, 11L, 11L, 11L, 17L, 17L, 23L, 17L, 11L, 15L, 11L, \n",
      "    17L, 88L, 21L, 17L, 17L, 24L, 11L, 11L, 14L, 88L, 11L, 24L, \n",
      "    14L, 17L, 17L, 17L, 11L, 11L, 88L, 24L, 17L, 17L, 14L, 11L, \n",
      "    17L, 17L, 17L, 11L, 17L, 11L, 17L, 17L, 11L, 11L, 24L, 17L, \n",
      "    17L, 11L, 11L, 11L, 11L, 21L, 11L, 17L, 11L, 11L, 17L, 11L, \n",
      "    17L, 17L, 17L, 15L, 17L, 21L, 17L, 11L, 17L, 11L, 11L, 17L, \n",
      "    17L, 11L, 11L, 24L, 17L, 11L, 17L, 17L, 11L, 17L), shp_employees = c(2L, \n",
      "    2L, 1L, 2L, 2L, 3L, 1L, 1L, 9L, 1L, 2L, 2L, 1L, 1L, 2L, 1L, \n",
      "    1L, 2L, 2L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 34L, \n",
      "    2L, 4L, 2L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, \n",
      "    2L, 1L, 3L, 1L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 1L, \n",
      "    1L, 7L, 1L, 1L, 2L, 1L, 4L, 4L, 1L, 1L, 1L, 2L, 2L, 1L, 2L, \n",
      "    2L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 1L, 3L, 2L\n",
      "    ), shp_avgmonthly_sale_cat = c(4L, 1L, 1L, 2L, 2L, 2L, 2L, \n",
      "    2L, 3L, 1L, 1L, 2L, 1L, 1L, 2L, 3L, 2L, 2L, 2L, 1L, 1L, 1L, \n",
      "    2L, 1L, 1L, 1L, 1L, 1L, 2L, 5L, 1L, 3L, 3L, 1L, 1L, 3L, 2L, \n",
      "    2L, 2L, 1L, 1L, 1L, 3L, 3L, 3L, 2L, 2L, 3L, 1L, 2L, 1L, 2L, \n",
      "    2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 1L, 4L, 1L, 2L, 2L, 1L, 3L, \n",
      "    3L, 1L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 3L, 2L, \n",
      "    1L, 1L, 1L, 3L, 3L, 2L, 3L, 2L), resilience_govern_careing_increases = c(3, \n",
      "    1, 1, 5, 3, 5, 1, 4, 1, 5, 3, 3, 2, 2, 1, 3, 1, 3, 3, 1, \n",
      "    1, 1, 3, 1, 1, 2, 2, 1, 1, 5, 1, 2, 1, 1, 1, 2, 3, 3, 2, \n",
      "    4, 2, 2, 3, 4, 3, 1, 1, 1, 4, 1, 1, 2, 1, 1, 2, 1, 1, 3, \n",
      "    3, 4, 3, 1, 5, 3, 3, 2, 4, 1, 2, 1, 1, 3, 1, 3, 1, 1, 1, \n",
      "    2, 1, 1, 2, 3, 1, 4, 2, 4, 3, 1, 1, 2), shp_content_value_euro = c(12889, \n",
      "    9206.4, 18412.8, 14730.3, 12889, 16571.5, 18412.8, 9206.4, \n",
      "    5523.8, 44190.8, 73651.3, 12889, 5523.8, 36825.6, 18412.8, \n",
      "    16571.5, 36825.6, 3682.6, 14730.3, 16571.5, 11047.7, 11047.7, \n",
      "    13809.6, 11047.7, 7365.1, 18412.8, 9206.4, 18412.8, 14730.3, \n",
      "    202541, 18412.8, 16571.5, 12889, 14730.3, 9206.4, 10127, \n",
      "    3682.6, 110476.9, 5523.8, 36825.6, 5523.8, 55238.4, 22095.4, \n",
      "    27619.2, 1841.3, 36825.6, 7365.1, 27619.2, 7365.1, 29460.5, \n",
      "    14730.3, 9206.4, 16571.5, 18412.8, 16571.5, 18412.8, 9206.4, \n",
      "    12889, 9206.4, 14730.3, 7365.1, 25777.9, 44190.8, 18412.8, \n",
      "    12889, 5523.8, 55238.4, 14730.3, 36825.6, 18412.8, 12889, \n",
      "    14730.3, 12889, 13809.6, 9206.4, 7365.1, 11047.7, 9206.4, \n",
      "    18412.8, 14730.3, 10127, 3682.6, 9206.4, 36825.6, 5523.8, \n",
      "    27619.2, 1841.3, 7365.1, 27619.2, 9206.4), shp_registered_capital_euro = c(3682.6, \n",
      "    441.9, 368.3, 1473, 1473, 736.5, 736.5, 294.6, 14730.3, 184.1, \n",
      "    73.7, 662.9, 1841.3, 1841.3, 2946.1, 14730.3, 2946.1, 368.3, \n",
      "    3682.6, 368.3, 736.5, 1841.3, 2946.1, 2577.8, 441.9, 736.5, \n",
      "    368.3, 331.4, 18412.8, 699687, 1473, 7365.1, 368.3, 736.5, \n",
      "    368.3, 1841.3, 110.5, 1104.8, 7365.1, 552.4, 368.3, 110.5, \n",
      "    22095.4, 2577.8, 1841.3, 736.5, 1841.3, 147.3, 1473, 3682.6, \n",
      "    3682.6, 1104.8, 1473, 2209.5, 1473, 3682.6, 441.9, 1473, \n",
      "    552.4, 368.3, 55.2, 110476.9, 184.1, 368.3, 662.9, 1841.3, \n",
      "    1104.8, 1841.3, 1841.3, 1104.8, 1841.3, 3682.6, 1841.3, 2946.1, \n",
      "    2946.1, 2209.5, 2577.8, 368.3, 331.4, 736.5, 1841.3, 110.5, \n",
      "    184.1, 552.4, 368.3, 2577.8, 1841.3, 1841.3, 147.3, 1104.8\n",
      "    )), method = \"cforest\", n_outer_folds = 2L, n_inner_folds = 2L, \n",
      "    metric = \"MAE\", trControl = list(method = \"repeatedcv\", number = 10L, \n",
      "        repeats = 5L, search = \"grid\", p = 0.75, initialWindow = NULL, \n",
      "        horizon = 1, fixedWindow = TRUE, skip = 0, verboseIter = FALSE, \n",
      "        returnData = TRUE, returnResamp = \"final\", savePredictions = FALSE, \n",
      "        classProbs = FALSE, summaryFunction = function (data, \n",
      "            lev = NULL, model = NULL) \n",
      "        {\n",
      "            if (is.character(data$obs)) \n",
      "                data$obs <- factor(data$obs, levels = lev)\n",
      "            postResample(data[, \"pred\"], data[, \"obs\"])\n",
      "        }, selectionFunction = \"best\", preProcOptions = list(\n",
      "            thresh = 0.95, ICAcomp = 3, k = 5, freqCut = 19, \n",
      "            uniqueCut = 10, cutoff = 0.9), sampling = NULL, index = NULL, \n",
      "        indexOut = NULL, indexFinal = NULL, timingSamps = 0, \n",
      "        predictionBounds = c(FALSE, FALSE), seeds = NA, adaptive = list(\n",
      "            min = 5, alpha = 0.05, method = \"gls\", complete = TRUE), \n",
      "        trim = FALSE, allowParallel = TRUE), savePredictions = \"final\", \n",
      "    outer_train_predict = TRUE, maximize = TRUE, controls = new(\"ForestControl\", \n",
      "        ntree = 100L, replace = FALSE, fraction = 0.632, trace = FALSE, \n",
      "        varctrl = new(\"VariableControl\", teststat = 2L, pvalue = TRUE, \n",
      "            tol = 1e-10, maxpts = 25000L, abseps = 1e-04, releps = 0), \n",
      "        splitctrl = new(\"SplitControl\", minprob = 0.01, minsplit = 20, \n",
      "            minbucket = 7, tol = 1e-10, maxsurrogate = 0L), gtctrl = new(\"GlobalTestControl\", \n",
      "            testtype = 4L, nresample = 9999L, randomsplits = TRUE, \n",
      "            mtry = 2L, mincriterion = 0), tgctrl = new(\"TreeGrowControl\", \n",
      "            stump = FALSE, maxdepth = 0L, savesplitstats = FALSE, \n",
      "            remove_weights = FALSE)))\n",
      "\n",
      "$output\n",
      "         predy    testy\n",
      "10   2927.4546     18.4\n",
      "20   4116.2614   1473.0\n",
      "22   2828.2715    268.1\n",
      "24   3407.1452      7.4\n",
      "47  17729.5367   1494.6\n",
      "64   2589.9133     55.2\n",
      "68    988.1883     73.7\n",
      "87  12625.2099    267.9\n",
      "96  13195.9241   1288.5\n",
      "103 14814.2120    119.0\n",
      "110 15756.0723   1189.8\n",
      "114  2967.9998     36.8\n",
      "117  3270.1810     19.8\n",
      "136   808.5574     37.4\n",
      "152  3790.7196     37.4\n",
      "165  3559.9421    421.4\n",
      "173  1065.5705   1473.0\n",
      "175   245.4763     11.0\n",
      "185   853.1469     44.7\n",
      "195  3443.0330    405.1\n",
      "202  9624.1949    112.1\n",
      "204  4200.5733     76.5\n",
      "232  3615.5945    149.5\n",
      "237  3499.2008    149.5\n",
      "244  4188.0481    110.5\n",
      "250 15369.2497     74.7\n",
      "257  3478.9877     38.3\n",
      "275   236.9617     39.7\n",
      "283  4350.3430     82.8\n",
      "302  6005.9061    178.5\n",
      "303  6103.0048    224.2\n",
      "305  2036.4651     37.4\n",
      "318  1498.7400    373.7\n",
      "323 15756.0723   1189.8\n",
      "339 14000.1240   4552.9\n",
      "340  4871.1476    165.6\n",
      "341  6708.7198    650.6\n",
      "345   651.4729     74.7\n",
      "347  2918.8197  24851.1\n",
      "355  3111.0749    126.4\n",
      "366   817.1524     82.8\n",
      "373  3549.2780    368.3\n",
      "376  1120.8088     76.5\n",
      "386  3695.1652    248.3\n",
      "7     680.9332     29.5\n",
      "11   1463.8828     18.4\n",
      "28    323.7265     76.5\n",
      "29    283.2110    168.6\n",
      "53   2156.4893     55.2\n",
      "62    975.8592     18.7\n",
      "79   1242.8112     36.8\n",
      "105   367.0237     79.3\n",
      "113  2308.5908    224.2\n",
      "118  1256.2132    119.0\n",
      "129   517.8831    153.1\n",
      "132   239.3129     26.2\n",
      "141  1583.5688     74.7\n",
      "143  2306.4272     44.8\n",
      "150  1276.2861   2615.6\n",
      "151  1354.0421 224190.4\n",
      "162  1347.1490    373.7\n",
      "163   202.0951     73.7\n",
      "164   872.6667     84.3\n",
      "177   451.5613  34120.0\n",
      "183   652.8213    793.2\n",
      "184  1525.4455    368.3\n",
      "186   688.2500    186.8\n",
      "193   642.2185   1868.3\n",
      "194   683.1562   1121.0\n",
      "203  1122.9878     37.4\n",
      "207   323.8280     76.5\n",
      "209  2432.5682    124.2\n",
      "210  1227.6911     82.8\n",
      "241  1343.0495     37.4\n",
      "264   331.5950    268.1\n",
      "266  1606.0383     39.7\n",
      "274  1094.2138     38.3\n",
      "280   733.5660   3624.4\n",
      "290   360.0106     38.3\n",
      "291   284.7834     56.0\n",
      "295  1698.8907    382.7\n",
      "296   999.6443     74.7\n",
      "327   476.1440    632.1\n",
      "330  1303.8091    214.8\n",
      "361   492.6452   1473.0\n",
      "363   366.9064     36.8\n",
      "364   330.3183    268.1\n",
      "365  1570.1410    448.4\n",
      "372   683.1562   1121.0\n",
      "377   877.4033    214.8\n",
      "\n",
      "$outer_result\n",
      "$outer_result[[1]]\n",
      "$outer_result[[1]]$preds\n",
      "         predy   testy\n",
      "10   2927.4546    18.4\n",
      "20   4116.2614  1473.0\n",
      "22   2828.2715   268.1\n",
      "24   3407.1452     7.4\n",
      "47  17729.5367  1494.6\n",
      "64   2589.9133    55.2\n",
      "68    988.1883    73.7\n",
      "87  12625.2099   267.9\n",
      "96  13195.9241  1288.5\n",
      "103 14814.2120   119.0\n",
      "110 15756.0723  1189.8\n",
      "114  2967.9998    36.8\n",
      "117  3270.1810    19.8\n",
      "136   808.5574    37.4\n",
      "152  3790.7196    37.4\n",
      "165  3559.9421   421.4\n",
      "173  1065.5705  1473.0\n",
      "175   245.4763    11.0\n",
      "185   853.1469    44.7\n",
      "195  3443.0330   405.1\n",
      "202  9624.1949   112.1\n",
      "204  4200.5733    76.5\n",
      "232  3615.5945   149.5\n",
      "237  3499.2008   149.5\n",
      "244  4188.0481   110.5\n",
      "250 15369.2497    74.7\n",
      "257  3478.9877    38.3\n",
      "275   236.9617    39.7\n",
      "283  4350.3430    82.8\n",
      "302  6005.9061   178.5\n",
      "303  6103.0048   224.2\n",
      "305  2036.4651    37.4\n",
      "318  1498.7400   373.7\n",
      "323 15756.0723  1189.8\n",
      "339 14000.1240  4552.9\n",
      "340  4871.1476   165.6\n",
      "341  6708.7198   650.6\n",
      "345   651.4729    74.7\n",
      "347  2918.8197 24851.1\n",
      "355  3111.0749   126.4\n",
      "366   817.1524    82.8\n",
      "373  3549.2780   368.3\n",
      "376  1120.8088    76.5\n",
      "386  3695.1652   248.3\n",
      "\n",
      "$outer_result[[1]]$train_preds\n",
      "      ytrain      predy\n",
      "7       29.5 15667.7593\n",
      "11      18.4   321.8593\n",
      "28      76.5   914.6842\n",
      "29     168.6   775.4921\n",
      "53      55.2  4333.1151\n",
      "62      18.7  9376.9148\n",
      "79      36.8  5876.3137\n",
      "105     79.3  2746.0124\n",
      "113    224.2  3946.4594\n",
      "118    119.0 10316.5287\n",
      "129    153.1  6332.6092\n",
      "132     26.2   694.7431\n",
      "141     74.7   651.4729\n",
      "143     44.8  2564.2270\n",
      "150   2615.6 15305.8382\n",
      "151 224190.4 21353.2853\n",
      "162    373.7 17644.1762\n",
      "163     73.7  2576.8340\n",
      "164     84.3  3035.9885\n",
      "177  34120.0  9553.7804\n",
      "183    793.2 15338.7430\n",
      "184    368.3  4391.8515\n",
      "186    186.8  7292.8854\n",
      "193   1868.3 15408.8020\n",
      "194   1121.0 11048.0310\n",
      "203     37.4  1120.8088\n",
      "207     76.5  1057.7229\n",
      "209    124.2 19915.9036\n",
      "210     82.8 15403.6167\n",
      "241     37.4  7077.9603\n",
      "264    268.1  2832.7558\n",
      "266     39.7  2584.7461\n",
      "274     38.3   963.6151\n",
      "280   3624.4 18647.7205\n",
      "290     38.3  1682.2977\n",
      "291     56.0  2942.1193\n",
      "295    382.7  1056.9959\n",
      "296     74.7  7007.8163\n",
      "327    632.1  4132.6984\n",
      "330    214.8 10312.8501\n",
      "361   1473.0  1065.5705\n",
      "363     36.8   774.5692\n",
      "364    268.1   247.4873\n",
      "365    448.4  4389.4649\n",
      "372   1121.0 11048.0310\n",
      "377    214.8  4204.5810\n",
      "\n",
      "$outer_result[[1]]$fit\n",
      "Conditional Inference Random Forest \n",
      "\n",
      "46 samples\n",
      "30 predictors\n",
      "\n",
      "No pre-processing\n",
      "Resampling: Cross-Validated (10 fold, repeated 5 times) \n",
      "Summary of sample sizes: 41, 42, 42, 41, 41, 40, ... \n",
      "Resampling results across tuning parameters:\n",
      "\n",
      "  mtry  RMSE      Rsquared   MAE     \n",
      "   2    16006.16  0.4191702  10191.11\n",
      "  16    17173.03  0.5085956  10309.88\n",
      "  30    18137.45  0.4707774  10262.71\n",
      "\n",
      "MAE was used to select the optimal model using the largest value.\n",
      "The final value used for the model was mtry = 16.\n",
      "\n",
      "$outer_result[[1]]$nfilter\n",
      "[1] 30\n",
      "\n",
      "\n",
      "$outer_result[[2]]\n",
      "$outer_result[[2]]$preds\n",
      "        predy    testy\n",
      "7    680.9332     29.5\n",
      "11  1463.8828     18.4\n",
      "28   323.7265     76.5\n",
      "29   283.2110    168.6\n",
      "53  2156.4893     55.2\n",
      "62   975.8592     18.7\n",
      "79  1242.8112     36.8\n",
      "105  367.0237     79.3\n",
      "113 2308.5908    224.2\n",
      "118 1256.2132    119.0\n",
      "129  517.8831    153.1\n",
      "132  239.3129     26.2\n",
      "141 1583.5688     74.7\n",
      "143 2306.4272     44.8\n",
      "150 1276.2861   2615.6\n",
      "151 1354.0421 224190.4\n",
      "162 1347.1490    373.7\n",
      "163  202.0951     73.7\n",
      "164  872.6667     84.3\n",
      "177  451.5613  34120.0\n",
      "183  652.8213    793.2\n",
      "184 1525.4455    368.3\n",
      "186  688.2500    186.8\n",
      "193  642.2185   1868.3\n",
      "194  683.1562   1121.0\n",
      "203 1122.9878     37.4\n",
      "207  323.8280     76.5\n",
      "209 2432.5682    124.2\n",
      "210 1227.6911     82.8\n",
      "241 1343.0495     37.4\n",
      "264  331.5950    268.1\n",
      "266 1606.0383     39.7\n",
      "274 1094.2138     38.3\n",
      "280  733.5660   3624.4\n",
      "290  360.0106     38.3\n",
      "291  284.7834     56.0\n",
      "295 1698.8907    382.7\n",
      "296  999.6443     74.7\n",
      "327  476.1440    632.1\n",
      "330 1303.8091    214.8\n",
      "361  492.6452   1473.0\n",
      "363  366.9064     36.8\n",
      "364  330.3183    268.1\n",
      "365 1570.1410    448.4\n",
      "372  683.1562   1121.0\n",
      "377  877.4033    214.8\n",
      "\n",
      "$outer_result[[2]]$train_preds\n",
      "     ytrain     predy\n",
      "10     18.4  318.8160\n",
      "20   1473.0 1686.7666\n",
      "22    268.1  370.1862\n",
      "24      7.4 1593.7036\n",
      "47   1494.6 1323.4287\n",
      "64     55.2  281.8831\n",
      "68     73.7 1660.0500\n",
      "87    267.9  568.1260\n",
      "96   1288.5  687.0974\n",
      "103   119.0  550.3109\n",
      "110  1189.8  691.0026\n",
      "114    36.8 1080.0400\n",
      "117    19.8 1120.7907\n",
      "136    37.4 1556.4030\n",
      "152    37.4  388.3653\n",
      "165   421.4 1607.6732\n",
      "173  1473.0  492.6452\n",
      "175    11.0  288.0103\n",
      "185    44.7  374.9911\n",
      "195   405.1  485.2384\n",
      "202   112.1  623.0343\n",
      "204    76.5  876.1097\n",
      "232   149.5 1018.1881\n",
      "237   149.5  372.7828\n",
      "244   110.5 1681.7266\n",
      "250    74.7  534.6769\n",
      "257    38.3  260.0191\n",
      "275    39.7  883.2103\n",
      "283    82.8 1969.7802\n",
      "302   178.5 1763.1784\n",
      "303   224.2  676.8253\n",
      "305    37.4 1095.2457\n",
      "318   373.7  973.6704\n",
      "323  1189.8  691.0026\n",
      "339  4552.9 2457.0844\n",
      "340   165.6 1235.9126\n",
      "341   650.6  575.9714\n",
      "345    74.7 1583.5688\n",
      "347 24851.1 2302.4913\n",
      "355   126.4  917.0140\n",
      "366    82.8  305.8071\n",
      "373   368.3  522.2752\n",
      "376    76.5 1127.1817\n",
      "386   248.3 1002.3044\n",
      "\n",
      "$outer_result[[2]]$fit\n",
      "Conditional Inference Random Forest \n",
      "\n",
      "44 samples\n",
      "30 predictors\n",
      "\n",
      "No pre-processing\n",
      "Resampling: Cross-Validated (10 fold, repeated 5 times) \n",
      "Summary of sample sizes: 38, 41, 39, 40, 41, 39, ... \n",
      "Resampling results across tuning parameters:\n",
      "\n",
      "  mtry  RMSE      Rsquared   MAE     \n",
      "   2    1932.789  0.3654182  1281.301\n",
      "  16    2039.668  0.2900425  1335.296\n",
      "  30    2124.337  0.3225065  1388.989\n",
      "\n",
      "MAE was used to select the optimal model using the largest value.\n",
      "The final value used for the model was mtry = 30.\n",
      "\n",
      "$outer_result[[2]]$nfilter\n",
      "[1] 30\n",
      "\n",
      "\n",
      "\n",
      "$outer_method\n",
      "[1] \"cv\"\n",
      "\n",
      "$outer_folds\n",
      "$outer_folds$Fold1\n",
      " [1]  2  4  5  6  9 12 13 15 16 17 19 21 22 26 31 35 36 37 41 45 46 48 52 53 55\n",
      "[26] 56 57 61 63 68 69 70 71 72 75 76 77 78 79 80 85 87 88 90\n",
      "\n",
      "$outer_folds$Fold2\n",
      " [1]  1  3  7  8 10 11 14 18 20 23 24 25 27 28 29 30 32 33 34 38 39 40 42 43 44\n",
      "[26] 47 49 50 51 54 58 59 60 62 64 65 66 67 73 74 81 82 83 84 86 89\n",
      "\n",
      "\n",
      "$dimx\n",
      "[1] 90 30\n",
      "\n",
      "$xsub\n",
      "    inundation_duration_h water_depth_cm contaminations.0 flowvelocity\n",
      "7                    12.0             20                0            2\n",
      "10                    2.0              3                1            4\n",
      "11                    0.5             10                0            2\n",
      "20                    7.0             21                0            5\n",
      "22                    2.0             30                0            2\n",
      "24                    9.0             20                0            4\n",
      "28                    3.0             30                0            2\n",
      "29                    3.0             40                0            2\n",
      "47                    4.0             80                0            5\n",
      "53                    1.0              5                0            1\n",
      "62                    5.0             20                0            4\n",
      "64                    3.0             10                0            4\n",
      "68                   10.0             20                0            5\n",
      "79                    3.0             40                0            5\n",
      "87                  600.0             30                0            4\n",
      "96                    3.0            100                0            4\n",
      "103                   2.0             20                0            2\n",
      "105                   2.0             50                0            4\n",
      "110                  48.0            120                0            5\n",
      "113                   9.0             50                0            4\n",
      "114                   2.0             10                0            4\n",
      "117                   2.0             10                0            3\n",
      "118                   5.0              5                0            3\n",
      "129                   1.0             10                0            2\n",
      "132                   3.0             20                0            2\n",
      "136                   2.0             20                0            3\n",
      "141                  10.0             40                0            5\n",
      "143                   3.0              7                0            3\n",
      "150                  72.0             45                0            5\n",
      "151                  70.0            100                0            5\n",
      "152                  70.0             75                0            5\n",
      "162                   3.0              5                0            2\n",
      "163                   2.0             20                0            1\n",
      "164                   2.0             30                0            2\n",
      "165                   5.0             80                0            4\n",
      "173                   4.0             20                0            4\n",
      "175                   1.0             10                0            4\n",
      "177                   3.0             70                0            3\n",
      "183                   2.0             20                0            2\n",
      "184                   3.0             10                0            3\n",
      "185                   4.0             20                0            2\n",
      "186                   2.0              2                0            3\n",
      "193                   4.0             60                0            4\n",
      "194                   4.0             50                0            3\n",
      "195                   2.0             40                0            3\n",
      "202                   0.5             20                1            3\n",
      "203                   3.0             10                0            1\n",
      "204                   2.0             20                0            2\n",
      "207                   2.0             30                0            3\n",
      "209                   3.0             80                0            4\n",
      "210                   3.0             10                0            1\n",
      "232                   3.0             20                0            4\n",
      "237                   2.0             30                0            3\n",
      "241                   0.5             10                0            1\n",
      "244                   2.0             30                0            2\n",
      "250                   3.0              5                0            2\n",
      "257                  10.0             50                1            4\n",
      "264                   2.0             30                0            4\n",
      "266                   2.0             40                0            5\n",
      "274                   8.0            100                0            5\n",
      "275                   3.0             20                0            3\n",
      "280                   4.0             90                0            5\n",
      "283                   4.0              5                0            4\n",
      "290                   9.0             50                0            4\n",
      "291                  12.0             20                0            5\n",
      "295                  15.0             50                0            5\n",
      "296                   2.0             20                0            4\n",
      "302                   1.0             50                0            5\n",
      "303                   3.0             70                0            2\n",
      "305                  33.0             50                0            5\n",
      "318                   5.0             40                0            4\n",
      "323                  48.0            120                0            5\n",
      "327                  12.0             50                0            5\n",
      "330                  10.0             20                0            4\n",
      "339                   5.0             15                0            2\n",
      "340                   7.0             40                0            3\n",
      "341                   5.0             40                0            3\n",
      "345                  10.0             40                0            5\n",
      "347                   5.0             20                0            5\n",
      "355                   2.0             40                0            3\n",
      "361                   4.0             20                0            4\n",
      "363                   6.0             50                0            5\n",
      "364                   2.0             20                0            5\n",
      "365                   3.0             15                0            4\n",
      "366                   2.0             10                0            2\n",
      "372                   4.0             50                0            3\n",
      "373                   3.0             60                0            4\n",
      "376                   3.0             30                0            1\n",
      "377                   3.0             30                1            3\n",
      "386                   3.0             40                0            5\n",
      "    emergency_measures.1 emergency_measures.2 emergency_measures.3\n",
      "7                      1                    0                    1\n",
      "10                     0                    0                    0\n",
      "11                     0                    0                    1\n",
      "20                     1                    0                    1\n",
      "22                     1                    1                    1\n",
      "24                     0                    0                    1\n",
      "28                     0                    0                    0\n",
      "29                     1                    0                    1\n",
      "47                     1                    1                    1\n",
      "53                     0                    1                    1\n",
      "62                     0                    0                    1\n",
      "64                     0                    0                    1\n",
      "68                     1                    1                    1\n",
      "79                     1                    0                    1\n",
      "87                     0                    0                    1\n",
      "96                     1                    1                    1\n",
      "103                    1                    0                    1\n",
      "105                    0                    0                    1\n",
      "110                    0                    0                    1\n",
      "113                    1                    1                    1\n",
      "114                    1                    1                    1\n",
      "117                    0                    1                    1\n",
      "118                    0                    1                    1\n",
      "129                    0                    1                    1\n",
      "132                    1                    0                    1\n",
      "136                    0                    0                    0\n",
      "141                    0                    0                    0\n",
      "143                    1                    0                    0\n",
      "150                    0                    0                    1\n",
      "151                    0                    0                    0\n",
      "152                    0                    0                    0\n",
      "162                    0                    0                    0\n",
      "163                    1                    0                    1\n",
      "164                    1                    0                    1\n",
      "165                    1                    0                    1\n",
      "173                    0                    1                    1\n",
      "175                    0                    1                    1\n",
      "177                    1                    1                    1\n",
      "183                    0                    0                    0\n",
      "184                    0                    1                    1\n",
      "185                    0                    0                    0\n",
      "186                    0                    1                    0\n",
      "193                    1                    1                    1\n",
      "194                    1                    1                    1\n",
      "195                    1                    1                    1\n",
      "202                    0                    0                    1\n",
      "203                    0                    0                    0\n",
      "204                    0                    1                    1\n",
      "207                    1                    1                    1\n",
      "209                    1                    1                    1\n",
      "210                    1                    1                    1\n",
      "232                    0                    0                    0\n",
      "237                    1                    1                    1\n",
      "241                    0                    0                    0\n",
      "244                    1                    0                    1\n",
      "250                    1                    1                    1\n",
      "257                    0                    1                    1\n",
      "264                    1                    1                    1\n",
      "266                    1                    1                    1\n",
      "274                    0                    1                    1\n",
      "275                    1                    0                    1\n",
      "280                    1                    0                    1\n",
      "283                    0                    1                    1\n",
      "290                    0                    0                    1\n",
      "291                    0                    0                    1\n",
      "295                    1                    1                    1\n",
      "296                    1                    1                    1\n",
      "302                    0                    0                    0\n",
      "303                    0                    1                    0\n",
      "305                    1                    1                    0\n",
      "318                    1                    1                    1\n",
      "323                    0                    0                    1\n",
      "327                    1                    1                    1\n",
      "330                    1                    1                    1\n",
      "339                    1                    1                    1\n",
      "340                    0                    0                    0\n",
      "341                    0                    1                    1\n",
      "345                    0                    0                    0\n",
      "347                    0                    0                    0\n",
      "355                    1                    0                    1\n",
      "361                    0                    1                    1\n",
      "363                    0                    1                    1\n",
      "364                    1                    1                    0\n",
      "365                    1                    1                    1\n",
      "366                    0                    0                    1\n",
      "372                    1                    1                    1\n",
      "373                    1                    1                    1\n",
      "376                    0                    0                    0\n",
      "377                    0                    1                    1\n",
      "386                    0                    0                    0\n",
      "    emergency_measures.4 emergency_measures.7 emergency_measures.8\n",
      "7                      0                    0                    0\n",
      "10                     1                    0                    0\n",
      "11                     0                    0                    0\n",
      "20                     1                    0                    0\n",
      "22                     1                    1                    0\n",
      "24                     1                    0                    0\n",
      "28                     1                    1                    0\n",
      "29                     0                    0                    0\n",
      "47                     1                    0                    0\n",
      "53                     1                    0                    0\n",
      "62                     1                    0                    0\n",
      "64                     1                    1                    0\n",
      "68                     1                    1                    0\n",
      "79                     1                    0                    0\n",
      "87                     1                    0                    0\n",
      "96                     1                    1                    1\n",
      "103                    0                    1                    0\n",
      "105                    1                    1                    0\n",
      "110                    0                    1                    0\n",
      "113                    1                    0                    0\n",
      "114                    1                    0                    0\n",
      "117                    0                    0                    0\n",
      "118                    1                    0                    0\n",
      "129                    0                    0                    0\n",
      "132                    1                    0                    0\n",
      "136                    0                    0                    0\n",
      "141                    1                    0                    1\n",
      "143                    1                    0                    0\n",
      "150                    0                    1                    0\n",
      "151                    0                    0                    0\n",
      "152                    0                    1                    0\n",
      "162                    0                    0                    1\n",
      "163                    1                    1                    0\n",
      "164                    1                    1                    0\n",
      "165                    0                    1                    0\n",
      "173                    1                    0                    0\n",
      "175                    1                    0                    0\n",
      "177                    1                    1                    0\n",
      "183                    0                    0                    0\n",
      "184                    1                    1                    0\n",
      "185                    0                    1                    0\n",
      "186                    1                    0                    0\n",
      "193                    1                    1                    0\n",
      "194                    1                    1                    0\n",
      "195                    1                    1                    0\n",
      "202                    1                    1                    0\n",
      "203                    1                    1                    0\n",
      "204                    0                    0                    0\n",
      "207                    1                    1                    0\n",
      "209                    1                    1                    0\n",
      "210                    1                    1                    0\n",
      "232                    0                    1                    0\n",
      "237                    1                    1                    0\n",
      "241                    0                    1                    0\n",
      "244                    1                    1                    0\n",
      "250                    1                    1                    0\n",
      "257                    1                    0                    0\n",
      "264                    1                    1                    0\n",
      "266                    1                    0                    0\n",
      "274                    1                    0                    0\n",
      "275                    1                    0                    0\n",
      "280                    0                    0                    0\n",
      "283                    1                    0                    0\n",
      "290                    1                    0                    0\n",
      "291                    1                    1                    0\n",
      "295                    1                    0                    0\n",
      "296                    1                    0                    0\n",
      "302                    0                    0                    0\n",
      "303                    0                    1                    0\n",
      "305                    0                    1                    0\n",
      "318                    1                    0                    0\n",
      "323                    0                    1                    0\n",
      "327                    1                    0                    0\n",
      "330                    1                    0                    0\n",
      "339                    1                    0                    0\n",
      "340                    0                    0                    0\n",
      "341                    0                    0                    0\n",
      "345                    0                    0                    0\n",
      "347                    1                    0                    0\n",
      "355                    1                    1                    0\n",
      "361                    1                    0                    0\n",
      "363                    1                    0                    0\n",
      "364                    0                    0                    0\n",
      "365                    1                    1                    0\n",
      "366                    1                    1                    0\n",
      "372                    1                    1                    0\n",
      "373                    1                    1                    0\n",
      "376                    1                    1                    0\n",
      "377                    1                    0                    0\n",
      "386                    0                    1                    0\n",
      "    overall_problem_house protect_valuables_impl water_barriers_impl\n",
      "7                       1                      1                   5\n",
      "10                      0                      5                   1\n",
      "11                      1                      5                   5\n",
      "20                      1                      5                   5\n",
      "22                      1                      1                   1\n",
      "24                      1                      1                   5\n",
      "28                      1                      1                   5\n",
      "29                      1                      4                   5\n",
      "47                      1                      5                   5\n",
      "53                      1                      5                   1\n",
      "62                      1                      1                   1\n",
      "64                      1                      1                   1\n",
      "68                      1                      1                   1\n",
      "79                      1                      4                   5\n",
      "87                      1                      5                   5\n",
      "96                      1                      5                   5\n",
      "103                     1                      5                   1\n",
      "105                     1                      1                   1\n",
      "110                     1                      1                   1\n",
      "113                     1                      1                   1\n",
      "114                     1                      1                   1\n",
      "117                     1                      1                   1\n",
      "118                     1                      1                   5\n",
      "129                     1                      5                   5\n",
      "132                     1                      1                   5\n",
      "136                     1                      5                   5\n",
      "141                     1                      5                   5\n",
      "143                     1                      1                   5\n",
      "150                     1                      5                   4\n",
      "151                     1                      5                   5\n",
      "152                     1                      5                   4\n",
      "162                     1                      5                   1\n",
      "163                     1                      5                   1\n",
      "164                     1                      5                   1\n",
      "165                     1                      5                   4\n",
      "173                     1                      1                   1\n",
      "175                     1                      1                   5\n",
      "177                     1                      1                   5\n",
      "183                     1                      5                   5\n",
      "184                     1                      4                   4\n",
      "185                     1                      1                   4\n",
      "186                     1                      1                   5\n",
      "193                     1                      4                   4\n",
      "194                     1                      4                   4\n",
      "195                     1                      4                   4\n",
      "202                     1                      5                   5\n",
      "203                     1                      4                   5\n",
      "204                     1                      5                   5\n",
      "207                     1                      1                   1\n",
      "209                     1                      5                   1\n",
      "210                     1                      5                   1\n",
      "232                     1                      1                   1\n",
      "237                     1                      1                   1\n",
      "241                     0                      1                   1\n",
      "244                     1                      1                   1\n",
      "250                     1                      5                   1\n",
      "257                     1                      5                   1\n",
      "264                     1                      2                   2\n",
      "266                     1                      1                   1\n",
      "274                     1                      5                   5\n",
      "275                     1                      5                   1\n",
      "280                     1                      5                   5\n",
      "283                     1                      5                   1\n",
      "290                     1                      1                   4\n",
      "291                     1                      1                   1\n",
      "295                     1                      1                   1\n",
      "296                     1                      1                   5\n",
      "302                     1                      4                   5\n",
      "303                     1                      4                   5\n",
      "305                     1                      1                   5\n",
      "318                     1                      2                   2\n",
      "323                     1                      1                   1\n",
      "327                     1                      2                   1\n",
      "330                     1                      1                   5\n",
      "339                     1                      5                   5\n",
      "340                     1                      5                   5\n",
      "341                     1                      5                   5\n",
      "345                     1                      5                   5\n",
      "347                     1                      1                   5\n",
      "355                     1                      5                   1\n",
      "361                     1                      1                   1\n",
      "363                     1                      1                   5\n",
      "364                     1                      1                   1\n",
      "365                     1                      4                   4\n",
      "366                     1                      1                   4\n",
      "372                     0                      4                   4\n",
      "373                     1                      4                   4\n",
      "376                     1                      4                   5\n",
      "377                     1                      5                   5\n",
      "386                     1                      2                   2\n",
      "    pumping_equipment_impl elevation_building_impl\n",
      "7                        5                       1\n",
      "10                       5                       1\n",
      "11                       5                       1\n",
      "20                       5                       1\n",
      "22                       5                       4\n",
      "24                       5                       1\n",
      "28                       5                       4\n",
      "29                       5                       4\n",
      "47                       1                       4\n",
      "53                       1                       1\n",
      "62                       1                       4\n",
      "64                       5                       1\n",
      "68                       5                       1\n",
      "79                       1                       4\n",
      "87                       5                       4\n",
      "96                       5                       4\n",
      "103                      5                       1\n",
      "105                      5                       1\n",
      "110                      5                       4\n",
      "113                      1                       4\n",
      "114                      5                       4\n",
      "117                      1                       4\n",
      "118                      1                       4\n",
      "129                      5                       4\n",
      "132                      5                       1\n",
      "136                      5                       4\n",
      "141                      5                       4\n",
      "143                      1                       1\n",
      "150                      1                       1\n",
      "151                      1                       4\n",
      "152                      5                       1\n",
      "162                      5                       4\n",
      "163                      5                       1\n",
      "164                      1                       4\n",
      "165                      4                       1\n",
      "173                      5                       1\n",
      "175                      5                       1\n",
      "177                      4                       4\n",
      "183                      5                       5\n",
      "184                      4                       5\n",
      "185                      4                       5\n",
      "186                      5                       1\n",
      "193                      5                       4\n",
      "194                      4                       4\n",
      "195                      5                       1\n",
      "202                      4                       4\n",
      "203                      1                       4\n",
      "204                      1                       1\n",
      "207                      5                       4\n",
      "209                      1                       4\n",
      "210                      1                       1\n",
      "232                      1                       1\n",
      "237                      5                       4\n",
      "241                      5                       1\n",
      "244                      5                       1\n",
      "250                      5                       4\n",
      "257                      5                       1\n",
      "264                      5                       4\n",
      "266                      5                       2\n",
      "274                      5                       1\n",
      "275                      1                       2\n",
      "280                      5                       2\n",
      "283                      1                       2\n",
      "290                      5                       2\n",
      "291                      5                       1\n",
      "295                      5                       1\n",
      "296                      1                       1\n",
      "302                      5                       2\n",
      "303                      2                       4\n",
      "305                      1                       2\n",
      "318                      2                       1\n",
      "323                      5                       4\n",
      "327                      5                       2\n",
      "330                      1                       4\n",
      "339                      1                       1\n",
      "340                      1                       1\n",
      "341                      5                       4\n",
      "345                      5                       4\n",
      "347                      1                       1\n",
      "355                      1                       4\n",
      "361                      5                       1\n",
      "363                      5                       1\n",
      "364                      5                       4\n",
      "365                      4                       5\n",
      "366                      4                       5\n",
      "372                      4                       4\n",
      "373                      5                       2\n",
      "376                      1                       4\n",
      "377                      1                       1\n",
      "386                      1                       1\n",
      "    resistant_material_building_impl electricity_higher_impl\n",
      "7                                  5                       5\n",
      "10                                 5                       5\n",
      "11                                 5                       5\n",
      "20                                 5                       5\n",
      "22                                 5                       4\n",
      "24                                 5                       1\n",
      "28                                 5                       5\n",
      "29                                 4                       4\n",
      "47                                 5                       5\n",
      "53                                 5                       1\n",
      "62                                 5                       5\n",
      "64                                 5                       5\n",
      "68                                 5                       1\n",
      "79                                 5                       4\n",
      "87                                 5                       1\n",
      "96                                 5                       5\n",
      "103                                5                       5\n",
      "105                                5                       5\n",
      "110                                5                       4\n",
      "113                                5                       1\n",
      "114                                5                       1\n",
      "117                                5                       4\n",
      "118                                4                       4\n",
      "129                                5                       5\n",
      "132                                5                       1\n",
      "136                                5                       5\n",
      "141                                5                       5\n",
      "143                                4                       5\n",
      "150                                5                       1\n",
      "151                                5                       1\n",
      "152                                5                       1\n",
      "162                                5                       4\n",
      "163                                5                       5\n",
      "164                                5                       5\n",
      "165                                5                       5\n",
      "173                                5                       5\n",
      "175                                5                       5\n",
      "177                                5                       5\n",
      "183                                5                       5\n",
      "184                                5                       1\n",
      "185                                4                       4\n",
      "186                                1                       5\n",
      "193                                5                       4\n",
      "194                                5                       4\n",
      "195                                5                       1\n",
      "202                                5                       5\n",
      "203                                4                       4\n",
      "204                                1                       5\n",
      "207                                5                       1\n",
      "209                                5                       5\n",
      "210                                5                       1\n",
      "232                                5                       5\n",
      "237                                5                       5\n",
      "241                                5                       5\n",
      "244                                5                       1\n",
      "250                                5                       5\n",
      "257                                5                       5\n",
      "264                                5                       4\n",
      "266                                5                       5\n",
      "274                                5                       1\n",
      "275                                5                       5\n",
      "280                                5                       5\n",
      "283                                5                       1\n",
      "290                                5                       5\n",
      "291                                5                       5\n",
      "295                                5                       1\n",
      "296                                1                       5\n",
      "302                                5                       2\n",
      "303                                5                       4\n",
      "305                                5                       5\n",
      "318                                5                       2\n",
      "323                                5                       4\n",
      "327                                5                       5\n",
      "330                                4                       4\n",
      "339                                5                       5\n",
      "340                                5                       1\n",
      "341                                5                       5\n",
      "345                                5                       5\n",
      "347                                4                       5\n",
      "355                                5                       5\n",
      "361                                5                       5\n",
      "363                                5                       5\n",
      "364                                5                       1\n",
      "365                                5                       1\n",
      "366                                4                       4\n",
      "372                                5                       4\n",
      "373                                5                       2\n",
      "376                                4                       4\n",
      "377                                1                       5\n",
      "386                                5                       5\n",
      "    flood_protections_impl flood_experience elevation_building_height_cm bage\n",
      "7                        5                4                           20   21\n",
      "10                       5                4                           30   22\n",
      "11                       5                1                           20   45\n",
      "20                       5                2                          200   33\n",
      "22                       5                4                          100    0\n",
      "24                       5                5                           70   45\n",
      "28                       5                4                           40   17\n",
      "29                       5                5                           20   14\n",
      "47                       5                2                          110    6\n",
      "53                       5                5                           80   30\n",
      "62                       5                3                           70   19\n",
      "64                       5                5                           40   18\n",
      "68                       5                5                          100   30\n",
      "79                       5                5                          100   21\n",
      "87                       5                6                          110   19\n",
      "96                       5                6                          150    5\n",
      "103                      5                5                           80   12\n",
      "105                      5                3                          100   12\n",
      "110                      5                5                          150   13\n",
      "113                      5                6                           30   31\n",
      "114                      1                6                           50   25\n",
      "117                      5                6                          100   19\n",
      "118                      5                6                          120    7\n",
      "129                      5                5                          120   20\n",
      "132                      5                6                           70    3\n",
      "136                      5                6                          100   51\n",
      "141                      5                2                           30   62\n",
      "143                      5                5                           70   47\n",
      "150                      5                4                           40   10\n",
      "151                      5                5                          110   14\n",
      "152                      5                5                          100   17\n",
      "162                      5                4                           20   24\n",
      "163                      5                5                           50   20\n",
      "164                      5                4                          110   16\n",
      "165                      5                4                          120   35\n",
      "173                      5                6                           40   12\n",
      "175                      5                5                           70   15\n",
      "177                      5                4                          100    8\n",
      "183                      5                3                           60   21\n",
      "184                      5                6                           40   57\n",
      "185                      5                6                          150   12\n",
      "186                      5                4                           50   23\n",
      "193                      4                6                           60   10\n",
      "194                      5                6                          150   20\n",
      "195                      5                5                           60    0\n",
      "202                      5                5                           80   23\n",
      "203                      5                6                          100   19\n",
      "204                      1                6                           80   16\n",
      "207                      5                6                           50    6\n",
      "209                      5                4                          150   28\n",
      "210                      5                5                          120    9\n",
      "232                      5                5                           80    6\n",
      "237                      5                6                           60   14\n",
      "241                      5                2                           20   24\n",
      "244                      5                6                           60   33\n",
      "250                      5                4                           50    5\n",
      "257                      5                4                           30   20\n",
      "264                      5                4                          100    0\n",
      "266                      5                6                           50   27\n",
      "274                      5                5                           60   24\n",
      "275                      5                4                           60   17\n",
      "280                      5                6                          100   22\n",
      "283                      5                5                           80   26\n",
      "290                      5                4                           60   18\n",
      "291                      5                5                           40   17\n",
      "295                      5                5                          100   28\n",
      "296                      5                4                           50   19\n",
      "302                      5                6                          150   42\n",
      "303                      5                5                          100   20\n",
      "305                      5                6                           40    5\n",
      "318                      5                5                           40   23\n",
      "323                      5                5                          150   13\n",
      "327                      5                6                           30   18\n",
      "330                      5                6                          120    3\n",
      "339                      5                6                           70   46\n",
      "340                      5                5                          150   19\n",
      "341                      5                5                          120   20\n",
      "345                      5                2                           30   62\n",
      "347                      5                5                           70   42\n",
      "355                      5                4                          110   16\n",
      "361                      5                6                           40   12\n",
      "363                      5                5                           70   15\n",
      "364                      5                5                           80   12\n",
      "365                      5                6                           40   56\n",
      "366                      5                6                          150   14\n",
      "372                      5                6                          150   20\n",
      "373                      5                5                           60    0\n",
      "376                      5                6                          100   18\n",
      "377                      1                6                           80   11\n",
      "386                      5                5                           80    3\n",
      "    b_area hh_monthly_income_cat shp_owner shp_sector shp_employees\n",
      "7     54.0                     7         1         17             2\n",
      "10    45.0                     3         3         17             2\n",
      "11    35.0                     3         3         12             1\n",
      "20    90.0                     4         3         17             2\n",
      "22    45.0                     3         3         11             2\n",
      "24    55.0                     3         3         31             3\n",
      "28    50.0                     4         3         31             1\n",
      "29    20.0                     3         3         17             1\n",
      "47   140.0                     5         3         21             9\n",
      "53    90.0                     2         1         11             1\n",
      "62   120.0                     4         1         11             2\n",
      "64    16.0                     4         1         11             2\n",
      "68    35.0                     2         1         11             1\n",
      "79    98.0                     3         3         17             1\n",
      "87    74.0                     4         2         17             2\n",
      "96    87.0                     5         3         23             1\n",
      "103  115.0                     3         3         17             1\n",
      "105   15.0                     3         1         11             2\n",
      "110   50.0                     3         1         15             2\n",
      "113  200.0                     4         1         11             1\n",
      "114   40.0                     3         1         17             2\n",
      "117   40.0                     4        88         88             2\n",
      "118   40.0                     3         1         21             1\n",
      "129  118.0                     4         3         17             1\n",
      "132   20.0                     3         1         17             1\n",
      "136   50.0                     2         1         24             1\n",
      "141   36.0                     2         3         11             1\n",
      "143   50.0                     3         3         11             2\n",
      "150   90.0                     3         3         14             2\n",
      "151 1000.0                     8         2         88            34\n",
      "152   80.0                     2         3         11             2\n",
      "162  120.0                     3         3         24             4\n",
      "163   40.0                     3         3         14             2\n",
      "164   50.0                     2         3         17             2\n",
      "165   20.0                     2         3         17             2\n",
      "173   43.0                     4         1         17             1\n",
      "175   15.0                     3         1         11             1\n",
      "177  850.0                     3         1         11             2\n",
      "183   72.0                     3         3         88             2\n",
      "184   56.0                     3         3         24             1\n",
      "185   48.0                     5         3         17             1\n",
      "186  125.0                     3         1         17             1\n",
      "193   50.0                     5         3         14             2\n",
      "194  120.0                     6         3         11             2\n",
      "195   28.0                     5         3         17             2\n",
      "202  150.0                     4         1         17             2\n",
      "203   50.0                     4         3         17             1\n",
      "204   48.0                     4         1         11             3\n",
      "207   35.0                     3         3         17             1\n",
      "209  240.0                     3         3         11             2\n",
      "210   92.8                     3         3         17             2\n",
      "232   80.0                     3         3         17             2\n",
      "237   90.0                     3         3         11             2\n",
      "241  120.0                     4         3         11             2\n",
      "244  120.0                     3         1         24             1\n",
      "250   60.0                     4         3         17             2\n",
      "257   45.0                     3         3         17             2\n",
      "264   45.0                     3         3         11             2\n",
      "266   40.0                     3         3         11             2\n",
      "274   65.0                     4         1         11             1\n",
      "275   50.0                     5         1         11             1\n",
      "280  160.0                     7         3         21             7\n",
      "283   90.0                     2         1         11             1\n",
      "290   80.0                     3         1         17             1\n",
      "291   16.0                     4         1         11             2\n",
      "295   35.0                     2         1         11             1\n",
      "296   80.0                     4         1         17             4\n",
      "302  156.0                     3         3         11             4\n",
      "303   98.0                     3         3         17             1\n",
      "305   80.0                     3         3         17             1\n",
      "318   56.0                     4         3         17             1\n",
      "323   50.0                     3         1         15             2\n",
      "327   80.0                     2         1         17             2\n",
      "330   40.0                     3         1         21             1\n",
      "339  110.0                     4         3         17             2\n",
      "340   84.0                     3         3         11             2\n",
      "341  118.0                     4         3         17             1\n",
      "345   36.0                     2         3         11             1\n",
      "347   50.0                     3         3         11             2\n",
      "355   50.0                     2         3         17             2\n",
      "361   43.0                     4         1         17             1\n",
      "363   15.0                     3         1         11             1\n",
      "364   40.0                     3         1         11             1\n",
      "365   56.0                     3         3         24             1\n",
      "366   48.0                     5         3         17             1\n",
      "372  120.0                     6         3         11             2\n",
      "373   28.0                     5         3         17             2\n",
      "376   50.0                     4         3         17             1\n",
      "377   48.0                     4         1         11             3\n",
      "386   80.0                     3         3         17             2\n",
      "    shp_avgmonthly_sale_cat resilience_govern_careing_increases\n",
      "7                         4                                   3\n",
      "10                        1                                   1\n",
      "11                        1                                   1\n",
      "20                        2                                   5\n",
      "22                        2                                   3\n",
      "24                        2                                   5\n",
      "28                        2                                   1\n",
      "29                        2                                   4\n",
      "47                        3                                   1\n",
      "53                        1                                   5\n",
      "62                        1                                   3\n",
      "64                        2                                   3\n",
      "68                        1                                   2\n",
      "79                        1                                   2\n",
      "87                        2                                   1\n",
      "96                        3                                   3\n",
      "103                       2                                   1\n",
      "105                       2                                   3\n",
      "110                       2                                   3\n",
      "113                       1                                   1\n",
      "114                       1                                   1\n",
      "117                       1                                   1\n",
      "118                       2                                   3\n",
      "129                       1                                   1\n",
      "132                       1                                   1\n",
      "136                       1                                   2\n",
      "141                       1                                   2\n",
      "143                       1                                   1\n",
      "150                       2                                   1\n",
      "151                       5                                   5\n",
      "152                       1                                   1\n",
      "162                       3                                   2\n",
      "163                       3                                   1\n",
      "164                       1                                   1\n",
      "165                       1                                   1\n",
      "173                       3                                   2\n",
      "175                       2                                   3\n",
      "177                       2                                   3\n",
      "183                       2                                   2\n",
      "184                       1                                   4\n",
      "185                       1                                   2\n",
      "186                       1                                   2\n",
      "193                       3                                   3\n",
      "194                       3                                   4\n",
      "195                       3                                   3\n",
      "202                       2                                   1\n",
      "203                       2                                   1\n",
      "204                       3                                   1\n",
      "207                       1                                   4\n",
      "209                       2                                   1\n",
      "210                       1                                   1\n",
      "232                       2                                   2\n",
      "237                       2                                   1\n",
      "241                       2                                   1\n",
      "244                       2                                   2\n",
      "250                       2                                   1\n",
      "257                       1                                   1\n",
      "264                       2                                   3\n",
      "266                       2                                   3\n",
      "274                       2                                   4\n",
      "275                       1                                   3\n",
      "280                       4                                   1\n",
      "283                       1                                   5\n",
      "290                       2                                   3\n",
      "291                       2                                   3\n",
      "295                       1                                   2\n",
      "296                       3                                   4\n",
      "302                       3                                   1\n",
      "303                       1                                   2\n",
      "305                       2                                   1\n",
      "318                       2                                   1\n",
      "323                       2                                   3\n",
      "327                       1                                   1\n",
      "330                       2                                   3\n",
      "339                       2                                   1\n",
      "340                       2                                   1\n",
      "341                       1                                   1\n",
      "345                       1                                   2\n",
      "347                       1                                   1\n",
      "355                       1                                   1\n",
      "361                       3                                   2\n",
      "363                       2                                   3\n",
      "364                       1                                   1\n",
      "365                       1                                   4\n",
      "366                       1                                   2\n",
      "372                       3                                   4\n",
      "373                       3                                   3\n",
      "376                       2                                   1\n",
      "377                       3                                   1\n",
      "386                       2                                   2\n",
      "    shp_content_value_euro shp_registered_capital_euro\n",
      "7                  12889.0                      3682.6\n",
      "10                  9206.4                       441.9\n",
      "11                 18412.8                       368.3\n",
      "20                 14730.3                      1473.0\n",
      "22                 12889.0                      1473.0\n",
      "24                 16571.5                       736.5\n",
      "28                 18412.8                       736.5\n",
      "29                  9206.4                       294.6\n",
      "47                  5523.8                     14730.3\n",
      "53                 44190.8                       184.1\n",
      "62                 73651.3                        73.7\n",
      "64                 12889.0                       662.9\n",
      "68                  5523.8                      1841.3\n",
      "79                 36825.6                      1841.3\n",
      "87                 18412.8                      2946.1\n",
      "96                 16571.5                     14730.3\n",
      "103                36825.6                      2946.1\n",
      "105                 3682.6                       368.3\n",
      "110                14730.3                      3682.6\n",
      "113                16571.5                       368.3\n",
      "114                11047.7                       736.5\n",
      "117                11047.7                      1841.3\n",
      "118                13809.6                      2946.1\n",
      "129                11047.7                      2577.8\n",
      "132                 7365.1                       441.9\n",
      "136                18412.8                       736.5\n",
      "141                 9206.4                       368.3\n",
      "143                18412.8                       331.4\n",
      "150                14730.3                     18412.8\n",
      "151               202541.0                    699687.0\n",
      "152                18412.8                      1473.0\n",
      "162                16571.5                      7365.1\n",
      "163                12889.0                       368.3\n",
      "164                14730.3                       736.5\n",
      "165                 9206.4                       368.3\n",
      "173                10127.0                      1841.3\n",
      "175                 3682.6                       110.5\n",
      "177               110476.9                      1104.8\n",
      "183                 5523.8                      7365.1\n",
      "184                36825.6                       552.4\n",
      "185                 5523.8                       368.3\n",
      "186                55238.4                       110.5\n",
      "193                22095.4                     22095.4\n",
      "194                27619.2                      2577.8\n",
      "195                 1841.3                      1841.3\n",
      "202                36825.6                       736.5\n",
      "203                 7365.1                      1841.3\n",
      "204                27619.2                       147.3\n",
      "207                 7365.1                      1473.0\n",
      "209                29460.5                      3682.6\n",
      "210                14730.3                      3682.6\n",
      "232                 9206.4                      1104.8\n",
      "237                16571.5                      1473.0\n",
      "241                18412.8                      2209.5\n",
      "244                16571.5                      1473.0\n",
      "250                18412.8                      3682.6\n",
      "257                 9206.4                       441.9\n",
      "264                12889.0                      1473.0\n",
      "266                 9206.4                       552.4\n",
      "274                14730.3                       368.3\n",
      "275                 7365.1                        55.2\n",
      "280                25777.9                    110476.9\n",
      "283                44190.8                       184.1\n",
      "290                18412.8                       368.3\n",
      "291                12889.0                       662.9\n",
      "295                 5523.8                      1841.3\n",
      "296                55238.4                      1104.8\n",
      "302                14730.3                      1841.3\n",
      "303                36825.6                      1841.3\n",
      "305                18412.8                      1104.8\n",
      "318                12889.0                      1841.3\n",
      "323                14730.3                      3682.6\n",
      "327                12889.0                      1841.3\n",
      "330                13809.6                      2946.1\n",
      "339                 9206.4                      2946.1\n",
      "340                 7365.1                      2209.5\n",
      "341                11047.7                      2577.8\n",
      "345                 9206.4                       368.3\n",
      "347                18412.8                       331.4\n",
      "355                14730.3                       736.5\n",
      "361                10127.0                      1841.3\n",
      "363                 3682.6                       110.5\n",
      "364                 9206.4                       184.1\n",
      "365                36825.6                       552.4\n",
      "366                 5523.8                       368.3\n",
      "372                27619.2                      2577.8\n",
      "373                 1841.3                      1841.3\n",
      "376                 7365.1                      1841.3\n",
      "377                27619.2                       147.3\n",
      "386                 9206.4                      1104.8\n",
      "\n",
      "$y\n",
      "       7       10       11       20       22       24       28       29 \n",
      "    29.5     18.4     18.4   1473.0    268.1      7.4     76.5    168.6 \n",
      "      47       53       62       64       68       79       87       96 \n",
      "  1494.6     55.2     18.7     55.2     73.7     36.8    267.9   1288.5 \n",
      "     103      105      110      113      114      117      118      129 \n",
      "   119.0     79.3   1189.8    224.2     36.8     19.8    119.0    153.1 \n",
      "     132      136      141      143      150      151      152      162 \n",
      "    26.2     37.4     74.7     44.8   2615.6 224190.4     37.4    373.7 \n",
      "     163      164      165      173      175      177      183      184 \n",
      "    73.7     84.3    421.4   1473.0     11.0  34120.0    793.2    368.3 \n",
      "     185      186      193      194      195      202      203      204 \n",
      "    44.7    186.8   1868.3   1121.0    405.1    112.1     37.4     76.5 \n",
      "     207      209      210      232      237      241      244      250 \n",
      "    76.5    124.2     82.8    149.5    149.5     37.4    110.5     74.7 \n",
      "     257      264      266      274      275      280      283      290 \n",
      "    38.3    268.1     39.7     38.3     39.7   3624.4     82.8     38.3 \n",
      "     291      295      296      302      303      305      318      323 \n",
      "    56.0    382.7     74.7    178.5    224.2     37.4    373.7   1189.8 \n",
      "     327      330      339      340      341      345      347      355 \n",
      "   632.1    214.8   4552.9    165.6    650.6     74.7  24851.1    126.4 \n",
      "     361      363      364      365      366      372      373      376 \n",
      "  1473.0     36.8    268.1    448.4     82.8   1121.0    368.3     76.5 \n",
      "     377      386 \n",
      "   214.8    248.3 \n",
      "\n",
      "$yfinal\n",
      "       7       10       11       20       22       24       28       29 \n",
      "    29.5     18.4     18.4   1473.0    268.1      7.4     76.5    168.6 \n",
      "      47       53       62       64       68       79       87       96 \n",
      "  1494.6     55.2     18.7     55.2     73.7     36.8    267.9   1288.5 \n",
      "     103      105      110      113      114      117      118      129 \n",
      "   119.0     79.3   1189.8    224.2     36.8     19.8    119.0    153.1 \n",
      "     132      136      141      143      150      151      152      162 \n",
      "    26.2     37.4     74.7     44.8   2615.6 224190.4     37.4    373.7 \n",
      "     163      164      165      173      175      177      183      184 \n",
      "    73.7     84.3    421.4   1473.0     11.0  34120.0    793.2    368.3 \n",
      "     185      186      193      194      195      202      203      204 \n",
      "    44.7    186.8   1868.3   1121.0    405.1    112.1     37.4     76.5 \n",
      "     207      209      210      232      237      241      244      250 \n",
      "    76.5    124.2     82.8    149.5    149.5     37.4    110.5     74.7 \n",
      "     257      264      266      274      275      280      283      290 \n",
      "    38.3    268.1     39.7     38.3     39.7   3624.4     82.8     38.3 \n",
      "     291      295      296      302      303      305      318      323 \n",
      "    56.0    382.7     74.7    178.5    224.2     37.4    373.7   1189.8 \n",
      "     327      330      339      340      341      345      347      355 \n",
      "   632.1    214.8   4552.9    165.6    650.6     74.7  24851.1    126.4 \n",
      "     361      363      364      365      366      372      373      376 \n",
      "  1473.0     36.8    268.1    448.4     82.8   1121.0    368.3     76.5 \n",
      "     377      386 \n",
      "   214.8    248.3 \n",
      "\n",
      "$final_fit\n",
      "Conditional Inference Random Forest \n",
      "\n",
      "90 samples\n",
      "30 predictors\n",
      "\n",
      "No pre-processing\n",
      "Resampling: Cross-Validated (10 fold, repeated 5 times) \n",
      "Summary of sample sizes: 81, 81, 82, 81, 81, 82, ... \n",
      "Resampling results across tuning parameters:\n",
      "\n",
      "  mtry  RMSE      Rsquared   MAE     \n",
      "   2    11574.84  0.2686700  5929.593\n",
      "  16    12634.98  0.3216620  5951.404\n",
      "  30    13623.26  0.3327763  6138.566\n",
      "\n",
      "MAE was used to select the optimal model using the largest value.\n",
      "The final value used for the model was mtry = 30.\n",
      "\n",
      "$final_vars\n",
      " [1] \"inundation_duration_h\"               \"water_depth_cm\"                     \n",
      " [3] \"contaminations.0\"                    \"flowvelocity\"                       \n",
      " [5] \"emergency_measures.1\"                \"emergency_measures.2\"               \n",
      " [7] \"emergency_measures.3\"                \"emergency_measures.4\"               \n",
      " [9] \"emergency_measures.7\"                \"emergency_measures.8\"               \n",
      "[11] \"overall_problem_house\"               \"protect_valuables_impl\"             \n",
      "[13] \"water_barriers_impl\"                 \"pumping_equipment_impl\"             \n",
      "[15] \"elevation_building_impl\"             \"resistant_material_building_impl\"   \n",
      "[17] \"electricity_higher_impl\"             \"flood_protections_impl\"             \n",
      "[19] \"flood_experience\"                    \"elevation_building_height_cm\"       \n",
      "[21] \"bage\"                                \"b_area\"                             \n",
      "[23] \"hh_monthly_income_cat\"               \"shp_owner\"                          \n",
      "[25] \"shp_sector\"                          \"shp_employees\"                      \n",
      "[27] \"shp_avgmonthly_sale_cat\"             \"resilience_govern_careing_increases\"\n",
      "[29] \"shp_content_value_euro\"              \"shp_registered_capital_euro\"        \n",
      "\n",
      "$roc\n",
      "NULL\n",
      "\n",
      "$trControl\n",
      "$trControl$method\n",
      "[1] \"repeatedcv\"\n",
      "\n",
      "$trControl$number\n",
      "[1] 10\n",
      "\n",
      "$trControl$repeats\n",
      "[1] 5\n",
      "\n",
      "$trControl$search\n",
      "[1] \"grid\"\n",
      "\n",
      "$trControl$p\n",
      "[1] 0.75\n",
      "\n",
      "$trControl$initialWindow\n",
      "NULL\n",
      "\n",
      "$trControl$horizon\n",
      "[1] 1\n",
      "\n",
      "$trControl$fixedWindow\n",
      "[1] TRUE\n",
      "\n",
      "$trControl$skip\n",
      "[1] 0\n",
      "\n",
      "$trControl$verboseIter\n",
      "[1] FALSE\n",
      "\n",
      "$trControl$returnData\n",
      "[1] TRUE\n",
      "\n",
      "$trControl$returnResamp\n",
      "[1] \"final\"\n",
      "\n",
      "$trControl$savePredictions\n",
      "[1] FALSE\n",
      "\n",
      "$trControl$classProbs\n",
      "[1] FALSE\n",
      "\n",
      "$trControl$summaryFunction\n",
      "function (data, lev = NULL, model = NULL) \n",
      "{\n",
      "    if (is.character(data$obs)) \n",
      "        data$obs <- factor(data$obs, levels = lev)\n",
      "    postResample(data[, \"pred\"], data[, \"obs\"])\n",
      "}\n",
      "<bytecode: 0x000001d26c979a98>\n",
      "<environment: namespace:caret>\n",
      "\n",
      "$trControl$selectionFunction\n",
      "[1] \"best\"\n",
      "\n",
      "$trControl$preProcOptions\n",
      "$trControl$preProcOptions$thresh\n",
      "[1] 0.95\n",
      "\n",
      "$trControl$preProcOptions$ICAcomp\n",
      "[1] 3\n",
      "\n",
      "$trControl$preProcOptions$k\n",
      "[1] 5\n",
      "\n",
      "$trControl$preProcOptions$freqCut\n",
      "[1] 19\n",
      "\n",
      "$trControl$preProcOptions$uniqueCut\n",
      "[1] 10\n",
      "\n",
      "$trControl$preProcOptions$cutoff\n",
      "[1] 0.9\n",
      "\n",
      "\n",
      "$trControl$sampling\n",
      "NULL\n",
      "\n",
      "$trControl$index\n",
      "NULL\n",
      "\n",
      "$trControl$indexOut\n",
      "NULL\n",
      "\n",
      "$trControl$indexFinal\n",
      "NULL\n",
      "\n",
      "$trControl$timingSamps\n",
      "[1] 0\n",
      "\n",
      "$trControl$predictionBounds\n",
      "[1] FALSE FALSE\n",
      "\n",
      "$trControl$seeds\n",
      "[1] NA\n",
      "\n",
      "$trControl$adaptive\n",
      "$trControl$adaptive$min\n",
      "[1] 5\n",
      "\n",
      "$trControl$adaptive$alpha\n",
      "[1] 0.05\n",
      "\n",
      "$trControl$adaptive$method\n",
      "[1] \"gls\"\n",
      "\n",
      "$trControl$adaptive$complete\n",
      "[1] TRUE\n",
      "\n",
      "\n",
      "$trControl$trim\n",
      "[1] FALSE\n",
      "\n",
      "$trControl$allowParallel\n",
      "[1] TRUE\n",
      "\n",
      "\n",
      "$bestTunes\n",
      "       mtry\n",
      "Fold 1   16\n",
      "Fold 2   30\n",
      "\n",
      "$finalTune\n",
      "  mtry\n",
      "3   30\n",
      "\n",
      "$summary\n",
      "     RMSE    Rsquared         MAE   \n",
      "2.433e+04   2.087e-03   5.904e+03   \n",
      "\n",
      "attr(,\"class\")\n",
      "[1] \"nestcv.train\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "crf_ncv = nestedcv.nestcv_train(\n",
    "    y=y, x=X,\n",
    "    method=\"cforest\",\n",
    "    savePredictions=\"final\",\n",
    "    outer_train_predict=True,\n",
    "    n_outer_folds=2,\n",
    "    n_inner_folds=2,\n",
    "    #tuneGrid=tg,\n",
    "    #cv_cores=2,  # leads to random errors\n",
    "    metric='MAE',#'RMSE',  # RMSE unit of target or use MAE due that more robust than RMSE further metrics options Rsquared, RMSE, MAE \n",
    "        # RMSE penalizes large gaps more harshly than MAE\n",
    "    maximize=True,\n",
    "    # #na_action =  stats.na_pass,\n",
    "    controls = #party.cforest_control( \n",
    "        party.cforest_unbiased(\n",
    "        # only mtry gets tuned by grid\n",
    "        mtry=2,  # mtry=0 =Bagging without random input var sampling\n",
    "        ntree = 100,  # didnt improved with 200 or 500 trees\n",
    "        # mincriterion = 0.05,   # the value of the test statistic (for testtype == \"Teststatistic\"), or 1 - p-value (for other values of testtype) that must be exceeded in order to implement a split.\n",
    "        #replace = False,\n",
    "        #fraction = 0.632,   # fraction of number of observations to draw without replacement (only relevant if replace = FALSE).\n",
    "    ),  # cforest_unbiased= subsampling without replacement repalce=False a\n",
    "    trControl = caret.trainControl(\n",
    "        method = \"repeatedcv\",  # \"oob\" - then no repeats are needed\n",
    "        number = 10,   ## = K-folds\n",
    "        repeats = 5,  # number of tried values for mtry\n",
    "        #savePredictions = \"final\"  # saves predictions from optimal tuning parameters\n",
    "    )\n",
    ")\n",
    "print(crf_ncv)\n",
    "# without maximize: 2.405e+04   2.098e-03   5.734e+03   \n",
    "# with maximize=True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Fitting final model using CV on whole data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Performing 2-fold outer CV, using 1 core\n",
      "\n",
      "R[write to console]: Duration: 21.05331 secs\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<emph>ListVector</emph> with 16 elements:\n",
       "<table class=\"rpy2_table\">\n",
       "<thead>\n",
       "</thead>\n",
       "<tbody>\n",
       "  <tr>\n",
       "    <td class=\"rpy2_rowname\">0</td>\n",
       "    <td class=\"rpy2_names\">call</td>\n",
       "    <td>$call\n",
       "(fu...</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td class=\"rpy2_rowname\">1</td>\n",
       "    <td class=\"rpy2_names\">output</td>\n",
       "    <td>        ...</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td class=\"rpy2_rowname\">2</td>\n",
       "    <td class=\"rpy2_names\">outer_result</td>\n",
       "    <td>[[1]]\n",
       "[[1...</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td class=\"rpy2_rowname\">3</td>\n",
       "    <td class=\"rpy2_names\">outer_method</td>\n",
       "    <td>['cv']</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td class=\"rpy2_rowname\">4</td>\n",
       "    <td class=\"rpy2_names\">outer_folds</td>\n",
       "    <td>$Fold1\n",
       "...</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td class=\"rpy2_rowname\">5</td>\n",
       "    <td class=\"rpy2_names\">dimx</td>\n",
       "    <td>[1] 90 30\n",
       "</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td class=\"rpy2_rowname\">6</td>\n",
       "    <td class=\"rpy2_names\">xsub</td>\n",
       "    <td>   ...</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td class=\"rpy2_rowname\">7</td>\n",
       "    <td class=\"rpy2_names\">y</td>\n",
       "    <td>[2.950000...</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td class=\"rpy2_rowname\">...</td>\n",
       "    <td class=\"rpy2_names\">...</td>\n",
       "    <td>...</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td class=\"rpy2_rowname\">14</td>\n",
       "    <td class=\"rpy2_names\">finalTune</td>\n",
       "    <td>  mtry\n",
       "3   30\n",
       "</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td class=\"rpy2_rowname\">15</td>\n",
       "    <td class=\"rpy2_names\">summary</td>\n",
       "    <td>[2.433276...</td>\n",
       "  </tr>\n",
       "</tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<rpy2.robjects.vectors.ListVector object at 0x000001D251C0DF40> [RTYPES.VECSXP]\n",
       "R classes: ('nestcv.train',)\n",
       "[LangSexpV..., ListSexpV..., ListSexpV..., StrSexpVe..., ..., ListSexpV..., ListSexpV..., ListSexpV..., FloatSexp...]\n",
       "  call: <class 'rpy2.robjects.language.LangVector'>\n",
       "  Rlang( (function (y, x, method = \"rf\", filterFUN = NULL, filter_options = NULL,  )\n",
       "<rpy2.robjects.vectors.ListVector object at 0x000001D251C0DF40> [RTYPES.VECSXP]\n",
       "R classes: ('nestcv.train',)\n",
       "[LangSexpV..., ListSexpV..., ListSexpV..., StrSexpVe..., ..., ListSexpV..., ListSexpV..., ListSexpV..., FloatSexp...]\n",
       "<rpy2.robjects.vectors.ListVector object at 0x000001D251C0DF40> [RTYPES.VECSXP]\n",
       "R classes: ('nestcv.train',)\n",
       "[LangSexpV..., ListSexpV..., ListSexpV..., StrSexpVe..., ..., ListSexpV..., ListSexpV..., ListSexpV..., FloatSexp...]\n",
       "  outer_method: <class 'numpy.ndarray'>\n",
       "  array(['cv'], dtype='<U2')\n",
       "...\n",
       "<rpy2.robjects.vectors.ListVector object at 0x000001D251C0DF40> [RTYPES.VECSXP]\n",
       "R classes: ('nestcv.train',)\n",
       "[LangSexpV..., ListSexpV..., ListSexpV..., StrSexpVe..., ..., ListSexpV..., ListSexpV..., ListSexpV..., FloatSexp...]\n",
       "<rpy2.robjects.vectors.ListVector object at 0x000001D251C0DF40> [RTYPES.VECSXP]\n",
       "R classes: ('nestcv.train',)\n",
       "[LangSexpV..., ListSexpV..., ListSexpV..., StrSexpVe..., ..., ListSexpV..., ListSexpV..., ListSexpV..., FloatSexp...]\n",
       "<rpy2.robjects.vectors.ListVector object at 0x000001D251C0DF40> [RTYPES.VECSXP]\n",
       "R classes: ('nestcv.train',)\n",
       "[LangSexpV..., ListSexpV..., ListSexpV..., StrSexpVe..., ..., ListSexpV..., ListSexpV..., ListSexpV..., FloatSexp...]\n",
       "  yfinal: <class 'numpy.ndarray'>\n",
       "  array([2.43327619e+04, 2.08688731e-03, 5.90411958e+03])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit = nestedcv.nestcv_glmnet(y, X,\n",
    "#     family = \"multinomial\",\n",
    "#     alpha = 1,\n",
    "#     n_outer_folds = 3)\n",
    "crf_ncv\n",
    "#nestedcv.innercv_summary(crf_ncv)\n",
    "#nestedcv.predSummary(crf_ncv)\n",
    "#nestedcv.summary(crf_ncv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conditional Inference Random Forest \n",
      "\n",
      "90 samples\n",
      "30 predictors\n",
      "\n",
      "No pre-processing\n",
      "Resampling: Cross-Validated (10 fold, repeated 5 times) \n",
      "Summary of sample sizes: 82, 80, 81, 82, 80, 82, ... \n",
      "Resampling results across tuning parameters:\n",
      "\n",
      "  mtry  RMSE      Rsquared   MAE     \n",
      "   2    12117.59  0.2585249  6246.422\n",
      "  16    13133.54  0.3203579  6257.250\n",
      "  30    13991.25  0.3413818  6335.243\n",
      "\n",
      "MAE was used to select the optimal model using the largest value.\n",
      "The final value used for the model was mtry = 30.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<rpy2.rinterface_lib.sexp.NULLType object at 0x000001D257860C00> [RTYPES.NILSXP]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## test nested CV \n",
    "\n",
    "base.set_seed(seed)\n",
    "## CV method\n",
    "fitControl = caret.trainControl(\n",
    "    method = \"repeatedcv\",  # \"oob\" - then no repeats are needed\n",
    "    number = 10,   ## = K-folds\n",
    "    repeats = 5,  # number of tried values for mtry\n",
    "    #savePredictions = \"final\"  # saves predictions from optimal tuning parameters\n",
    ")\n",
    "\n",
    "# robjects.r('''\n",
    "#         r_grid <- function(verbose=FALSE) {\n",
    "#             expand.grid(ntree=10)#         }     ''')\n",
    "# f = robjects.globalenv['r_grid']\n",
    "# createCfGrid = base.expand_grid(controls = party.cforest_control(mtry=3, ntree=200)) #qnorm() =90th percentile\n",
    "# mincriterion=stats.qnorm(0.9) # = default\n",
    "# \" train() will generate the grid for you. If you want to specify ntree you just pass a controls object in as another argument to train but leave out mtry:\"\"\n",
    "# https://stackoverflow.com/questions/20337137/run-cforest-with-controls-cforest-unbiased-using-caret-package?rq=4\n",
    "\n",
    "\n",
    "## CIT handles by default missing values in response, while CRF doesnt accept missing vlaues in response\n",
    "base.set_seed(seed)\n",
    "\n",
    "# tg = expand.grid(\n",
    "#     lambda=exp(seq(log(2e-3) , log(1e0), length.out=100)),\n",
    "#     alpha=seq(0.8, 1, 0.1))\n",
    "\n",
    "crf_cv = caret.train(\n",
    "        Formula(f'{target} ~ .'), \n",
    "        data = df_candidates,\n",
    "        method = \"cforest\",\n",
    "        metric='MAE',#'RMSE',  # RMSE unit of target or use MAE due that more robust than RMSE further metrics options Rsquared, RMSE, MAE \n",
    "        # RMSE penalizes large gaps more harshly than MAE\n",
    "        maximize=True,\n",
    "        #na_action =  stats.na_pass,\n",
    "        controls = #party.cforest_control( \n",
    "            party.cforest_unbiased(\n",
    "            # only mtry gets tuned by grid\n",
    "            mtry=2,  # mtry=0 =Bagging without random input var sampling\n",
    "            ntree = 100,  # didnt improved with 200 or 500 trees\n",
    "           # mincriterion = 0.05,   # the value of the test statistic (for testtype == \"Teststatistic\"), or 1 - p-value (for other values of testtype) that must be exceeded in order to implement a split.\n",
    "            #replace = False,\n",
    "            #fraction = 0.632,   # fraction of number of observations to draw without replacement (only relevant if replace = FALSE).\n",
    "        ),  # cforest_unbiased= subsampling without replacement repalce=False a\n",
    "        trControl = fitControl,\n",
    "        #tuneGrid = #params_grid, # createCfGrid\n",
    "        #verbose = False\n",
    "    )\n",
    "print(crf_cv) # 5687.575\n",
    "\n",
    "base.warnings()\n",
    "\n",
    "#  2    12073.87  0.2206921  6275.344   # cforest_control\n",
    "#  2    12117.59  0.2585249  6246.422   # unbiased version\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size (76, 30)\n",
      "Test size (14, 30)\n"
     ]
    }
   ],
   "source": [
    "## test train split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.15, \n",
    "    random_state=seed, shuffle=True\n",
    ")\n",
    "\n",
    "# normlaize via MinMaxScaler, transform X_train ,then use the fitted scaler for X_test\n",
    "X_train, X_test = fs.normalize_X(X_train, X_test)\n",
    "\n",
    "print(\"Training size\", X_train.shape)\n",
    "print(\"Test size\", X_test.shape)\n",
    "\n",
    "train = pd.concat([y_train.reset_index(), X_train], axis=1).drop(\"index\", axis=1)\n",
    "test = pd.concat([y_test.reset_index(), X_test], axis=1).drop(\"index\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## target transformations to test\n",
    "# train_log = train.copy()\n",
    "# train_quantile = train.copy()\n",
    "# train_boxcox = train.copy()\n",
    "# train_sqrt = train.copy()\n",
    "\n",
    "# train_log[target] = np.log(train[target])\n",
    "# target_quantile = quantile_transform(np.array(train[target]).reshape(-1, 1), n_quantiles=100, \n",
    "#         output_distribution=\"normal\",\n",
    "#         random_state=seed, copy=True\n",
    "#     ) # n_quantiles def=1000 or n_samples\n",
    "# train_quantile[target] = pd.Series(target_quantile.reshape(-1, ))\n",
    "\n",
    "# train_sqrt[target] = np.sqrt(train[target])\n",
    "# train_boxcox[target] = stats.boxcox(np.array(train[target]).reshape(-1,)+0.0001)[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t Random Forest using Conditional Inference Trees\n",
      "\n",
      "Number of trees:  300 \n",
      "\n",
      "Response:  Target_contentloss_euro \n",
      "Inputs:  inundation_duration_h, water_depth_cm, contaminations.0, flowvelocity, emergency_measures.1, emergency_measures.2, emergency_measures.3, emergency_measures.4, emergency_measures.7, emergency_measures.8, overall_problem_house, protect_valuables_impl, water_barriers_impl, pumping_equipment_impl, elevation_building_impl, resistant_material_building_impl, electricity_higher_impl, flood_protections_impl, flood_experience, elevation_building_height_cm, bage, b_area, hh_monthly_income_cat, shp_owner, shp_sector, shp_employees, shp_avgmonthly_sale_cat, resilience_govern_careing_increases, shp_content_value_euro, shp_registered_capital_euro \n",
      "Number of observations:  76 \n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<rpy2.rinterface_lib.sexp.NULLType object at 0x000001D257860C00> [RTYPES.NILSXP]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##  CV with gridSearch from R \n",
    "## Due that cforest is a R package it only accepts other R functions for tunning and cross validation  \n",
    "## CIT handles by default missing values in response, while CRF doesnt accept missing vlaues in response\n",
    "\n",
    "# ## Define the hyperparamters\n",
    "## NOTE: cant define hyperparameter ranges for cforest, caret.train(method=\"cforest\") is doing this by itself\n",
    "## train() Doc: https://search.r-project.org/CRAN/refmans/caret/html/train.html\n",
    "\n",
    "base.set_seed(seed)\n",
    "## CV method\n",
    "fitControl = caret.trainControl(\n",
    "    method = \"repeatedcv\",  # \"oob\" - then no repeats are needed\n",
    "    number = 10,   ## = K-folds\n",
    "    repeats = 5,  # number of tried values for mtry\n",
    "    #savePredictions = \"final\"  # saves predictions from optimal tuning parameters\n",
    "    )\n",
    "\n",
    "# robjects.r('''\n",
    "#         r_grid <- function(verbose=FALSE) {\n",
    "#             expand.grid(ntree=10)\n",
    "#         }\n",
    "#     ''')\n",
    "# f = robjects.globalenv['r_grid']\n",
    "# createCfGrid = base.expand_grid(controls = party.cforest_control(mtry=3, ntree=200)) #qnorm() =90th percentile\n",
    "# mincriterion=stats.qnorm(0.9) # = default\n",
    "# \" train() will generate the grid for you. If you want to specify ntree you just pass a controls object in as another argument to train but leave out mtry:\"\"\n",
    "# https://stackoverflow.com/questions/20337137/run-cforest-with-controls-cforest-unbiased-using-caret-package?rq=4\n",
    "\n",
    " \n",
    "## CIT handles by default missing values in response, while CRF doesnt accept missing vlaues in response\n",
    "# base.set_seed(seed)\n",
    "# crf_cv = caret.train(\n",
    "#         Formula(f'{target} ~ .'), \n",
    "#         data = train,\n",
    "#         method = \"cforest\",\n",
    "#         metric='MAE',#'RMSE',  # RMSE unit of target or use MAE due that more robust than RMSE further metrics options Rsquared, RMSE, MAE \n",
    "#         # RMSE penalizes large gaps more harshly than MAE\n",
    "#         maximize=True,\n",
    "#         #na_action =  stats.na_pass,\n",
    "#         controls = #party.cforest_control( \n",
    "#             party.cforest_unbiased(\n",
    "#             # only mtry gets tuned by grid\n",
    "#             mtry=2,  # mtry=0 =Bagging without random input var sampling\n",
    "#             ntree = 100,  # didnt improved with 200 or 500 trees\n",
    "#            # mincriterion = 0.05,   # the value of the test statistic (for testtype == \"Teststatistic\"), or 1 - p-value (for other values of testtype) that must be exceeded in order to implement a split.\n",
    "#             #replace = False,\n",
    "#             #fraction = 0.632,   # fraction of number of observations to draw without replacement (only relevant if replace = FALSE).\n",
    "#         ),  # cforest_unbiased= subsampling without replacement repalce=False a\n",
    "#         trControl = fitControl,\n",
    "        #tuneGrid = #params_grid, # createCfGrid\n",
    "        #verbose = False\n",
    "#    )\n",
    "\n",
    "#base.set_seed(seed)\n",
    "crf_cv = party.cforest(Formula(f'{target} ~ .'),  \n",
    "    data=train,\n",
    "    # data=pd.concat(\n",
    "    #         [y.reset_index(), pd.DataFrame(X, columns=X_unscaled.columns)], \n",
    "    #         axis=1,\n",
    "    #         ).drop(\"index\", axis=1),\n",
    "    #weights=1,\n",
    "    control= party.cforest_control(mtry=2, ntree=300)\n",
    "    #control= party.cforest_unbiased(mtry=best_hyperparameters.mtry, ntree=300)\n",
    "    #control = partykit.ctree_control(mincriterion = 0.8)\n",
    ")\n",
    "\n",
    "print(crf_cv) # 5687.575\n",
    "\n",
    "base.warnings()\n",
    "\n",
    "# models_trained = {}         # incl no transformation\n",
    "# for idx, train_ds in enumerate([train, train_quantile, train_boxcox, train_sqrt, train_log]):\n",
    "# #for train_ds in [{train: \"no transformation\"}, {train_log:\"natural log\"}, {train_quantile: \"quantile\"}, {train_boxcox:\"box-cox\"}, {train_sqrt:\"sqrt\"}]:\n",
    "#     transf_type = [\"no\", \"quantile\", \"boxcox\", \"sqrt\", \"natural-log\"][idx]\n",
    "# models_trained[f\"cit_{transf_type}_cv\"] = \n",
    "# m = caret.train(\n",
    "#         Formula(f'{target} ~ .'), \n",
    "#         data = train,\n",
    "#         method = \"cforest\",\n",
    "#         metric='MAE',#'RMSE',  # RMSE unit of target or use MAE due that more robust than RMSE further metrics options Rsquared, RMSE, MAE \n",
    "#         # RMSE penalizes large gaps more harshly than MAE\n",
    "#         #maximize=True,\n",
    "#         #na_action =  stats_r.na_pass,\n",
    "#         controls = party.cforest_control( \n",
    "#             #party.cforest_unbiased(\n",
    "#             # only mtry gets tuned by grid\n",
    "#             mtry=2,  # mtry=0 =Bagging without random input var sampling\n",
    "#             ntree = 100,  # didnt improved with 200 or 500 trees\n",
    "#            # mincriterion = 0.05,   # the value of the test statistic (for testtype == \"Teststatistic\"), or 1 - p-value (for other values of testtype) that must be exceeded in order to implement a split.\n",
    "#             replace = False,\n",
    "#             #fraction = 0.632,   # fraction of number of observations to draw without replacement (only relevant if replace = FALSE).\n",
    "#         ),  # cforest_unbiased= subsampling without replacement repalce=False a\n",
    "#         trControl = fitControl,\n",
    "#         #tuneGrid = #params_grid, # createCfGrid\n",
    "#         #verbose = False\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test conditional permutation importance (discussed by Debeer & Stobl 2020)\n",
    "Replace party::varimp() by more stable (in regard to FI score for multiple repeats) and computational faster permimp:permimp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "permimp = importr(\"permimp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76, 31)\n",
      "(14, 31)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)\n",
    "\n",
    "varimp = party.varimp(crf_cv, conditional=False)  # old FI apporach (probably also based on permutation)\n",
    "#party.varimp(crf_cv, conditional = True )\n",
    "fi = permimp.permimp(crf_cv, conditional=True, progressBar=False)\n",
    "# Error in permimp.default(list(method = \"cforest\", modelInfo = list(label = \"Conditional Inference Random Forest\",  : \n",
    "#   The permimp functions only works for random forest objects from the party- and randomForest-packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<emph>ListVector</emph> with 4 elements:\n",
       "<table class=\"rpy2_table\">\n",
       "<thead>\n",
       "</thead>\n",
       "<tbody>\n",
       "  <tr>\n",
       "    <td class=\"rpy2_rowname\">0</td>\n",
       "    <td class=\"rpy2_names\">values</td>\n",
       "    <td>[-1.07569...</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td class=\"rpy2_rowname\">1</td>\n",
       "    <td class=\"rpy2_names\">perTree</td>\n",
       "    <td>   ...</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td class=\"rpy2_rowname\">2</td>\n",
       "    <td class=\"rpy2_names\">type</td>\n",
       "    <td>['Conditi...</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td class=\"rpy2_rowname\">3</td>\n",
       "    <td class=\"rpy2_names\">info</td>\n",
       "    <td>$threshol...</td>\n",
       "  </tr>\n",
       "</tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<rpy2.robjects.vectors.ListVector object at 0x000001D27E1BFC00> [RTYPES.VECSXP]\n",
       "R classes: ('VarImp',)\n",
       "[FloatSexpV..., ListSexpVe..., StrSexpVec..., ListSexpVe...]\n",
       "  values: <class 'rpy2.rinterface.FloatSexpVector'>\n",
       "  <rpy2.rinterface.FloatSexpVector object at 0x000001D27E35EAC0> [RTYPES.REALSXP]\n",
       "  perTree: <class 'rpy2.rinterface.ListSexpVector'>\n",
       "  <rpy2.rinterface.ListSexpVector object at 0x000001D27E35E480> [RTYPES.VECSXP]\n",
       "  type: <class 'rpy2.rinterface_lib.sexp.StrSexpVector'>\n",
       "  <rpy2.rinterface_lib.sexp.StrSexpVector object at 0x000001D27E35EBC0> [RTYPES.STRSXP]\n",
       "  info: <class 'rpy2.rinterface.ListSexpVector'>\n",
       "  <rpy2.rinterface.ListSexpVector object at 0x000001D27E35EA00> [RTYPES.VECSXP]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fi#[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<emph>ListVector</emph> with 4 elements:\n",
       "<table class=\"rpy2_table\">\n",
       "<thead>\n",
       "</thead>\n",
       "<tbody>\n",
       "  <tr>\n",
       "    <td class=\"rpy2_rowname\">0</td>\n",
       "    <td class=\"rpy2_names\">values</td>\n",
       "    <td>[-1.63776...</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td class=\"rpy2_rowname\">1</td>\n",
       "    <td class=\"rpy2_names\">perTree</td>\n",
       "    <td>   ...</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td class=\"rpy2_rowname\">2</td>\n",
       "    <td class=\"rpy2_names\">type</td>\n",
       "    <td>['Conditi...</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td class=\"rpy2_rowname\">3</td>\n",
       "    <td class=\"rpy2_names\">info</td>\n",
       "    <td>$threshol...</td>\n",
       "  </tr>\n",
       "</tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<rpy2.robjects.vectors.ListVector object at 0x000001D27E2A7580> [RTYPES.VECSXP]\n",
       "R classes: ('VarImp',)\n",
       "[FloatSexpV..., ListSexpVe..., StrSexpVec..., ListSexpVe...]\n",
       "  values: <class 'rpy2.rinterface.FloatSexpVector'>\n",
       "  <rpy2.rinterface.FloatSexpVector object at 0x000001D27E34BC00> [RTYPES.REALSXP]\n",
       "  perTree: <class 'rpy2.rinterface.ListSexpVector'>\n",
       "  <rpy2.rinterface.ListSexpVector object at 0x000001D27D184D40> [RTYPES.VECSXP]\n",
       "  type: <class 'rpy2.rinterface_lib.sexp.StrSexpVector'>\n",
       "  <rpy2.rinterface_lib.sexp.StrSexpVector object at 0x000001D27E35A400> [RTYPES.STRSXP]\n",
       "  info: <class 'rpy2.rinterface.ListSexpVector'>\n",
       "  <rpy2.rinterface.ListSexpVector object at 0x000001D27E35A6C0> [RTYPES.VECSXP]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_importance = pd.DataFrame(\n",
    "            {f\"{model_name}_importances\" : fi[0]},\n",
    "            index=X_unscaled.columns.to_list(),\n",
    "        ) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Error in h(simpleError(msg, call)) : \n",
      "  error in evaluating the argument 'object' in selecting a method for function 'show': could not find function \"train.formula\"\n",
      "\n",
      "R[write to console]: Error in train.formula(form = Target_contentloss_euro ~ ., data = list( : \n",
      "  could not find function \"train.formula\"\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76, 31)\n",
      "(14, 31)\n"
     ]
    },
    {
     "ename": "RRuntimeError",
     "evalue": "Error in train.formula(form = Target_contentloss_euro ~ ., data = list( : \n  could not find function \"train.formula\"\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mRRuntimeError\u001b[0m                             Traceback (most recent call last)\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\py396_c3\\lib\\site-packages\\rpy2\\robjects\\robject.py:115\u001b[0m, in \u001b[0;36mRObjectMixin.__str__\u001b[1;34m(self)\u001b[0m\n",
      "\u001b[0;32m    114\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[1;32m--> 115\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__show(\u001b[39mself\u001b[39;49m)\n",
      "\u001b[0;32m    116\u001b[0m     \u001b[39m# There can be situation where an invalid call to R`s\u001b[39;00m\n",
      "\u001b[0;32m    117\u001b[0m     \u001b[39m# show is made. Possibly some form of signature overriding\u001b[39;00m\n",
      "\u001b[0;32m    118\u001b[0m     \u001b[39m# that goes through in R through dispatch (although it\u001b[39;00m\n",
      "\u001b[0;32m    119\u001b[0m     \u001b[39m# should not?). In that case this is an problem upstream\u001b[39;00m\n",
      "\u001b[0;32m    120\u001b[0m     \u001b[39m# and this try/except is a workaround until it gets fixed.\u001b[39;00m\n",
      "\u001b[0;32m    121\u001b[0m     \u001b[39m# (issue #908).\u001b[39;00m\n",
      "\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\py396_c3\\lib\\site-packages\\rpy2\\rinterface_lib\\conversion.py:45\u001b[0m, in \u001b[0;36m_cdata_res_to_rinterface.<locals>._\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m     44\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n",
      "\u001b[1;32m---> 45\u001b[0m     cdata \u001b[39m=\u001b[39m function(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[0;32m     46\u001b[0m     \u001b[39m# TODO: test cdata is of the expected CType\u001b[39;00m\n",
      "\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\py396_c3\\lib\\site-packages\\rpy2\\rinterface.py:873\u001b[0m, in \u001b[0;36mSexpClosure.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m    872\u001b[0m     \u001b[39mif\u001b[39;00m error_occured[\u001b[39m0\u001b[39m]:\n",
      "\u001b[1;32m--> 873\u001b[0m         \u001b[39mraise\u001b[39;00m embedded\u001b[39m.\u001b[39mRRuntimeError(_rinterface\u001b[39m.\u001b[39m_geterrmessage())\n",
      "\u001b[0;32m    874\u001b[0m \u001b[39mreturn\u001b[39;00m res\n",
      "\n",
      "\u001b[1;31mRRuntimeError\u001b[0m: Error in h(simpleError(msg, call)) : \n",
      "  error in evaluating the argument 'object' in selecting a method for function 'show': could not find function \"train.formula\"\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[1;31mRRuntimeError\u001b[0m                             Traceback (most recent call last)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\formatters.py:339\u001b[0m, in \u001b[0;36mBaseFormatter.__call__\u001b[1;34m(self, obj)\u001b[0m\n",
      "\u001b[0;32m    337\u001b[0m     \u001b[39mpass\u001b[39;00m\n",
      "\u001b[0;32m    338\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;32m--> 339\u001b[0m     \u001b[39mreturn\u001b[39;00m printer(obj)\n",
      "\u001b[0;32m    340\u001b[0m \u001b[39m# Finally look for special method names\u001b[39;00m\n",
      "\u001b[0;32m    341\u001b[0m method \u001b[39m=\u001b[39m get_real_method(obj, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_method)\n",
      "\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\py396_c3\\lib\\site-packages\\rpy2\\ipython\\html.py:262\u001b[0m, in \u001b[0;36mhtml_rlist\u001b[1;34m(vector, display_nrowmax, size_tail, table_class)\u001b[0m\n",
      "\u001b[0;32m    257\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mhtml_rlist\u001b[39m(vector,\n",
      "\u001b[0;32m    258\u001b[0m                display_nrowmax\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m,\n",
      "\u001b[0;32m    259\u001b[0m                size_tail\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n",
      "\u001b[0;32m    260\u001b[0m                table_class\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrpy2_table\u001b[39m\u001b[39m'\u001b[39m):\n",
      "\u001b[0;32m    261\u001b[0m     rg \u001b[39m=\u001b[39m \u001b[39mrange\u001b[39m(\u001b[39mmax\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39mlen\u001b[39m(vector)\u001b[39m-\u001b[39msize_tail), \u001b[39mlen\u001b[39m(vector))\n",
      "\u001b[1;32m--> 262\u001b[0m     html \u001b[39m=\u001b[39m template_vector_vertical\u001b[39m.\u001b[39;49mrender({\n",
      "\u001b[0;32m    263\u001b[0m         \u001b[39m'\u001b[39;49m\u001b[39mtable_class\u001b[39;49m\u001b[39m'\u001b[39;49m: table_class,\n",
      "\u001b[0;32m    264\u001b[0m         \u001b[39m'\u001b[39;49m\u001b[39mclsname\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39mtype\u001b[39;49m(vector)\u001b[39m.\u001b[39;49m\u001b[39m__name__\u001b[39;49m,\n",
      "\u001b[0;32m    265\u001b[0m         \u001b[39m'\u001b[39;49m\u001b[39mvector\u001b[39;49m\u001b[39m'\u001b[39;49m: vector,\n",
      "\u001b[0;32m    266\u001b[0m         \u001b[39m'\u001b[39;49m\u001b[39mhas_vector_names\u001b[39;49m\u001b[39m'\u001b[39;49m: vector\u001b[39m.\u001b[39;49mnames \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m rinterface\u001b[39m.\u001b[39;49mNULL,\n",
      "\u001b[0;32m    267\u001b[0m         \u001b[39m'\u001b[39;49m\u001b[39mdisplay_nrowmax\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39mmin\u001b[39;49m(display_nrowmax, \u001b[39mlen\u001b[39;49m(vector)),\n",
      "\u001b[0;32m    268\u001b[0m         \u001b[39m'\u001b[39;49m\u001b[39msize_tail\u001b[39;49m\u001b[39m'\u001b[39;49m: size_tail,\n",
      "\u001b[0;32m    269\u001b[0m         \u001b[39m'\u001b[39;49m\u001b[39melt_i_tail\u001b[39;49m\u001b[39m'\u001b[39;49m: rg})\n",
      "\u001b[0;32m    270\u001b[0m     \u001b[39mreturn\u001b[39;00m html\n",
      "\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\py396_c3\\lib\\site-packages\\jinja2\\environment.py:1301\u001b[0m, in \u001b[0;36mTemplate.render\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m   1299\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menvironment\u001b[39m.\u001b[39mconcat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mroot_render_func(ctx))  \u001b[39m# type: ignore\u001b[39;00m\n",
      "\u001b[0;32m   1300\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n",
      "\u001b[1;32m-> 1301\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menvironment\u001b[39m.\u001b[39;49mhandle_exception()\n",
      "\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\py396_c3\\lib\\site-packages\\jinja2\\environment.py:936\u001b[0m, in \u001b[0;36mEnvironment.handle_exception\u001b[1;34m(self, source)\u001b[0m\n",
      "\u001b[0;32m    931\u001b[0m \u001b[39m\"\"\"Exception handling helper.  This is used internally to either raise\u001b[39;00m\n",
      "\u001b[0;32m    932\u001b[0m \u001b[39mrewritten exceptions or return a rendered traceback for the template.\u001b[39;00m\n",
      "\u001b[0;32m    933\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n",
      "\u001b[0;32m    934\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdebug\u001b[39;00m \u001b[39mimport\u001b[39;00m rewrite_traceback_stack\n",
      "\u001b[1;32m--> 936\u001b[0m \u001b[39mraise\u001b[39;00m rewrite_traceback_stack(source\u001b[39m=\u001b[39msource)\n",
      "\n",
      "File \u001b[1;32m<template>:13\u001b[0m, in \u001b[0;36mtop-level template code\u001b[1;34m()\u001b[0m\n",
      "\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\py396_c3\\lib\\site-packages\\jinja2\\filters.py:1002\u001b[0m, in \u001b[0;36mdo_format\u001b[1;34m(value, *args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m    997\u001b[0m \u001b[39mif\u001b[39;00m args \u001b[39mand\u001b[39;00m kwargs:\n",
      "\u001b[0;32m    998\u001b[0m     \u001b[39mraise\u001b[39;00m FilterArgumentError(\n",
      "\u001b[0;32m    999\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mcan\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt handle positional and keyword arguments at the same time\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[0;32m   1000\u001b[0m     )\n",
      "\u001b[1;32m-> 1002\u001b[0m \u001b[39mreturn\u001b[39;00m soft_str(value) \u001b[39m%\u001b[39;49m (kwargs \u001b[39mor\u001b[39;49;00m args)\n",
      "\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\py396_c3\\lib\\site-packages\\rpy2\\robjects\\robject.py:124\u001b[0m, in \u001b[0;36mRObjectMixin.__str__\u001b[1;34m(self)\u001b[0m\n",
      "\u001b[0;32m    122\u001b[0m     \u001b[39mexcept\u001b[39;00m rpy2\u001b[39m.\u001b[39mrinterface\u001b[39m.\u001b[39membedded\u001b[39m.\u001b[39mRRuntimeError \u001b[39mas\u001b[39;00m rre:\n",
      "\u001b[0;32m    123\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mInvalid call to \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mshow()\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m in R: \u001b[39m\u001b[39m{\u001b[39;00mrre\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;32m--> 124\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__print(\u001b[39mself\u001b[39;49m)\n",
      "\u001b[0;32m    125\u001b[0m s \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m, s)\n",
      "\u001b[0;32m    126\u001b[0m \u001b[39mreturn\u001b[39;00m s\n",
      "\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\py396_c3\\lib\\site-packages\\rpy2\\rinterface_lib\\conversion.py:45\u001b[0m, in \u001b[0;36m_cdata_res_to_rinterface.<locals>._\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m     44\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n",
      "\u001b[1;32m---> 45\u001b[0m     cdata \u001b[39m=\u001b[39m function(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[0;32m     46\u001b[0m     \u001b[39m# TODO: test cdata is of the expected CType\u001b[39;00m\n",
      "\u001b[0;32m     47\u001b[0m     \u001b[39mreturn\u001b[39;00m _cdata_to_rinterface(cdata)\n",
      "\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\py396_c3\\lib\\site-packages\\rpy2\\rinterface.py:873\u001b[0m, in \u001b[0;36mSexpClosure.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m    866\u001b[0m     res \u001b[39m=\u001b[39m rmemory\u001b[39m.\u001b[39mprotect(\n",
      "\u001b[0;32m    867\u001b[0m         openrlib\u001b[39m.\u001b[39mrlib\u001b[39m.\u001b[39mR_tryEval(\n",
      "\u001b[0;32m    868\u001b[0m             call_r,\n",
      "\u001b[0;32m    869\u001b[0m             call_context\u001b[39m.\u001b[39m__sexp__\u001b[39m.\u001b[39m_cdata,\n",
      "\u001b[0;32m    870\u001b[0m             error_occured)\n",
      "\u001b[0;32m    871\u001b[0m     )\n",
      "\u001b[0;32m    872\u001b[0m     \u001b[39mif\u001b[39;00m error_occured[\u001b[39m0\u001b[39m]:\n",
      "\u001b[1;32m--> 873\u001b[0m         \u001b[39mraise\u001b[39;00m embedded\u001b[39m.\u001b[39mRRuntimeError(_rinterface\u001b[39m.\u001b[39m_geterrmessage())\n",
      "\u001b[0;32m    874\u001b[0m \u001b[39mreturn\u001b[39;00m res\n",
      "\n",
      "\u001b[1;31mRRuntimeError\u001b[0m: Error in train.formula(form = Target_contentloss_euro ~ ., data = list( : \n",
      "  could not find function \"train.formula\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<rpy2.robjects.vectors.ListVector object at 0x0000021E477FF580> [RTYPES.VECSXP]\n",
       "R classes: ('train', 'train.formula')\n",
       "[StrSexpVe..., ListSexpV..., StrSexpVe..., ListSexpV..., ..., BoolSexpV..., LangSexpV..., StrSexpVe..., ListSexpV...]\n",
       "  method: <class 'numpy.ndarray'>\n",
       "  array(['cforest'], dtype='<U7')\n",
       "<rpy2.robjects.vectors.ListVector object at 0x0000021E477FF580> [RTYPES.VECSXP]\n",
       "R classes: ('train', 'train.formula')\n",
       "[StrSexpVe..., ListSexpV..., StrSexpVe..., ListSexpV..., ..., BoolSexpV..., LangSexpV..., StrSexpVe..., ListSexpV...]\n",
       "  modelType: <class 'numpy.ndarray'>\n",
       "  array(['Regression'], dtype='<U10')\n",
       "<rpy2.robjects.vectors.ListVector object at 0x0000021E477FF580> [RTYPES.VECSXP]\n",
       "R classes: ('train', 'train.formula')\n",
       "[StrSexpVe..., ListSexpV..., StrSexpVe..., ListSexpV..., ..., BoolSexpV..., LangSexpV..., StrSexpVe..., ListSexpV...]\n",
       "...\n",
       "  bestTune: <class 'rpy2.robjects.vectors.BoolVector'>\n",
       "  <rpy2.robjects.vectors.BoolVector object at 0x0000021E5E1303C0> [RTYPES.LGLSXP]\n",
       "R classes: ('logical',)\n",
       "[NA]\n",
       "  call: <class 'rpy2.robjects.Formula'>\n",
       "  <rpy2.robjects.Formula object at 0x0000021E4764D200> [RTYPES.LANGSXP]\n",
       "R classes: ('terms', 'formula')\n",
       "  dots: <class 'numpy.ndarray'>\n",
       "  array(['inundation_duration_h', 'water_depth_cm', 'contaminations.0',\n",
       "       'flowvelocity', 'emergency_measures.1', 'emergency_measures.2',\n",
       "       'emergency_measures.3', 'emergency_measures.4',\n",
       "       'emergency_measures.7', 'emergency_measures.8',\n",
       "       'overall_problem_house', 'protect_valuables_impl',\n",
       "       'water_barriers_impl', 'pumping_equipment_impl',\n",
       "       'elevation_building_impl', 'resistant_material_building_impl',\n",
       "       'electricity_higher_impl', 'flood_protections_impl',\n",
       "       'flood_experience', 'elevation_building_height_cm', 'bage',\n",
       "       'b_area', 'hh_monthly_income_cat', 'shp_owner', 'shp_sector',\n",
       "       'shp_employees', 'shp_avgmonthly_sale_cat',\n",
       "       'resilience_govern_careing_increases', 'shp_content_value_euro',\n",
       "       'shp_registered_capital_euro'], dtype='<U35')\n",
       "<rpy2.robjects.vectors.ListVector object at 0x0000021E477FF580> [RTYPES.VECSXP]\n",
       "R classes: ('train', 'train.formula')\n",
       "[StrSexpVe..., ListSexpV..., StrSexpVe..., ListSexpV..., ..., BoolSexpV..., LangSexpV..., StrSexpVe..., ListSexpV...]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Empirical median ~ predicted median\n",
    "\n",
    "And further statitics compared to their empirical coutnerpart.\n",
    "-  mean /variance / std  compared to empirical distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIT:  Target_contentloss_euro\n",
      "(14, 30)\n",
      "y_test median: 96.85\n",
      "y_test mean: 271.9642857142857\n",
      "no\n",
      "973.9624431694617\n",
      "DescribeResult(nobs=14, minmax=(134.88039844019926, 16844.30185853222), mean=3559.783320559504, variance=33453257.45741129, skewness=1.8304053171834829, kurtosis=1.6676565896737214)\n",
      "quantile\n",
      "-0.05326385050003997\n",
      "DescribeResult(nobs=14, minmax=(-0.1725587024442954, 0.2574443967911894), mean=-0.027031089936802522, variance=0.017924055365391597, skewness=0.765807131297393, kurtosis=-0.42347996162618795)\n",
      "boxcox\n",
      "2.985739564048908\n",
      "DescribeResult(nobs=14, minmax=(2.919697891048595, 3.0823515467601386), mean=2.9950477139838716, variance=0.0024643930358130553, skewness=0.2526952352506137, kurtosis=-0.9999098489908715)\n",
      "sqrt\n",
      "24.64957400923098\n",
      "DescribeResult(nobs=14, minmax=(21.429810382708407, 29.442191107500317), mean=24.757678642247807, variance=5.650421846739868, skewness=0.7065185399242351, kurtosis=-0.06593704909733678)\n",
      "natural-log\n",
      "5.176853487041242\n",
      "DescribeResult(nobs=14, minmax=(4.986971088485798, 5.542900268381954), mean=5.188171541380997, variance=0.02866654043511827, skewness=0.5455928603197139, kurtosis=-0.6699581346896668)\n"
     ]
    }
   ],
   "source": [
    "print(\"CIT: \", target)\n",
    "print(X_test.shape)\n",
    "print(\"y_test median:\", np.median(y_test))\n",
    "print(\"y_test mean:\", np.mean(y_test))\n",
    "\n",
    "for model_name, model_cv in models_trained.items():\n",
    "\n",
    "    model_name = model_name.split(\"_\")[1]\n",
    "    print(model_name)\n",
    "    y_pred = stats_r.predict(model_cv, newdata=X_test)#, OOB=True, type=\"response\") #  type = \"prob\" # conditional class probabilities extractPrediction(\n",
    "    print(np.median(y_pred))\n",
    "    print(stats.describe(y_pred))\n",
    "# for model_name, model_cv in models_trained.items():\n",
    "#     print(model_name)\n",
    "#     print(stats.describe(\n",
    "    #e.empirical_vs_predicted(\n",
    "    #    X_test, y_test,\n",
    "    #    models_list=[model, model_log, model_quantile, model_boxcox, model_sqrt]    \n",
    "    #)\n",
    "\n",
    "## TODO idea: make a median/mean etc of best model as boxplots 8one (3 models for each target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cit_no_cv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Anna\\Documents\\UNI\\MA_topic\\flood-loss-models-4-HCMC\\feature-selection-from-remote-fs\\model_preprocessing\\Feature_selection\\crf_feature_selection.ipynb Cell 26\u001b[0m in \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Anna/Documents/UNI/MA_topic/flood-loss-models-4-HCMC/feature-selection-from-remote-fs/model_preprocessing/Feature_selection/crf_feature_selection.ipynb#X33sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# evalution results of the three tested models during CV and tunning\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Anna/Documents/UNI/MA_topic/flood-loss-models-4-HCMC/feature-selection-from-remote-fs/model_preprocessing/Feature_selection/crf_feature_selection.ipynb#X33sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m fs\u001b[39m.\u001b[39mr_models_cv_results(cit_no_cv)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cit_no_cv' is not defined"
     ]
    }
   ],
   "source": [
    "# evalution results of the three tested models during CV and tunning\n",
    "fs.r_models_cv_results(crf_cv)\n",
    "#models_trained.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_log' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Anna\\Documents\\UNI\\MA_topic\\flood-loss-models-4-HCMC\\feature-selection-from-remote-fs\\model_preprocessing\\Feature_selection\\crf_feature_selection.ipynb Cell 27\u001b[0m in \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Anna/Documents/UNI/MA_topic/flood-loss-models-4-HCMC/feature-selection-from-remote-fs/model_preprocessing/Feature_selection/crf_feature_selection.ipynb#X34sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m## store trained model for evaluation\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Anna/Documents/UNI/MA_topic/flood-loss-models-4-HCMC/feature-selection-from-remote-fs/model_preprocessing/Feature_selection/crf_feature_selection.ipynb#X34sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m filename \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m./models_trained/crf_\u001b[39m\u001b[39m{\u001b[39;00mtarget\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Anna/Documents/UNI/MA_topic/flood-loss-models-4-HCMC/feature-selection-from-remote-fs/model_preprocessing/Feature_selection/crf_feature_selection.ipynb#X34sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m pickle\u001b[39m.\u001b[39mdump(model_log, \u001b[39mopen\u001b[39m(filename, \u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model_log' is not defined"
     ]
    }
   ],
   "source": [
    "## store trained model for evaluation\n",
    "filename = f'./models_trained/crf_{target}'\n",
    "pickle.dump(model_log, open(filename, 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mtry\n",
      "1   2.0\n"
     ]
    }
   ],
   "source": [
    "## get best model\n",
    "\n",
    "#print(crf_cv.names)#$param\n",
    "best_hyperparameters = fs.r_best_hyperparamters(crf_cv)\n",
    "best_hyperparameters = fs.r_dataframe_to_pandas(best_hyperparameters)\n",
    "print(best_hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t Random Forest using Conditional Inference Trees\n",
      "\n",
      "Number of trees:  300 \n",
      "\n",
      "Response:  Target_contentloss_euro \n",
      "Inputs:  inundation_duration_h, water_depth_cm, contaminations.0, flowvelocity, emergency_measures.1, emergency_measures.2, emergency_measures.3, emergency_measures.4, emergency_measures.6, emergency_measures.7, emergency_measures.8, overall_problem_house, protect_valuables_impl, water_barriers_impl, pumping_equipment_impl, elevation_building_impl, resistant_material_building_impl, electricity_higher_impl, flood_protections_impl, flood_experience, elevation_rel2surrounding_cat, bage, b_area, hh_monthly_income_cat, shp_owner, shp_sector, shp_employees, shp_avgmonthly_sale_cat, contaminations_heavy \n",
      "Number of observations:  118 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## refit model with best hyperparamters\n",
    "#cit_model = partykit.ctree(Formula(f'{target} ~ .'),  \n",
    "crf_model = party.cforest(Formula(f'{target} ~ .'),  \n",
    "                                data=train,\n",
    "                                #weights=1,\n",
    "                                #control= party.cforest_control(mtry=best_hyperparameters.mtry, ntree=300)\n",
    "                                control= party.cforest_unbiased(mtry=best_hyperparameters.mtry, ntree=300)\n",
    "                                #control = partykit.ctree_control(mincriterion = 0.8)\n",
    "                          )\n",
    "print(crf_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rpy2.robjects.vectors.ListVector"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crf_model_eval = pickle.load(open(f\"./models_trained/crf_{target}\", 'rb'))\n",
    "\n",
    "#crf_model_eval = pickle.load(open(f\"./models_trained/crf_{target}\", 'rb'))\n",
    "type(crf_model_eval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target_contentloss_euro\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training set\n",
      "Model Performance:\n",
      "        Root Mean Square Error: 19855.52\n",
      "        Normalized Root Mean Square Error: 14.67\n",
      "        Mean Absolute Error: 4095.58\n",
      "        Mean Bias Error: 38.88\n",
      "        R²-Score: 0.075\n",
      "    \n",
      "\n",
      "Testing set\n",
      "Model Performance:\n",
      "        Root Mean Square Error: 8600.8\n",
      "        Normalized Root Mean Square Error: 9.82\n",
      "        Mean Absolute Error: 3933.96\n",
      "        Mean Bias Error: 548.47\n",
      "        R²-Score: 0.013\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mse</th>\n",
       "      <th>rmse</th>\n",
       "      <th>nrmse</th>\n",
       "      <th>mae</th>\n",
       "      <th>mbe</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>73973764.8</td>\n",
       "      <td>8600.800242</td>\n",
       "      <td>9.820836</td>\n",
       "      <td>3933.957143</td>\n",
       "      <td>548.471429</td>\n",
       "      <td>0.012932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          mse         rmse     nrmse          mae         mbe        r2\n",
       "0  73973764.8  8600.800242  9.820836  3933.957143  548.471429  0.012932"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Predict\n",
    "\n",
    "print(target)\n",
    "\n",
    "y_pred = stats_r.predict(crf_model_eval, newdata=X_test)#, OOB=True, type=\"response\") #  type = \"prob\" # conditional class probabilities extractPrediction(\n",
    "y_pred  = base.round(y_pred)\n",
    "\n",
    "## get back to python dtypes\n",
    "y_pred = np.array(y_pred)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "## print evaluation report + check for overfitting \n",
    "y_pred_train = np.round(stats_r.predict(crf_model_eval, newdata=X_train), 1)#.reshape(-1)\n",
    "print(\"\\nTraining set\")\n",
    "e.evaluation_report(y_train, y_pred_train)\n",
    "\n",
    "print(\"\\nTesting set\")\n",
    "e.evaluation_report(y_test, y_pred)  # 1590, 1306.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_sqrt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Anna\\Documents\\UNI\\MA_topic\\flood-loss-models-4-HCMC\\feature-selection-from-remote-fs\\model_preprocessing\\Feature_selection\\crf_feature_selection.ipynb Cell 36\u001b[0m in \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Anna/Documents/UNI/MA_topic/flood-loss-models-4-HCMC/feature-selection-from-remote-fs/model_preprocessing/Feature_selection/crf_feature_selection.ipynb#X50sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m## Code snippet from Danielas CRF script and from https://cran.r-project.org/web/packages/stablelearner/vignettes/forests.html\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Anna/Documents/UNI/MA_topic/flood-loss-models-4-HCMC/feature-selection-from-remote-fs/model_preprocessing/Feature_selection/crf_feature_selection.ipynb#X50sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Anna/Documents/UNI/MA_topic/flood-loss-models-4-HCMC/feature-selection-from-remote-fs/model_preprocessing/Feature_selection/crf_feature_selection.ipynb#X50sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m## Calculate variance importance based on selection frequency\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Anna/Documents/UNI/MA_topic/flood-loss-models-4-HCMC/feature-selection-from-remote-fs/model_preprocessing/Feature_selection/crf_feature_selection.ipynb#X50sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Anna/Documents/UNI/MA_topic/flood-loss-models-4-HCMC/feature-selection-from-remote-fs/model_preprocessing/Feature_selection/crf_feature_selection.ipynb#X50sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# Extract variable importance values from the model\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Anna/Documents/UNI/MA_topic/flood-loss-models-4-HCMC/feature-selection-from-remote-fs/model_preprocessing/Feature_selection/crf_feature_selection.ipynb#X50sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m varimp \u001b[39m=\u001b[39m party\u001b[39m.\u001b[39mvarimp(model_sqrt, conditional \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model_sqrt' is not defined"
     ]
    }
   ],
   "source": [
    "## Code snippet from Danielas CRF script and from https://cran.r-project.org/web/packages/stablelearner/vignettes/forests.html\n",
    "\n",
    "## Calculate variance importance based on selection frequency\n",
    "# varimp = party.varimp(model, measures=[\"freq\"])\n",
    "# varimp_df = pd.DataFrame({'Variable': varimp.names, 'Importance': varimp})\n",
    "## Sort the variable importance in descending order\n",
    "# varimp_df = varimp_df.sort_values(by='freq', ascending=False)\n",
    "## Plot the variance importance\n",
    "# varimp_df.plot(kind='bar', x='term', y='freq', figsize=(10, 6))\n",
    "\n",
    "# Extract variable importance values from the model\n",
    "varimp = party.varimp(model_sqrt, conditional = True )  # compute conditional variable importance scores\n",
    "# t = caret.varImp(crf_model)#, conditional=True) # caret derives FI a bit differently than party package\n",
    "# pd.DataFrame({\"names\":X.columns.to_list(), \"importances\":pd.Series(t)[0]}).sort_values(\"importances\", ascending=False).head(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get best model from model_list:\n",
    "\n",
    "for model_name, model_cv in models_trained.items():\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.19997089e+05,  2.23055806e+05,  0.00000000e+00,  3.97822201e+05,\n",
       "        1.23512119e+04, -6.12748497e+04, -3.82051254e+04, -3.18881921e+05,\n",
       "        7.70345205e+04,  1.45679200e+05,  0.00000000e+00, -1.39186059e+02,\n",
       "       -4.24174029e+05,  2.75498702e+05, -2.27007553e+03, -1.46943839e+05,\n",
       "       -3.19491218e+03, -5.40854200e+04,  0.00000000e+00,  1.05465621e+05,\n",
       "        2.94141327e+04, -2.34927585e+05, -4.95047254e+04,  1.77174178e+05,\n",
       "        7.06148940e+03, -1.99461282e+05,  3.35327042e+05,  9.28430465e+04,\n",
       "       -5.73933234e+01])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "varimp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(118,)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>importances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>flowvelocity</td>\n",
       "      <td>397822.200668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>shp_employees</td>\n",
       "      <td>335327.041844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>water_barriers_impl</td>\n",
       "      <td>275498.701596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>water_depth_cm</td>\n",
       "      <td>223055.805529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>hh_monthly_income_cat</td>\n",
       "      <td>177174.178024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     name    importances\n",
       "3            flowvelocity  397822.200668\n",
       "26          shp_employees  335327.041844\n",
       "13    water_barriers_impl  275498.701596\n",
       "1          water_depth_cm  223055.805529\n",
       "23  hh_monthly_income_cat  177174.178024"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # ## Feature importance \n",
    "\n",
    "\n",
    "df_importance = pd.DataFrame({\n",
    "    \"name\" : X_train.columns.to_list(),\n",
    "    \"importances\" : varimp,\n",
    "     }) \n",
    "df_importance = df_importance.sort_values(\"importances\", ascending=False)  # get most important features to the top\n",
    "df_importance.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "519997.0891648732\n",
      "519997.0891648732\n"
     ]
    }
   ],
   "source": [
    "## define threshold according to Hilpert 2020: \"The rule of thumb is to take the absolute minimum value as a cutoff point.\"\" \n",
    "fi_threshold = np.abs(np.min(varimp))\n",
    "fi_threshold\n",
    "print(fi_threshold)\n",
    "\n",
    "## this is to high set to fi_threshold = fi_threshold /10\n",
    "fi_threshold = fi_threshold # / 5\n",
    "print(fi_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fi_threshold = 20000\n",
    "df_importance = df_importance.loc[df_importance.importances > 0.000, : ]      # drop features which dont reduce the loss\n",
    "#df_importance = df_importance.loc[df_importance.importances > fi_threshold, : ]      # drop features which dont reduce the loss\n",
    "\n",
    "df_importance = df_importance.sort_values(\"importances\", ascending=True)\n",
    "print(\"5 most important features:\")\n",
    "df_importance.shape\n",
    "\n",
    "# plot feature importance\n",
    "#fig, ax = plt.subplots(figsize=(12,10))\n",
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "\n",
    "# keep only features which reduce the loss\n",
    "df_importance = df_importance.loc[df_importance.importances > 0, : ]\n",
    "\n",
    "sns.barplot(\n",
    "    data=df_importance, \n",
    "    x=\"importances\", y=\"name\",\n",
    "    width=0.4,\n",
    "    color='steelblue',\n",
    "    #errorbar=\"sd\",\n",
    "    errorbar=(\"pi\", 50), \n",
    "    capsize=.1, errcolor=\".5\",\n",
    "    linewidth=3, #edgecolor=\".3\", #facecolor=(0,0,0,0),\n",
    ")\n",
    "plt.ylabel(\"\")\n",
    "plt.xticks(\n",
    "    rotation = 90\n",
    "    )\n",
    "plt.title(f\"CRF (transform): Feature Importances for {target}\")\n",
    "plt.show()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index([24, 4, 20, 8, 27, 19, 9, 23, 1, 13, 26, 3], dtype='int64')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Anna\\Documents\\UNI\\MA_topic\\flood-loss-models-4-HCMC\\feature-selection-from-remote-fs\\model_preprocessing\\Feature_selection\\crf_feature_selection.ipynb Cell 40\u001b[0m in \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Anna/Documents/UNI/MA_topic/flood-loss-models-4-HCMC/feature-selection-from-remote-fs/model_preprocessing/Feature_selection/crf_feature_selection.ipynb#X50sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m selected_feat \u001b[39m=\u001b[39m df_importance\u001b[39m.\u001b[39mT\u001b[39m.\u001b[39mcolumns\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Anna/Documents/UNI/MA_topic/flood-loss-models-4-HCMC/feature-selection-from-remote-fs/model_preprocessing/Feature_selection/crf_feature_selection.ipynb#X50sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m## write selected predictors to disk\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Anna/Documents/UNI/MA_topic/flood-loss-models-4-HCMC/feature-selection-from-remote-fs/model_preprocessing/Feature_selection/crf_feature_selection.ipynb#X50sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m fs\u001b[39m.\u001b[39;49msave_selected_features(X_train, pd\u001b[39m.\u001b[39;49mDataFrame(y_train), selected_feat, filename\u001b[39m=\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m../../input_survey_data/fs_crf_\u001b[39;49m\u001b[39m{\u001b[39;49;00mtarget\u001b[39m}\u001b[39;49;00m\u001b[39m.xlsx\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\Anna\\Documents\\UNI\\MA_topic\\flood-loss-models-4-HCMC\\feature-selection-from-remote-fs\\model_preprocessing\\Feature_selection\\../../..\\utils\\utils_feature_selection.py:164\u001b[0m, in \u001b[0;36msave_selected_features\u001b[1;34m(X_train, y_train, selected_feat_cols, filename)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msave_selected_features\u001b[39m(X_train, y_train, selected_feat_cols, filename\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfs_model.xlsx\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    158\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[39m    Selects feautres from training set and saves them in excel file\u001b[39;00m\n\u001b[0;32m    160\u001b[0m \u001b[39m    X_train (df): X training set with predictors\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \u001b[39m    y_train (df): y training set with target\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[39m    selected_feat_cols (list): column names of selected features\u001b[39;00m\n\u001b[0;32m    163\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 164\u001b[0m     selected_feat \u001b[39m=\u001b[39m X_train\u001b[39m.\u001b[39;49mloc[:,selected_feat_cols]\n\u001b[0;32m    165\u001b[0m     not_selected_feat \u001b[39m=\u001b[39m X_train\u001b[39m.\u001b[39mdrop( selected_feat, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m    167\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mtotal features: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat((X_train\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m])))\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\py396_c3\\lib\\site-packages\\pandas\\core\\indexing.py:1097\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1095\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_scalar_access(key):\n\u001b[0;32m   1096\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_value(\u001b[39m*\u001b[39mkey, takeable\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_takeable)\n\u001b[1;32m-> 1097\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_tuple(key)\n\u001b[0;32m   1098\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1099\u001b[0m     \u001b[39m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m     axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39mor\u001b[39;00m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\py396_c3\\lib\\site-packages\\pandas\\core\\indexing.py:1289\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1286\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_multi_take_opportunity(tup):\n\u001b[0;32m   1287\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_multi_take(tup)\n\u001b[1;32m-> 1289\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_tuple_same_dim(tup)\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\py396_c3\\lib\\site-packages\\pandas\\core\\indexing.py:955\u001b[0m, in \u001b[0;36m_LocationIndexer._getitem_tuple_same_dim\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m    952\u001b[0m \u001b[39mif\u001b[39;00m com\u001b[39m.\u001b[39mis_null_slice(key):\n\u001b[0;32m    953\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m--> 955\u001b[0m retval \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39;49m(retval, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\u001b[39m.\u001b[39;49m_getitem_axis(key, axis\u001b[39m=\u001b[39;49mi)\n\u001b[0;32m    956\u001b[0m \u001b[39m# We should never have retval.ndim < self.ndim, as that should\u001b[39;00m\n\u001b[0;32m    957\u001b[0m \u001b[39m#  be handled by the _getitem_lowerdim call above.\u001b[39;00m\n\u001b[0;32m    958\u001b[0m \u001b[39massert\u001b[39;00m retval\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mndim\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\py396_c3\\lib\\site-packages\\pandas\\core\\indexing.py:1332\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1329\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(key, \u001b[39m\"\u001b[39m\u001b[39mndim\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m key\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1330\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCannot index with multidimensional key\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 1332\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_iterable(key, axis\u001b[39m=\u001b[39;49maxis)\n\u001b[0;32m   1334\u001b[0m \u001b[39m# nested tuple slicing\u001b[39;00m\n\u001b[0;32m   1335\u001b[0m \u001b[39mif\u001b[39;00m is_nested_tuple(key, labels):\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\py396_c3\\lib\\site-packages\\pandas\\core\\indexing.py:1272\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_iterable\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1269\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_key(key, axis)\n\u001b[0;32m   1271\u001b[0m \u001b[39m# A collection of keys\u001b[39;00m\n\u001b[1;32m-> 1272\u001b[0m keyarr, indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_listlike_indexer(key, axis)\n\u001b[0;32m   1273\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_reindex_with_indexers(\n\u001b[0;32m   1274\u001b[0m     {axis: [keyarr, indexer]}, copy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, allow_dups\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1275\u001b[0m )\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\py396_c3\\lib\\site-packages\\pandas\\core\\indexing.py:1462\u001b[0m, in \u001b[0;36m_LocIndexer._get_listlike_indexer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1459\u001b[0m ax \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_axis(axis)\n\u001b[0;32m   1460\u001b[0m axis_name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_axis_name(axis)\n\u001b[1;32m-> 1462\u001b[0m keyarr, indexer \u001b[39m=\u001b[39m ax\u001b[39m.\u001b[39;49m_get_indexer_strict(key, axis_name)\n\u001b[0;32m   1464\u001b[0m \u001b[39mreturn\u001b[39;00m keyarr, indexer\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\py396_c3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5876\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   5873\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   5874\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 5876\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   5878\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[0;32m   5879\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[0;32m   5880\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\py396_c3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5935\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   5933\u001b[0m     \u001b[39mif\u001b[39;00m use_interval_msg:\n\u001b[0;32m   5934\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[1;32m-> 5935\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   5937\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[0;32m   5938\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index([24, 4, 20, 8, 27, 19, 9, 23, 1, 13, 26, 3], dtype='int64')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "##Feature selection\n",
    "selected_feat = df_importance.T.columns\n",
    "\n",
    "## write selected predictors to disk\n",
    "fs.save_selected_features(X_train, pd.DataFrame(y_train), selected_feat, filename=f\"../../input_survey_data/fs_crf_{target}.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistics related to CIT and CRF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The log rather than the p-value is used because it is numerically much more stable when used for comparisons, computing the minimal value, etc. Note that the p-values can become extremely small when significant. \n",
    "\n",
    "\n",
    "statistic DEF: \n",
    "\n",
    "citrerion DEF: \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## get signifcant features\n",
    "# selected_feat = cit_stats.loc[:, cit_stats.loc[\"p_value\",:]<= 0.05]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Snippet from: https://cran.r-project.org/web/packages/stablelearner/vignettes/forests.html\n",
    "# cf_stablelearner = stablelearner.stabletree(cit_model,\n",
    "#   sampler = stablelearner.subsampling, savetrees = True, B = 100, v = 0.632)\n",
    "# #Internally, stablelearner::stabletree() does the following: For each of the 100 trees to be generated, the dataset is resampled according to the resampling method specified (in our case subsampling with a fraction of v = 0.632) and the function call of our initial tree (which we labeled ct_partykit) is updated with respect to this resampled data and reevaluated, resulting in a new tree. All the 100 trees together then build the forest.\n",
    "\n",
    "# #2.2 Gaining insight into the forest\n",
    "# #The following summary prints the variable selection frequency (freq) as well as the average number of splits in each variable (mean) over all 100 trees. As we do not want to focus on our initial tree (remember that we just grew a forest, where all trees are of equal interest), we set original = FALSE, as already mentioned in the introduction:\n",
    "# t = base.summary(cf_stablelearner, original = False)\n",
    "\n",
    "# ## Variable selection overview:\n",
    "# ## Note: n python we can see the R df.index which contains the variable names, therefore it is not very usefull\n",
    "# #pd.DataFrame(t).iloc[3,:][0] # frequency\n",
    "# #pd.DataFrame(t).iloc[3,:][1] # mean\n",
    "# #print(X.columns[:23])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## actual p-values (without log)\n",
    "# strucchange = importr(\"strucchange\")\n",
    "# strucchange.sctest(cit_model, node = 1)[1]  # p values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cit_model_p.rx(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cit_model_p.names\n",
    "cit_model_p = np.array(cit_model_p.rx(3))\n",
    "cit_model_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py396_c3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
