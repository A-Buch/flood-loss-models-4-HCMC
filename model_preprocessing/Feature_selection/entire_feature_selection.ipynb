{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"Data preprocessing for HCMC survey dataset\"\"\"\n",
    "\n",
    "__author__ = \"Anna Buch, Heidelberg University\"\n",
    "__email__ = \"a.buch@stud.uni-heidelberg.de\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection \n",
    "Enitre workflow with all models for the target variables relative content loss and business reduction (degree of loss) as well for the binary version of relative content loss (chance of loss)\n",
    "\n",
    "Due to the samll sample size a nested CV is used to have the possibility to even get generalization error, in the inner CV the best hyperaparamters based on k-fold are selected; in the outer cv the generalization error across all tested models is evaluated. A seprate unseen validation set as done by train-test split would have an insufficent small sample size.\n",
    "Nested CV is computationally intensive but with the samll sample size and a well chosen set of only most important hyperparameters this can be overcome.\n",
    "\n",
    "- Logistic Regression (binrary rcloss)\n",
    "- Elastic Net\n",
    "- eXtreme Gradient Boosting\n",
    "- Conditional Random Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "import joblib\n",
    "\n",
    "\n",
    "## TODO move to utils\n",
    "def load_config(config_file):\n",
    "    \"\"\"\n",
    "    Load config file\n",
    "    :param config_file: path to config file (str)\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    assert os.path.exists(\n",
    "        config_file\n",
    "    ), f\"Configuration file does not exist: {os.path.abspath(config_file)}\"\n",
    "    with open(config_file, \"r\") as src:\n",
    "        config = json.load(src)\n",
    "    return config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os, sys\n",
    "from pathlib import Path\n",
    "import json\n",
    "import copy as cp\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import pickle\n",
    "import joblib\n",
    "\n",
    "#from xgboost import XGBRegressor, XGBRFRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, RepeatedStratifiedKFold, RepeatedKFold, cross_val_score, cross_validate\n",
    "from sklearn.metrics import make_scorer, r2_score, mean_squared_error, median_absolute_error, PredictionErrorDisplay,  f1_score, confusion_matrix, mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from scipy import stats\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "#os.chdir(sys.path[0])\n",
    "sys.path.insert(0, \"../../../\")\n",
    "import utils.utils_feature_selection as fs\n",
    "import utils.utils_evaluation as e\n",
    "import utils.utils_figures as f\n",
    "import utils.settings as s\n",
    "import utils.pipelines as p\n",
    "\n",
    "p.main()  # create/update model settings\n",
    "#s.init()\n",
    "seed = s.seed\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "targets = [\"Target_relative_contentloss_euro\", \"Target_businessreduction\"]\n",
    "target = targets[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load R packages to process Conditional Random Forest in python\n",
    "*Note 1: all needed R packages have to be previously loaded in R*\n",
    "\n",
    "*Note 2: Make sure that caret package version >= 6.0-81, otherwise caret.train() throws an error*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rpy2\n",
    "import rpy2.robjects as robjects\n",
    "from rpy2.robjects.packages import importr, data\n",
    "import rpy2.robjects.packages as rpackages\n",
    "\n",
    "\n",
    "# get basic R packages\n",
    "utils = importr('utils')\n",
    "base = importr('base')\n",
    "dplyr = importr('dplyr')\n",
    "stats_r = importr(\"stats\")  # rename due to similar python package\n",
    "\n",
    "# pandas.DataFrames to R dataframes \n",
    "from rpy2.robjects import pandas2ri, Formula\n",
    "pandas2ri.activate()\n",
    "\n",
    "# print r df in html\n",
    "import rpy2.ipython.html\n",
    "rpy2.ipython.html.init_printing()\n",
    "\n",
    "\n",
    "# get libraries for CRF processing, ctree_controls etc\n",
    "partykit = importr('partykit')\n",
    "party = importr('party')\n",
    "caret = importr('caret') # package version >=\n",
    "nestedcv = importr('nestedcv')\n",
    "#stablelearner = importr('stablelearner')\n",
    "ggplot2 = importr('ggplot2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(397, 40)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target_businessreduction</th>\n",
       "      <th>inundation_duration_h</th>\n",
       "      <th>water_depth_cm</th>\n",
       "      <th>contaminations.0</th>\n",
       "      <th>flowvelocity</th>\n",
       "      <th>emergency_measures.1</th>\n",
       "      <th>emergency_measures.2</th>\n",
       "      <th>emergency_measures.3</th>\n",
       "      <th>emergency_measures.4</th>\n",
       "      <th>emergency_measures.7</th>\n",
       "      <th>emergency_measures.8</th>\n",
       "      <th>overall_problem_house</th>\n",
       "      <th>protect_valuables_impl</th>\n",
       "      <th>water_barriers_impl</th>\n",
       "      <th>pumping_equipment_impl</th>\n",
       "      <th>elevation_building_impl</th>\n",
       "      <th>resistant_material_building_impl</th>\n",
       "      <th>electricity_higher_impl</th>\n",
       "      <th>flood_protections_impl</th>\n",
       "      <th>flood_experience</th>\n",
       "      <th>elevation_building_height_cm</th>\n",
       "      <th>bage</th>\n",
       "      <th>b_area</th>\n",
       "      <th>floors</th>\n",
       "      <th>hh_monthly_income_cat</th>\n",
       "      <th>shp_owner</th>\n",
       "      <th>shp_sector</th>\n",
       "      <th>shp_employees</th>\n",
       "      <th>shp_avgmonthly_sale_cat</th>\n",
       "      <th>shp_profits_last5years</th>\n",
       "      <th>resilience_more_future_affected</th>\n",
       "      <th>resilience_govern_warnings_helpful</th>\n",
       "      <th>resilience_govern_careing</th>\n",
       "      <th>resilience_govern_careing_increases</th>\n",
       "      <th>perception_private_economy_future</th>\n",
       "      <th>contaminations_light</th>\n",
       "      <th>contaminations_heavy</th>\n",
       "      <th>shp_suppliers_HCMC</th>\n",
       "      <th>shp_content_value_euro</th>\n",
       "      <th>shp_registered_capital_euro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>70.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>130.0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11047.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>736.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Target_businessreduction  inundation_duration_h  water_depth_cm   \n",
       "395                       NaN                    4.0            70.0  \\\n",
       "396                       0.0                    3.0           100.0   \n",
       "\n",
       "     contaminations.0  flowvelocity  emergency_measures.1   \n",
       "395                 0             1                     1  \\\n",
       "396                 0             1                     1   \n",
       "\n",
       "     emergency_measures.2  emergency_measures.3  emergency_measures.4   \n",
       "395                     0                     1                     0  \\\n",
       "396                     0                     1                     0   \n",
       "\n",
       "     emergency_measures.7  emergency_measures.8  overall_problem_house   \n",
       "395                     0                     0                      1  \\\n",
       "396                     0                     0                      0   \n",
       "\n",
       "     protect_valuables_impl  water_barriers_impl  pumping_equipment_impl   \n",
       "395                       1                    5                       1  \\\n",
       "396                       1                    5                       5   \n",
       "\n",
       "     elevation_building_impl  resistant_material_building_impl   \n",
       "395                        1                                 5  \\\n",
       "396                        5                                 5   \n",
       "\n",
       "     electricity_higher_impl  flood_protections_impl  flood_experience   \n",
       "395                        5                       5                 5  \\\n",
       "396                        5                       5                 4   \n",
       "\n",
       "     elevation_building_height_cm  bage  b_area  floors   \n",
       "395                          70.0   NaN   130.0       2  \\\n",
       "396                           NaN   5.0    33.0       2   \n",
       "\n",
       "     hh_monthly_income_cat  shp_owner  shp_sector  shp_employees   \n",
       "395                    NaN          1          17              2  \\\n",
       "396                    1.0          1          11              2   \n",
       "\n",
       "     shp_avgmonthly_sale_cat  shp_profits_last5years   \n",
       "395                        3                     4.0  \\\n",
       "396                        3                     4.0   \n",
       "\n",
       "     resilience_more_future_affected  resilience_govern_warnings_helpful   \n",
       "395                              5.0                                 1.0  \\\n",
       "396                              NaN                                 NaN   \n",
       "\n",
       "     resilience_govern_careing  resilience_govern_careing_increases   \n",
       "395                        1.0                                  1.0  \\\n",
       "396                        NaN                                  NaN   \n",
       "\n",
       "     perception_private_economy_future  contaminations_light   \n",
       "395                                3.0                     1  \\\n",
       "396                                3.0                     1   \n",
       "\n",
       "     contaminations_heavy  shp_suppliers_HCMC  shp_content_value_euro   \n",
       "395                     0                   1                     NaN  \\\n",
       "396                     0                   1                     NaN   \n",
       "\n",
       "     shp_registered_capital_euro  \n",
       "395                      11047.7  \n",
       "396                        736.5  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_candidates = pd.read_excel(\"../../../input_survey_data/input_data_contentloss_tueb.xlsx\")\n",
    "df_candidates = pd.read_excel(\"../../../input_survey_data/input_data_businessreduction_tueb.xlsx\")\n",
    "\n",
    "print(df_candidates.shape)\n",
    "df_candidates.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    397.000000\n",
      "mean       1.921914\n",
      "std        0.478263\n",
      "min        1.000000\n",
      "25%        2.000000\n",
      "50%        2.000000\n",
      "75%        2.000000\n",
      "max        6.000000\n",
      "Name: floors, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "## impl in data_cleaning\n",
    "#print(df_candidates.floors.describe())\n",
    "try: \n",
    "    df_candidates = df_candidates[df_candidates.floors < 3, : ]\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(397, 35)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target_businessreduction</th>\n",
       "      <th>inundation_duration_h</th>\n",
       "      <th>water_depth_cm</th>\n",
       "      <th>contaminations.0</th>\n",
       "      <th>flowvelocity</th>\n",
       "      <th>emergency_measures.1</th>\n",
       "      <th>emergency_measures.2</th>\n",
       "      <th>emergency_measures.3</th>\n",
       "      <th>emergency_measures.4</th>\n",
       "      <th>emergency_measures.7</th>\n",
       "      <th>emergency_measures.8</th>\n",
       "      <th>overall_problem_house</th>\n",
       "      <th>protect_valuables_impl</th>\n",
       "      <th>water_barriers_impl</th>\n",
       "      <th>pumping_equipment_impl</th>\n",
       "      <th>elevation_building_impl</th>\n",
       "      <th>resistant_material_building_impl</th>\n",
       "      <th>electricity_higher_impl</th>\n",
       "      <th>flood_protections_impl</th>\n",
       "      <th>flood_experience</th>\n",
       "      <th>bage</th>\n",
       "      <th>b_area</th>\n",
       "      <th>hh_monthly_income_cat</th>\n",
       "      <th>shp_owner</th>\n",
       "      <th>shp_sector</th>\n",
       "      <th>shp_employees</th>\n",
       "      <th>shp_avgmonthly_sale_cat</th>\n",
       "      <th>shp_profits_last5years</th>\n",
       "      <th>resilience_more_future_affected</th>\n",
       "      <th>resilience_govern_warnings_helpful</th>\n",
       "      <th>resilience_govern_careing</th>\n",
       "      <th>perception_private_economy_future</th>\n",
       "      <th>shp_suppliers_HCMC</th>\n",
       "      <th>shp_content_value_euro</th>\n",
       "      <th>shp_registered_capital_euro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>130.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11047.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>736.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Target_businessreduction  inundation_duration_h  water_depth_cm   \n",
       "395                       NaN                    4.0            70.0  \\\n",
       "396                       0.0                    3.0           100.0   \n",
       "\n",
       "     contaminations.0  flowvelocity  emergency_measures.1   \n",
       "395                 0             1                     1  \\\n",
       "396                 0             1                     1   \n",
       "\n",
       "     emergency_measures.2  emergency_measures.3  emergency_measures.4   \n",
       "395                     0                     1                     0  \\\n",
       "396                     0                     1                     0   \n",
       "\n",
       "     emergency_measures.7  emergency_measures.8  overall_problem_house   \n",
       "395                     0                     0                      1  \\\n",
       "396                     0                     0                      0   \n",
       "\n",
       "     protect_valuables_impl  water_barriers_impl  pumping_equipment_impl   \n",
       "395                       1                    5                       1  \\\n",
       "396                       1                    5                       5   \n",
       "\n",
       "     elevation_building_impl  resistant_material_building_impl   \n",
       "395                        1                                 5  \\\n",
       "396                        5                                 5   \n",
       "\n",
       "     electricity_higher_impl  flood_protections_impl  flood_experience  bage   \n",
       "395                        5                       5                 5   NaN  \\\n",
       "396                        5                       5                 4   5.0   \n",
       "\n",
       "     b_area  hh_monthly_income_cat  shp_owner  shp_sector  shp_employees   \n",
       "395   130.0                    NaN          1          17              2  \\\n",
       "396    33.0                    1.0          1          11              2   \n",
       "\n",
       "     shp_avgmonthly_sale_cat  shp_profits_last5years   \n",
       "395                        3                     4.0  \\\n",
       "396                        3                     4.0   \n",
       "\n",
       "     resilience_more_future_affected  resilience_govern_warnings_helpful   \n",
       "395                              5.0                                 1.0  \\\n",
       "396                              NaN                                 NaN   \n",
       "\n",
       "     resilience_govern_careing  perception_private_economy_future   \n",
       "395                        1.0                                3.0  \\\n",
       "396                        NaN                                3.0   \n",
       "\n",
       "     shp_suppliers_HCMC  shp_content_value_euro  shp_registered_capital_euro  \n",
       "395                   1                     NaN                      11047.7  \n",
       "396                   1                     NaN                        736.5  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### TODO impl this cell in data_cleaning\n",
    "\n",
    "#df_candidates = df_candidates.drop([\"Target_contentloss_euro\", \"shp_content_value_euro\"], axis=1)\n",
    "#df_candidates = df_candidates.drop([\"Target_relative_contentloss_euro\"], axis=1)\n",
    "\n",
    "\n",
    "try:\n",
    "    #if target==\"Target_relative_contentloss_euro\": \n",
    "    df_candidates = df_candidates.drop(\"floors\", axis=1 )  # remove if still in ds due that it's used for shp_content_value and relative content loss\n",
    "    df_candidates = df_candidates.drop(\"buildingtype_moon\", axis=1)  # remove due to 64 % missing values   \n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    df_candidates = df_candidates.drop(\"elevation_building_height_cm\", axis=1)\n",
    "    df_candidates = df_candidates.drop([\"contaminations_light\",\"contaminations_heavy\"], axis=1)\n",
    "    df_candidates = df_candidates.drop(\"resilience_govern_careing_increases\", axis=1)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "\n",
    "print(df_candidates.shape)\n",
    "df_candidates.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test remove further features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of missing values per feature [%]\n",
      " shp_content_value_euro                16.0\n",
      "shp_registered_capital_euro           12.0\n",
      "Target_businessreduction               9.0\n",
      "bage                                   7.0\n",
      "perception_private_economy_future      7.0\n",
      "hh_monthly_income_cat                  6.0\n",
      "resilience_govern_careing              6.0\n",
      "resilience_govern_warnings_helpful     5.0\n",
      "resilience_more_future_affected        4.0\n",
      "shp_profits_last5years                 4.0\n",
      "inundation_duration_h                  2.0\n",
      "b_area                                 1.0\n",
      "water_depth_cm                         0.0\n",
      "contaminations.0                       0.0\n",
      "shp_suppliers_HCMC                     0.0\n",
      "dtype: float64 2\n"
     ]
    }
   ],
   "source": [
    "## delete features with more than 10% missing values\n",
    "print(\"Percentage of missing values per feature [%]\\n\", round(df_candidates.isna().mean().sort_values(ascending=False)[:15]  * 100), 2) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(scores.keys())\n",
    "# scores[\"test_neg_MAE\"].mean()\n",
    "\n",
    "score_names_for_performance = {\n",
    "    \"neg_MAE\": \"neg_mean_absolute_error\",\n",
    "    \"neg_RMSE\": \"neg_root_mean_squared_error\",\n",
    "    \"R2\": \"r2\",\n",
    "    \"neg_MAPE\": \"neg_mean_absolute_percentage_error\",\n",
    "    \"neg_MBE\": make_scorer(e.mean_bias_error, greater_is_better=True)\n",
    "}\n",
    "## mean of negMAE for outer cv (XGB) : -0.11740830879165003\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Appling crf on Target_businessreduction:\n",
      "Dropping 36 records from entire dataset due that these values are nan in target variable\n",
      "Using  213  records, from those have  {73}  cases with zero-loss or zero-reduction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Fitting final model using CV on whole data\n",
      "\n",
      "R[write to console]: Performing 10-fold outer CV, using 1 core\n",
      "\n",
      "R[write to console]: Duration: 5.384809 mins\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$call\n",
      "(function (y, x, method = \"rf\", filterFUN = NULL, filter_options = NULL, \n",
      "    weights = NULL, balance = NULL, balance_options = NULL, outer_method = c(\"cv\", \n",
      "        \"LOOCV\"), n_outer_folds = 10, n_inner_folds = 10, outer_folds = NULL, \n",
      "    inner_folds = NULL, pass_outer_folds = FALSE, cv.cores = 1, \n",
      "    multicore_fork = (Sys.info()[\"sysname\"] != \"Windows\"), metric = ifelse(is.factor(y), \n",
      "        \"logLoss\", \"RMSE\"), trControl = NULL, tuneGrid = NULL, \n",
      "    savePredictions = \"final\", outer_train_predict = FALSE, finalCV = TRUE, \n",
      "    na.option = \"pass\", verbose = TRUE, ...) \n",
      "{\n",
      "    start <- Sys.time()\n",
      "    nestcv.call <- match.call(expand.dots = TRUE)\n",
      "    outer_method <- match.arg(outer_method)\n",
      "    if (is.character(y)) \n",
      "        y <- factor(y)\n",
      "    if (!is.null(balance) & is.numeric(y)) {\n",
      "        stop(\"`balance` can only be used for classification\")\n",
      "    }\n",
      "    ok <- checkxy(y, x, na.option, weights)\n",
      "    y <- y[ok$r]\n",
      "    x <- x[ok$r, ok$c]\n",
      "    weights <- weights[ok$r]\n",
      "    if (!is.null(balance) & !is.null(weights)) {\n",
      "        stop(\"`balance` and `weights` cannot be used at the same time\")\n",
      "    }\n",
      "    if (is.null(outer_folds)) {\n",
      "        outer_folds <- switch(outer_method, cv = createFolds(y, \n",
      "            k = n_outer_folds), LOOCV = 1:length(y))\n",
      "    }\n",
      "    else {\n",
      "        if (\"n_outer_folds\" %in% names(nestcv.call)) {\n",
      "            if (n_outer_folds != length(outer_folds)) \n",
      "                stop(\"Mismatch between n_outer_folds and length(outer_folds)\")\n",
      "        }\n",
      "        n_outer_folds <- length(outer_folds)\n",
      "    }\n",
      "    if (!is.null(inner_folds)) {\n",
      "        if (length(inner_folds) != length(outer_folds)) \n",
      "            stop(\"Mismatch in length(outer_folds) and length(inner_folds)\")\n",
      "        if (\"n_inner_folds\" %in% names(nestcv.call)) {\n",
      "            if (n_inner_folds != length(inner_folds)) \n",
      "                stop(\"Mismatch between n_inner_folds and length(inner_folds)\")\n",
      "        }\n",
      "        n_inner_folds <- length(inner_folds[[1]])\n",
      "        outer_train_size <- sapply(swapFoldIndex(outer_folds), \n",
      "            length)\n",
      "        chk <- vapply(seq_along(outer_train_size), function(i) {\n",
      "            max(unlist(inner_folds[[i]])) > outer_train_size[i]\n",
      "        }, logical(1))\n",
      "        if (any(chk)) \n",
      "            stop(\"inner_folds contains index out of range\")\n",
      "        if (!is.null(balance)) \n",
      "            stop(\"`balance` cannot be used if `inner_folds` is specified\")\n",
      "        inner_train_folds <- lapply(inner_folds, swapFoldIndex)\n",
      "    }\n",
      "    else inner_train_folds <- NULL\n",
      "    if (is.null(trControl)) {\n",
      "        trControl <- if (is.factor(y)) {\n",
      "            trainControl(method = \"cv\", number = n_inner_folds, \n",
      "                classProbs = TRUE, savePredictions = savePredictions, \n",
      "                summaryFunction = mnLogLoss)\n",
      "        }\n",
      "        else trainControl(method = \"cv\", number = n_inner_folds, \n",
      "            savePredictions = savePredictions)\n",
      "    }\n",
      "    if (!is.null(tuneGrid)) {\n",
      "        if (nrow(tuneGrid) == 1) {\n",
      "            trControl <- trainControl(method = \"none\", classProbs = TRUE)\n",
      "            inner_train_folds <- NULL\n",
      "        }\n",
      "    }\n",
      "    if (is.na(finalCV)) {\n",
      "        final_fit <- finalTune <- filtx <- yfinal <- xsub <- NA\n",
      "    }\n",
      "    else {\n",
      "        if (verbose) \n",
      "            message(\"Fitting final model using CV on whole data\")\n",
      "        dat <- nest_filt_bal(NULL, y, x, filterFUN, filter_options, \n",
      "            balance, balance_options)\n",
      "        yfinal <- dat$ytrain\n",
      "        filtx <- dat$filt_xtrain\n",
      "        if (finalCV) {\n",
      "            trControlFinal <- trControl\n",
      "            if (pass_outer_folds) {\n",
      "                if (n_outer_folds == trControl$number && trControl$method == \n",
      "                  \"cv\" && is.null(balance)) {\n",
      "                  train_folds <- swapFoldIndex(outer_folds, length(y))\n",
      "                  trControlFinal$index <- train_folds\n",
      "                  trControlFinal$indexOut <- outer_folds\n",
      "                }\n",
      "                else message(\"Cannot pass `outer_folds` to final CV\")\n",
      "            }\n",
      "            if (cv.cores >= 2) {\n",
      "                if (Sys.info()[\"sysname\"] == \"Windows\") {\n",
      "                  cl <- makeCluster(cv.cores)\n",
      "                  registerDoParallel(cl)\n",
      "                }\n",
      "                else {\n",
      "                  registerDoParallel(cores = cv.cores)\n",
      "                }\n",
      "            }\n",
      "            printlog <- capture.output({\n",
      "                final_fit <- caret::train(x = filtx, y = yfinal, \n",
      "                  method = method, weights = weights, metric = metric, \n",
      "                  trControl = trControlFinal, tuneGrid = tuneGrid, \n",
      "                  ...)\n",
      "            })\n",
      "            finalTune <- final_fit$bestTune\n",
      "            if (cv.cores >= 2) {\n",
      "                if (Sys.info()[\"sysname\"] == \"Windows\") \n",
      "                  stopCluster(cl)\n",
      "                foreach::registerDoSEQ()\n",
      "            }\n",
      "        }\n",
      "    }\n",
      "    if (verbose && (!multicore_fork || Sys.getenv(\"RSTUDIO\") == \n",
      "        \"1\")) {\n",
      "        message(\"Performing \", n_outer_folds, \"-fold outer CV, using \", \n",
      "            plural(cv.cores, \"core(s)\"))\n",
      "    }\n",
      "    if (!multicore_fork && cv.cores >= 2) {\n",
      "        cl <- makeCluster(cv.cores)\n",
      "        dots <- list(...)\n",
      "        varlist <- c(\"outer_folds\", \"inner_train_folds\", \"y\", \n",
      "            \"x\", \"method\", \"filterFUN\", \"filter_options\", \"weights\", \n",
      "            \"balance\", \"balance_options\", \"metric\", \"trControl\", \n",
      "            \"tuneGrid\", \"outer_train_predict\", \"nestcv.trainCore\", \n",
      "            \"dots\")\n",
      "        clusterExport(cl, varlist = varlist, envir = environment())\n",
      "        if (verbose) {\n",
      "            if (!requireNamespace(\"pbapply\", quietly = TRUE)) {\n",
      "                stop(\"Package 'pbapply' must be installed\", call. = FALSE)\n",
      "            }\n",
      "            outer_res <- pbapply::pblapply(seq_along(outer_folds), \n",
      "                function(i) {\n",
      "                  args <- c(list(i = i, y = y, x = x, outer_folds = outer_folds, \n",
      "                    inner_train_folds = inner_train_folds, method = method, \n",
      "                    filterFUN = filterFUN, filter_options = filter_options, \n",
      "                    weights = weights, balance = balance, balance_options = balance_options, \n",
      "                    metric = metric, trControl = trControl, tuneGrid = tuneGrid, \n",
      "                    outer_train_predict = outer_train_predict), \n",
      "                    dots)\n",
      "                  do.call(nestcv.trainCore, args)\n",
      "                }, cl = cl)\n",
      "        }\n",
      "        else {\n",
      "            outer_res <- parLapply(cl = cl, seq_along(outer_folds), \n",
      "                function(i) {\n",
      "                  args <- c(list(i = i, y = y, x = x, outer_folds = outer_folds, \n",
      "                    inner_train_folds = inner_train_folds, method = method, \n",
      "                    filterFUN = filterFUN, filter_options = filter_options, \n",
      "                    weights = weights, balance = balance, balance_options = balance_options, \n",
      "                    metric = metric, trControl = trControl, tuneGrid = tuneGrid, \n",
      "                    outer_train_predict = outer_train_predict), \n",
      "                    dots)\n",
      "                  do.call(nestcv.trainCore, args)\n",
      "                })\n",
      "        }\n",
      "        stopCluster(cl)\n",
      "    }\n",
      "    else {\n",
      "        outer_res <- mclapply(seq_along(outer_folds), function(i) {\n",
      "            nestcv.trainCore(i, y, x, outer_folds, inner_train_folds, \n",
      "                method, filterFUN, filter_options, weights, balance, \n",
      "                balance_options, metric, trControl, tuneGrid, \n",
      "                outer_train_predict, verbose, ...)\n",
      "        }, mc.cores = cv.cores, mc.allow.recursive = FALSE)\n",
      "    }\n",
      "    predslist <- lapply(outer_res, \"[[\", \"preds\")\n",
      "    output <- data.table::rbindlist(predslist)\n",
      "    output <- as.data.frame(output)\n",
      "    if (!is.null(rownames(x))) {\n",
      "        rownames(output) <- unlist(lapply(predslist, rownames))\n",
      "    }\n",
      "    summary <- predSummary(output)\n",
      "    caret.roc <- NULL\n",
      "    if (is.factor(y) & nlevels(y) == 2) {\n",
      "        caret.roc <- pROC::roc(output$testy, output$predyp, direction = \"<\", \n",
      "            quiet = TRUE)\n",
      "    }\n",
      "    bestTunes <- lapply(outer_res, function(i) i$fit$bestTune)\n",
      "    bestTunes <- as.data.frame(data.table::rbindlist(bestTunes))\n",
      "    rownames(bestTunes) <- paste(\"Fold\", seq_len(nrow(bestTunes)))\n",
      "    if (!is.na(finalCV) && !finalCV) {\n",
      "        if (verbose) \n",
      "            message(\"Fitting single final model\")\n",
      "        finalTune <- finaliseTune(bestTunes)\n",
      "        fitControl <- trainControl(method = \"none\", classProbs = is.factor(y))\n",
      "        final_fit <- caret::train(x = filtx, y = yfinal, method = method, \n",
      "            weights = weights, trControl = fitControl, tuneGrid = finalTune, \n",
      "            ...)\n",
      "    }\n",
      "    if (!is.na(finalCV)) {\n",
      "        all_vars <- unlist(lapply(outer_res, function(i) {\n",
      "            colnames(i$fit$trainingData)\n",
      "        }))\n",
      "        all_vars <- unique(c(all_vars, colnames(filtx)))\n",
      "        all_vars <- all_vars[all_vars %in% colnames(x)]\n",
      "        xsub <- x[, all_vars]\n",
      "    }\n",
      "    end <- Sys.time()\n",
      "    if (verbose) \n",
      "        message(\"Duration: \", format(end - start))\n",
      "    out <- list(call = nestcv.call, output = output, outer_result = outer_res, \n",
      "        outer_method = outer_method, outer_folds = outer_folds, \n",
      "        dimx = dim(x), xsub = xsub, y = y, yfinal = yfinal, final_fit = final_fit, \n",
      "        final_vars = colnames(filtx), roc = caret.roc, trControl = trControl, \n",
      "        bestTunes = bestTunes, finalTune = finalTune, summary = summary)\n",
      "    class(out) <- \"nestcv.train\"\n",
      "    out\n",
      "})(y = c(`0` = 0, `2` = 0, `4` = 0, `5` = 0, `6` = 0, `8` = 20, \n",
      "`9` = 0, `10` = 5, `11` = 10, `12` = 30, `19` = 0, `20` = 5, \n",
      "`21` = 0, `22` = 100, `23` = 10, `24` = 5, `25` = 0, `26` = 0, \n",
      "`27` = 30, `28` = 50, `29` = 70, `30` = 0, `32` = 30, `38` = 10, \n",
      "`39` = 20, `44` = 10, `45` = 0, `46` = 0, `47` = 60, `48` = 10, \n",
      "`49` = 5, `50` = 0, `53` = 20, `55` = 0, `56` = 0, `58` = 0, \n",
      "`61` = 0, `62` = 5, `63` = 0, `65` = 0, `66` = 0, `67` = 0, `68` = 10, \n",
      "`69` = 10, `72` = 5, `73` = 0, `74` = 30, `77` = 40, `78` = 10, \n",
      "`79` = 50, `80` = 10, `81` = 50, `84` = 0, `93` = 0, `94` = 0, \n",
      "`95` = 20, `96` = 90, `101` = 50, `102` = 30, `105` = 35, `109` = 0, \n",
      "`111` = 0, `112` = 0, `113` = 10, `114` = 5, `118` = 50, `125` = 10, \n",
      "`126` = 0, `129` = 5, `130` = 5, `132` = 0, `134` = 60, `136` = 5, \n",
      "`138` = 50, `140` = 50, `143` = 30, `147` = 0, `149` = 45, `151` = 100, \n",
      "`152` = 10, `153` = 20, `156` = 0, `158` = 0, `162` = 10, `163` = 0, \n",
      "`164` = 20, `165` = 0, `166` = 50, `168` = 0, `171` = 0, `172` = 0, \n",
      "`173` = 80, `175` = 12, `177` = 100, `178` = 0, `181` = 5, `182` = 50, \n",
      "`183` = 50, `184` = 20, `185` = 40, `192` = 0, `193` = 100, `194` = 20, \n",
      "`195` = 50, `196` = 0, `197` = 0, `199` = 5, `201` = 20, `202` = 30, \n",
      "`203` = 5, `206` = 10, `207` = 0, `209` = 0, `210` = 0, `211` = 0, \n",
      "`216` = 0, `217` = 0, `218` = 5, `219` = 20, `221` = 5, `222` = 0, \n",
      "`223` = 0, `228` = 7, `229` = 20, `230` = 40, `232` = 20, `233` = 40, \n",
      "`235` = 10, `236` = 40, `237` = 30, `238` = 20, `239` = 20, `240` = 30, \n",
      "`241` = 10, `242` = 30, `243` = 10, `244` = 60, `246` = 30, `249` = 0, \n",
      "`250` = 0, `251` = 0, `252` = 0, `254` = 0, `256` = 0, `257` = 10, \n",
      "`263` = 0, `264` = 100, `265` = 20, `266` = 20, `267` = 100, \n",
      "`274` = 20, `275` = 20, `279` = 10, `280` = 30, `283` = 30, `285` = 0, \n",
      "`286` = 0, `287` = 1, `289` = 0, `290` = 10, `292` = 0, `293` = 10, \n",
      "`294` = 0, `295` = 15, `296` = 5, `297` = 5, `298` = 40, `301` = 40, \n",
      "`302` = 20, `303` = 50, `304` = 50, `305` = 60, `313` = 0, `314` = 0, \n",
      "`317` = 50, `318` = 40, `320` = 0, `324` = 0, `325` = 100, `330` = 70, \n",
      "`337` = 10, `338` = 10, `340` = 10, `341` = 10, `342` = 20, `347` = 15, \n",
      "`350` = 4, `351` = 100, `352` = 0, `354` = 10, `355` = 10, `356` = 20, \n",
      "`359` = 0, `360` = 0, `361` = 80, `363` = 20, `364` = 10, `365` = 60, \n",
      "`366` = 70, `372` = 20, `373` = 50, `374` = 0, `375` = 0, `376` = 5, \n",
      "`379` = 0, `386` = 100, `387` = 40, `388` = 30, `389` = 20, `390` = 20, \n",
      "`391` = 30, `392` = 30, `393` = 10), x = list(inundation_duration_h = c(0.00750625521267723, \n",
      "0.00333611342785655, 0.0116763969974979, 0.00125104253544621, \n",
      "0.0617180984153461, 0.0116763969974979, 0.0533778148457048, 0.00750625521267723, \n",
      "0.00125104253544621, 0.0200166805671393, 0.0158465387823186, \n",
      "0.0283569641367807, 0.00125104253544621, 0.00750625521267723, \n",
      "0.00333611342785655, 0.036697247706422, 0.00750625521267723, \n",
      "0.00750625521267723, 0.02418682235196, 0.0116763969974979, 0.0116763969974979, \n",
      "0.0116763969974979, 0.0116763969974979, 0.00750625521267723, \n",
      "0.0116763969974979, 0.00333611342785655, 0.00333611342785655, \n",
      "0.00333611342785655, 0.0158465387823186, 0.00750625521267723, \n",
      "0.0325271059216013, 0.00750625521267723, 0.00333611342785655, \n",
      "0.0116763969974979, 0.00333611342785655, 0.00750625521267723, \n",
      "0.0116763969974979, 0.0200166805671393, 0.0200166805671393, 0.0158465387823186, \n",
      "0.0116763969974979, 0.00125104253544621, 0.0408673894912427, \n",
      "0.0200166805671393, 0.00333611342785655, 0.00333611342785655, \n",
      "0.02418682235196, 0.00750625521267723, 0.00333611342785655, 0.0116763969974979, \n",
      "0.00333611342785655, 0.0116763969974979, 0.0116763969974979, \n",
      "0.00750625521267723, 0.124270225187656, 0.00750625521267723, \n",
      "0.0116763969974979, 0.0200166805671393, 0.00750625521267723, \n",
      "0.00750625521267723, 0.299416180150125, 0.00333611342785655, \n",
      "0.00333611342785655, 0.036697247706422, 0.00750625521267723, \n",
      "0.0200166805671393, 0.299416180150125, 0.0116763969974979, 0.00333611342785655, \n",
      "0.00750625521267723, 0.0116763969974979, 0.02418682235196, 0.00750625521267723, \n",
      "0.0200166805671393, 0.0158465387823186, 0.0116763969974979, 0.0492076730608841, \n",
      "1, 0.291075896580484, 0.291075896580484, 0.0158465387823186, \n",
      "0.0116763969974979, 0.199332777314429, 0.0116763969974979, 0.00750625521267723, \n",
      "0.00750625521267723, 0.0200166805671393, 0.00750625521267723, \n",
      "0.00750625521267723, 0.00750625521267723, 0.0116763969974979, \n",
      "0.0158465387823186, 0.00333611342785655, 0.0116763969974979, \n",
      "0.00333611342785655, 0.0116763969974979, 0.0116763969974979, \n",
      "0.00750625521267723, 0.0116763969974979, 0.0158465387823186, \n",
      "0.02418682235196, 0.0158465387823186, 0.0158465387823186, 0.00750625521267723, \n",
      "0.00125104253544621, 0.00750625521267723, 0.0116763969974979, \n",
      "0.0116763969974979, 0.00125104253544621, 0.0116763969974979, \n",
      "0.0158465387823186, 0.00750625521267723, 0.0116763969974979, \n",
      "0.0116763969974979, 0.00750625521267723, 0.00750625521267723, \n",
      "0.00333611342785655, 0.0116763969974979, 0.00750625521267723, \n",
      "0.0116763969974979, 0.00333611342785655, 0.0158465387823186, \n",
      "0.0116763969974979, 0.0116763969974979, 0.0116763969974979, 0.0116763969974979, \n",
      "0.00750625521267723, 0.00750625521267723, 0.0158465387823186, \n",
      "0.00750625521267723, 0.0116763969974979, 0.0116763969974979, \n",
      "0.00750625521267723, 0.00125104253544621, 0.0200166805671393, \n",
      "0.0116763969974979, 0.00750625521267723, 0.00750625521267723, \n",
      "0.0200166805671393, 0.0116763969974979, 0.00333611342785655, \n",
      "0.0116763969974979, 0, 0.0700583819849875, 0.0408673894912427, \n",
      "0.00125104253544621, 0.00750625521267723, 0.00750625521267723, \n",
      "0.00750625521267723, 0.0116763969974979, 0.0325271059216013, \n",
      "0.0116763969974979, 0.00333611342785655, 0.0158465387823186, \n",
      "0.0158465387823186, 0.199332777314429, 0.00750625521267723, 0.0492076730608841, \n",
      "0.0408673894912427, 0.036697247706422, 0.0408673894912427, 0.0992493744787323, \n",
      "0.00333611342785655, 0.0617180984153461, 0.00750625521267723, \n",
      "0.00750625521267723, 0.00750625521267723, 0.00333611342785655, \n",
      "0.00333611342785655, 0.0116763969974979, 0.0992493744787323, \n",
      "0.136780650542118, 0.0116763969974979, 0.124270225187656, 0.0200166805671393, \n",
      "0.0200166805671393, 0.0158465387823186, 0.00542118432026689, \n",
      "0.0116763969974979, 0.0408673894912427, 0.499582985821518, 0.0992493744787323, \n",
      "0.0283569641367807, 0.0200166805671393, 0.00750625521267723, \n",
      "0.0200166805671393, 0.0492076730608841, 0.0200166805671393, 0.199332777314429, \n",
      "0.00125104253544621, 0.00750625521267723, 0.699749791492911, \n",
      "0.02418682235196, 0.0283569641367807, 0.0158465387823186, 0.02418682235196, \n",
      "0.00750625521267723, 0.0116763969974979, 0.00750625521267723, \n",
      "0.0158465387823186, 0.0116763969974979, 0.00125104253544621, \n",
      "0.0158465387823186, 0.0116763969974979, 0.0116763969974979, 0.0116763969974979, \n",
      "0.0116763969974979, 0.00750625521267723, 0.0200166805671393, \n",
      "0.0158465387823186, 0.00750625521267723, 0.0200166805671393, \n",
      "0.0158465387823186), water_depth_cm = c(0.0825688073394495, 0.00917431192660551, \n",
      "0.036697247706422, 0.018348623853211, 0.174311926605505, 0.26605504587156, \n",
      "0.174311926605505, 0.018348623853211, 0.0825688073394495, 0.348623853211009, \n",
      "0.44954128440367, 0.18348623853211, 0.0825688073394495, 0.26605504587156, \n",
      "0.0825688073394495, 0.174311926605505, 0.0825688073394495, 0.174311926605505, \n",
      "0.26605504587156, 0.26605504587156, 0.357798165137615, 0.174311926605505, \n",
      "0.036697247706422, 0.44954128440367, 0.128440366972477, 0.357798165137615, \n",
      "1, 0.26605504587156, 0.724770642201835, 0.26605504587156, 0.541284403669725, \n",
      "0.0825688073394495, 0.036697247706422, 0.128440366972477, 0.0825688073394495, \n",
      "0.036697247706422, 0.0275229357798165, 0.174311926605505, 0.0825688073394495, \n",
      "0.0825688073394495, 0.036697247706422, 0, 0.174311926605505, \n",
      "0.128440366972477, 0.0825688073394495, 0.00917431192660551, 0.0825688073394495, \n",
      "0.357798165137615, 0.44954128440367, 0.357798165137615, 0.0825688073394495, \n",
      "0.26605504587156, 0.357798165137615, 0.26605504587156, 0.174311926605505, \n",
      "0.44954128440367, 0.908256880733945, 0.44954128440367, 0.174311926605505, \n",
      "0.44954128440367, 0.908256880733945, 0.174311926605505, 0, 0.44954128440367, \n",
      "0.0825688073394495, 0.036697247706422, 0.357798165137615, 0.220183486238532, \n",
      "0.0825688073394495, 0.44954128440367, 0.174311926605505, 0.357798165137615, \n",
      "0.174311926605505, 0.44954128440367, 0.44954128440367, 0.055045871559633, \n",
      "0.403669724770642, 0.63302752293578, 0.908256880733945, 0.678899082568807, \n",
      "0.0825688073394495, 0.0458715596330275, 0.174311926605505, 0.036697247706422, \n",
      "0.174311926605505, 0.26605504587156, 0.724770642201835, 0.128440366972477, \n",
      "0.0825688073394495, 0.036697247706422, 0.018348623853211, 0.174311926605505, \n",
      "0.0825688073394495, 0.63302752293578, 0.0825688073394495, 0.128440366972477, \n",
      "0.908256880733945, 0.174311926605505, 0.0825688073394495, 0.174311926605505, \n",
      "0.220183486238532, 0.541284403669725, 0.44954128440367, 0.357798165137615, \n",
      "0.036697247706422, 0.0825688073394495, 0.174311926605505, 0.26605504587156, \n",
      "0.174311926605505, 0.0825688073394495, 0.26605504587156, 0.26605504587156, \n",
      "0.724770642201835, 0.0825688073394495, 0.174311926605505, 0.018348623853211, \n",
      "0.00917431192660551, 0.055045871559633, 0.0825688073394495, 0.0825688073394495, \n",
      "0.018348623853211, 0.26605504587156, 0.0825688073394495, 0.541284403669725, \n",
      "0.357798165137615, 0.174311926605505, 0.26605504587156, 0.174311926605505, \n",
      "0.44954128440367, 0.26605504587156, 0.174311926605505, 0.357798165137615, \n",
      "0.036697247706422, 0.0825688073394495, 0.174311926605505, 0.26605504587156, \n",
      "0.26605504587156, 0.63302752293578, 0.174311926605505, 0.036697247706422, \n",
      "0.174311926605505, 0.26605504587156, 0.018348623853211, 0.357798165137615, \n",
      "0.44954128440367, 0.0825688073394495, 0.26605504587156, 0.357798165137615, \n",
      "0.357798165137615, 0.44954128440367, 0.908256880733945, 0.174311926605505, \n",
      "0.357798165137615, 0.81651376146789, 0.036697247706422, 0.908256880733945, \n",
      "0.44954128440367, 0.44954128440367, 0.174311926605505, 0.44954128440367, \n",
      "0.128440366972477, 0.128440366972477, 0.174311926605505, 0.44954128440367, \n",
      "0.174311926605505, 0.036697247706422, 0.174311926605505, 0.357798165137615, \n",
      "0.44954128440367, 0.63302752293578, 0.174311926605505, 0.44954128440367, \n",
      "0.44954128440367, 0.26605504587156, 0.44954128440367, 0.357798165137615, \n",
      "0.63302752293578, 0.26605504587156, 0.357798165137615, 0.174311926605505, \n",
      "0.63302752293578, 0.63302752293578, 0.357798165137615, 0.357798165137615, \n",
      "0.44954128440367, 0.174311926605505, 0.403669724770642, 0.174311926605505, \n",
      "0.174311926605505, 0.26605504587156, 0.357798165137615, 0.541284403669725, \n",
      "0.174311926605505, 0.44954128440367, 0.174311926605505, 0.44954128440367, \n",
      "0.174311926605505, 0.128440366972477, 0.0825688073394495, 0.44954128440367, \n",
      "0.541284403669725, 0.0825688073394495, 0.26605504587156, 0.26605504587156, \n",
      "0.26605504587156, 0.357798165137615, 0.357798165137615, 0.26605504587156, \n",
      "0.44954128440367, 0.541284403669725, 0.357798165137615, 0.357798165137615, \n",
      "0.541284403669725), contaminations.0 = c(1, 1, 0, 1, 0, 0, 1, \n",
      "1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
      "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
      "0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, \n",
      "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, \n",
      "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, \n",
      "0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, \n",
      "0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
      "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, \n",
      "0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
      "0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), flowvelocity = c(0.25, \n",
      "0.25, 0.5, 0.25, 0.5, 0.25, 0.75, 0.75, 0.25, 0.25, 1, 1, 0, \n",
      "0.25, 0.75, 0.75, 0.5, 1, 0.5, 0.25, 0.25, 1, 0, 0.5, 0.5, 0.25, \n",
      "1, 0.5, 1, 0.75, 0.75, 0.75, 0, 0.5, 0, 0.5, 0.25, 0.75, 0.75, \n",
      "0.25, 0, 0.75, 1, 0.25, 0.75, 0.25, 0.25, 0.25, 0.5, 1, 0.25, \n",
      "1, 0.25, 0.25, 0.5, 0.75, 0.75, 0.5, 0.25, 0.75, 1, 0.25, 0.5, \n",
      "0.75, 0.75, 0.5, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.5, 1, \n",
      "1, 0.5, 0.75, 1, 1, 1, 0.75, 0.25, 0.25, 0.25, 0, 0.25, 0.75, \n",
      "0, 0, 0, 0, 0.75, 0.75, 0.5, 0.75, 0.5, 1, 0.25, 0.5, 0.25, 0, \n",
      "0.75, 0.5, 0.5, 0, 0.5, 0.75, 1, 0.5, 0, 0.5, 0.5, 0.75, 0, 0, \n",
      "0.25, 0.5, 0.75, 0.25, 0.75, 0.25, 0.5, 0.25, 1, 0.75, 0.75, \n",
      "0.25, 0.25, 0.5, 0.5, 0.5, 0.5, 0.25, 0, 0.25, 0.5, 0.25, 0, \n",
      "0, 0.25, 0.5, 0.5, 0.25, 1, 0.75, 0.75, 0.75, 0.75, 1, 1, 1, \n",
      "0.5, 0.25, 1, 0.75, 1, 1, 1, 0.75, 0.75, 0.5, 0.5, 0.5, 1, 0.75, \n",
      "0.25, 0.5, 0.5, 1, 0.25, 1, 1, 0.25, 0.75, 0.5, 0.75, 0.75, 0.25, \n",
      "0.5, 0.75, 0.25, 0.75, 0.5, 0.5, 0.25, 1, 0.75, 1, 0.25, 0.5, \n",
      "0.5, 1, 0.25, 0, 0.75, 1, 1, 0.75, 0.25, 0.5, 0.75, 0, 0.75, \n",
      "0, 0, 1, 0.25, 1, 0.75, 0.5, 0.5, 0.25, 0.5), emergency_measures.1 = c(0, \n",
      "0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, \n",
      "0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, \n",
      "1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, \n",
      "1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, \n",
      "1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, \n",
      "1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, \n",
      "0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, \n",
      "1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, \n",
      "0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, \n",
      "1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, \n",
      "0, 1), emergency_measures.2 = c(0, 0, 0, 0, 0, 0, 1, 0, 0, 1, \n",
      "0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, \n",
      "1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, \n",
      "0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, \n",
      "1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, \n",
      "1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, \n",
      "0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, \n",
      "0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, \n",
      "0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, \n",
      "0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, \n",
      "1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1), emergency_measures.3 = c(0, \n",
      "0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, \n",
      "0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, \n",
      "1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, \n",
      "1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, \n",
      "1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, \n",
      "1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, \n",
      "1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, \n",
      "1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, \n",
      "0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, \n",
      "1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, \n",
      "1, 1), emergency_measures.4 = c(0, 0, 0, 0, 0, 1, 1, 1, 0, 1, \n",
      "0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, \n",
      "0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, \n",
      "0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, \n",
      "1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, \n",
      "0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n",
      "0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, \n",
      "1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, \n",
      "0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, \n",
      "0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, \n",
      "1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1), emergency_measures.7 = c(0, \n",
      "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, \n",
      "1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, \n",
      "1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, \n",
      "0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, \n",
      "1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, \n",
      "0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, \n",
      "0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, \n",
      "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, \n",
      "1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, \n",
      "1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, \n",
      "1, 1), emergency_measures.8 = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
      "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
      "0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
      "0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
      "0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
      "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
      "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, \n",
      "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, \n",
      "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, \n",
      "0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
      "0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0), overall_problem_house = c(1, \n",
      "1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, \n",
      "1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n",
      "1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, \n",
      "1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, \n",
      "1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, \n",
      "1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, \n",
      "1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, \n",
      "1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n",
      "1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n",
      "1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n",
      "1, 1), protect_valuables_impl = c(1, 0, 1, 0, 0, 1, 1, 1, 1, \n",
      "1, 1, 1, 0, 0, 0, 0, 0, 0, 0.75, 0, 0.75, 0, 1, 1, 1, 1, 1, 1, \n",
      "1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0.75, \n",
      "0.75, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, \n",
      "0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, \n",
      "0, 0, 0, 0, 0, 0, 1, 1, 0.75, 0, 0, 0.75, 0.75, 0.75, 0, 0, 1, \n",
      "1, 1, 0.75, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, \n",
      "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0.25, 0.25, \n",
      "0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, \n",
      "0.75, 0.75, 0, 0, 0, 0.25, 1, 0.25, 0, 0.25, 0.25, 0, 1, 0.25, \n",
      "1, 1, 0, 0, 1, 0, 0.25, 1, 1, 1, 0, 0, 0, 0, 0, 0.75, 0, 0.75, \n",
      "0.75, 0, 0, 0.75, 1, 0.25, 0, 0, 0, 0, 0, 0, 0.25), water_barriers_impl = c(1, \n",
      "1, 1, 1, 1, 1, 0.75, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, \n",
      "0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0.75, 1, 1, \n",
      "0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, \n",
      "1, 0, 0, 1, 0, 0, 1, 0, 1, 0.75, 1, 0, 0, 1, 0.75, 1, 1, 0.75, \n",
      "0, 1, 1, 0, 0, 0, 0.75, 1, 1, 1, 0.75, 0, 1, 1, 0, 0, 0, 1, 0.75, \n",
      "0.75, 0, 0.75, 0.75, 0.75, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, \n",
      "1, 0, 1, 1, 0, 0, 0, 1, 0.75, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
      "0, 0, 1, 0, 1, 1, 1, 0.75, 0, 0.25, 0.25, 0, 0, 0, 1, 0, 1, 1, \n",
      "0, 1, 1, 1, 0, 0.75, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0.25, \n",
      "1, 0.25, 1, 1, 1, 1, 0.25, 0.25, 1, 1, 0, 1, 0.75, 0, 1, 0, 0, \n",
      "1, 1, 0.75, 0, 1, 0, 0.75, 0.75, 0.75, 0.75, 0, 1, 1, 0, 0.25, \n",
      "0, 0, 0, 0, 0, 0, 0), pumping_equipment_impl = c(1, 0, 1, 1, \n",
      "1, 0.75, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, \n",
      "0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, \n",
      "1, 0, 0, 1, 0, 0, 0, 0.75, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, \n",
      "0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, \n",
      "0.75, 1, 1, 1, 1, 1, 1, 0.75, 1, 0, 1, 1, 0.75, 0.75, 0, 1, 0.75, \n",
      "1, 1, 1, 1, 0, 0.75, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, \n",
      "0.75, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, \n",
      "1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0.25, 0, 1, 0, 1, 1, 1, 0, \n",
      "1, 0, 1, 0, 0, 1, 0.25, 0, 0, 0.25, 1, 1, 0.25, 0, 1, 0.25, 0, \n",
      "1, 0.25, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0.75, 0.75, \n",
      "0.75, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0), elevation_building_impl = c(0.75, \n",
      "0, 0, 0, 0.75, 0.75, 0, 0, 0, 1, 0, 0, 0, 0.75, 0, 0, 0.75, 0, \n",
      "0.75, 0.75, 0.75, 1, 0, 0, 0, 0.75, 0, 0.75, 0.75, 1, 0, 0, 0, \n",
      "0, 0, 0, 0, 0.75, 0, 1, 1, 0, 0, 0.75, 0, 1, 0, 0.75, 0, 0.75, \n",
      "0, 0, 0.75, 0, 0, 1, 0.75, 0.75, 0, 0, 0.75, 0, 0, 0.75, 0.75, \n",
      "0.75, 1, 1, 0.75, 1, 0, 0.75, 0.75, 0, 1, 0, 1, 1, 0.75, 0, 0, \n",
      "0, 1, 0.75, 0, 0.75, 0, 0.75, 1, 1, 0.75, 0, 0, 0.75, 0.75, 0.75, \n",
      "1, 1, 1, 1, 0.75, 0.75, 0.75, 0, 0, 0, 0, 0.75, 0.75, 0.75, 0, \n",
      "0.75, 0.75, 0, 0, 0, 1, 0.75, 0.75, 0, 0.75, 0.75, 0.75, 0, 1, \n",
      "0, 0, 0, 0.75, 0.75, 0, 0, 0, 0, 0.75, 0, 0, 0.75, 1, 0.75, 0.75, \n",
      "0.25, 0, 0, 0, 0, 0.75, 0.25, 0.25, 1, 0, 0.25, 0.75, 0.25, 0.25, \n",
      "0, 0, 0, 0, 0.25, 1, 1, 0, 0, 0, 1, 0.25, 0.75, 0.25, 0.75, 0.25, \n",
      "0.25, 0.25, 0, 0.75, 0, 0.25, 0, 0.25, 0.75, 1, 1, 0, 0.75, 1, \n",
      "0, 1, 0, 1, 0.75, 0.75, 1, 1, 0.75, 0, 0, 0.75, 1, 1, 0.75, 0.25, \n",
      "0, 0, 0.75, 0.25, 0, 0, 0.25, 0, 0.25, 0.25, 0.75, 0.25), resistant_material_building_impl = c(1, \n",
      "1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0.75, 1, 0.75, \n",
      "1, 1, 1, 1, 0.75, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n",
      "1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n",
      "1, 1, 1, 0.75, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0.75, 1, 1, 1, 1, 0, \n",
      "1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0.75, 1, \n",
      "1, 1, 1, 1, 1, 1, 1, 1, 0.75, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n",
      "1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n",
      "1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0.75, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n",
      "1, 1, 0, 1, 0, 1, 1, 1, 0.25, 1, 1, 1, 1, 1, 1, 1, 1, 0.75, 1, \n",
      "1, 1, 1, 1, 0.75, 1, 0.25, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0.75, \n",
      "1, 1, 1, 1, 0.75, 1, 1, 1, 1, 1, 1, 1, 1, 1), electricity_higher_impl = c(1, \n",
      "0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0.75, 0, 0, 0.75, 1, 0.75, \n",
      "1, 0.75, 1, 1, 0, 1, 0.75, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, \n",
      "1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0.75, 0, 1, 1, 0, 1, 1, 1, 1, \n",
      "0, 1, 1, 1, 0, 0, 0, 0.75, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, \n",
      "0, 0, 1, 1, 1, 0.75, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, \n",
      "0, 0.75, 0, 0.75, 0.75, 0, 0, 1, 1, 1, 1, 0.75, 0, 0, 1, 0, 1, \n",
      "1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, \n",
      "0, 1, 1, 1, 0.75, 0, 0, 1, 1, 0, 0.75, 0, 1, 1, 0, 1, 0.75, 1, \n",
      "0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0.25, 0.75, 0.25, 1, \n",
      "0.25, 1, 1, 0.25, 1, 1, 0, 0.75, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0.75, \n",
      "1, 1, 1, 1, 1, 1, 0, 0, 0.75, 0.75, 0.25, 0, 1, 0.75, 1, 1, 0, \n",
      "1, 0, 0, 0, 1, 0), flood_protections_impl = c(1, 1, 1, 1, 1, \n",
      "1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n",
      "1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n",
      "1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, \n",
      "1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n",
      "1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0.75, 1, 1, 1, 1, 1, 1, 1, \n",
      "1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n",
      "1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n",
      "1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n",
      "1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n",
      "1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1), \n",
      "    flood_experience = c(0.8, 0.8, 0.4, 0, 0.8, 0.6, 0.6, 0.6, \n",
      "    0, 0.2, 0.4, 0.2, 0.8, 0.6, 1, 0.8, 0.8, 1, 0.8, 0.6, 0.8, \n",
      "    1, 1, 0.8, 0.6, 0.4, 1, 0.2, 0.2, 0.6, 0.6, 0, 0.8, 0.8, \n",
      "    0.8, 0.8, 0.4, 0.4, 0.6, 0.6, 0.8, 0.8, 0.8, 0.6, 0.6, 0.4, \n",
      "    0.6, 0.8, 1, 0.8, 1, 1, 1, 1, 1, 1, 1, 0.4, 0.8, 0.4, 0.8, \n",
      "    1, 1, 1, 1, 1, 0.8, 0.8, 0.8, 0.6, 1, 1, 1, 0.4, 0.4, 0.8, \n",
      "    1, 0.8, 0.8, 0.8, 1, 1, 0.4, 0.6, 0.8, 0.6, 0.6, 0, 1, 0.4, \n",
      "    0.4, 1, 0.8, 0.6, 0.8, 1, 0.6, 0.4, 1, 1, 0.8, 1, 1, 0.8, \n",
      "    0.8, 1, 0.8, 0.6, 0.8, 1, 1, 1, 0.6, 0.8, 0.8, 0.6, 0.2, \n",
      "    0.4, 0.4, 0.4, 0.2, 0.4, 0.8, 1, 0.8, 0.8, 1, 1, 1, 1, 1, \n",
      "    1, 0.8, 0.2, 1, 1, 1, 1, 0.6, 0.6, 0.6, 0.8, 0, 0.6, 0.6, \n",
      "    0.8, 0.6, 1, 1, 1, 0.8, 0.6, 0.4, 1, 0.8, 0.8, 0.8, 0.8, \n",
      "    0.4, 0.6, 0.6, 0.8, 0.8, 0.8, 0.6, 0.4, 0.6, 0.8, 1, 0.8, \n",
      "    1, 1, 1, 1, 0.4, 0.8, 1, 1, 1, 1, 0.8, 0.8, 0.8, 0.8, 0.6, \n",
      "    0.8, 1, 1, 0.4, 0.6, 0.6, 1, 0.4, 0.4, 1, 0.8, 0.8, 1, 1, \n",
      "    1, 0.8, 0.8, 1, 1, 0.8, 0.8, 1, 1, 1, 1, 0.8, 1, 1), bage = c(0.181818181818182, \n",
      "    0.318181818181818, 0.303030303030303, 0.303030303030303, \n",
      "    0.303030303030303, 0.378787878787879, 0.772727272727273, \n",
      "    0.333333333333333, 0.681818181818182, 0.0454545454545455, \n",
      "    0.348484848484849, 0.5, 0.257575757575758, 0, 0.242424242424242, \n",
      "    0.681818181818182, 0.681818181818182, 0.454545454545455, \n",
      "    0.257575757575758, 0.257575757575758, 0.212121212121212, \n",
      "    0.287878787878788, 0.303030303030303, 0.393939393939394, \n",
      "    0.303030303030303, 0.439393939393939, 0.348484848484849, \n",
      "    0.0151515151515152, 0.0909090909090909, 0.272727272727273, \n",
      "    0.348484848484849, 0.666666666666667, 0.454545454545455, \n",
      "    0.363636363636364, 0.454545454545455, 0.318181818181818, \n",
      "    0.318181818181818, 0.287878787878788, 0.303030303030303, \n",
      "    0.151515151515152, 0.454545454545455, 0.303030303030303, \n",
      "    0.454545454545455, 0.151515151515152, 0.303030303030303, \n",
      "    0.303030303030303, 0.318181818181818, 0.106060606060606, \n",
      "    0.681818181818182, 0.318181818181818, 0.318181818181818, \n",
      "    0.0909090909090909, 0.257575757575758, 0.0757575757575758, \n",
      "    0.136363636363636, 0.378787878787879, 0.0757575757575758, \n",
      "    0.409090909090909, 0.363636363636364, 0.181818181818182, \n",
      "    0.212121212121212, 0.409090909090909, 0.424242424242424, \n",
      "    0.46969696969697, 0.378787878787879, 0.106060606060606, 0.303030303030303, \n",
      "    0.151515151515152, 0.303030303030303, 0.272727272727273, \n",
      "    0.0454545454545455, 0.287878787878788, 0.772727272727273, \n",
      "    0.424242424242424, 0.287878787878788, 0.712121212121212, \n",
      "    0.242424242424242, 0.333333333333333, 0.212121212121212, \n",
      "    0.257575757575758, 0.681818181818182, 0.53030303030303, 1, \n",
      "    0.363636363636364, 0.303030303030303, 0.242424242424242, \n",
      "    0.53030303030303, 0, 0.242424242424242, 0.0909090909090909, \n",
      "    0.0606060606060606, 0.181818181818182, 0.227272727272727, \n",
      "    0.121212121212121, 0.181818181818182, 0.681818181818182, \n",
      "    0.439393939393939, 0.318181818181818, 0.863636363636364, \n",
      "    0.181818181818182, 0.363636363636364, 0.151515151515152, \n",
      "    0.303030303030303, 0, 0.212121212121212, 0.287878787878788, \n",
      "    0.287878787878788, 0.287878787878788, 0.348484848484849, \n",
      "    0.287878787878788, 0.287878787878788, 0.0909090909090909, \n",
      "    0.424242424242424, 0.136363636363636, 0.0909090909090909, \n",
      "    0.257575757575758, 0.0606060606060606, 0.121212121212121, \n",
      "    0.166666666666667, 0.0606060606060606, 0.212121212121212, \n",
      "    0.393939393939394, 0.242424242424242, 0.212121212121212, \n",
      "    0.151515151515152, 0.0909090909090909, 0.424242424242424, \n",
      "    0.212121212121212, 0.181818181818182, 0.212121212121212, \n",
      "    0.0454545454545455, 0.515151515151515, 0.242424242424242, \n",
      "    0.363636363636364, 0.0151515151515152, 0.5, 0.5, 0, 0.181818181818182, \n",
      "    0.0757575757575758, 0.0606060606060606, 0.212121212121212, \n",
      "    0.303030303030303, 0.727272727272727, 0.303030303030303, \n",
      "    0.257575757575758, 0, 0.242424242424242, 0.409090909090909, \n",
      "    0.272727272727273, 0.363636363636364, 0.257575757575758, \n",
      "    0.439393939393939, 0.333333333333333, 0.393939393939394, \n",
      "    0.318181818181818, 0.439393939393939, 0.272727272727273, \n",
      "    0.303030303030303, 0.272727272727273, 0.136363636363636, \n",
      "    0.424242424242424, 0.227272727272727, 0.424242424242424, \n",
      "    0.287878787878788, 0.287878787878788, 0.287878787878788, \n",
      "    0.0757575757575758, 0.636363636363636, 0.303030303030303, \n",
      "    0.166666666666667, 0.0757575757575758, 0.0151515151515152, \n",
      "    0.0606060606060606, 0.393939393939394, 0.348484848484849, \n",
      "    0.272727272727273, 0.363636363636364, 0.272727272727273, \n",
      "    0.0454545454545455, 0.272727272727273, 0.121212121212121, \n",
      "    0.287878787878788, 0.303030303030303, 0.227272727272727, \n",
      "    0.636363636363636, 0.242424242424242, 0.666666666666667, \n",
      "    1, 0.227272727272727, 0.242424242424242, 0.227272727272727, \n",
      "    0.0303030303030303, 0.106060606060606, 0.181818181818182, \n",
      "    0.227272727272727, 0.181818181818182, 0.848484848484849, \n",
      "    0.212121212121212, 0.303030303030303, 0, 0.212121212121212, \n",
      "    0.287878787878788, 0.272727272727273, 0.0454545454545455, \n",
      "    0.0454545454545455, 0.424242424242424, 0.181818181818182, \n",
      "    0.0303030303030303, 0.5, 0.227272727272727, 0.0151515151515152, \n",
      "    0.454545454545455), b_area = c(0.0131578947368421, 0.0384615384615385, \n",
      "    0.0688259109311741, 0.0435222672064777, 0.0334008097165992, \n",
      "    0.506072874493927, 0.062753036437247, 0.0334008097165992, \n",
      "    0.0232793522267206, 0.0688259109311741, 0.0991902834008097, \n",
      "    0.0789473684210526, 0.0303643724696356, 0.0334008097165992, \n",
      "    0.0688259109311741, 0.0435222672064777, 0.0334008097165992, \n",
      "    0.0283400809716599, 0.0688259109311741, 0.0384615384615385, \n",
      "    0.00809716599190283, 0.0789473684210526, 0.0121457489878543, \n",
      "    0.0536437246963563, 0.0384615384615385, 0.0860323886639676, \n",
      "    0.149797570850202, 0.103238866396761, 0.129554655870445, \n",
      "    0.0688259109311741, 0.114372469635628, 0.0850202429149798, \n",
      "    0.0789473684210526, 0.121862348178138, 0.0445344129554656, \n",
      "    0.0232793522267206, 0.0607287449392712, 0.109311740890688, \n",
      "    0.0688259109311741, 0, 0.0121457489878543, 0.0283400809716599, \n",
      "    0.0232793522267206, 0.0688259109311741, 0.0688259109311741, \n",
      "    0.00303643724696356, 0.0809716599190283, 0.0182186234817814, \n",
      "    0.145748987854251, 0.0870445344129555, 0.0789473684210526, \n",
      "    0.0688259109311741, 0.0688259109311741, 0.190283400809717, \n",
      "    0.0182186234817814, 0.190283400809717, 0.0759109311740891, \n",
      "    0.0313765182186235, 0.0445344129554656, 0.00303643724696356, \n",
      "    0.0303643724696356, 0.0384615384615385, 0.0566801619433198, \n",
      "    0.190283400809717, 0.0283400809716599, 0.0283400809716599, \n",
      "    0.0253036437246964, 0.119433198380567, 0.107287449392713, \n",
      "    0.0698380566801619, 0.00809716599190283, 0.15080971659919, \n",
      "    0.0384615384615385, 0.0374493927125506, 0.0890688259109312, \n",
      "    0.0384615384615385, 0.048582995951417, 0.0303643724696356, \n",
      "    1, 0.0688259109311741, 0.0384615384615385, 0.143623481781377, \n",
      "    0.101214574898785, 0.109311740890688, 0.0283400809716599, \n",
      "    0.0384615384615385, 0.00809716599190283, 0.0232793522267206, \n",
      "    0.0313765182186235, 0.109311740890688, 0.0242914979757085, \n",
      "    0.0313765182186235, 0.00303643724696356, 0.848178137651822, \n",
      "    0.0283400809716599, 0.00809716599190283, 0.0182186234817814, \n",
      "    0.0607287449392712, 0.0445344129554656, 0.0364372469635627, \n",
      "    0.0222672064777328, 0.0384615384615385, 0.109311740890688, \n",
      "    0.0161943319838057, 0.0587044534412955, 0.0890688259109312, \n",
      "    0.190283400809717, 0.0890688259109312, 0.139676113360324, \n",
      "    0.0384615384615385, 0.048582995951417, 0.0232793522267206, \n",
      "    0.230769230769231, 0.0817813765182186, 0.0121457489878543, \n",
      "    0.0688259109311741, 0.0283400809716599, 0.0283400809716599, \n",
      "    0.0566801619433198, 0.048582995951417, 0.0435222672064777, \n",
      "    0.0526315789473684, 0.109311740890688, 0.0991902834008097, \n",
      "    0.0182186234817814, 0.0688259109311741, 0.0637651821862348, \n",
      "    0.0334008097165992, 0.0688259109311741, 0.0789473684210526, \n",
      "    0.175101214574899, 0.139676113360324, 0.0688259109311741, \n",
      "    0.109311740890688, 0.0688259109311741, 0.048582995951417, \n",
      "    0.109311740890688, 0.0941295546558704, 0.0738866396761134, \n",
      "    0.048582995951417, 0.0303643724696356, 0.0384615384615385, \n",
      "    0.0435222672064777, 0.062753036437247, 0.0334008097165992, \n",
      "    0.0303643724696356, 0.0334008097165992, 0.0688259109311741, \n",
      "    0.0283400809716599, 0.0789473684210526, 0.0536437246963563, \n",
      "    0.0384615384615385, 0.0860323886639676, 0.149797570850202, \n",
      "    0.0789473684210526, 0.121862348178138, 0.0445344129554656, \n",
      "    0.0232793522267206, 0.0607287449392712, 0.0688259109311741, \n",
      "    0, 0.0121457489878543, 0.0283400809716599, 0.0232793522267206, \n",
      "    0.0688259109311741, 0.00303643724696356, 0.0809716599190283, \n",
      "    0.0182186234817814, 0.145748987854251, 0.0870445344129555, \n",
      "    0.0789473684210526, 0.0688259109311741, 0.190283400809717, \n",
      "    0.0182186234817814, 0.0313765182186235, 0.0445344129554656, \n",
      "    0.0738866396761134, 0.0384615384615385, 0.0566801619433198, \n",
      "    0.0283400809716599, 0.0253036437246964, 0.119433198380567, \n",
      "    0.0728744939271255, 0.107287449392713, 0.0698380566801619, \n",
      "    0.0384615384615385, 0.048582995951417, 0.0384615384615385, \n",
      "    0.101214574898785, 0.109311740890688, 0.0384615384615385, \n",
      "    0.0313765182186235, 0.109311740890688, 0.0242914979757085, \n",
      "    0.0313765182186235, 0.00303643724696356, 0.0283400809716599, \n",
      "    0.0445344129554656, 0.0364372469635627, 0.109311740890688, \n",
      "    0.0161943319838057, 0.0587044534412955, 0.0890688259109312, \n",
      "    0.0384615384615385, 0.0121457489878543, 0.0688259109311741, \n",
      "    0.0637651821862348, 0.0334008097165992, 0.175101214574899, \n",
      "    0.139676113360324, 0.0688259109311741, 0.0688259109311741, \n",
      "    0.048582995951417), hh_monthly_income_cat = c(0, 0.333333333333333, \n",
      "    0.166666666666667, 0.333333333333333, 0.166666666666667, \n",
      "    0.333333333333333, 0, 0.166666666666667, 0.166666666666667, \n",
      "    0.5, 0.333333333333333, 0.333333333333333, 0.166666666666667, \n",
      "    0.166666666666667, 0.166666666666667, 0.166666666666667, \n",
      "    0.166666666666667, 0.166666666666667, 0.166666666666667, \n",
      "    0.333333333333333, 0.166666666666667, 0.333333333333333, \n",
      "    0.166666666666667, 0.333333333333333, 0.5, 0.333333333333333, \n",
      "    0.833333333333333, 0.333333333333333, 0.5, 0.333333333333333, \n",
      "    0.333333333333333, 0.333333333333333, 0, 0.166666666666667, \n",
      "    0, 0.166666666666667, 0.333333333333333, 0.333333333333333, \n",
      "    0.166666666666667, 0.166666666666667, 0.333333333333333, \n",
      "    0.166666666666667, 0, 0.166666666666667, 0.333333333333333, \n",
      "    0.5, 0.333333333333333, 0.333333333333333, 0.166666666666667, \n",
      "    0.166666666666667, 0.166666666666667, 0.166666666666667, \n",
      "    0.166666666666667, 0.166666666666667, 0.166666666666667, \n",
      "    0.166666666666667, 0.5, 0.333333333333333, 0.333333333333333, \n",
      "    0.166666666666667, 0, 0.333333333333333, 0.166666666666667, \n",
      "    0.333333333333333, 0.166666666666667, 0.166666666666667, \n",
      "    0.333333333333333, 0.5, 0.333333333333333, 0.333333333333333, \n",
      "    0.166666666666667, 0.166666666666667, 0, 0, 0.166666666666667, \n",
      "    0.166666666666667, 0.166666666666667, 0.333333333333333, \n",
      "    1, 0, 0.166666666666667, 0.166666666666667, 0.333333333333333, \n",
      "    0.166666666666667, 0.166666666666667, 0, 0, 0.166666666666667, \n",
      "    0, 0.166666666666667, 0.333333333333333, 0.333333333333333, \n",
      "    0.166666666666667, 0.166666666666667, 0.166666666666667, \n",
      "    0, 0.166666666666667, 0.166666666666667, 0.166666666666667, \n",
      "    0.5, 0.333333333333333, 0.5, 0.666666666666667, 0.5, 0, 0.166666666666667, \n",
      "    0.333333333333333, 0.166666666666667, 0.333333333333333, \n",
      "    0.333333333333333, 0.333333333333333, 0.166666666666667, \n",
      "    0.166666666666667, 0.166666666666667, 0, 0.166666666666667, \n",
      "    0.333333333333333, 0.166666666666667, 0.166666666666667, \n",
      "    0.166666666666667, 0.333333333333333, 0.166666666666667, \n",
      "    0, 0.166666666666667, 0.166666666666667, 0.166666666666667, \n",
      "    0.166666666666667, 0.333333333333333, 0.166666666666667, \n",
      "    0.166666666666667, 0.333333333333333, 0, 0, 0.333333333333333, \n",
      "    0.166666666666667, 0.333333333333333, 0.166666666666667, \n",
      "    0, 0.333333333333333, 0.333333333333333, 0.166666666666667, \n",
      "    0.333333333333333, 0.333333333333333, 0, 0.166666666666667, \n",
      "    0.166666666666667, 0.166666666666667, 0.166666666666667, \n",
      "    0.166666666666667, 0.333333333333333, 0.333333333333333, \n",
      "    0.5, 0.333333333333333, 0.833333333333333, 0, 0.166666666666667, \n",
      "    0, 0.166666666666667, 0.333333333333333, 0.166666666666667, \n",
      "    0.166666666666667, 0.333333333333333, 0.166666666666667, \n",
      "    0, 0.333333333333333, 0.5, 0.333333333333333, 0.333333333333333, \n",
      "    0.166666666666667, 0.166666666666667, 0.166666666666667, \n",
      "    0.166666666666667, 0.166666666666667, 0.166666666666667, \n",
      "    0.333333333333333, 0.333333333333333, 0.166666666666667, \n",
      "    0.333333333333333, 0.166666666666667, 0.166666666666667, \n",
      "    0.333333333333333, 0.5, 0.166666666666667, 0.333333333333333, \n",
      "    0.333333333333333, 0.166666666666667, 0.166666666666667, \n",
      "    0.166666666666667, 0.333333333333333, 0.166666666666667, \n",
      "    0, 0, 0.166666666666667, 0.333333333333333, 0.333333333333333, \n",
      "    0.166666666666667, 0.166666666666667, 0.166666666666667, \n",
      "    0.5, 0.666666666666667, 0.5, 0, 0.166666666666667, 0.333333333333333, \n",
      "    0, 0.166666666666667, 0.166666666666667, 0.333333333333333, \n",
      "    0.333333333333333, 0, 0, 0.166666666666667, 0.333333333333333\n",
      "    ), shp_owner = c(1, 0, 0, 0, 0, 1, 0, 1, 1, 0.5, 1, 1, 1, \n",
      "    1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, \n",
      "    0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, \n",
      "    1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, \n",
      "    0, 1, 0, 0.5, 1, 1, 0.5, 0, 0.5, 1, 1, 1, 1, 1, 1, 1, 1, \n",
      "    1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, \n",
      "    0.5, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, \n",
      "    1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0.5, 0, 0, 0, \n",
      "    1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, \n",
      "    0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, \n",
      "    1, 1, 0, 1, 0.5, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, \n",
      "    1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0), shp_sector = c(0.0779220779220779, \n",
      "    0.25974025974026, 0, 0, 0, 0.0779220779220779, 0.012987012987013, \n",
      "    0.0779220779220779, 0.012987012987013, 0.25974025974026, \n",
      "    0, 0.0779220779220779, 0.0779220779220779, 0, 0, 0.25974025974026, \n",
      "    0, 0, 0, 0.25974025974026, 0.0779220779220779, 0.0779220779220779, \n",
      "    0.0779220779220779, 0, 0, 0.0389610389610389, 0.12987012987013, \n",
      "    0.025974025974026, 0.12987012987013, 0.0779220779220779, \n",
      "    1, 0, 0, 0.0779220779220779, 0, 0.142857142857143, 0, 0, \n",
      "    0.0779220779220779, 0.142857142857143, 0.142857142857143, \n",
      "    0.0779220779220779, 0, 1, 0.0779220779220779, 0.142857142857143, \n",
      "    0, 0.0389610389610389, 0, 0.0779220779220779, 0.0779220779220779, \n",
      "    0.0779220779220779, 1, 0, 0.0779220779220779, 0.12987012987013, \n",
      "    0.155844155844156, 0.0779220779220779, 0.0779220779220779, \n",
      "    0, 0, 0, 0.0779220779220779, 0, 0.0779220779220779, 0.12987012987013, \n",
      "    0, 0, 0.0779220779220779, 0.12987012987013, 0.0779220779220779, \n",
      "    0.168831168831169, 0.168831168831169, 0, 0.0779220779220779, \n",
      "    0, 0.155844155844156, 0, 1, 0, 0.0779220779220779, 0, 0.155844155844156, \n",
      "    0.168831168831169, 0.0389610389610389, 0.0779220779220779, \n",
      "    0.0779220779220779, 0, 0, 0, 0.0779220779220779, 0.0779220779220779, \n",
      "    0, 0, 0, 0.0779220779220779, 0.142857142857143, 1, 0.168831168831169, \n",
      "    0.0779220779220779, 0.142857142857143, 0.0389610389610389, \n",
      "    0, 0.0779220779220779, 0.142857142857143, 0, 0.142857142857143, \n",
      "    0.012987012987013, 0.0779220779220779, 0.0779220779220779, \n",
      "    0.168831168831169, 0.0779220779220779, 0, 0.0779220779220779, \n",
      "    0.0779220779220779, 0, 0.0389610389610389, 0.0779220779220779, \n",
      "    1, 0, 0, 0.0779220779220779, 0.0779220779220779, 0, 0.0779220779220779, \n",
      "    0.0779220779220779, 0.168831168831169, 0.168831168831169, \n",
      "    0.285714285714286, 0, 0, 0, 0, 0, 0, 0, 0.168831168831169, \n",
      "    0.168831168831169, 0, 0.0779220779220779, 0.0779220779220779, \n",
      "    0.25974025974026, 0, 0.012987012987013, 0.0779220779220779, \n",
      "    0.0779220779220779, 0, 0, 0, 0.0779220779220779, 0, 0, 0.0389610389610389, \n",
      "    0.12987012987013, 0, 0.0779220779220779, 0, 0.142857142857143, \n",
      "    0, 0.0779220779220779, 0.142857142857143, 0.142857142857143, \n",
      "    0.0779220779220779, 0, 0.0779220779220779, 0.142857142857143, \n",
      "    0, 0.0389610389610389, 0, 0.0779220779220779, 0.0779220779220779, \n",
      "    0.0779220779220779, 0, 0.0779220779220779, 0.0779220779220779, \n",
      "    0.0779220779220779, 0, 0, 0.0779220779220779, 0.12987012987013, \n",
      "    0, 0, 0, 0.0779220779220779, 0.12987012987013, 0, 0.155844155844156, \n",
      "    0.0779220779220779, 0.155844155844156, 0.168831168831169, \n",
      "    0.0779220779220779, 0, 0, 0.0779220779220779, 0.0779220779220779, \n",
      "    0, 0, 0.168831168831169, 0.0779220779220779, 0, 0.0779220779220779, \n",
      "    0.142857142857143, 0, 0.0779220779220779, 0.0779220779220779, \n",
      "    0.0779220779220779, 0.168831168831169, 0.168831168831169, \n",
      "    0, 0, 0, 0, 0), shp_employees = c(0, 0, 0, 0, 0, 0, 0.0303030303030303, \n",
      "    0.0303030303030303, 0, 0.0606060606060606, 0.0909090909090909, \n",
      "    0.0303030303030303, 0.0303030303030303, 0.0303030303030303, \n",
      "    0.0303030303030303, 0.0606060606060606, 0, 0.0303030303030303, \n",
      "    0.0303030303030303, 0, 0, 0, 0, 0, 0, 0.0909090909090909, \n",
      "    0.181818181818182, 0.0909090909090909, 0.242424242424242, \n",
      "    0.0606060606060606, 0.0909090909090909, 0.0303030303030303, \n",
      "    0, 0.0303030303030303, 0.0303030303030303, 0, 0.0606060606060606, \n",
      "    0.0303030303030303, 0, 0.0303030303030303, 0.0606060606060606, \n",
      "    0, 0, 0, 0.0909090909090909, 0, 0.0606060606060606, 0.0303030303030303, \n",
      "    0.0909090909090909, 0, 0, 0, 0, 0.0303030303030303, 0, 0.0303030303030303, \n",
      "    0, 0, 0, 0.0303030303030303, 0, 0.0303030303030303, 0.0303030303030303, \n",
      "    0, 0.0303030303030303, 0, 0, 0.0303030303030303, 0, 0, 0, \n",
      "    0.0303030303030303, 0, 0, 0.0303030303030303, 0.0303030303030303, \n",
      "    0.0909090909090909, 0.181818181818182, 1, 0.0303030303030303, \n",
      "    0, 0.0303030303030303, 0.151515151515152, 0.0909090909090909, \n",
      "    0.0303030303030303, 0.0303030303030303, 0.0303030303030303, \n",
      "    0.0303030303030303, 0, 0.0303030303030303, 0, 0, 0, 0.0303030303030303, \n",
      "    0, 0.0303030303030303, 0, 0.0303030303030303, 0, 0, 0, 0.0303030303030303, \n",
      "    0.0303030303030303, 0.0303030303030303, 0, 0, 0.0303030303030303, \n",
      "    0, 0.0303030303030303, 0, 0, 0, 0.0303030303030303, 0.0303030303030303, \n",
      "    0, 0, 0.0606060606060606, 0, 0.0303030303030303, 0.0303030303030303, \n",
      "    0, 0.0303030303030303, 0.0303030303030303, 0, 0, 0.0303030303030303, \n",
      "    0, 0, 0, 0.0303030303030303, 0.0303030303030303, 0.0303030303030303, \n",
      "    0, 0.0303030303030303, 0.0303030303030303, 0.0303030303030303, \n",
      "    0, 0, 0.121212121212121, 0.0303030303030303, 0, 0, 0, 0.0303030303030303, \n",
      "    0.0303030303030303, 0.0303030303030303, 0.0303030303030303, \n",
      "    0.0303030303030303, 0.0303030303030303, 0, 0, 0, 0.0909090909090909, \n",
      "    0.181818181818182, 0, 0.0303030303030303, 0.0303030303030303, \n",
      "    0, 0.0606060606060606, 0, 0.0303030303030303, 0.0606060606060606, \n",
      "    0, 0, 0.0909090909090909, 0, 0.0606060606060606, 0.0303030303030303, \n",
      "    0.0909090909090909, 0, 0, 0, 0.0303030303030303, 0, 0, 0, \n",
      "    0, 0.0303030303030303, 0.0303030303030303, 0, 0, 0.0303030303030303, \n",
      "    0.0303030303030303, 0, 0, 0.0303030303030303, 0.0909090909090909, \n",
      "    0, 0.151515151515152, 0.0909090909090909, 0.0303030303030303, \n",
      "    0, 0.0303030303030303, 0, 0, 0, 0, 0, 0, 0.0303030303030303, \n",
      "    0.0303030303030303, 0, 0, 0, 0, 0.0303030303030303, 0, 0, \n",
      "    0.0303030303030303, 0.0303030303030303, 0, 0.0303030303030303, \n",
      "    0.0303030303030303), shp_avgmonthly_sale_cat = c(0.25, 0, \n",
      "    0, 0.25, 0, 0, 0, 0, 0, 0.75, 0.5, 0.25, 0.25, 0.25, 0.25, \n",
      "    0.25, 0, 0.25, 0.5, 0.25, 0.25, 0.5, 0, 0.25, 0, 0.25, 0.75, \n",
      "    0.25, 0.5, 0.5, 0.5, 0.25, 0, 0, 0, 0, 0.25, 0, 0.25, 0.5, \n",
      "    0.5, 0, 0, 0.25, 0.5, 0.5, 0.5, 0.5, 0.5, 0, 0.25, 0.25, \n",
      "    0.25, 0.25, 0.25, 0.25, 0.5, 0, 0.25, 0.25, 0, 0, 0, 0, 0, \n",
      "    0.25, 0.25, 0.25, 0, 0.5, 0, 0.25, 0, 0, 0.25, 0, 0.5, 0.25, \n",
      "    1, 0, 0.25, 0.25, 0.25, 0.5, 0.5, 0, 0, 0.25, 0, 0.25, 0.5, \n",
      "    0.5, 0.25, 0.25, 0, 0, 0.25, 0.25, 0, 0, 0.5, 0.5, 0.5, 0.5, \n",
      "    0, 0, 0.5, 0, 0.25, 0.25, 0.25, 0, 0.25, 0, 0, 0.25, 0.25, \n",
      "    1, 0.25, 0, 0, 0, 0, 0, 0, 0.25, 1, 1, 0, 0.25, 0.25, 0, \n",
      "    0, 0.25, 0.25, 0.5, 0.25, 0, 0.5, 0.25, 0, 0, 0.25, 0, 0, \n",
      "    0.25, 0.25, 0.25, 0.25, 0.5, 0.25, 0, 0.25, 0.75, 0, 0, 0, \n",
      "    0, 0.25, 0.25, 0.5, 0.5, 0, 0, 0.5, 0.5, 0.5, 0.5, 0.5, 0, \n",
      "    0.25, 0.25, 0.25, 0.25, 0, 0.25, 0, 0, 0, 0.25, 0.25, 0.25, \n",
      "    0.25, 0, 0.5, 0, 0.5, 0.25, 0.25, 0.5, 0, 0, 0.25, 0.5, 0.5, \n",
      "    0.25, 0, 0, 0, 0.5, 0.5, 0, 0, 0.25, 0, 0.25, 1, 1, 0.25, \n",
      "    0, 0, 0.25, 0.5), shp_profits_last5years = c(1, 0.666666666666667, \n",
      "    0.333333333333333, 0.333333333333333, 0.333333333333333, \n",
      "    0.666666666666667, 0.666666666666667, 0.666666666666667, \n",
      "    0.666666666666667, 0.333333333333333, 0.333333333333333, \n",
      "    0.333333333333333, 0.666666666666667, 0.666666666666667, \n",
      "    0.666666666666667, 1, 0.666666666666667, 1, 0, 0.666666666666667, \n",
      "    1, 0.333333333333333, 0.666666666666667, 0.333333333333333, \n",
      "    0.333333333333333, 0.333333333333333, 0.666666666666667, \n",
      "    0.333333333333333, 0.333333333333333, 0.666666666666667, \n",
      "    0.333333333333333, 0.333333333333333, 0.666666666666667, \n",
      "    0.666666666666667, 0.333333333333333, 0.333333333333333, \n",
      "    1, 1, 1, 1, 0.333333333333333, 1, 1, 0.333333333333333, 0, \n",
      "    0.333333333333333, 1, 0.666666666666667, 0.333333333333333, \n",
      "    0.666666666666667, 0.333333333333333, 0.333333333333333, \n",
      "    1, 0.333333333333333, 0.333333333333333, 1, 0.666666666666667, \n",
      "    0.666666666666667, 0.666666666666667, 1, 0.333333333333333, \n",
      "    1, 1, 0.666666666666667, 0.666666666666667, 0.666666666666667, \n",
      "    0.333333333333333, 0.333333333333333, 0.333333333333333, \n",
      "    0.333333333333333, 0.333333333333333, 0, 0.333333333333333, \n",
      "    0.666666666666667, 0.333333333333333, 1, 1, 1, 1, 0.333333333333333, \n",
      "    0.333333333333333, 1, 0.333333333333333, 0.333333333333333, \n",
      "    0.666666666666667, 0.333333333333333, 0.333333333333333, \n",
      "    0.333333333333333, 1, 0.333333333333333, 1, 1, 0.333333333333333, \n",
      "    0, 0.333333333333333, 0.666666666666667, 0.333333333333333, \n",
      "    0.666666666666667, 0.666666666666667, 0.333333333333333, \n",
      "    0.333333333333333, 0.666666666666667, 0.666666666666667, \n",
      "    0.666666666666667, 1, 1, 0.333333333333333, 1, 0.333333333333333, \n",
      "    0.666666666666667, 0.333333333333333, 1, 0.333333333333333, \n",
      "    0.666666666666667, 0.666666666666667, 0.333333333333333, \n",
      "    1, 1, 0.333333333333333, 1, 0.666666666666667, 0.333333333333333, \n",
      "    0.666666666666667, 0.333333333333333, 0.666666666666667, \n",
      "    0.666666666666667, 0.666666666666667, 0.666666666666667, \n",
      "    0.666666666666667, 0.666666666666667, 0.666666666666667, \n",
      "    0.666666666666667, 0.666666666666667, 0.333333333333333, \n",
      "    1, 0.333333333333333, 1, 1, 0.333333333333333, 0.333333333333333, \n",
      "    0.666666666666667, 0.666666666666667, 0.333333333333333, \n",
      "    0.666666666666667, 0.666666666666667, 0.666666666666667, \n",
      "    0.666666666666667, 0.666666666666667, 1, 0.333333333333333, \n",
      "    0.333333333333333, 0.333333333333333, 0.333333333333333, \n",
      "    0.666666666666667, 0.666666666666667, 0.666666666666667, \n",
      "    0.333333333333333, 0.333333333333333, 1, 1, 1, 0.333333333333333, \n",
      "    1, 1, 0, 0.333333333333333, 1, 0.666666666666667, 0.333333333333333, \n",
      "    0.666666666666667, 0.333333333333333, 0.333333333333333, \n",
      "    0.333333333333333, 0.333333333333333, 0.666666666666667, \n",
      "    0.666666666666667, 0.333333333333333, 1, 1, 0.666666666666667, \n",
      "    0.333333333333333, 0.333333333333333, 0.333333333333333, \n",
      "    0.333333333333333, 0.333333333333333, 1, 1, 0.333333333333333, \n",
      "    0.333333333333333, 0.333333333333333, 0.333333333333333, \n",
      "    1, 0.333333333333333, 1, 1, 0.333333333333333, 0.333333333333333, \n",
      "    0.666666666666667, 0.333333333333333, 0.666666666666667, \n",
      "    0.666666666666667, 1, 1, 0.666666666666667, 0.666666666666667, \n",
      "    0.666666666666667, 0.666666666666667, 0.666666666666667, \n",
      "    0.666666666666667, 0.666666666666667, 0.666666666666667, \n",
      "    1, 0.333333333333333), resilience_more_future_affected = c(0.25, \n",
      "    0, 0.5, 0.75, 1, 0.25, 0.75, 0.75, 0.75, 1, 0.5, 0.5, 0.25, \n",
      "    0.75, 1, 0, 0.5, 1, 0.75, 0.5, 0.75, 1, 0.75, 1, 1, 0, 0.5, \n",
      "    0.25, 0.75, 0.75, 0.75, 0.25, 1, 1, 1, 1, 0.75, 0.75, 1, \n",
      "    0.75, 1, 1, 1, 0, 0.75, 0.75, 1, 0.5, 0.5, 0.75, 0.75, 1, \n",
      "    0.5, 0.75, 0.25, 0.75, 0.5, 0, 1, 0.75, 1, 0.75, 0.75, 0, \n",
      "    0, 1, 1, 0.75, 0, 1, 0, 1, 0.75, 1, 1, 0.25, 0.25, 0.25, \n",
      "    0.75, 1, 0.5, 1, 0, 0.25, 0.5, 0.5, 0.75, 0.75, 1, 0.25, \n",
      "    0, 0.75, 1, 0, 0, 0.25, 1, 0, 0.75, 0.75, 0.25, 0.25, 1, \n",
      "    0.5, 0.25, 1, 1, 1, 0.5, 0.5, 1, 0.25, 1, 0.75, 1, 0.75, \n",
      "    1, 1, 0.75, 1, 0.75, 0.25, 0.75, 1, 0.75, 0.5, 0.75, 0.5, \n",
      "    0.25, 1, 1, 1, 0.75, 0, 0.75, 1, 0.25, 0, 1, 1, 0.5, 0, 0.75, \n",
      "    0.75, 0.75, 0.25, 0.75, 1, 1, 1, 1, 1, 0, 0.5, 1, 1, 1, 1, \n",
      "    0.75, 1, 0.75, 1, 1, 1, 0.75, 0.75, 1, 0.5, 0.5, 0.75, 0.75, \n",
      "    1, 0.75, 0.25, 0, 1, 0.5, 0.75, 0.75, 1, 1, 0.75, 1, 0, 1, \n",
      "    0.25, 0.25, 0.5, 0, 0.25, 0.5, 1, 0.25, 0, 0.75, 1, 0, 0.75, \n",
      "    0.75, 1, 0.5, 0.25, 1, 0.5, 1, 0.5, 0.75, 0.5, 1, 1, 0.75, \n",
      "    0.75, 1), resilience_govern_warnings_helpful = c(1, 0.25, \n",
      "    0, 0, 0, 0, 0.5, 0.25, 0, 0.5, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
      "    0, 0.75, 0.5, 0, 0.25, 0.5, 1, 0, 0, 0, 0, 0, 0.25, 0.25, \n",
      "    0, 0, 0, 0.25, 0.25, 0.5, 0.25, 0.75, 0, 0, 0, 0, 0, 0, 0.75, \n",
      "    0.25, 0.75, 0.25, 0, 0, 0.25, 1, 0.25, 0.5, 0.5, 0.5, 0.75, \n",
      "    0.5, 0.75, 0, 0, 0, 0.75, 0, 0, 0, 0.5, 0.75, 0, 0.25, 0, \n",
      "    0, 0.5, 0.25, 0, 0, 0, 0, 0.25, 1, 0, 1, 0.75, 0.75, 0.25, \n",
      "    0, 0.75, 0.25, 0.5, 0.25, 0.25, 0, 0, 0.25, 0, 0.5, 0.25, \n",
      "    0.75, 0.25, 0, 0, 0.25, 0.75, 0.25, 0, 0.25, 0, 0, 0, 1, \n",
      "    0, 0, 0, 0, 0, 0, 0, 0, 0.75, 0.75, 0.5, 0.75, 0.25, 0.75, \n",
      "    0.5, 0.25, 0, 0, 0, 0, 0.75, 0.25, 0, 0.25, 1, 0, 0, 0, 0.25, \n",
      "    0, 0.5, 0.25, 0, 0, 0, 0, 0.5, 0.25, 0.5, 1, 0, 0.25, 0, \n",
      "    0, 0, 0.25, 0.5, 0.25, 0.75, 0, 0, 0, 0, 0, 0.75, 0.25, 0.75, \n",
      "    0.25, 0, 0.25, 1, 0.5, 0.5, 0.75, 0.75, 0, 0.75, 0, 0, 0, \n",
      "    0, 0.5, 0.5, 0.25, 0, 1, 0, 0.75, 0, 0.75, 0.25, 0.5, 0.25, \n",
      "    0, 0.5, 0.25, 0, 0, 0.25, 0.75, 0, 0, 0.25, 0.75, 0.5, 0, \n",
      "    0, 0, 0.25, 0), resilience_govern_careing = c(1, 0.75, 1, \n",
      "    0.75, 1, 0.25, 0.5, 0.5, 0.75, 0.5, 0, 0, 0, 0.5, 0, 0, 0, \n",
      "    0.5, 0.25, 0, 0.75, 0.75, 0.5, 0.25, 0.5, 0.75, 0.25, 0.25, \n",
      "    0.25, 0, 0, 0.75, 0.25, 0, 0, 0, 0.25, 0.25, 0.75, 0.25, \n",
      "    1, 0.75, 0.5, 0, 0.75, 0.75, 0, 0.75, 0.75, 1, 0.25, 0.5, \n",
      "    0, 0.75, 1, 0.25, 0, 0.75, 0.75, 0.75, 0.5, 0.75, 0.75, 0.75, \n",
      "    0.75, 0.5, 0, 0.75, 0, 0.5, 1, 0.5, 0.25, 0.5, 0, 0.75, 0.75, \n",
      "    0.75, 0.75, 0.75, 0.25, 0.25, 1, 0.75, 0.5, 0.5, 0.5, 0.25, \n",
      "    0.75, 0.75, 0.75, 0.5, 0.25, 1, 0.5, 0.25, 0.25, 1, 0.25, \n",
      "    0.25, 0.25, 0.5, 0, 0.25, 0.25, 0.75, 0.25, 0, 0.25, 0, 0.75, \n",
      "    0.75, 1, 0.75, 0, 0.25, 0, 0.75, 0.25, 0.25, 0.25, 0.75, \n",
      "    0.25, 0.5, 0.75, 0.75, 0.75, 0.75, 0.25, 0, 0.25, 0.75, 0.75, \n",
      "    0.75, 0.25, 0, 0.25, 1, 0, 0, 0, 0.75, 0.75, 0.5, 0.5, 0, \n",
      "    0.5, 0, 0.5, 0.75, 0.25, 0.5, 0.75, 0.25, 0.25, 0, 0, 0, \n",
      "    0.25, 0.75, 0.25, 1, 0.75, 0.5, 0.75, 0.75, 0, 0.75, 0.75, \n",
      "    1, 0.25, 0.5, 0.75, 1, 0.75, 0.75, 0.5, 0.75, 0.75, 0.5, \n",
      "    0, 0.75, 0.5, 0, 0.5, 0.75, 0.75, 0.25, 1, 0.75, 0.5, 0.75, \n",
      "    0.75, 0.75, 0.5, 0.25, 0.5, 0.25, 0.25, 0, 0.25, 0.25, 0.75, \n",
      "    0, 0, 0.75, 0.75, 0.75, 0.25, 0.75, 0.75, 0.25, 0), perception_private_economy_future = c(1, \n",
      "    1, 0.5, 1, 0.5, 1, 1, 1, 0.5, 1, 0.5, 0.5, 0.5, 0.5, 0.5, \n",
      "    0.5, 0.5, 0.5, 0, 0, 0, 0.5, 0, 1, 0.5, 0, 1, 1, 0.5, 0.5, \n",
      "    0.5, 1, 0.5, 0.5, 0.5, 0.5, 1, 1, 0, 1, 1, 0.5, 0.5, 0.5, \n",
      "    0.5, 0.5, 0.5, 1, 1, 0.5, 1, 0.5, 1, 1, 1, 0.5, 1, 1, 0.5, \n",
      "    1, 1, 0.5, 0.5, 1, 0.5, 0.5, 0.5, 1, 1, 1, 0, 0.5, 1, 0.5, \n",
      "    0.5, 1, 0.5, 0, 0.5, 0.5, 0.5, 0, 0, 0, 1, 1, 1, 1, 0.5, \n",
      "    1, 1, 0, 1, 1, 1, 1, 0.5, 1, 0.5, 1, 0, 0.5, 0.5, 0.5, 1, \n",
      "    1, 0.5, 0.5, 1, 1, 0.5, 1, 1, 0.5, 0.5, 1, 0.5, 0.5, 0.5, \n",
      "    0.5, 0.5, 0.5, 0, 1, 0, 1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, \n",
      "    0.5, 1, 1, 1, 0.5, 1, 1, 0.5, 1, 1, 1, 1, 1, 0.5, 0.5, 0.5, \n",
      "    0.5, 0.5, 1, 0.5, 0, 1, 0.5, 0.5, 0.5, 0.5, 1, 0, 1, 1, 0.5, \n",
      "    0.5, 0.5, 0.5, 0.5, 1, 1, 0.5, 1, 0.5, 1, 1, 1, 0.5, 1, 0.5, \n",
      "    0.5, 0.5, 0.5, 1, 0.5, 1, 1, 1, 0.5, 0.5, 0, 0, 1, 0.5, 1, \n",
      "    1, 0, 1, 1, 0.5, 1, 0.5, 0.5, 1, 1, 1, 0.5, 1, 0.5, 0.5, \n",
      "    0.5, 0.5, 0.5, 1, 1), shp_suppliers_HCMC = c(1, 1, 1, 1, \n",
      "    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n",
      "    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n",
      "    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n",
      "    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n",
      "    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n",
      "    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, \n",
      "    0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n",
      "    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n",
      "    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n",
      "    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n",
      "    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1), \n",
      "    shp_content_value_euro = c(0.00365624450818671, 0.159049366499169, \n",
      "    0.159049366499169, 0.067641764489203, 0.0493600455131699, \n",
      "    0.0402191860251534, 0.13162678803512, 0.0402191860251534, \n",
      "    0.0859229870301366, 0.027970642813953, 0.0493600455131699, \n",
      "    0.067641764489203, 0.13162678803512, 0.0585009050011865, \n",
      "    0.0493600455131699, 0.07678212754212, 0.0219374670491203, \n",
      "    0.0402191860251534, 0.067641764489203, 0.0859229870301366, \n",
      "    0.0402191860251534, 0.067641764489203, 0.0127971039962033, \n",
      "    0.067641764489203, 0.0310783265371368, 0.13162678803512, \n",
      "    0.122485928547103, 0.0493600455131699, 0.0219374670491203, \n",
      "    0.0219374670491203, 0.0585009050011865, 0.0310783265371368, \n",
      "    0.213894026992169, 0.0585009050011865, 0.13162678803512, \n",
      "    0.0219374670491203, 0.0585009050011865, 0.360146289495135, \n",
      "    0.0859229870301366, 0.0219374670491203, 0.0493600455131699, \n",
      "    0.067641764489203, 0.0219374670491203, 0.0173672855226618, \n",
      "    0.268738191050069, 0.067641764489203, 0.13162678803512, 0.0859229870301366, \n",
      "    0.067641764489203, 0.177330589040103, 0.0859229870301366, \n",
      "    0.0859229870301366, 0.0950638465181531, 0.07678212754212, \n",
      "    0.0127971039962033, 0.0219374670491203, 0.07678212754212, \n",
      "    0.0402191860251534, 0.0585009050011865, 0.0127971039962033, \n",
      "    0.0585009050011865, 0.0585009050011865, 0.140767647523136, \n",
      "    0.07678212754212, 0.0493600455131699, 0.063071086527645, \n",
      "    0.0310783265371368, 0.067641764489203, 0.0493600455131699, \n",
      "    0.0402191860251534, 0.0310783265371368, 0.177330589040103, \n",
      "    0.0859229870301366, 0.0402191860251534, 0.0127971039962033, \n",
      "    0.0859229870301366, 0.177330589040103, 0.0859229870301366, \n",
      "    1, 0.0859229870301366, 0.0402191860251534, 0.0310783265371368, \n",
      "    0.067641764489203, 0.07678212754212, 0.0585009050011865, \n",
      "    0.067641764489203, 0.0402191860251534, 0, 0.0127971039962033, \n",
      "    0.268738191050069, 0.0310783265371368, 0.0447893675516119, \n",
      "    0.0127971039962033, 0.542961493515068, 0.0402191860251534, \n",
      "    0.0402191860251534, 0.0402191860251534, 0.0219374670491203, \n",
      "    0.177330589040103, 0.0219374670491203, 0.01645334850439, \n",
      "    0.10420470600617, 0.13162678803512, 0.00365624450818671, \n",
      "    0.0127971039962033, 0.0219374670491203, 0.908592397990034, \n",
      "    0.0219374670491203, 0.177330589040103, 0.0310783265371368, \n",
      "    0.00365624450818671, 0.0310783265371368, 0.140767647523136, \n",
      "    0.067641764489203, 0.0585009050011865, 0.0219374670491203, \n",
      "    0.0585009050011865, 0.0402191860251534, 0.0173672855226618, \n",
      "    0.0493600455131699, 0.0219374670491203, 0.0402191860251534, \n",
      "    0.0402191860251534, 0.10420470600617, 0.0127971039962033, \n",
      "    0.0402191860251534, 0.0859229870301366, 0.0310783265371368, \n",
      "    0.0402191860251534, 0.07678212754212, 0.13162678803512, 0.07678212754212, \n",
      "    0.13162678803512, 0.0859229870301366, 0.177330589040103, \n",
      "    0.0585009050011865, 0.07678212754212, 0.0402191860251534, \n",
      "    0.0310783265371368, 0.0859229870301366, 0.0859229870301366, \n",
      "    0.159049366499169, 0.067641764489203, 0.13162678803512, 0.0402191860251534, \n",
      "    0.13162678803512, 0.0585009050011865, 0.0493600455131699, \n",
      "    0.0402191860251534, 0.067641764489203, 0.067641764489203, \n",
      "    0.0310783265371368, 0.13162678803512, 0.122485928547103, \n",
      "    0.213894026992169, 0.0585009050011865, 0.13162678803512, \n",
      "    0.0219374670491203, 0.0585009050011865, 0.0859229870301366, \n",
      "    0.0219374670491203, 0.0493600455131699, 0.067641764489203, \n",
      "    0.0219374670491203, 0.268738191050069, 0.067641764489203, \n",
      "    0.13162678803512, 0.0859229870301366, 0.067641764489203, \n",
      "    0.177330589040103, 0.0859229870301366, 0.0859229870301366, \n",
      "    0.07678212754212, 0.0127971039962033, 0.0402191860251534, \n",
      "    0.0585009050011865, 0.0493600455131699, 0.0585009050011865, \n",
      "    0.140767647523136, 0.063071086527645, 0.0310783265371368, \n",
      "    0.067641764489203, 0.0310783265371368, 0.0493600455131699, \n",
      "    0.0402191860251534, 0.0859229870301366, 0.177330589040103, \n",
      "    0.0402191860251534, 0.067641764489203, 0.07678212754212, \n",
      "    0.067641764489203, 0.0127971039962033, 0.268738191050069, \n",
      "    0.0310783265371368, 0.0447893675516119, 0.0127971039962033, \n",
      "    0.0402191860251534, 0.177330589040103, 0.0219374670491203, \n",
      "    0.13162678803512, 0.00365624450818671, 0.0127971039962033, \n",
      "    0.0219374670491203, 0.0310783265371368, 0.0585009050011865, \n",
      "    0.0402191860251534, 0.0859229870301366, 0.0310783265371368, \n",
      "    0.13162678803512, 0.07678212754212, 0.13162678803512, 0.177330589040103, \n",
      "    0.0585009050011865), shp_registered_capital_euro = c(0.000210533778165146, \n",
      "    0.000473808197296306, 0, 0.000473808197296306, 0.000221110492071609, \n",
      "    0.000473808197296306, 0.000473808197296306, 0.000579003622095727, \n",
      "    0.000473808197296306, 0.00521088967029524, 0.00205274006925175, \n",
      "    0.00205274006925175, 0.00257914597894777, 0.00205274006925175, \n",
      "    0.00100007117842602, 0.00100007117842602, 0.00152647708812204, \n",
      "    0.000736939687861163, 0.000473808197296306, 0.00100007117842602, \n",
      "    0.000368469843930581, 0.0210012088898138, 0.00468448376059922, \n",
      "    0.000473808197296306, 2.62988561998553e-05, 0.00521088967029524, \n",
      "    0.15785045155422, 0.00310540896007748, 0.0210012088898138, \n",
      "    0.00205274006925175, 0.00100007117842602, 0.0036318148697735, \n",
      "    0.000210533778165146, 0.00100007117842602, 0.00257914597894777, \n",
      "    0.000473808197296306, 0.00257914597894777, 5.27406409660142e-05, \n",
      "    0.000473808197296306, 0.000736939687861163, 0.00100007117842602, \n",
      "    0.000210533778165146, 0.00257914597894777, 0.00100007117842602, \n",
      "    0.00152647708812204, 0.000842135112660584, 0.000473808197296306, \n",
      "    0.0525817044002846, 0.00257914597894777, 0.00257914597894777, \n",
      "    0.00257914597894777, 0.00152647708812204, 0.00626355856112097, \n",
      "    0.000473808197296306, 0.00257914597894777, 0.00415822077946951, \n",
      "    0.0210012088898138, 0.000105338353365725, 0.00257914597894777, \n",
      "    0.000473808197296306, 0.000210533778165146, 0.00100007117842602, \n",
      "    0.000736939687861163, 0.000473808197296306, 0.00100007117842602, \n",
      "    0.00415822077946951, 0.00152647708812204, 0.00415822077946951, \n",
      "    0.0036318148697735, 0.0157377215071188, 0.000579003622095727, \n",
      "    0.000105338353365725, 0.00100007117842602, 0.000736939687861163, \n",
      "    0.00205274006925175, 0.000421067556330292, 0.00152647708812204, \n",
      "    0.0157377215071188, 1, 0.00205274006925175, 0.00257914597894777, \n",
      "    5.27406409660142e-05, 0.00100007117842602, 0.0104742341244239, \n",
      "    0.000473808197296306, 0.00100007117842602, 0.000473808197296306, \n",
      "    0.00257914597894777, 0.000210533778165146, 0.000736939687861163, \n",
      "    0.00626355856112097, 0.00257914597894777, 0.000105338353365725, \n",
      "    0.00152647708812204, 0.000210533778165146, 0.00100007117842602, \n",
      "    0.000105338353365725, 0.0104742341244239, 0.000736939687861163, \n",
      "    0.000473808197296306, 0.00152647708812204, 0.0315280407266374, \n",
      "    0.0036318148697735, 0.00257914597894777, 0.000473808197296306, \n",
      "    0.000105338353365725, 0.0104742341244239, 0.000168512779671899, \n",
      "    0.00100007117842602, 0.00257914597894777, 0.00100007117842602, \n",
      "    0.00205274006925175, 0.00521088967029524, 0.00521088967029524, \n",
      "    0.00205274006925175, 0, 0.0525817044002846, 0.000473808197296306, \n",
      "    0.000473808197296306, 0.000736939687861163, 0.00100007117842602, \n",
      "    0.00152647708812204, 0.000210533778165146, 0.000105338353365725, \n",
      "    0.000473808197296306, 0.00152647708812204, 0.000579003622095727, \n",
      "    0.00257914597894777, 0.00152647708812204, 0.00205274006925175, \n",
      "    0.00836889634277243, 0.00257914597894777, 0.000473808197296306, \n",
      "    0.00310540896007748, 0.00521088967029524, 0.00521088967029524, \n",
      "    0.00205274006925175, 0.00100007117842602, 0.0157377215071188, \n",
      "    0.00521088967029524, 0.000315872131530871, 0.000473808197296306, \n",
      "    0.000473808197296306, 0.000473808197296306, 0.000579003622095727, \n",
      "    0.00257914597894777, 0.00205274006925175, 0.00100007117842602, \n",
      "    0.000736939687861163, 0.0210012088898138, 0.000473808197296306, \n",
      "    2.62988561998553e-05, 0.00521088967029524, 0.15785045155422, \n",
      "    0.000210533778165146, 0.00100007117842602, 0.00257914597894777, \n",
      "    0.000473808197296306, 0.00257914597894777, 0.000473808197296306, \n",
      "    0.000736939687861163, 0.00100007117842602, 0.000210533778165146, \n",
      "    0.00257914597894777, 0.00152647708812204, 0.000842135112660584, \n",
      "    0.000473808197296306, 0.0525817044002846, 0.00257914597894777, \n",
      "    0.00257914597894777, 0.00257914597894777, 0.00152647708812204, \n",
      "    0.000473808197296306, 0.00257914597894777, 0.000105338353365725, \n",
      "    0.00257914597894777, 0.0104742341244239, 0.00100007117842602, \n",
      "    0.000736939687861163, 0.00415822077946951, 0.00152647708812204, \n",
      "    0.00415822077946951, 0.00310540896007748, 0.0036318148697735, \n",
      "    0.0157377215071188, 0.000421067556330292, 0.00152647708812204, \n",
      "    0.00257914597894777, 0.00100007117842602, 0.0104742341244239, \n",
      "    0.00100007117842602, 0.000210533778165146, 0.000736939687861163, \n",
      "    0.00626355856112097, 0.00257914597894777, 0.000105338353365725, \n",
      "    0.000210533778165146, 0.000736939687861163, 0.000473808197296306, \n",
      "    0.0036318148697735, 0.00257914597894777, 0.000473808197296306, \n",
      "    0.000105338353365725, 0.00257914597894777, 0.00205274006925175, \n",
      "    0.00152647708812204, 0.000579003622095727, 0.00257914597894777, \n",
      "    0.00836889634277243, 0.00257914597894777, 0.000473808197296306, \n",
      "    0.00521088967029524, 0.00521088967029524)), method = \"cforest\", \n",
      "    metric = \"MAE\", trControl = list(method = \"repeatedcv\", number = 10L, \n",
      "        repeats = 5L, search = \"grid\", p = 0.75, initialWindow = NULL, \n",
      "        horizon = 1, fixedWindow = TRUE, skip = 0, verboseIter = FALSE, \n",
      "        returnData = TRUE, returnResamp = \"final\", savePredictions = FALSE, \n",
      "        classProbs = FALSE, summaryFunction = function (data, \n",
      "            lev = NULL, model = NULL) \n",
      "        {\n",
      "            if (is.character(data$obs)) \n",
      "                data$obs <- factor(data$obs, levels = lev)\n",
      "            postResample(data[, \"pred\"], data[, \"obs\"])\n",
      "        }, selectionFunction = \"best\", preProcOptions = list(\n",
      "            thresh = 0.95, ICAcomp = 3, k = 5, freqCut = 19, \n",
      "            uniqueCut = 10, cutoff = 0.9), sampling = NULL, index = NULL, \n",
      "        indexOut = NULL, indexFinal = NULL, timingSamps = 0, \n",
      "        predictionBounds = c(FALSE, FALSE), seeds = NA, adaptive = list(\n",
      "            min = 5, alpha = 0.05, method = \"gls\", complete = TRUE), \n",
      "        trim = FALSE, allowParallel = TRUE), savePredictions = \"final\", \n",
      "    outer_train_predict = TRUE, controls = new(\"ForestControl\", \n",
      "        ntree = 100L, replace = FALSE, fraction = 0.632, trace = FALSE, \n",
      "        varctrl = new(\"VariableControl\", teststat = 2L, pvalue = TRUE, \n",
      "            tol = 1e-10, maxpts = 25000L, abseps = 1e-04, releps = 0), \n",
      "        splitctrl = new(\"SplitControl\", minprob = 0.01, minsplit = 20, \n",
      "            minbucket = 7, tol = 1e-10, maxsurrogate = 0L), gtctrl = new(\"GlobalTestControl\", \n",
      "            testtype = 4L, nresample = 9999L, randomsplits = TRUE, \n",
      "            mtry = 2L, mincriterion = 0), tgctrl = new(\"TreeGrowControl\", \n",
      "            stump = FALSE, maxdepth = 0L, savesplitstats = FALSE, \n",
      "            remove_weights = FALSE)))\n",
      "\n",
      "$output\n",
      "        predy testy\n",
      "2    8.833834     0\n",
      "27  27.937061     0\n",
      "37  14.615202     5\n",
      "50  17.845469    10\n",
      "60  22.575237     0\n",
      "67  19.579783     0\n",
      "115  6.823183     0\n",
      "122 15.659160     7\n",
      "126 26.535158    40\n",
      "130 28.177537    20\n",
      "132 14.024426    30\n",
      "145 10.197752     0\n",
      "147 20.522583    20\n",
      "174 21.275486    50\n",
      "175 23.404663    40\n",
      "180 19.249895    10\n",
      "193 31.152538     0\n",
      "195 17.494840    20\n",
      "198 17.753879    70\n",
      "202 13.248579     0\n",
      "209 25.212503    20\n",
      "14  14.768053    10\n",
      "15  10.668293     5\n",
      "26  36.108277     0\n",
      "34   8.050022     0\n",
      "40   6.907285     0\n",
      "53  21.487319     0\n",
      "59  21.532302    35\n",
      "71  24.807330    60\n",
      "93  21.512425   100\n",
      "96  21.059252    50\n",
      "97   9.922892    50\n",
      "106 14.694972     5\n",
      "123 24.921134    20\n",
      "135 16.602649    10\n",
      "139 19.093646     0\n",
      "144 14.738360    10\n",
      "154 12.217264    30\n",
      "177 21.962637     0\n",
      "184 18.553808    20\n",
      "188 13.827495     0\n",
      "191 29.541580    20\n",
      "3    4.518178     0\n",
      "7   10.491477     5\n",
      "12   8.791781     0\n",
      "25  24.438492    10\n",
      "33   9.082161     0\n",
      "43  19.595966    10\n",
      "47  33.885398    40\n",
      "69  25.719551     5\n",
      "77  32.259583    45\n",
      "80  28.563774    20\n",
      "105  8.321974     0\n",
      "107 26.251362    20\n",
      "111 24.466932     0\n",
      "137 32.535095    30\n",
      "156 19.358395     0\n",
      "167 35.063539    40\n",
      "179 25.954791    70\n",
      "186 30.054724     4\n",
      "197 22.535017    60\n",
      "199 31.342306    20\n",
      "201  7.898401     0\n",
      "22  12.209283    30\n",
      "29  16.846180    10\n",
      "38  12.275982     0\n",
      "39   8.541118     0\n",
      "44  18.983176     5\n",
      "64  14.704946     5\n",
      "87  12.948362    50\n",
      "89  11.949364     0\n",
      "91  22.771308    80\n",
      "95  11.512448     5\n",
      "98  26.095971    20\n",
      "110 25.218719    10\n",
      "128 34.305172    40\n",
      "129 28.362813    30\n",
      "149 24.038997   100\n",
      "165 10.614902     5\n",
      "173 32.690282     0\n",
      "181 29.519957    10\n",
      "187 24.867466   100\n",
      "189 25.485993    10\n",
      "207 30.908942    30\n",
      "0   10.498826     0\n",
      "6   12.520342     0\n",
      "8    6.379518    10\n",
      "23  15.518330    10\n",
      "28  31.368020    60\n",
      "45   9.712062     0\n",
      "46  17.231920    30\n",
      "48  19.412066    10\n",
      "61  11.430268     0\n",
      "76  31.715530     0\n",
      "94  10.078731     0\n",
      "100 25.472282     0\n",
      "102 32.801719    20\n",
      "113 17.423147     0\n",
      "124 32.998730    40\n",
      "134 23.569726    30\n",
      "148 24.403134    20\n",
      "151 14.102541    20\n",
      "155 23.302013     0\n",
      "157 23.026664     1\n",
      "166 20.186582    40\n",
      "170 26.010448    50\n",
      "194 23.009245    80\n",
      "9   22.374700    30\n",
      "10  15.079232     0\n",
      "30  17.720509     5\n",
      "41  16.439809     0\n",
      "51  28.548356    50\n",
      "54  13.825371     0\n",
      "62  11.559031     0\n",
      "63  22.320046    10\n",
      "74  17.734301    50\n",
      "75  11.892427    30\n",
      "109 20.176977     5\n",
      "112 30.613813     0\n",
      "120 16.352325     0\n",
      "150 16.571537    20\n",
      "171 34.159925    60\n",
      "172 34.590026     0\n",
      "178 13.874209   100\n",
      "183 16.475349    10\n",
      "192 13.310925     0\n",
      "200 38.609182    50\n",
      "211 34.746315    30\n",
      "16  22.072225     0\n",
      "17  21.726260     0\n",
      "24  12.735375    20\n",
      "31  15.800749     0\n",
      "35   8.606020     0\n",
      "55  32.703280    20\n",
      "66  21.639397    10\n",
      "70  19.682332     0\n",
      "79  25.040337    10\n",
      "92   8.892502    12\n",
      "103 31.895815    50\n",
      "104  6.940567     0\n",
      "116 20.495728     0\n",
      "162 17.576349     0\n",
      "168 17.733446    20\n",
      "169 35.951552    50\n",
      "176 20.886471     0\n",
      "196 13.645017    10\n",
      "205 20.138741   100\n",
      "206 28.351443    40\n",
      "1   10.670095     0\n",
      "4    9.233223     0\n",
      "13  23.868716   100\n",
      "18  19.495833    30\n",
      "42  25.410982    10\n",
      "78  31.789542   100\n",
      "83  13.745351    10\n",
      "84  13.936183     0\n",
      "85  13.976039    20\n",
      "90  14.916150     0\n",
      "99  21.414064    40\n",
      "125 19.659029    20\n",
      "127 23.152685    10\n",
      "131 27.319308    20\n",
      "136 23.614548    60\n",
      "142  4.908518     0\n",
      "143 17.025920     0\n",
      "152 25.793611    10\n",
      "163 24.365979    15\n",
      "164 20.929467     5\n",
      "182 20.550923    10\n",
      "204 21.145849     0\n",
      "21  31.421908     0\n",
      "49  26.043894    50\n",
      "56  34.422966    90\n",
      "57  18.397697    50\n",
      "68   9.285084     5\n",
      "82  13.480177     0\n",
      "86  24.380494     0\n",
      "88  16.031625     0\n",
      "118 14.232838    20\n",
      "133 19.456304    10\n",
      "140 11.849224     0\n",
      "146 34.062300   100\n",
      "153 26.257809    30\n",
      "158 18.950920     0\n",
      "159 24.417541    10\n",
      "160 19.231603     0\n",
      "161  8.704162    10\n",
      "185 13.596679    15\n",
      "203 26.039299     5\n",
      "208 33.441030    20\n",
      "212 20.563414    10\n",
      "5   18.617189    20\n",
      "11  17.823893     5\n",
      "19  25.140339    50\n",
      "20  18.493477    70\n",
      "32  12.777570    20\n",
      "36  13.298440     0\n",
      "52  20.836413     0\n",
      "58  18.011013    30\n",
      "65  17.801185    50\n",
      "72  14.285890     5\n",
      "73  24.810596    50\n",
      "81  13.550908     0\n",
      "101 37.657478   100\n",
      "108 21.969386    30\n",
      "114 17.740597     0\n",
      "117 19.624323     5\n",
      "119 11.630682     5\n",
      "121 17.142002     0\n",
      "138 14.151442     0\n",
      "141 23.130051     0\n",
      "190 22.091835    10\n",
      "210 23.068490    30\n",
      "\n",
      "$outer_result\n",
      "$outer_result[[1]]\n",
      "$outer_result[[1]]$preds\n",
      "        predy testy\n",
      "2    8.833834     0\n",
      "27  27.937061     0\n",
      "37  14.615202     5\n",
      "50  17.845469    10\n",
      "60  22.575237     0\n",
      "67  19.579783     0\n",
      "115  6.823183     0\n",
      "122 15.659160     7\n",
      "126 26.535158    40\n",
      "130 28.177537    20\n",
      "132 14.024426    30\n",
      "145 10.197752     0\n",
      "147 20.522583    20\n",
      "174 21.275486    50\n",
      "175 23.404663    40\n",
      "180 19.249895    10\n",
      "193 31.152538     0\n",
      "195 17.494840    20\n",
      "198 17.753879    70\n",
      "202 13.248579     0\n",
      "209 25.212503    20\n",
      "\n",
      "$outer_result[[1]]$train_preds\n",
      "    ytrain     predy\n",
      "0        0  7.886294\n",
      "2        0  9.142979\n",
      "5        0  4.883394\n",
      "6        0 10.003929\n",
      "8       20 18.028909\n",
      "9        0 10.977951\n",
      "10       5  8.834185\n",
      "11      10  6.889447\n",
      "12      30 25.914912\n",
      "19       0 14.529503\n",
      "20       5 13.973828\n",
      "21       0  8.665300\n",
      "22     100 36.445075\n",
      "23      10 12.268787\n",
      "24       5 12.158042\n",
      "25       0 15.462408\n",
      "26       0 13.868551\n",
      "27      30 21.024619\n",
      "28      50 29.007749\n",
      "29      70 30.761942\n",
      "30       0 29.560255\n",
      "32      30 14.243445\n",
      "38      10 13.743564\n",
      "39      20 14.304399\n",
      "44      10 18.828728\n",
      "45       0 29.215699\n",
      "47      60 40.918651\n",
      "48      10 15.986823\n",
      "49       5 14.366962\n",
      "50       0 14.143598\n",
      "53      20 13.307717\n",
      "55       0  8.979669\n",
      "56       0  7.034111\n",
      "58       0  6.060814\n",
      "61       0 11.989003\n",
      "63       0 13.180344\n",
      "65       0  7.941829\n",
      "66       0  6.864722\n",
      "67       0 13.743980\n",
      "68      10 22.821195\n",
      "69      10 18.928246\n",
      "72       5 13.663437\n",
      "73       0  8.383539\n",
      "74      30 18.177816\n",
      "77      40 40.605859\n",
      "78      10 16.299068\n",
      "79      50 29.948497\n",
      "81      50 35.529101\n",
      "84       0 18.740295\n",
      "93       0 24.588676\n",
      "94       0 12.405499\n",
      "95      20 30.993897\n",
      "96      90 43.180098\n",
      "101     50 21.275486\n",
      "102     30 18.483406\n",
      "105     35 26.155238\n",
      "111      0  8.416934\n",
      "112      0  9.410134\n",
      "113     10 22.407012\n",
      "114      5 10.412092\n",
      "118     50 21.089218\n",
      "125     10 18.531543\n",
      "129      5  9.499800\n",
      "130      5 22.527948\n",
      "132      0 17.382167\n",
      "134     60 32.686523\n",
      "136      5 12.570188\n",
      "138     50 27.153345\n",
      "140     50 22.227196\n",
      "143     30 13.020863\n",
      "147      0 20.052885\n",
      "149     45 35.822697\n",
      "151    100 39.571553\n",
      "152     10 25.670288\n",
      "153     20 23.365189\n",
      "156      0 10.697905\n",
      "158      0 10.967367\n",
      "162     10 14.160518\n",
      "163      0 13.911555\n",
      "164     20 18.346052\n",
      "165      0 20.959177\n",
      "166     50 20.639203\n",
      "168      0  9.961873\n",
      "171      0  8.366995\n",
      "172      0 13.934914\n",
      "173     80 29.012263\n",
      "175     12  8.532094\n",
      "177    100 35.947753\n",
      "178      0  8.153131\n",
      "181      5 10.141758\n",
      "182     50 23.910008\n",
      "183     50 17.167062\n",
      "184     20 20.199370\n",
      "185     40 24.324954\n",
      "192      0 20.432122\n",
      "193    100 45.407788\n",
      "194     20 27.354138\n",
      "195     50 37.425438\n",
      "196      0  6.679118\n",
      "197      0  7.017354\n",
      "199      5 19.281277\n",
      "201     20 25.304434\n",
      "202     30 21.213157\n",
      "203      5 17.229122\n",
      "206     10 21.383144\n",
      "207      0 26.121324\n",
      "209      0 25.977167\n",
      "210      0 16.311122\n",
      "211      0 16.973589\n",
      "217      0 17.858871\n",
      "218      5 16.909373\n",
      "219     20 12.183124\n",
      "221      5 13.095494\n",
      "222      0 12.147136\n",
      "223      0 14.576531\n",
      "229     20 25.792321\n",
      "230     40 29.526498\n",
      "232     20 23.258226\n",
      "235     10 20.939824\n",
      "236     40 35.178842\n",
      "237     30 26.886586\n",
      "239     20 25.143373\n",
      "241     10 12.803294\n",
      "242     30 26.969252\n",
      "243     10 16.937608\n",
      "244     60 26.612597\n",
      "246     30 29.520809\n",
      "249      0 15.585150\n",
      "250      0 16.366399\n",
      "251      0 14.978628\n",
      "252      0 17.273539\n",
      "254      0  4.883394\n",
      "256      0 14.817359\n",
      "257     10 16.677138\n",
      "264    100 38.820801\n",
      "266     20 21.357991\n",
      "267    100 36.283720\n",
      "274     20 15.952135\n",
      "275     20 15.887855\n",
      "279     10 18.828728\n",
      "280     30 31.756070\n",
      "283     30 16.844189\n",
      "285      0 17.083057\n",
      "286      0 14.829109\n",
      "287      1 17.472653\n",
      "289      0 17.445723\n",
      "290     10 23.202942\n",
      "292      0 15.223953\n",
      "293     10  9.286534\n",
      "294      0 16.112920\n",
      "295     15 21.434290\n",
      "296      5 16.131979\n",
      "297      5  8.383539\n",
      "298     40 22.413792\n",
      "301     40 41.609985\n",
      "302     20 22.057404\n",
      "303     50 34.622371\n",
      "304     50 32.915375\n",
      "305     60 40.565844\n",
      "313      0 30.427655\n",
      "314      0 24.306656\n",
      "320      0 17.940315\n",
      "324      0 12.491276\n",
      "325    100 25.037613\n",
      "330     70 31.279788\n",
      "338     10 25.974042\n",
      "340     10 15.485196\n",
      "341     10 16.886140\n",
      "342     20 22.696698\n",
      "347     15 17.231869\n",
      "350      4 20.052885\n",
      "351    100 31.829436\n",
      "352      0 10.967367\n",
      "354     10 22.257256\n",
      "355     10 22.169339\n",
      "356     20 27.944487\n",
      "359      0 15.645058\n",
      "361     80 29.012263\n",
      "364     10 15.386758\n",
      "365     60 29.116029\n",
      "372     20 27.354138\n",
      "373     50 39.868533\n",
      "374      0  6.708027\n",
      "376      5 23.602920\n",
      "379      0 22.844697\n",
      "386    100 37.794710\n",
      "387     40 29.222896\n",
      "388     30 32.113612\n",
      "389     20 35.344285\n",
      "391     30 28.779024\n",
      "392     30 35.392207\n",
      "393     10 18.447693\n",
      "\n",
      "$outer_result[[1]]$fit\n",
      "Conditional Inference Random Forest \n",
      "\n",
      "192 samples\n",
      " 34 predictor\n",
      "\n",
      "No pre-processing\n",
      "Resampling: Cross-Validated (10 fold, repeated 5 times) \n",
      "Summary of sample sizes: 173, 173, 173, 173, 172, 173, ... \n",
      "Resampling results across tuning parameters:\n",
      "\n",
      "  mtry  RMSE      Rsquared   MAE     \n",
      "   2    24.40993  0.2281612  18.87473\n",
      "  18    23.81457  0.2148593  18.04356\n",
      "  34    23.95927  0.2003328  18.13731\n",
      "\n",
      "MAE was used to select the optimal model using the smallest value.\n",
      "The final value used for the model was mtry = 18.\n",
      "\n",
      "$outer_result[[1]]$nfilter\n",
      "[1] 34\n",
      "\n",
      "\n",
      "$outer_result[[2]]\n",
      "$outer_result[[2]]$preds\n",
      "        predy testy\n",
      "14  14.768053    10\n",
      "15  10.668293     5\n",
      "26  36.108277     0\n",
      "34   8.050022     0\n",
      "40   6.907285     0\n",
      "53  21.487319     0\n",
      "59  21.532302    35\n",
      "71  24.807330    60\n",
      "93  21.512425   100\n",
      "96  21.059252    50\n",
      "97   9.922892    50\n",
      "106 14.694972     5\n",
      "123 24.921134    20\n",
      "135 16.602649    10\n",
      "139 19.093646     0\n",
      "144 14.738360    10\n",
      "154 12.217264    30\n",
      "177 21.962637     0\n",
      "184 18.553808    20\n",
      "188 13.827495     0\n",
      "191 29.541580    20\n",
      "\n",
      "$outer_result[[2]]$train_preds\n",
      "    ytrain     predy\n",
      "0        0  7.354064\n",
      "2        0  6.149886\n",
      "4        0  5.486064\n",
      "5        0  3.369950\n",
      "6        0  7.370002\n",
      "8       20 14.206831\n",
      "9        0  7.350902\n",
      "10       5  6.499029\n",
      "11      10  6.104645\n",
      "12      30 24.692738\n",
      "19       0 15.599446\n",
      "20       5 12.874533\n",
      "21       0  7.818959\n",
      "22     100 37.885774\n",
      "25       0 17.827686\n",
      "26       0 16.406311\n",
      "27      30 22.027628\n",
      "28      50 28.524650\n",
      "29      70 31.770975\n",
      "30       0 32.193675\n",
      "32      30 16.589924\n",
      "38      10 12.274631\n",
      "39      20 15.951072\n",
      "44      10 20.679144\n",
      "46       0 19.320580\n",
      "47      60 43.797295\n",
      "48      10 17.687984\n",
      "49       5 15.139499\n",
      "50       0 13.222282\n",
      "53      20 10.722917\n",
      "55       0  7.975426\n",
      "58       0  4.921433\n",
      "61       0  9.616738\n",
      "62       5  8.508486\n",
      "63       0 12.253960\n",
      "65       0  3.992950\n",
      "67       0 13.497416\n",
      "68      10 26.023563\n",
      "69      10 14.228320\n",
      "72       5 15.499344\n",
      "73       0  9.268099\n",
      "74      30 21.493005\n",
      "77      40 39.339405\n",
      "78      10 16.225692\n",
      "79      50 32.390406\n",
      "80      10 21.727504\n",
      "81      50 38.008132\n",
      "84       0 16.894740\n",
      "94       0 12.157636\n",
      "95      20 31.528921\n",
      "96      90 46.543509\n",
      "101     50 21.221445\n",
      "102     30 20.065383\n",
      "109      0 17.196522\n",
      "111      0 13.772869\n",
      "112      0 12.935071\n",
      "113     10 16.567896\n",
      "114      5 12.564852\n",
      "118     50 27.326111\n",
      "125     10 16.960506\n",
      "126      0 14.723130\n",
      "129      5  8.152509\n",
      "130      5 18.451830\n",
      "132      0 16.184516\n",
      "136      5  8.345727\n",
      "138     50 28.590538\n",
      "140     50 19.974856\n",
      "143     30 16.076686\n",
      "147      0 18.861482\n",
      "149     45 35.019148\n",
      "151    100 44.190920\n",
      "152     10 24.959978\n",
      "153     20 30.162179\n",
      "156      0 11.639547\n",
      "158      0 13.486617\n",
      "162     10 10.104411\n",
      "163      0 12.742418\n",
      "164     20 15.171716\n",
      "165      0 17.508581\n",
      "166     50 15.783555\n",
      "168      0  9.528891\n",
      "171      0  4.929651\n",
      "172      0 10.223284\n",
      "173     80 32.962899\n",
      "175     12  5.080859\n",
      "178      0  4.821464\n",
      "181      5 10.116860\n",
      "184     20 23.162770\n",
      "185     40 27.420211\n",
      "192      0 17.862786\n",
      "193    100 50.185757\n",
      "194     20 31.038798\n",
      "195     50 39.964372\n",
      "196      0  4.155029\n",
      "197      0  6.272603\n",
      "201     20 28.042194\n",
      "202     30 13.672516\n",
      "203      5 20.558138\n",
      "206     10 25.781840\n",
      "207      0 24.347381\n",
      "209      0 20.929247\n",
      "210      0 15.707439\n",
      "211      0 13.926485\n",
      "216      0  4.315244\n",
      "217      0 17.825252\n",
      "218      5 18.096910\n",
      "219     20 10.378948\n",
      "221      5  8.035453\n",
      "222      0 11.658533\n",
      "223      0 16.261820\n",
      "228      7 14.023990\n",
      "230     40 31.049197\n",
      "232     20 18.380834\n",
      "233     40 30.799096\n",
      "235     10 25.519009\n",
      "236     40 33.630776\n",
      "237     30 34.657761\n",
      "238     20 25.869340\n",
      "239     20 27.584239\n",
      "240     30 14.628047\n",
      "241     10 12.202426\n",
      "242     30 24.848671\n",
      "244     60 30.566710\n",
      "246     30 22.756143\n",
      "249      0 11.999959\n",
      "251      0  9.566291\n",
      "252      0 15.134367\n",
      "254      0  3.369950\n",
      "256      0 12.670224\n",
      "263      0  8.509144\n",
      "264    100 41.574176\n",
      "265     20 22.907701\n",
      "266     20 22.777856\n",
      "267    100 41.282706\n",
      "274     20 14.916813\n",
      "275     20 17.225817\n",
      "279     10 20.679144\n",
      "280     30 36.369760\n",
      "285      0 15.262498\n",
      "286      0 14.398731\n",
      "287      1 16.830265\n",
      "289      0 14.177346\n",
      "290     10 27.085608\n",
      "292      0 11.116981\n",
      "293     10  8.896536\n",
      "294      0 15.553872\n",
      "295     15 24.190939\n",
      "296      5 18.903425\n",
      "297      5  9.403926\n",
      "298     40 24.631831\n",
      "301     40 40.532620\n",
      "302     20 19.069781\n",
      "303     50 33.028400\n",
      "304     50 32.504917\n",
      "305     60 41.533369\n",
      "313      0 23.498746\n",
      "314      0 25.200023\n",
      "317     50 21.221445\n",
      "318     40 32.201211\n",
      "320      0 15.334521\n",
      "325    100 26.672837\n",
      "330     70 35.486447\n",
      "337     10 18.125901\n",
      "338     10 25.162817\n",
      "340     10 15.284452\n",
      "341     10 14.192943\n",
      "347     15 18.542858\n",
      "350      4 18.861482\n",
      "351    100 38.665229\n",
      "354     10 22.386547\n",
      "355     10 16.407432\n",
      "359      0  7.099372\n",
      "360      0 18.954142\n",
      "361     80 32.962899\n",
      "363     20 14.278591\n",
      "364     10  8.129847\n",
      "365     60 28.862656\n",
      "366     70 24.606869\n",
      "372     20 31.038798\n",
      "373     50 45.266448\n",
      "374      0  4.184819\n",
      "375      0 11.900653\n",
      "376      5 19.462811\n",
      "379      0 22.523807\n",
      "386    100 33.513344\n",
      "387     40 31.227022\n",
      "388     30 38.960702\n",
      "389     20 37.315009\n",
      "390     20 28.000067\n",
      "391     30 29.993213\n",
      "392     30 29.478814\n",
      "393     10 17.731957\n",
      "\n",
      "$outer_result[[2]]$fit\n",
      "Conditional Inference Random Forest \n",
      "\n",
      "192 samples\n",
      " 34 predictor\n",
      "\n",
      "No pre-processing\n",
      "Resampling: Cross-Validated (10 fold, repeated 5 times) \n",
      "Summary of sample sizes: 173, 173, 173, 173, 173, 173, ... \n",
      "Resampling results across tuning parameters:\n",
      "\n",
      "  mtry  RMSE      Rsquared   MAE     \n",
      "   2    23.63374  0.2857152  18.27964\n",
      "  18    23.19422  0.2347968  17.69032\n",
      "  34    23.12714  0.2230693  17.56902\n",
      "\n",
      "MAE was used to select the optimal model using the smallest value.\n",
      "The final value used for the model was mtry = 34.\n",
      "\n",
      "$outer_result[[2]]$nfilter\n",
      "[1] 34\n",
      "\n",
      "\n",
      "$outer_result[[3]]\n",
      "$outer_result[[3]]$preds\n",
      "        predy testy\n",
      "3    4.518178     0\n",
      "7   10.491477     5\n",
      "12   8.791781     0\n",
      "25  24.438492    10\n",
      "33   9.082161     0\n",
      "43  19.595966    10\n",
      "47  33.885398    40\n",
      "69  25.719551     5\n",
      "77  32.259583    45\n",
      "80  28.563774    20\n",
      "105  8.321974     0\n",
      "107 26.251362    20\n",
      "111 24.466932     0\n",
      "137 32.535095    30\n",
      "156 19.358395     0\n",
      "167 35.063539    40\n",
      "179 25.954791    70\n",
      "186 30.054724     4\n",
      "197 22.535017    60\n",
      "199 31.342306    20\n",
      "201  7.898401     0\n",
      "\n",
      "$outer_result[[3]]$train_preds\n",
      "    ytrain     predy\n",
      "0        0  7.518517\n",
      "2        0  8.415769\n",
      "4        0  5.809755\n",
      "6        0  9.808050\n",
      "8       20 17.400935\n",
      "9        0  7.572843\n",
      "11      10  6.935881\n",
      "12      30 28.116963\n",
      "19       0 15.439848\n",
      "20       5 11.085055\n",
      "22     100 39.501375\n",
      "23      10 13.731029\n",
      "24       5  9.327150\n",
      "25       0 17.464231\n",
      "26       0 15.682237\n",
      "27      30 19.304607\n",
      "28      50 30.026563\n",
      "29      70 28.332726\n",
      "30       0 23.891993\n",
      "32      30 15.168553\n",
      "38      10 13.905963\n",
      "39      20 13.120222\n",
      "45       0 27.277915\n",
      "46       0 25.795220\n",
      "47      60 38.792883\n",
      "48      10 16.978824\n",
      "49       5 15.875700\n",
      "50       0 11.536842\n",
      "53      20 13.556576\n",
      "56       0  7.391595\n",
      "58       0  6.184513\n",
      "61       0 10.485431\n",
      "62       5  9.656309\n",
      "63       0 10.282583\n",
      "65       0  6.090132\n",
      "66       0  6.797863\n",
      "67       0 14.117966\n",
      "68      10 20.465914\n",
      "72       5 15.990611\n",
      "73       0  7.523464\n",
      "74      30 21.823165\n",
      "78      10 16.123504\n",
      "79      50 34.103998\n",
      "80      10 21.951724\n",
      "81      50 38.527997\n",
      "84       0 21.655266\n",
      "93       0 24.096239\n",
      "94       0 10.863934\n",
      "95      20 31.629940\n",
      "96      90 43.119367\n",
      "101     50 25.598971\n",
      "102     30 19.518487\n",
      "105     35 27.042257\n",
      "109      0 19.732404\n",
      "111      0  8.096020\n",
      "112      0 10.194826\n",
      "113     10 22.485963\n",
      "114      5 11.710193\n",
      "118     50 22.360452\n",
      "125     10 20.233353\n",
      "126      0 12.241391\n",
      "129      5  8.016315\n",
      "132      0 11.201884\n",
      "134     60 37.469856\n",
      "136      5 10.050503\n",
      "138     50 30.338252\n",
      "140     50 22.806333\n",
      "143     30 16.761358\n",
      "147      0 30.054724\n",
      "151    100 42.616217\n",
      "152     10 26.154958\n",
      "156      0 11.129962\n",
      "158      0 10.306665\n",
      "162     10 13.394703\n",
      "163      0 10.510933\n",
      "164     20 18.092942\n",
      "165      0 18.112393\n",
      "166     50 12.721999\n",
      "168      0 11.506123\n",
      "171      0  6.469579\n",
      "172      0  9.987555\n",
      "173     80 27.145973\n",
      "175     12  7.594662\n",
      "177    100 36.727324\n",
      "178      0  8.280912\n",
      "181      5  9.946057\n",
      "182     50 22.955587\n",
      "183     50 13.221496\n",
      "184     20 19.613446\n",
      "185     40 26.744004\n",
      "192      0 16.987079\n",
      "193    100 46.428121\n",
      "194     20 31.342306\n",
      "195     50 35.741975\n",
      "196      0  7.898401\n",
      "199      5 16.444096\n",
      "202     30 18.932032\n",
      "203      5 20.646981\n",
      "206     10 26.750812\n",
      "209      0 29.582075\n",
      "210      0 15.228519\n",
      "211      0 13.890247\n",
      "216      0  6.264385\n",
      "217      0 11.476220\n",
      "218      5 16.674875\n",
      "219     20 10.448616\n",
      "221      5 10.100952\n",
      "222      0 13.993492\n",
      "223      0 15.601884\n",
      "228      7 16.135887\n",
      "229     20 28.875932\n",
      "230     40 31.339918\n",
      "232     20 20.131328\n",
      "233     40 30.075436\n",
      "235     10 22.173597\n",
      "236     40 34.943997\n",
      "237     30 34.195741\n",
      "238     20 26.391951\n",
      "239     20 28.684344\n",
      "240     30 16.089658\n",
      "241     10 11.165116\n",
      "242     30 22.486158\n",
      "243     10 17.627195\n",
      "244     60 30.104196\n",
      "249      0 11.430509\n",
      "250      0 17.256704\n",
      "251      0  7.889048\n",
      "252      0 18.736023\n",
      "254      0  4.518178\n",
      "256      0 17.699164\n",
      "257     10 19.457422\n",
      "263      0  7.597003\n",
      "264    100 41.177974\n",
      "265     20 22.259921\n",
      "266     20 21.886772\n",
      "267    100 36.615024\n",
      "274     20 15.339437\n",
      "275     20 14.044721\n",
      "279     10 24.438492\n",
      "280     30 28.761213\n",
      "283     30 14.887384\n",
      "285      0 18.272390\n",
      "287      1 16.843528\n",
      "289      0 13.899647\n",
      "290     10 25.059286\n",
      "292      0 12.111067\n",
      "293     10  7.591566\n",
      "294      0 15.006063\n",
      "295     15 23.225519\n",
      "296      5 17.720951\n",
      "297      5  7.523464\n",
      "298     40 24.019188\n",
      "302     20 19.014486\n",
      "303     50 37.709305\n",
      "304     50 32.000926\n",
      "305     60 41.538638\n",
      "313      0 30.168488\n",
      "314      0 24.369701\n",
      "317     50 25.598971\n",
      "318     40 27.955526\n",
      "320      0 18.387677\n",
      "324      0 12.778231\n",
      "325    100 29.125741\n",
      "337     10 19.476663\n",
      "338     10 26.645465\n",
      "340     10 17.268349\n",
      "341     10 17.112241\n",
      "342     20 25.719551\n",
      "347     15 20.090293\n",
      "351    100 34.189641\n",
      "352      0 10.306665\n",
      "354     10 27.149592\n",
      "355     10 21.347543\n",
      "356     20 29.041555\n",
      "359      0  7.481096\n",
      "360      0 25.143873\n",
      "361     80 27.145973\n",
      "363     20 14.269826\n",
      "364     10 10.023637\n",
      "366     70 25.421067\n",
      "373     50 39.073515\n",
      "375      0 11.739395\n",
      "376      5 19.037699\n",
      "379      0 25.453058\n",
      "386    100 37.903492\n",
      "387     40 31.448153\n",
      "388     30 34.373703\n",
      "389     20 39.980683\n",
      "390     20 29.082451\n",
      "391     30 31.478574\n",
      "392     30 36.638587\n",
      "393     10 19.427780\n",
      "\n",
      "$outer_result[[3]]$fit\n",
      "Conditional Inference Random Forest \n",
      "\n",
      "192 samples\n",
      " 34 predictor\n",
      "\n",
      "No pre-processing\n",
      "Resampling: Cross-Validated (10 fold, repeated 5 times) \n",
      "Summary of sample sizes: 172, 173, 173, 173, 173, 172, ... \n",
      "Resampling results across tuning parameters:\n",
      "\n",
      "  mtry  RMSE      Rsquared   MAE     \n",
      "   2    24.46638  0.2124638  18.92292\n",
      "  18    24.22042  0.1826386  18.56246\n",
      "  34    24.21890  0.1801142  18.54412\n",
      "\n",
      "MAE was used to select the optimal model using the smallest value.\n",
      "The final value used for the model was mtry = 34.\n",
      "\n",
      "$outer_result[[3]]$nfilter\n",
      "[1] 34\n",
      "\n",
      "\n",
      "$outer_result[[4]]\n",
      "$outer_result[[4]]$preds\n",
      "        predy testy\n",
      "22  12.209283    30\n",
      "29  16.846180    10\n",
      "38  12.275982     0\n",
      "39   8.541118     0\n",
      "44  18.983176     5\n",
      "64  14.704946     5\n",
      "87  12.948362    50\n",
      "89  11.949364     0\n",
      "91  22.771308    80\n",
      "95  11.512448     5\n",
      "98  26.095971    20\n",
      "110 25.218719    10\n",
      "128 34.305172    40\n",
      "129 28.362813    30\n",
      "149 24.038997   100\n",
      "165 10.614902     5\n",
      "173 32.690282     0\n",
      "181 29.519957    10\n",
      "187 24.867466   100\n",
      "189 25.485993    10\n",
      "207 30.908942    30\n",
      "\n",
      "$outer_result[[4]]$train_preds\n",
      "    ytrain     predy\n",
      "0        0  7.969245\n",
      "2        0  9.538571\n",
      "4        0  6.455844\n",
      "5        0  4.072617\n",
      "6        0  7.357045\n",
      "8       20 20.251664\n",
      "9        0  8.515413\n",
      "10       5  8.028513\n",
      "11      10  5.538031\n",
      "12      30 28.484259\n",
      "19       0 12.481972\n",
      "20       5  8.030336\n",
      "21       0  7.018504\n",
      "22     100 34.617078\n",
      "23      10 14.545856\n",
      "24       5 10.764087\n",
      "25       0 12.909937\n",
      "26       0 13.854291\n",
      "27      30 18.605054\n",
      "28      50 30.810961\n",
      "29      70 29.970976\n",
      "30       0 14.521249\n",
      "38      10 12.941606\n",
      "39      20 11.592829\n",
      "44      10 19.944540\n",
      "45       0 21.803843\n",
      "46       0 26.876407\n",
      "47      60 38.895641\n",
      "49       5 14.392422\n",
      "50       0 13.710071\n",
      "53      20 16.703247\n",
      "55       0  6.127661\n",
      "56       0  4.715308\n",
      "58       0  5.364920\n",
      "61       0  9.021449\n",
      "62       5 13.091237\n",
      "66       0  7.562623\n",
      "67       0 14.343005\n",
      "68      10 16.578051\n",
      "69      10 15.141945\n",
      "73       0 10.269847\n",
      "74      30 23.354776\n",
      "77      40 36.586713\n",
      "78      10 13.872989\n",
      "79      50 31.510935\n",
      "80      10 23.132483\n",
      "81      50 37.842671\n",
      "84       0 18.117273\n",
      "93       0 27.467654\n",
      "94       0  8.877010\n",
      "95      20 30.267241\n",
      "96      90 45.602225\n",
      "101     50 22.202938\n",
      "102     30 16.607818\n",
      "105     35 26.058604\n",
      "109      0 19.189076\n",
      "111      0  6.852003\n",
      "112      0 13.186936\n",
      "113     10 21.022903\n",
      "118     50 25.788921\n",
      "125     10 17.307521\n",
      "126      0 13.931589\n",
      "129      5  7.527194\n",
      "130      5 20.064454\n",
      "132      0 12.141008\n",
      "134     60 37.767956\n",
      "136      5 11.775912\n",
      "138     50 24.462971\n",
      "140     50 20.367447\n",
      "143     30 15.444920\n",
      "147      0 25.179116\n",
      "149     45 31.942838\n",
      "151    100 41.189093\n",
      "152     10 26.851506\n",
      "153     20 23.987298\n",
      "156      0  9.932392\n",
      "158      0 10.049826\n",
      "162     10 11.639178\n",
      "163      0 10.082891\n",
      "164     20 17.403104\n",
      "165      0 21.215699\n",
      "168      0 11.298554\n",
      "172      0 11.447272\n",
      "175     12  8.591609\n",
      "177    100 38.956987\n",
      "178      0  9.810993\n",
      "182     50 23.406474\n",
      "183     50 12.870551\n",
      "185     40 25.558333\n",
      "192      0 14.881516\n",
      "193    100 45.016876\n",
      "194     20 29.261261\n",
      "195     50 39.833808\n",
      "196      0  5.374090\n",
      "197      0  6.701171\n",
      "199      5 19.200042\n",
      "201     20 22.203604\n",
      "202     30 21.143360\n",
      "203      5 19.171018\n",
      "207      0 25.987193\n",
      "209      0 29.611197\n",
      "210      0 13.601745\n",
      "211      0 10.292835\n",
      "216      0  5.438636\n",
      "217      0 13.834695\n",
      "218      5 18.643656\n",
      "219     20 15.531792\n",
      "221      5 13.000794\n",
      "222      0 12.343719\n",
      "223      0 15.006632\n",
      "228      7 12.631800\n",
      "229     20 28.596374\n",
      "230     40 32.799527\n",
      "232     20 20.373529\n",
      "233     40 31.094213\n",
      "235     10 19.703364\n",
      "238     20 25.848496\n",
      "239     20 24.568248\n",
      "240     30 17.247937\n",
      "241     10 14.463829\n",
      "242     30 24.299798\n",
      "243     10 15.644096\n",
      "244     60 28.125587\n",
      "246     30 29.385854\n",
      "249      0  8.013231\n",
      "250      0 18.241075\n",
      "251      0 10.816239\n",
      "252      0 20.956540\n",
      "254      0  4.072617\n",
      "256      0 14.470776\n",
      "257     10 17.201707\n",
      "263      0  7.802913\n",
      "264    100 41.232918\n",
      "265     20 20.065149\n",
      "266     20 20.731078\n",
      "274     20 13.777199\n",
      "275     20 13.188583\n",
      "279     10 19.944540\n",
      "280     30 24.251432\n",
      "283     30 18.527299\n",
      "285      0 14.985095\n",
      "286      0 13.131278\n",
      "287      1 15.105453\n",
      "289      0 12.994188\n",
      "290     10 23.760289\n",
      "292      0 12.527706\n",
      "293     10  7.941639\n",
      "294      0 12.511923\n",
      "295     15 20.159510\n",
      "296      5 19.935447\n",
      "298     40 24.659393\n",
      "301     40 38.933539\n",
      "302     20 15.650129\n",
      "303     50 37.765074\n",
      "304     50 32.729784\n",
      "305     60 42.731975\n",
      "313      0 31.797223\n",
      "317     50 22.202938\n",
      "318     40 26.371378\n",
      "320      0 13.347771\n",
      "324      0 10.784475\n",
      "325    100 28.303991\n",
      "330     70 31.745668\n",
      "337     10 18.028273\n",
      "340     10 14.629178\n",
      "341     10 14.868217\n",
      "342     20 20.586775\n",
      "347     15 16.061484\n",
      "350      4 25.179116\n",
      "352      0 10.135729\n",
      "355     10 20.315665\n",
      "356     20 25.897362\n",
      "359      0 13.196592\n",
      "360      0 26.468414\n",
      "361     80 22.771308\n",
      "363     20 13.627705\n",
      "364     10 10.859903\n",
      "365     60 28.462386\n",
      "366     70 24.463113\n",
      "372     20 29.261261\n",
      "373     50 45.434270\n",
      "374      0  5.412840\n",
      "375      0  9.967498\n",
      "376      5 19.359592\n",
      "379      0 24.806465\n",
      "386    100 40.134830\n",
      "387     40 32.544567\n",
      "389     20 37.997584\n",
      "390     20 24.493800\n",
      "391     30 30.091697\n",
      "392     30 37.314855\n",
      "393     10 17.555192\n",
      "\n",
      "$outer_result[[4]]$fit\n",
      "Conditional Inference Random Forest \n",
      "\n",
      "192 samples\n",
      " 34 predictor\n",
      "\n",
      "No pre-processing\n",
      "Resampling: Cross-Validated (10 fold, repeated 5 times) \n",
      "Summary of sample sizes: 173, 173, 173, 172, 173, 173, ... \n",
      "Resampling results across tuning parameters:\n",
      "\n",
      "  mtry  RMSE      Rsquared   MAE     \n",
      "   2    23.23177  0.2446419  17.87848\n",
      "  18    22.98089  0.1921959  17.38223\n",
      "  34    22.98716  0.1899481  17.30943\n",
      "\n",
      "MAE was used to select the optimal model using the smallest value.\n",
      "The final value used for the model was mtry = 34.\n",
      "\n",
      "$outer_result[[4]]$nfilter\n",
      "[1] 34\n",
      "\n",
      "\n",
      "$outer_result[[5]]\n",
      "$outer_result[[5]]$preds\n",
      "        predy testy\n",
      "0   10.498826     0\n",
      "6   12.520342     0\n",
      "8    6.379518    10\n",
      "23  15.518330    10\n",
      "28  31.368020    60\n",
      "45   9.712062     0\n",
      "46  17.231920    30\n",
      "48  19.412066    10\n",
      "61  11.430268     0\n",
      "76  31.715530     0\n",
      "94  10.078731     0\n",
      "100 25.472282     0\n",
      "102 32.801719    20\n",
      "113 17.423147     0\n",
      "124 32.998730    40\n",
      "134 23.569726    30\n",
      "148 24.403134    20\n",
      "151 14.102541    20\n",
      "155 23.302013     0\n",
      "157 23.026664     1\n",
      "166 20.186582    40\n",
      "170 26.010448    50\n",
      "194 23.009245    80\n",
      "\n",
      "$outer_result[[5]]$train_preds\n",
      "    ytrain     predy\n",
      "2        0  8.787829\n",
      "4        0  6.040821\n",
      "5        0  4.497885\n",
      "6        0  9.746761\n",
      "8       20 16.540044\n",
      "10       5  7.852175\n",
      "12      30 24.398977\n",
      "19       0 18.819494\n",
      "20       5 13.134992\n",
      "21       0  7.243583\n",
      "22     100 36.070538\n",
      "23      10 12.795344\n",
      "24       5 11.929533\n",
      "25       0 18.629977\n",
      "26       0 15.257439\n",
      "27      30 20.768337\n",
      "28      50 28.284794\n",
      "29      70 32.451829\n",
      "30       0 20.929311\n",
      "32      30 15.221607\n",
      "39      20 12.735103\n",
      "44      10 22.720682\n",
      "45       0 24.741221\n",
      "46       0 22.440712\n",
      "48      10 15.792430\n",
      "49       5 19.709866\n",
      "50       0 13.604002\n",
      "53      20 12.834055\n",
      "55       0  7.466489\n",
      "56       0  6.403158\n",
      "58       0  7.867212\n",
      "61       0 10.704828\n",
      "62       5 11.645773\n",
      "63       0 12.227097\n",
      "65       0  9.163568\n",
      "66       0  7.959729\n",
      "67       0 12.637580\n",
      "68      10 23.090058\n",
      "69      10 17.976311\n",
      "72       5 12.185873\n",
      "77      40 36.057776\n",
      "79      50 34.655751\n",
      "80      10 18.433707\n",
      "81      50 34.844094\n",
      "84       0 22.332706\n",
      "93       0 23.181800\n",
      "94       0 12.551670\n",
      "95      20 31.390245\n",
      "96      90 39.217342\n",
      "101     50 27.214145\n",
      "102     30 19.090835\n",
      "105     35 23.745858\n",
      "109      0 21.071975\n",
      "112      0 10.980580\n",
      "113     10 19.999932\n",
      "114      5 13.185878\n",
      "118     50 22.639271\n",
      "125     10 21.902333\n",
      "126      0 14.852291\n",
      "129      5  8.659237\n",
      "130      5 20.523846\n",
      "132      0 12.901190\n",
      "134     60 35.636386\n",
      "136      5 12.259372\n",
      "138     50 29.372937\n",
      "140     50 25.699859\n",
      "143     30 13.148533\n",
      "149     45 35.927952\n",
      "151    100 39.481342\n",
      "152     10 31.505712\n",
      "153     20 23.928641\n",
      "156      0 10.025480\n",
      "158      0 10.546250\n",
      "162     10 10.841368\n",
      "163      0 16.044962\n",
      "164     20 17.219445\n",
      "165      0 20.868375\n",
      "166     50 18.512145\n",
      "168      0 11.344933\n",
      "171      0  9.335065\n",
      "172      0 11.890583\n",
      "173     80 23.009245\n",
      "175     12  9.323057\n",
      "177    100 37.510310\n",
      "181      5 13.004631\n",
      "182     50 25.629302\n",
      "183     50 14.228826\n",
      "184     20 25.261592\n",
      "185     40 25.253691\n",
      "193    100 45.997759\n",
      "195     50 38.648414\n",
      "196      0  7.701545\n",
      "197      0  8.173083\n",
      "199      5 16.068467\n",
      "201     20 25.092963\n",
      "202     30 19.946170\n",
      "203      5 18.559612\n",
      "206     10 26.489478\n",
      "207      0 26.218487\n",
      "209      0 27.430767\n",
      "211      0 17.290451\n",
      "216      0  6.917618\n",
      "217      0 11.683881\n",
      "218      5 15.208339\n",
      "219     20 10.907324\n",
      "221      5  9.343076\n",
      "222      0 13.769940\n",
      "223      0 17.720304\n",
      "228      7 15.089997\n",
      "229     20 31.313714\n",
      "232     20 18.774462\n",
      "233     40 28.611679\n",
      "235     10 21.968408\n",
      "236     40 36.457136\n",
      "237     30 32.202174\n",
      "238     20 24.375749\n",
      "239     20 28.197969\n",
      "240     30 15.835530\n",
      "241     10 12.808199\n",
      "243     10 17.698691\n",
      "244     60 29.273062\n",
      "246     30 30.221492\n",
      "249      0 11.302605\n",
      "250      0 17.032101\n",
      "251      0 10.927146\n",
      "252      0 18.807762\n",
      "254      0  4.497885\n",
      "256      0 18.484894\n",
      "257     10 16.702197\n",
      "263      0  7.302154\n",
      "264    100 38.746707\n",
      "265     20 22.918216\n",
      "267    100 35.470124\n",
      "274     20 16.914250\n",
      "279     10 22.720682\n",
      "280     30 26.309461\n",
      "283     30 15.386207\n",
      "286      0 21.969984\n",
      "289      0 13.875907\n",
      "290     10 27.818942\n",
      "292      0 14.407401\n",
      "293     10  9.074378\n",
      "294      0 16.052636\n",
      "295     15 24.157679\n",
      "296      5 13.352963\n",
      "297      5  9.885345\n",
      "301     40 36.085942\n",
      "302     20 22.037346\n",
      "303     50 40.681123\n",
      "305     60 41.330547\n",
      "313      0 27.375170\n",
      "314      0 23.426912\n",
      "317     50 27.563431\n",
      "318     40 28.733276\n",
      "320      0 16.357629\n",
      "324      0 16.945490\n",
      "325    100 31.819250\n",
      "330     70 27.595824\n",
      "337     10 22.363552\n",
      "338     10 23.533179\n",
      "340     10 21.321038\n",
      "341     10 17.508450\n",
      "342     20 20.805989\n",
      "347     15 16.172166\n",
      "350      4 31.715530\n",
      "351    100 31.271947\n",
      "352      0 10.645762\n",
      "354     10 24.944943\n",
      "355     10 19.808417\n",
      "356     20 30.208307\n",
      "359      0 11.679679\n",
      "360      0 25.825633\n",
      "363     20 16.289143\n",
      "364     10 13.421592\n",
      "365     60 29.638736\n",
      "366     70 22.604907\n",
      "372     20 32.396765\n",
      "373     50 41.535740\n",
      "374      0  8.180388\n",
      "375      0 12.175420\n",
      "376      5 22.999647\n",
      "379      0 26.668171\n",
      "386    100 36.986344\n",
      "387     40 31.405277\n",
      "388     30 31.247111\n",
      "389     20 36.935447\n",
      "390     20 29.204525\n",
      "391     30 31.300389\n",
      "392     30 35.708083\n",
      "393     10 19.611799\n",
      "\n",
      "$outer_result[[5]]$fit\n",
      "Conditional Inference Random Forest \n",
      "\n",
      "190 samples\n",
      " 34 predictor\n",
      "\n",
      "No pre-processing\n",
      "Resampling: Cross-Validated (10 fold, repeated 5 times) \n",
      "Summary of sample sizes: 171, 171, 171, 171, 172, 171, ... \n",
      "Resampling results across tuning parameters:\n",
      "\n",
      "  mtry  RMSE      Rsquared   MAE     \n",
      "   2    24.32042  0.2238010  18.75485\n",
      "  18    24.17031  0.1698201  18.33405\n",
      "  34    24.33987  0.1532367  18.40058\n",
      "\n",
      "MAE was used to select the optimal model using the smallest value.\n",
      "The final value used for the model was mtry = 18.\n",
      "\n",
      "$outer_result[[5]]$nfilter\n",
      "[1] 34\n",
      "\n",
      "\n",
      "$outer_result[[6]]\n",
      "$outer_result[[6]]$preds\n",
      "       predy testy\n",
      "9   22.37470    30\n",
      "10  15.07923     0\n",
      "30  17.72051     5\n",
      "41  16.43981     0\n",
      "51  28.54836    50\n",
      "54  13.82537     0\n",
      "62  11.55903     0\n",
      "63  22.32005    10\n",
      "74  17.73430    50\n",
      "75  11.89243    30\n",
      "109 20.17698     5\n",
      "112 30.61381     0\n",
      "120 16.35233     0\n",
      "150 16.57154    20\n",
      "171 34.15993    60\n",
      "172 34.59003     0\n",
      "178 13.87421   100\n",
      "183 16.47535    10\n",
      "192 13.31093     0\n",
      "200 38.60918    50\n",
      "211 34.74631    30\n",
      "\n",
      "$outer_result[[6]]$train_preds\n",
      "    ytrain     predy\n",
      "0        0 10.371216\n",
      "2        0  6.581072\n",
      "4        0  6.390804\n",
      "5        0  4.307078\n",
      "6        0  9.575327\n",
      "8       20 18.529039\n",
      "9        0 10.294763\n",
      "10       5  8.219177\n",
      "11      10  7.320077\n",
      "20       5 12.573916\n",
      "21       0  7.221237\n",
      "22     100 40.075818\n",
      "23      10 13.984221\n",
      "24       5 10.437629\n",
      "25       0 20.805971\n",
      "26       0 16.168766\n",
      "27      30 19.272972\n",
      "28      50 27.415311\n",
      "29      70 26.601500\n",
      "30       0 25.207741\n",
      "32      30 16.666263\n",
      "38      10 14.274624\n",
      "39      20 15.050739\n",
      "44      10 19.839667\n",
      "45       0 28.935699\n",
      "46       0 25.642051\n",
      "47      60 36.162923\n",
      "48      10 13.284932\n",
      "50       0 14.303027\n",
      "53      20 13.339488\n",
      "55       0  7.700098\n",
      "56       0  6.510629\n",
      "58       0  6.369440\n",
      "61       0 12.322062\n",
      "62       5 10.512114\n",
      "63       0 11.755884\n",
      "65       0  6.201382\n",
      "66       0  7.291392\n",
      "68      10 23.410282\n",
      "69      10 17.514108\n",
      "72       5 14.375053\n",
      "73       0 10.223110\n",
      "74      30 20.608558\n",
      "77      40 38.929205\n",
      "78      10 17.202033\n",
      "79      50 26.354859\n",
      "80      10 20.512533\n",
      "84       0 16.352031\n",
      "93       0 27.480459\n",
      "95      20 32.548530\n",
      "96      90 41.465094\n",
      "101     50 21.634217\n",
      "102     30 19.729085\n",
      "105     35 23.623814\n",
      "109      0 17.756758\n",
      "111      0  7.534781\n",
      "114      5 13.207950\n",
      "118     50 23.225129\n",
      "125     10 18.089898\n",
      "126      0 15.171450\n",
      "129      5  8.711470\n",
      "130      5 22.449525\n",
      "132      0 16.575263\n",
      "134     60 33.044895\n",
      "136      5  8.795726\n",
      "138     50 29.105748\n",
      "147      0 16.739301\n",
      "149     45 35.237329\n",
      "151    100 33.423237\n",
      "152     10 24.569900\n",
      "153     20 25.329060\n",
      "156      0 11.438045\n",
      "158      0 11.241067\n",
      "162     10 13.485247\n",
      "163      0 15.005482\n",
      "164     20 18.215431\n",
      "165      0 20.277045\n",
      "166     50 21.984865\n",
      "168      0 11.576413\n",
      "171      0  7.790779\n",
      "172      0 13.063662\n",
      "173     80 30.693051\n",
      "175     12  9.196025\n",
      "177    100 37.850278\n",
      "178      0  8.473699\n",
      "181      5 10.383983\n",
      "182     50 24.652794\n",
      "183     50 14.099068\n",
      "184     20 26.831311\n",
      "185     40 24.988790\n",
      "192      0 19.433367\n",
      "193    100 45.895571\n",
      "194     20 29.910843\n",
      "195     50 36.631116\n",
      "196      0  7.201624\n",
      "197      0  7.670527\n",
      "199      5 22.108781\n",
      "201     20 23.355534\n",
      "202     30 22.386906\n",
      "206     10 23.127169\n",
      "207      0 23.906797\n",
      "210      0 17.236177\n",
      "211      0 18.784746\n",
      "216      0  6.098535\n",
      "217      0 16.155938\n",
      "218      5 17.551578\n",
      "219     20 11.444950\n",
      "221      5 10.640098\n",
      "223      0 13.267042\n",
      "228      7 15.779680\n",
      "229     20 26.649670\n",
      "230     40 24.537306\n",
      "232     20 20.523093\n",
      "233     40 27.473923\n",
      "235     10 21.300617\n",
      "236     40 31.213363\n",
      "237     30 29.191167\n",
      "238     20 29.559614\n",
      "239     20 23.696289\n",
      "240     30 19.117909\n",
      "241     10 15.167585\n",
      "242     30 27.916316\n",
      "243     10 16.856726\n",
      "244     60 28.332023\n",
      "246     30 28.577935\n",
      "249      0 11.780533\n",
      "250      0 20.104505\n",
      "251      0  9.533643\n",
      "252      0 13.753141\n",
      "254      0  4.307078\n",
      "256      0 13.374900\n",
      "257     10 15.713224\n",
      "263      0  6.869741\n",
      "264    100 42.092057\n",
      "265     20 18.008788\n",
      "266     20 19.736689\n",
      "267    100 33.034990\n",
      "275     20 15.879570\n",
      "279     10 19.839667\n",
      "280     30 29.561780\n",
      "283     30 14.857585\n",
      "285      0 14.751164\n",
      "286      0 12.618388\n",
      "287      1 14.674845\n",
      "289      0 15.553731\n",
      "290     10 20.947911\n",
      "292      0 15.261181\n",
      "293     10  9.198745\n",
      "294      0 16.852825\n",
      "295     15 20.258957\n",
      "296      5 18.030623\n",
      "297      5 10.223110\n",
      "298     40 23.676324\n",
      "301     40 39.246765\n",
      "302     20 18.927869\n",
      "303     50 32.744806\n",
      "304     50 28.392539\n",
      "314      0 22.706371\n",
      "317     50 21.634217\n",
      "318     40 25.442270\n",
      "320      0 17.347401\n",
      "324      0  9.344970\n",
      "330     70 31.850964\n",
      "337     10 18.818799\n",
      "338     10 23.279876\n",
      "340     10 13.590277\n",
      "342     20 22.597858\n",
      "347     15 14.482510\n",
      "350      4 16.739301\n",
      "351    100 33.404944\n",
      "352      0 11.391908\n",
      "354     10 23.399388\n",
      "355     10 20.752405\n",
      "356     20 26.445199\n",
      "360      0 23.679935\n",
      "361     80 30.693051\n",
      "363     20 17.508480\n",
      "364     10 13.130632\n",
      "365     60 32.433818\n",
      "366     70 24.546647\n",
      "372     20 29.910843\n",
      "374      0  7.201624\n",
      "375      0 11.543884\n",
      "376      5 22.735982\n",
      "379      0 25.050465\n",
      "386    100 34.281301\n",
      "387     40 28.793598\n",
      "388     30 29.482775\n",
      "389     20 36.110543\n",
      "390     20 24.684763\n",
      "391     30 30.094782\n",
      "393     10 20.556858\n",
      "\n",
      "$outer_result[[6]]$fit\n",
      "Conditional Inference Random Forest \n",
      "\n",
      "192 samples\n",
      " 34 predictor\n",
      "\n",
      "No pre-processing\n",
      "Resampling: Cross-Validated (10 fold, repeated 5 times) \n",
      "Summary of sample sizes: 173, 173, 173, 173, 173, 173, ... \n",
      "Resampling results across tuning parameters:\n",
      "\n",
      "  mtry  RMSE      Rsquared   MAE     \n",
      "   2    23.81155  0.2428114  18.18616\n",
      "  18    23.59976  0.1876904  17.82281\n",
      "  34    23.77221  0.1622301  17.89900\n",
      "\n",
      "MAE was used to select the optimal model using the smallest value.\n",
      "The final value used for the model was mtry = 18.\n",
      "\n",
      "$outer_result[[6]]$nfilter\n",
      "[1] 34\n",
      "\n",
      "\n",
      "$outer_result[[7]]\n",
      "$outer_result[[7]]$preds\n",
      "        predy testy\n",
      "16  22.072225     0\n",
      "17  21.726260     0\n",
      "24  12.735375    20\n",
      "31  15.800749     0\n",
      "35   8.606020     0\n",
      "55  32.703280    20\n",
      "66  21.639397    10\n",
      "70  19.682332     0\n",
      "79  25.040337    10\n",
      "92   8.892502    12\n",
      "103 31.895815    50\n",
      "104  6.940567     0\n",
      "116 20.495728     0\n",
      "162 17.576349     0\n",
      "168 17.733446    20\n",
      "169 35.951552    50\n",
      "176 20.886471     0\n",
      "196 13.645017    10\n",
      "205 20.138741   100\n",
      "206 28.351443    40\n",
      "\n",
      "$outer_result[[7]]$train_preds\n",
      "    ytrain     predy\n",
      "0        0  9.178212\n",
      "2        0  7.863996\n",
      "4        0  7.704902\n",
      "5        0  4.881607\n",
      "6        0 13.028439\n",
      "8       20 18.680613\n",
      "9        0 10.848501\n",
      "10       5  9.842043\n",
      "11      10  8.489801\n",
      "12      30 22.193518\n",
      "19       0 13.406224\n",
      "20       5 14.791534\n",
      "21       0  9.934800\n",
      "22     100 35.727511\n",
      "23      10 15.704390\n",
      "24       5 13.351843\n",
      "27      30 21.030376\n",
      "28      50 29.183852\n",
      "29      70 28.567490\n",
      "30       0 31.075442\n",
      "32      30 17.163691\n",
      "38      10 14.998231\n",
      "44      10 19.941647\n",
      "45       0 26.906597\n",
      "46       0 18.363173\n",
      "47      60 38.185198\n",
      "48      10 20.168609\n",
      "49       5 16.918580\n",
      "53      20 12.131012\n",
      "55       0  9.011133\n",
      "56       0  8.571098\n",
      "61       0  9.548607\n",
      "62       5 12.215978\n",
      "63       0 12.702561\n",
      "65       0  7.560449\n",
      "66       0  7.798059\n",
      "67       0 14.655199\n",
      "68      10 24.562112\n",
      "69      10 16.289033\n",
      "72       5 13.635422\n",
      "73       0 10.486835\n",
      "74      30 18.733735\n",
      "77      40 32.487656\n",
      "78      10 15.195241\n",
      "79      50 30.610443\n",
      "80      10 19.974221\n",
      "81      50 31.986490\n",
      "84       0 21.374913\n",
      "93       0 21.280412\n",
      "94       0 15.158439\n",
      "96      90 40.592781\n",
      "101     50 22.924630\n",
      "102     30 20.548686\n",
      "105     35 17.576114\n",
      "109      0 19.038405\n",
      "111      0 13.522748\n",
      "112      0 13.147294\n",
      "113     10 21.269799\n",
      "114      5 16.638417\n",
      "118     50 25.564233\n",
      "126      0 14.650059\n",
      "129      5  8.821464\n",
      "130      5 22.624251\n",
      "134     60 30.360529\n",
      "136      5 13.706205\n",
      "138     50 27.979993\n",
      "140     50 23.178463\n",
      "143     30 13.084241\n",
      "147      0 21.533306\n",
      "149     45 35.790200\n",
      "151    100 36.152954\n",
      "153     20 29.693996\n",
      "156      0 11.539407\n",
      "158      0  9.668217\n",
      "162     10 11.176008\n",
      "163      0 13.090971\n",
      "164     20 16.289238\n",
      "165      0 17.785026\n",
      "166     50 18.940472\n",
      "168      0 13.744042\n",
      "171      0  8.313421\n",
      "172      0 12.450564\n",
      "173     80 35.441515\n",
      "177    100 33.522130\n",
      "178      0  8.647876\n",
      "181      5 12.218599\n",
      "182     50 27.133572\n",
      "183     50 16.368094\n",
      "184     20 26.755145\n",
      "185     40 25.895932\n",
      "192      0 20.891068\n",
      "193    100 46.538727\n",
      "194     20 31.576059\n",
      "197      0  9.210972\n",
      "199      5 21.667528\n",
      "201     20 26.245507\n",
      "202     30 19.422138\n",
      "203      5 19.285710\n",
      "206     10 24.963360\n",
      "207      0 22.772238\n",
      "209      0 29.390576\n",
      "210      0 15.399886\n",
      "211      0 18.759641\n",
      "216      0  5.357254\n",
      "218      5 20.865929\n",
      "219     20 11.427164\n",
      "221      5 13.588024\n",
      "222      0 13.151019\n",
      "223      0 16.246433\n",
      "228      7 13.349953\n",
      "229     20 24.749996\n",
      "230     40 29.994196\n",
      "232     20 15.853387\n",
      "233     40 27.572771\n",
      "235     10 25.919967\n",
      "236     40 32.415738\n",
      "237     30 31.136761\n",
      "238     20 27.679466\n",
      "239     20 24.794501\n",
      "240     30 15.007220\n",
      "241     10 12.958016\n",
      "242     30 25.373762\n",
      "243     10 15.742674\n",
      "244     60 26.103839\n",
      "246     30 23.511891\n",
      "249      0 15.249714\n",
      "250      0 19.825298\n",
      "251      0 14.205650\n",
      "252      0 16.480721\n",
      "254      0  4.881607\n",
      "256      0 14.216068\n",
      "257     10 16.907386\n",
      "263      0 10.972457\n",
      "264    100 39.789103\n",
      "265     20 23.694007\n",
      "266     20 24.975567\n",
      "267    100 36.126103\n",
      "274     20 17.099788\n",
      "275     20 15.348940\n",
      "279     10 19.941647\n",
      "280     30 29.005523\n",
      "283     30 14.886861\n",
      "285      0 18.093130\n",
      "286      0 17.209308\n",
      "287      1 18.946356\n",
      "289      0 12.847569\n",
      "290     10 25.352722\n",
      "292      0 13.373908\n",
      "293     10  9.749997\n",
      "295     15 24.202688\n",
      "296      5 15.785587\n",
      "297      5 10.757826\n",
      "298     40 23.066199\n",
      "301     40 33.490421\n",
      "304     50 28.294420\n",
      "305     60 38.180971\n",
      "313      0 26.597637\n",
      "314      0 20.180232\n",
      "317     50 22.924630\n",
      "318     40 29.377905\n",
      "324      0 14.780865\n",
      "325    100 25.051726\n",
      "330     70 35.690646\n",
      "337     10 22.386329\n",
      "338     10 23.106231\n",
      "340     10 15.447900\n",
      "341     10 17.395051\n",
      "342     20 22.624251\n",
      "347     15 16.131133\n",
      "350      4 21.533306\n",
      "351    100 35.814146\n",
      "352      0  9.668217\n",
      "354     10 19.743449\n",
      "355     10 17.314563\n",
      "356     20 29.415099\n",
      "359      0 11.343745\n",
      "360      0 20.342069\n",
      "361     80 35.441515\n",
      "363     20 16.439339\n",
      "365     60 31.062965\n",
      "366     70 23.244218\n",
      "372     20 31.576059\n",
      "373     50 38.944211\n",
      "374      0  7.146101\n",
      "375      0 12.873764\n",
      "376      5 21.425209\n",
      "379      0 24.860348\n",
      "388     30 35.373608\n",
      "389     20 32.862808\n",
      "390     20 27.936046\n",
      "391     30 30.986487\n",
      "392     30 29.426506\n",
      "393     10 19.859575\n",
      "\n",
      "$outer_result[[7]]$fit\n",
      "Conditional Inference Random Forest \n",
      "\n",
      "193 samples\n",
      " 34 predictor\n",
      "\n",
      "No pre-processing\n",
      "Resampling: Cross-Validated (10 fold, repeated 5 times) \n",
      "Summary of sample sizes: 174, 174, 174, 174, 174, 174, ... \n",
      "Resampling results across tuning parameters:\n",
      "\n",
      "  mtry  RMSE      Rsquared   MAE     \n",
      "   2    24.00610  0.2270156  18.75705\n",
      "  18    23.71331  0.1930918  18.40060\n",
      "  34    23.83597  0.1762275  18.51612\n",
      "\n",
      "MAE was used to select the optimal model using the smallest value.\n",
      "The final value used for the model was mtry = 18.\n",
      "\n",
      "$outer_result[[7]]$nfilter\n",
      "[1] 34\n",
      "\n",
      "\n",
      "$outer_result[[8]]\n",
      "$outer_result[[8]]$preds\n",
      "        predy testy\n",
      "1   10.670095     0\n",
      "4    9.233223     0\n",
      "13  23.868716   100\n",
      "18  19.495833    30\n",
      "42  25.410982    10\n",
      "78  31.789542   100\n",
      "83  13.745351    10\n",
      "84  13.936183     0\n",
      "85  13.976039    20\n",
      "90  14.916150     0\n",
      "99  21.414064    40\n",
      "125 19.659029    20\n",
      "127 23.152685    10\n",
      "131 27.319308    20\n",
      "136 23.614548    60\n",
      "142  4.908518     0\n",
      "143 17.025920     0\n",
      "152 25.793611    10\n",
      "163 24.365979    15\n",
      "164 20.929467     5\n",
      "182 20.550923    10\n",
      "204 21.145849     0\n",
      "\n",
      "$outer_result[[8]]$train_preds\n",
      "    ytrain     predy\n",
      "0        0  6.602419\n",
      "4        0  6.301246\n",
      "5        0  4.908518\n",
      "8       20 12.343841\n",
      "9        0  9.783583\n",
      "10       5  8.586236\n",
      "11      10  4.543326\n",
      "12      30 24.313673\n",
      "19       0 16.005727\n",
      "20       5 11.628152\n",
      "21       0  7.453013\n",
      "23      10 15.022670\n",
      "24       5 12.724364\n",
      "25       0 15.164848\n",
      "26       0 18.133080\n",
      "28      50 26.722435\n",
      "29      70 31.138670\n",
      "30       0 22.942084\n",
      "32      30 15.070508\n",
      "38      10 14.561720\n",
      "39      20 14.828649\n",
      "44      10 25.793611\n",
      "45       0 18.243780\n",
      "46       0 18.813689\n",
      "47      60 35.800614\n",
      "48      10 13.175339\n",
      "49       5 15.834660\n",
      "50       0 17.730385\n",
      "53      20 13.139102\n",
      "55       0  7.473209\n",
      "56       0  6.602940\n",
      "58       0  4.461665\n",
      "61       0 11.115205\n",
      "62       5 11.568410\n",
      "63       0 12.435324\n",
      "65       0  7.613646\n",
      "66       0  7.334006\n",
      "67       0 16.757374\n",
      "69      10 15.444106\n",
      "72       5 17.994935\n",
      "73       0  8.876858\n",
      "74      30 22.304949\n",
      "77      40 34.268112\n",
      "78      10 17.710002\n",
      "79      50 33.638647\n",
      "80      10 21.887323\n",
      "81      50 33.817936\n",
      "84       0 15.820046\n",
      "93       0 16.820441\n",
      "94       0  9.811479\n",
      "95      20 32.873994\n",
      "96      90 39.995619\n",
      "101     50 23.089338\n",
      "102     30 19.384299\n",
      "105     35 27.072409\n",
      "109      0 20.920021\n",
      "111      0  7.789385\n",
      "112      0 12.058072\n",
      "113     10 18.880839\n",
      "114      5 13.562459\n",
      "118     50 26.558417\n",
      "125     10 19.760479\n",
      "126      0 10.410698\n",
      "129      5  7.152286\n",
      "130      5 19.919513\n",
      "132      0 17.641755\n",
      "134     60 34.217506\n",
      "136      5 10.441276\n",
      "138     50 29.833273\n",
      "140     50 22.506098\n",
      "143     30 15.740710\n",
      "147      0 24.188756\n",
      "149     45 38.050041\n",
      "152     10 30.333359\n",
      "153     20 30.182262\n",
      "156      0 10.538902\n",
      "158      0 11.264545\n",
      "165      0 24.633156\n",
      "166     50 17.835353\n",
      "168      0  9.225955\n",
      "171      0  5.340783\n",
      "173     80 31.785960\n",
      "175     12  7.944687\n",
      "177    100 36.340916\n",
      "178      0  8.285954\n",
      "181      5 10.530215\n",
      "182     50 25.912756\n",
      "183     50 14.022069\n",
      "184     20 26.515120\n",
      "192      0 15.027536\n",
      "193    100 46.951621\n",
      "194     20 30.538671\n",
      "195     50 36.685491\n",
      "196      0  5.558640\n",
      "197      0  7.320969\n",
      "199      5 15.795856\n",
      "201     20 27.050061\n",
      "202     30 21.895906\n",
      "203      5 20.406356\n",
      "206     10 21.408222\n",
      "207      0 17.184422\n",
      "209      0 27.637092\n",
      "210      0 13.137395\n",
      "211      0 15.817363\n",
      "216      0  5.524431\n",
      "217      0 11.015357\n",
      "218      5 22.254167\n",
      "219     20 13.760608\n",
      "221      5 11.556441\n",
      "222      0 12.928648\n",
      "223      0 12.931477\n",
      "228      7 12.711099\n",
      "229     20 30.802414\n",
      "230     40 34.645718\n",
      "233     40 28.313831\n",
      "236     40 32.437075\n",
      "237     30 22.271937\n",
      "238     20 23.736833\n",
      "240     30 16.009791\n",
      "241     10 14.932112\n",
      "242     30 21.514947\n",
      "243     10 14.362373\n",
      "246     30 28.426873\n",
      "249      0  8.127752\n",
      "250      0 17.068629\n",
      "251      0 10.773646\n",
      "252      0 13.573922\n",
      "257     10 15.814199\n",
      "263      0  8.176180\n",
      "264    100 34.420873\n",
      "265     20 22.100002\n",
      "266     20 23.593089\n",
      "267    100 34.362339\n",
      "274     20 15.781376\n",
      "275     20 15.834935\n",
      "280     30 19.683372\n",
      "283     30 15.610609\n",
      "285      0 17.551564\n",
      "286      0 17.465283\n",
      "287      1 17.081674\n",
      "289      0 16.203845\n",
      "290     10 27.865081\n",
      "292      0 15.494928\n",
      "293     10  8.813301\n",
      "294      0 15.107766\n",
      "297      5  8.958287\n",
      "298     40 24.733002\n",
      "301     40 35.002155\n",
      "302     20 19.515846\n",
      "303     50 39.191325\n",
      "304     50 34.444797\n",
      "305     60 43.849283\n",
      "313      0 26.002326\n",
      "314      0 26.226070\n",
      "317     50 23.089338\n",
      "318     40 29.710731\n",
      "320      0 16.723267\n",
      "324      0 10.451378\n",
      "325    100 27.363304\n",
      "330     70 35.631893\n",
      "337     10 20.141467\n",
      "338     10 24.327327\n",
      "341     10 15.451589\n",
      "342     20 19.919513\n",
      "347     15 19.125101\n",
      "350      4 24.188756\n",
      "351    100 35.796258\n",
      "352      0 11.166420\n",
      "354     10 19.331801\n",
      "355     10 20.912180\n",
      "356     20 32.671379\n",
      "359      0  8.437800\n",
      "360      0 28.238991\n",
      "361     80 31.785960\n",
      "363     20 16.056931\n",
      "364     10 12.349935\n",
      "365     60 33.758896\n",
      "366     70 21.831650\n",
      "372     20 30.538671\n",
      "373     50 43.384950\n",
      "374      0  5.558640\n",
      "375      0 10.446418\n",
      "376      5 21.785841\n",
      "386    100 39.163764\n",
      "387     40 32.168277\n",
      "388     30 32.549785\n",
      "389     20 37.646771\n",
      "390     20 28.455416\n",
      "391     30 31.479018\n",
      "392     30 32.203399\n",
      "393     10 19.970910\n",
      "\n",
      "$outer_result[[8]]$fit\n",
      "Conditional Inference Random Forest \n",
      "\n",
      "191 samples\n",
      " 34 predictor\n",
      "\n",
      "No pre-processing\n",
      "Resampling: Cross-Validated (10 fold, repeated 5 times) \n",
      "Summary of sample sizes: 172, 172, 172, 172, 172, 171, ... \n",
      "Resampling results across tuning parameters:\n",
      "\n",
      "  mtry  RMSE      Rsquared   MAE     \n",
      "   2    23.65659  0.2115729  18.49041\n",
      "  18    23.33827  0.1831548  17.91997\n",
      "  34    23.30894  0.1794357  17.76047\n",
      "\n",
      "MAE was used to select the optimal model using the smallest value.\n",
      "The final value used for the model was mtry = 34.\n",
      "\n",
      "$outer_result[[8]]$nfilter\n",
      "[1] 34\n",
      "\n",
      "\n",
      "$outer_result[[9]]\n",
      "$outer_result[[9]]$preds\n",
      "        predy testy\n",
      "21  31.421908     0\n",
      "49  26.043894    50\n",
      "56  34.422966    90\n",
      "57  18.397697    50\n",
      "68   9.285084     5\n",
      "82  13.480177     0\n",
      "86  24.380494     0\n",
      "88  16.031625     0\n",
      "118 14.232838    20\n",
      "133 19.456304    10\n",
      "140 11.849224     0\n",
      "146 34.062300   100\n",
      "153 26.257809    30\n",
      "158 18.950920     0\n",
      "159 24.417541    10\n",
      "160 19.231603     0\n",
      "161  8.704162    10\n",
      "185 13.596679    15\n",
      "203 26.039299     5\n",
      "208 33.441030    20\n",
      "212 20.563414    10\n",
      "\n",
      "$outer_result[[9]]$train_preds\n",
      "    ytrain     predy\n",
      "0        0  8.921706\n",
      "2        0  7.837637\n",
      "4        0  6.567979\n",
      "5        0  4.307517\n",
      "6        0  9.579806\n",
      "8       20 20.678055\n",
      "9        0  8.128736\n",
      "10       5  8.415306\n",
      "11      10  6.108395\n",
      "12      30 18.599184\n",
      "19       0 13.894552\n",
      "20       5 10.560616\n",
      "21       0 10.810790\n",
      "22     100 29.592907\n",
      "23      10 16.990963\n",
      "24       5  9.319864\n",
      "25       0 21.000292\n",
      "26       0 15.837037\n",
      "27      30 19.016933\n",
      "28      50 32.214883\n",
      "29      70 26.777124\n",
      "32      30 20.297989\n",
      "38      10 13.833488\n",
      "39      20 14.603919\n",
      "44      10 21.071863\n",
      "45       0 24.825128\n",
      "46       0 20.887103\n",
      "47      60 33.447927\n",
      "48      10 16.310807\n",
      "49       5 14.349099\n",
      "50       0 16.822146\n",
      "53      20 15.376719\n",
      "55       0  7.473481\n",
      "56       0  7.225002\n",
      "58       0  5.547982\n",
      "61       0 15.044759\n",
      "62       5 11.497134\n",
      "63       0 12.884913\n",
      "65       0  6.921754\n",
      "66       0  6.938496\n",
      "67       0 15.402412\n",
      "68      10 25.117961\n",
      "69      10 17.935450\n",
      "72       5 10.603129\n",
      "73       0  9.532466\n",
      "74      30 21.953424\n",
      "77      40 32.898502\n",
      "78      10 14.513284\n",
      "80      10 24.590427\n",
      "81      50 37.357600\n",
      "84       0 16.931834\n",
      "93       0 24.385424\n",
      "94       0 11.270975\n",
      "95      20 31.291376\n",
      "102     30 21.628244\n",
      "105     35 22.960910\n",
      "109      0 13.745048\n",
      "111      0  9.610560\n",
      "112      0 12.065018\n",
      "113     10 20.834155\n",
      "114      5 13.442201\n",
      "118     50 27.673943\n",
      "125     10 19.473317\n",
      "126      0 14.590851\n",
      "130      5 21.827703\n",
      "132      0 17.190622\n",
      "134     60 33.668067\n",
      "136      5 11.479751\n",
      "138     50 30.248982\n",
      "140     50 21.847948\n",
      "143     30 11.197850\n",
      "147      0 22.320007\n",
      "149     45 35.374898\n",
      "151    100 36.663364\n",
      "152     10 30.911754\n",
      "153     20 29.956559\n",
      "156      0 13.982986\n",
      "162     10 16.896311\n",
      "163      0 14.631800\n",
      "164     20 18.745775\n",
      "166     50 20.373886\n",
      "171      0  7.783452\n",
      "172      0 15.091710\n",
      "173     80 34.594813\n",
      "175     12  7.038097\n",
      "177    100 34.316569\n",
      "178      0  6.208996\n",
      "181      5 11.320578\n",
      "182     50 23.523498\n",
      "183     50 16.594231\n",
      "184     20 30.190641\n",
      "185     40 28.597544\n",
      "192      0 18.928901\n",
      "193    100 42.715188\n",
      "194     20 29.990643\n",
      "195     50 31.507245\n",
      "196      0  5.947347\n",
      "197      0  6.906161\n",
      "199      5 21.685366\n",
      "201     20 26.780310\n",
      "202     30 26.136337\n",
      "203      5 23.030870\n",
      "206     10 24.024253\n",
      "207      0 20.741231\n",
      "209      0 29.081064\n",
      "210      0 14.729452\n",
      "211      0 16.238881\n",
      "216      0  5.373759\n",
      "217      0 19.087788\n",
      "218      5 15.976242\n",
      "221      5 10.451871\n",
      "222      0 15.301616\n",
      "223      0 15.125422\n",
      "228      7 16.097693\n",
      "229     20 28.781083\n",
      "230     40 27.309433\n",
      "232     20 21.960245\n",
      "233     40 31.156795\n",
      "235     10 28.541777\n",
      "236     40 29.315933\n",
      "237     30 27.209926\n",
      "238     20 29.976559\n",
      "239     20 25.688666\n",
      "240     30 21.304231\n",
      "242     30 28.401511\n",
      "243     10 18.850548\n",
      "244     60 28.954574\n",
      "246     30 22.236979\n",
      "249      0 15.200951\n",
      "250      0 19.335718\n",
      "252      0 12.836666\n",
      "254      0  4.307517\n",
      "256      0 12.735888\n",
      "257     10 14.553572\n",
      "263      0 11.157978\n",
      "265     20 22.398432\n",
      "266     20 20.465268\n",
      "267    100 35.193606\n",
      "274     20 15.074661\n",
      "275     20 17.928642\n",
      "279     10 21.071863\n",
      "283     30 16.789426\n",
      "285      0 13.850925\n",
      "286      0 14.231882\n",
      "287      1 16.428204\n",
      "294      0 17.371218\n",
      "295     15 22.252381\n",
      "296      5 11.968166\n",
      "297      5  9.878241\n",
      "298     40 25.254444\n",
      "301     40 33.320184\n",
      "302     20 18.580640\n",
      "303     50 34.840831\n",
      "304     50 36.430039\n",
      "305     60 40.001455\n",
      "313      0 25.863539\n",
      "314      0 24.430842\n",
      "317     50 18.397697\n",
      "318     40 27.168148\n",
      "320      0 16.637755\n",
      "324      0 10.420099\n",
      "325    100 23.379731\n",
      "330     70 32.336425\n",
      "337     10 20.739693\n",
      "338     10 18.237949\n",
      "340     10 16.726951\n",
      "341     10 13.825551\n",
      "342     20 21.827703\n",
      "350      4 22.320007\n",
      "351    100 36.584975\n",
      "352      0 13.569773\n",
      "354     10 22.388427\n",
      "355     10 21.201001\n",
      "356     20 31.023566\n",
      "359      0  9.184087\n",
      "360      0 24.596841\n",
      "361     80 34.594813\n",
      "363     20 15.143411\n",
      "364     10  9.982947\n",
      "365     60 33.989426\n",
      "366     70 26.118726\n",
      "372     20 29.990643\n",
      "373     50 35.790841\n",
      "374      0  5.947347\n",
      "375      0  8.760772\n",
      "379      0 20.576644\n",
      "386    100 35.162211\n",
      "387     40 32.906565\n",
      "388     30 33.632192\n",
      "390     20 25.861300\n",
      "391     30 30.042732\n",
      "392     30 30.091455\n",
      "\n",
      "$outer_result[[9]]$fit\n",
      "Conditional Inference Random Forest \n",
      "\n",
      "192 samples\n",
      " 34 predictor\n",
      "\n",
      "No pre-processing\n",
      "Resampling: Cross-Validated (10 fold, repeated 5 times) \n",
      "Summary of sample sizes: 173, 173, 173, 173, 172, 172, ... \n",
      "Resampling results across tuning parameters:\n",
      "\n",
      "  mtry  RMSE      Rsquared   MAE     \n",
      "   2    23.71327  0.2224268  18.41171\n",
      "  18    23.37610  0.1922465  17.89207\n",
      "  34    23.42432  0.1784386  17.88304\n",
      "\n",
      "MAE was used to select the optimal model using the smallest value.\n",
      "The final value used for the model was mtry = 34.\n",
      "\n",
      "$outer_result[[9]]$nfilter\n",
      "[1] 34\n",
      "\n",
      "\n",
      "$outer_result[[10]]\n",
      "$outer_result[[10]]$preds\n",
      "       predy testy\n",
      "5   18.61719    20\n",
      "11  17.82389     5\n",
      "19  25.14034    50\n",
      "20  18.49348    70\n",
      "32  12.77757    20\n",
      "36  13.29844     0\n",
      "52  20.83641     0\n",
      "58  18.01101    30\n",
      "65  17.80118    50\n",
      "72  14.28589     5\n",
      "73  24.81060    50\n",
      "81  13.55091     0\n",
      "101 37.65748   100\n",
      "108 21.96939    30\n",
      "114 17.74060     0\n",
      "117 19.62432     5\n",
      "119 11.63068     5\n",
      "121 17.14200     0\n",
      "138 14.15144     0\n",
      "141 23.13005     0\n",
      "190 22.09183    10\n",
      "210 23.06849    30\n",
      "\n",
      "$outer_result[[10]]$train_preds\n",
      "    ytrain     predy\n",
      "0        0  7.120825\n",
      "2        0  8.880289\n",
      "4        0  7.711575\n",
      "5        0  4.421792\n",
      "6        0 11.826317\n",
      "9        0  9.003378\n",
      "10       5 10.313200\n",
      "11      10  6.612046\n",
      "12      30 23.996724\n",
      "19       0 16.351758\n",
      "21       0  7.675153\n",
      "22     100 34.478447\n",
      "23      10 12.871570\n",
      "24       5 11.617999\n",
      "25       0 17.457942\n",
      "26       0 15.523615\n",
      "27      30 17.878239\n",
      "30       0 26.697206\n",
      "32      30 14.255161\n",
      "38      10 14.017847\n",
      "39      20 11.914650\n",
      "44      10 17.902818\n",
      "45       0 28.681515\n",
      "46       0 26.375151\n",
      "47      60 37.374662\n",
      "48      10 19.632139\n",
      "49       5 15.321370\n",
      "50       0 13.589106\n",
      "55       0  8.528932\n",
      "56       0  7.472050\n",
      "58       0  6.603903\n",
      "62       5 14.752629\n",
      "63       0  9.513508\n",
      "65       0  6.606650\n",
      "66       0  5.793283\n",
      "67       0 14.155345\n",
      "68      10 22.348971\n",
      "69      10 17.737003\n",
      "72       5 14.303386\n",
      "73       0  7.549113\n",
      "74      30 17.937181\n",
      "77      40 28.917946\n",
      "78      10 15.609200\n",
      "79      50 33.860774\n",
      "80      10 18.781501\n",
      "81      50 38.965271\n",
      "93       0 23.234132\n",
      "94       0 12.234744\n",
      "95      20 28.605102\n",
      "96      90 38.978734\n",
      "101     50 23.333150\n",
      "105     35 19.204314\n",
      "109      0 16.407694\n",
      "111      0 10.044941\n",
      "112      0 11.505477\n",
      "113     10 20.405458\n",
      "114      5 10.525218\n",
      "125     10 17.215554\n",
      "126      0 14.326134\n",
      "129      5  7.516980\n",
      "130      5 19.369257\n",
      "132      0 12.069828\n",
      "134     60 32.008127\n",
      "140     50 24.402473\n",
      "143     30 12.243338\n",
      "147      0 24.160894\n",
      "149     45 29.732858\n",
      "151    100 38.402946\n",
      "152     10 26.105058\n",
      "153     20 24.026583\n",
      "158      0 10.299390\n",
      "162     10 11.446298\n",
      "163      0 15.194655\n",
      "164     20 20.469768\n",
      "165      0 19.091925\n",
      "166     50 20.225126\n",
      "168      0 11.007521\n",
      "171      0  9.561349\n",
      "172      0 12.982899\n",
      "173     80 29.966569\n",
      "175     12  7.930083\n",
      "177    100 31.391042\n",
      "178      0  8.942769\n",
      "181      5 10.702831\n",
      "182     50 22.304330\n",
      "183     50 16.709477\n",
      "184     20 24.135608\n",
      "185     40 26.314753\n",
      "192      0 17.509786\n",
      "194     20 26.925669\n",
      "195     50 31.057143\n",
      "196      0  6.052414\n",
      "197      0  8.289318\n",
      "199      5 21.940702\n",
      "201     20 24.880459\n",
      "203      5 16.733731\n",
      "206     10 21.786566\n",
      "207      0 21.213087\n",
      "209      0 27.706748\n",
      "210      0 14.077180\n",
      "216      0  6.003651\n",
      "217      0 14.932039\n",
      "219     20 10.985126\n",
      "222      0 14.340373\n",
      "228      7 16.212342\n",
      "229     20 25.503836\n",
      "230     40 22.871772\n",
      "232     20 25.926379\n",
      "233     40 25.704185\n",
      "235     10 20.211255\n",
      "236     40 28.473020\n",
      "237     30 26.877176\n",
      "238     20 27.285205\n",
      "239     20 21.960666\n",
      "240     30 14.389682\n",
      "241     10 12.149393\n",
      "242     30 28.316919\n",
      "243     10 17.318864\n",
      "244     60 26.148160\n",
      "246     30 27.206795\n",
      "250      0 17.383647\n",
      "251      0 15.518631\n",
      "254      0  4.421792\n",
      "256      0 14.775224\n",
      "257     10 16.218794\n",
      "263      0 10.137622\n",
      "264    100 40.780669\n",
      "265     20 20.907987\n",
      "266     20 19.790408\n",
      "267    100 32.175147\n",
      "274     20 15.520344\n",
      "275     20 13.728365\n",
      "279     10 17.902818\n",
      "280     30 30.570157\n",
      "283     30 15.744345\n",
      "285      0 17.399487\n",
      "286      0 17.251544\n",
      "287      1 15.358946\n",
      "289      0 18.670557\n",
      "290     10 20.982276\n",
      "292      0 16.186916\n",
      "293     10  7.949967\n",
      "294      0 14.493732\n",
      "295     15 21.080284\n",
      "296      5 17.674325\n",
      "297      5  7.705218\n",
      "298     40 22.714457\n",
      "301     40 31.845603\n",
      "302     20 19.744737\n",
      "303     50 32.963673\n",
      "304     50 34.555652\n",
      "305     60 41.249926\n",
      "313      0 26.214600\n",
      "314      0 25.503827\n",
      "317     50 23.333150\n",
      "318     40 27.363017\n",
      "320      0 16.450092\n",
      "324      0 13.559811\n",
      "325    100 25.711652\n",
      "330     70 29.916517\n",
      "337     10 17.110554\n",
      "338     10 21.683226\n",
      "340     10 14.752785\n",
      "341     10 17.533461\n",
      "342     20 19.469257\n",
      "347     15 15.738033\n",
      "350      4 24.160894\n",
      "351    100 32.860318\n",
      "352      0 10.404390\n",
      "354     10 22.676553\n",
      "356     20 25.200149\n",
      "359      0 14.108358\n",
      "360      0 18.338949\n",
      "361     80 29.966569\n",
      "363     20 14.424949\n",
      "364     10 15.352668\n",
      "365     60 29.035139\n",
      "366     70 22.664180\n",
      "372     20 26.630914\n",
      "373     50 35.147505\n",
      "374      0  6.146531\n",
      "375      0 13.109350\n",
      "376      5 20.070755\n",
      "379      0 21.912189\n",
      "386    100 38.530991\n",
      "387     40 27.262802\n",
      "388     30 33.773687\n",
      "389     20 34.036629\n",
      "390     20 22.996448\n",
      "392     30 32.221151\n",
      "393     10 18.784050\n",
      "\n",
      "$outer_result[[10]]$fit\n",
      "Conditional Inference Random Forest \n",
      "\n",
      "191 samples\n",
      " 34 predictor\n",
      "\n",
      "No pre-processing\n",
      "Resampling: Cross-Validated (10 fold, repeated 5 times) \n",
      "Summary of sample sizes: 172, 171, 171, 172, 172, 172, ... \n",
      "Resampling results across tuning parameters:\n",
      "\n",
      "  mtry  RMSE      Rsquared   MAE     \n",
      "   2    24.00207  0.2253217  18.22683\n",
      "  18    23.86640  0.1704512  17.96391\n",
      "  34    24.01913  0.1524683  18.04953\n",
      "\n",
      "MAE was used to select the optimal model using the smallest value.\n",
      "The final value used for the model was mtry = 18.\n",
      "\n",
      "$outer_result[[10]]$nfilter\n",
      "[1] 34\n",
      "\n",
      "\n",
      "\n",
      "$outer_method\n",
      "[1] \"cv\"\n",
      "\n",
      "$outer_folds\n",
      "$outer_folds$Fold01\n",
      " [1]   3  28  38  51  61  68 116 123 127 131 133 146 148 175 176 181 194 196 199\n",
      "[20] 203 210\n",
      "\n",
      "$outer_folds$Fold02\n",
      " [1]  15  16  27  35  41  54  60  72  94  97  98 107 124 136 140 145 155 178 185\n",
      "[20] 189 192\n",
      "\n",
      "$outer_folds$Fold03\n",
      " [1]   4   8  13  26  34  44  48  70  78  81 106 108 112 138 157 168 180 187 198\n",
      "[20] 200 202\n",
      "\n",
      "$outer_folds$Fold04\n",
      " [1]  23  30  39  40  45  65  88  90  92  96  99 111 129 130 150 166 174 182 188\n",
      "[20] 190 208\n",
      "\n",
      "$outer_folds$Fold05\n",
      " [1]   1   7   9  24  29  46  47  49  62  77  95 101 103 114 125 135 149 152 156\n",
      "[20] 158 167 171 195\n",
      "\n",
      "$outer_folds$Fold06\n",
      " [1]  10  11  31  42  52  55  63  64  75  76 110 113 121 151 172 173 179 184 193\n",
      "[20] 201 212\n",
      "\n",
      "$outer_folds$Fold07\n",
      " [1]  17  18  25  32  36  56  67  71  80  93 104 105 117 163 169 170 177 197 206\n",
      "[20] 207\n",
      "\n",
      "$outer_folds$Fold08\n",
      " [1]   2   5  14  19  43  79  84  85  86  91 100 126 128 132 137 143 144 153 164\n",
      "[20] 165 183 205\n",
      "\n",
      "$outer_folds$Fold09\n",
      " [1]  22  50  57  58  69  83  87  89 119 134 141 147 154 159 160 161 162 186 204\n",
      "[20] 209 213\n",
      "\n",
      "$outer_folds$Fold10\n",
      " [1]   6  12  20  21  33  37  53  59  66  73  74  82 102 109 115 118 120 122 139\n",
      "[20] 142 191 211\n",
      "\n",
      "\n",
      "$dimx\n",
      "[1] 213  34\n",
      "\n",
      "$xsub\n",
      "    inundation_duration_h water_depth_cm contaminations.0 flowvelocity\n",
      "0             0.007506255    0.082568807                1         0.25\n",
      "1             0.003336113    0.009174312                1         0.25\n",
      "2             0.011676397    0.036697248                0         0.50\n",
      "3             0.001251043    0.018348624                1         0.25\n",
      "4             0.061718098    0.174311927                0         0.50\n",
      "5             0.011676397    0.266055046                0         0.25\n",
      "6             0.053377815    0.174311927                1         0.75\n",
      "7             0.007506255    0.018348624                1         0.75\n",
      "8             0.001251043    0.082568807                0         0.25\n",
      "9             0.020016681    0.348623853                0         0.25\n",
      "10            0.015846539    0.449541284                0         1.00\n",
      "11            0.028356964    0.183486239                0         1.00\n",
      "12            0.001251043    0.082568807                0         0.00\n",
      "13            0.007506255    0.266055046                0         0.25\n",
      "14            0.003336113    0.082568807                0         0.75\n",
      "15            0.036697248    0.174311927                0         0.75\n",
      "16            0.007506255    0.082568807                0         0.50\n",
      "17            0.007506255    0.174311927                0         1.00\n",
      "18            0.024186822    0.266055046                1         0.50\n",
      "19            0.011676397    0.266055046                0         0.25\n",
      "20            0.011676397    0.357798165                0         0.25\n",
      "21            0.011676397    0.174311927                0         1.00\n",
      "22            0.011676397    0.036697248                0         0.00\n",
      "23            0.007506255    0.449541284                0         0.50\n",
      "24            0.011676397    0.128440367                0         0.50\n",
      "25            0.003336113    0.357798165                0         0.25\n",
      "26            0.003336113    1.000000000                0         1.00\n",
      "27            0.003336113    0.266055046                0         0.50\n",
      "28            0.015846539    0.724770642                0         1.00\n",
      "29            0.007506255    0.266055046                0         0.75\n",
      "30            0.032527106    0.541284404                0         0.75\n",
      "31            0.007506255    0.082568807                0         0.75\n",
      "32            0.003336113    0.036697248                0         0.00\n",
      "33            0.011676397    0.128440367                0         0.50\n",
      "34            0.003336113    0.082568807                0         0.00\n",
      "35            0.007506255    0.036697248                0         0.50\n",
      "36            0.011676397    0.027522936                0         0.25\n",
      "37            0.020016681    0.174311927                0         0.75\n",
      "38            0.020016681    0.082568807                0         0.75\n",
      "39            0.015846539    0.082568807                0         0.25\n",
      "40            0.011676397    0.036697248                0         0.00\n",
      "41            0.001251043    0.000000000                0         0.75\n",
      "42            0.040867389    0.174311927                0         1.00\n",
      "43            0.020016681    0.128440367                0         0.25\n",
      "44            0.003336113    0.082568807                0         0.75\n",
      "45            0.003336113    0.009174312                0         0.25\n",
      "46            0.024186822    0.082568807                0         0.25\n",
      "47            0.007506255    0.357798165                0         0.25\n",
      "48            0.003336113    0.449541284                0         0.50\n",
      "49            0.011676397    0.357798165                0         1.00\n",
      "50            0.003336113    0.082568807                0         0.25\n",
      "51            0.011676397    0.266055046                0         1.00\n",
      "52            0.011676397    0.357798165                0         0.25\n",
      "53            0.007506255    0.266055046                0         0.25\n",
      "54            0.124270225    0.174311927                0         0.50\n",
      "55            0.007506255    0.449541284                0         0.75\n",
      "56            0.011676397    0.908256881                0         0.75\n",
      "57            0.020016681    0.449541284                1         0.50\n",
      "58            0.007506255    0.174311927                0         0.25\n",
      "59            0.007506255    0.449541284                0         0.75\n",
      "60            0.299416180    0.908256881                0         1.00\n",
      "61            0.003336113    0.174311927                0         0.25\n",
      "62            0.003336113    0.000000000                0         0.50\n",
      "63            0.036697248    0.449541284                0         0.75\n",
      "64            0.007506255    0.082568807                0         0.75\n",
      "65            0.020016681    0.036697248                0         0.50\n",
      "66            0.299416180    0.357798165                0         0.25\n",
      "67            0.011676397    0.220183486                0         0.25\n",
      "68            0.003336113    0.082568807                0         0.25\n",
      "69            0.007506255    0.449541284                1         0.25\n",
      "70            0.011676397    0.174311927                0         0.25\n",
      "71            0.024186822    0.357798165                0         0.25\n",
      "72            0.007506255    0.174311927                0         0.50\n",
      "73            0.020016681    0.449541284                0         1.00\n",
      "74            0.015846539    0.449541284                0         1.00\n",
      "75            0.011676397    0.055045872                0         0.50\n",
      "76            0.049207673    0.403669725                0         0.75\n",
      "77            1.000000000    0.633027523                0         1.00\n",
      "78            0.291075897    0.908256881                0         1.00\n",
      "79            0.291075897    0.678899083                0         1.00\n",
      "80            0.015846539    0.082568807                0         0.75\n",
      "81            0.011676397    0.045871560                0         0.25\n",
      "82            0.199332777    0.174311927                0         0.25\n",
      "83            0.011676397    0.036697248                0         0.25\n",
      "84            0.007506255    0.174311927                0         0.00\n",
      "85            0.007506255    0.266055046                0         0.25\n",
      "86            0.020016681    0.724770642                0         0.75\n",
      "87            0.007506255    0.128440367                1         0.00\n",
      "88            0.007506255    0.082568807                1         0.00\n",
      "89            0.007506255    0.036697248                0         0.00\n",
      "90            0.011676397    0.018348624                0         0.00\n",
      "91            0.015846539    0.174311927                0         0.75\n",
      "92            0.003336113    0.082568807                0         0.75\n",
      "93            0.011676397    0.633027523                0         0.50\n",
      "94            0.003336113    0.082568807                0         0.75\n",
      "95            0.011676397    0.128440367                0         0.50\n",
      "96            0.011676397    0.908256881                0         1.00\n",
      "97            0.007506255    0.174311927                0         0.25\n",
      "98            0.011676397    0.082568807                0         0.50\n",
      "99            0.015846539    0.174311927                0         0.25\n",
      "100           0.024186822    0.220183486                0         0.00\n",
      "101           0.015846539    0.541284404                0         0.75\n",
      "102           0.015846539    0.449541284                0         0.50\n",
      "103           0.007506255    0.357798165                0         0.50\n",
      "104           0.001251043    0.036697248                1         0.00\n",
      "105           0.007506255    0.082568807                1         0.50\n",
      "106           0.011676397    0.174311927                0         0.75\n",
      "107           0.011676397    0.266055046                0         1.00\n",
      "108           0.001251043    0.174311927                1         0.50\n",
      "109           0.011676397    0.082568807                0         0.00\n",
      "110           0.015846539    0.266055046                0         0.50\n",
      "111           0.007506255    0.266055046                0         0.50\n",
      "112           0.011676397    0.724770642                0         0.75\n",
      "113           0.011676397    0.082568807                0         0.00\n",
      "114           0.007506255    0.174311927                0         0.00\n",
      "115           0.007506255    0.018348624                0         0.25\n",
      "116           0.003336113    0.009174312                0         0.50\n",
      "117           0.011676397    0.055045872                0         0.75\n",
      "118           0.007506255    0.082568807                0         0.25\n",
      "119           0.011676397    0.082568807                1         0.75\n",
      "120           0.003336113    0.018348624                0         0.25\n",
      "121           0.015846539    0.266055046                0         0.50\n",
      "122           0.011676397    0.082568807                0         0.25\n",
      "123           0.011676397    0.541284404                0         1.00\n",
      "124           0.011676397    0.357798165                1         0.75\n",
      "125           0.011676397    0.174311927                0         0.75\n",
      "126           0.007506255    0.266055046                0         0.25\n",
      "127           0.007506255    0.174311927                0         0.25\n",
      "128           0.015846539    0.449541284                0         0.50\n",
      "129           0.007506255    0.266055046                0         0.50\n",
      "130           0.011676397    0.174311927                0         0.50\n",
      "131           0.011676397    0.357798165                0         0.50\n",
      "132           0.007506255    0.036697248                0         0.25\n",
      "133           0.001251043    0.082568807                0         0.00\n",
      "134           0.020016681    0.174311927                0         0.25\n",
      "135           0.011676397    0.266055046                0         0.50\n",
      "136           0.007506255    0.266055046                0         0.25\n",
      "137           0.007506255    0.633027523                0         0.00\n",
      "138           0.020016681    0.174311927                0         0.00\n",
      "139           0.011676397    0.036697248                0         0.25\n",
      "140           0.003336113    0.174311927                0         0.50\n",
      "141           0.011676397    0.266055046                1         0.50\n",
      "142           0.000000000    0.018348624                1         0.25\n",
      "143           0.070058382    0.357798165                0         1.00\n",
      "144           0.040867389    0.449541284                1         0.75\n",
      "145           0.001251043    0.082568807                0         0.75\n",
      "146           0.007506255    0.266055046                0         0.75\n",
      "147           0.007506255    0.357798165                0         0.75\n",
      "148           0.007506255    0.357798165                0         1.00\n",
      "149           0.011676397    0.449541284                0         1.00\n",
      "150           0.032527106    0.908256881                0         1.00\n",
      "151           0.011676397    0.174311927                0         0.50\n",
      "152           0.003336113    0.357798165                0         0.25\n",
      "153           0.015846539    0.816513761                0         1.00\n",
      "154           0.015846539    0.036697248                0         0.75\n",
      "155           0.199332777    0.908256881                0         1.00\n",
      "156           0.007506255    0.449541284                0         1.00\n",
      "157           0.049207673    0.449541284                0         1.00\n",
      "158           0.040867389    0.174311927                0         0.75\n",
      "159           0.036697248    0.449541284                0         0.75\n",
      "160           0.040867389    0.128440367                0         0.50\n",
      "161           0.099249374    0.128440367                0         0.50\n",
      "162           0.003336113    0.174311927                0         0.50\n",
      "163           0.061718098    0.449541284                0         1.00\n",
      "164           0.007506255    0.174311927                0         0.75\n",
      "165           0.007506255    0.036697248                0         0.25\n",
      "166           0.007506255    0.174311927                0         0.50\n",
      "167           0.003336113    0.357798165                0         0.50\n",
      "168           0.003336113    0.449541284                0         1.00\n",
      "169           0.011676397    0.633027523                0         0.25\n",
      "170           0.099249374    0.174311927                0         1.00\n",
      "171           0.136780651    0.449541284                0         1.00\n",
      "172           0.011676397    0.449541284                0         0.25\n",
      "173           0.124270225    0.266055046                0         0.75\n",
      "174           0.020016681    0.449541284                1         0.50\n",
      "175           0.020016681    0.357798165                0         0.75\n",
      "176           0.015846539    0.633027523                0         0.75\n",
      "177           0.005421184    0.266055046                0         0.25\n",
      "178           0.011676397    0.357798165                0         0.50\n",
      "179           0.040867389    0.174311927                0         0.75\n",
      "180           0.499582986    0.633027523                0         0.25\n",
      "181           0.099249374    0.633027523                0         0.75\n",
      "182           0.028356964    0.357798165                0         0.50\n",
      "183           0.020016681    0.357798165                0         0.50\n",
      "184           0.007506255    0.449541284                1         0.25\n",
      "185           0.020016681    0.174311927                0         1.00\n",
      "186           0.049207673    0.403669725                0         0.75\n",
      "187           0.020016681    0.174311927                0         1.00\n",
      "188           0.199332777    0.174311927                0         0.25\n",
      "189           0.001251043    0.266055046                0         0.50\n",
      "190           0.007506255    0.357798165                0         0.50\n",
      "191           0.699749791    0.541284404                0         1.00\n",
      "192           0.024186822    0.174311927                0         0.25\n",
      "193           0.028356964    0.449541284                0         0.00\n",
      "194           0.015846539    0.174311927                0         0.75\n",
      "195           0.024186822    0.449541284                0         1.00\n",
      "196           0.007506255    0.174311927                0         1.00\n",
      "197           0.011676397    0.128440367                0         0.75\n",
      "198           0.007506255    0.082568807                0         0.25\n",
      "199           0.015846539    0.449541284                0         0.50\n",
      "200           0.011676397    0.541284404                0         0.75\n",
      "201           0.001251043    0.082568807                1         0.00\n",
      "202           0.015846539    0.266055046                1         0.75\n",
      "203           0.011676397    0.266055046                0         0.00\n",
      "204           0.011676397    0.266055046                0         0.00\n",
      "205           0.011676397    0.357798165                0         1.00\n",
      "206           0.011676397    0.357798165                0         0.25\n",
      "207           0.007506255    0.266055046                0         1.00\n",
      "208           0.020016681    0.449541284                0         0.75\n",
      "209           0.015846539    0.541284404                0         0.50\n",
      "210           0.007506255    0.357798165                0         0.50\n",
      "211           0.020016681    0.357798165                0         0.25\n",
      "212           0.015846539    0.541284404                0         0.50\n",
      "    emergency_measures.1 emergency_measures.2 emergency_measures.3\n",
      "0                      0                    0                    0\n",
      "1                      0                    0                    0\n",
      "2                      0                    0                    0\n",
      "3                      0                    0                    0\n",
      "4                      1                    0                    1\n",
      "5                      0                    0                    0\n",
      "6                      1                    1                    1\n",
      "7                      0                    0                    0\n",
      "8                      0                    0                    1\n",
      "9                      0                    1                    1\n",
      "10                     1                    0                    1\n",
      "11                     1                    0                    1\n",
      "12                     0                    0                    0\n",
      "13                     1                    1                    1\n",
      "14                     0                    1                    1\n",
      "15                     0                    0                    1\n",
      "16                     1                    1                    1\n",
      "17                     0                    1                    1\n",
      "18                     1                    1                    1\n",
      "19                     0                    0                    0\n",
      "20                     1                    0                    1\n",
      "21                     0                    0                    0\n",
      "22                     0                    0                    0\n",
      "23                     0                    1                    1\n",
      "24                     1                    0                    1\n",
      "25                     1                    1                    1\n",
      "26                     1                    0                    1\n",
      "27                     1                    0                    1\n",
      "28                     1                    1                    1\n",
      "29                     1                    0                    1\n",
      "30                     1                    1                    0\n",
      "31                     1                    1                    1\n",
      "32                     0                    1                    1\n",
      "33                     1                    0                    1\n",
      "34                     1                    0                    1\n",
      "35                     1                    0                    0\n",
      "36                     0                    0                    0\n",
      "37                     0                    0                    1\n",
      "38                     0                    1                    1\n",
      "39                     0                    0                    1\n",
      "40                     0                    0                    1\n",
      "41                     0                    0                    0\n",
      "42                     1                    1                    1\n",
      "43                     1                    0                    1\n",
      "44                     1                    1                    1\n",
      "45                     1                    1                    1\n",
      "46                     1                    1                    1\n",
      "47                     1                    1                    0\n",
      "48                     0                    0                    0\n",
      "49                     1                    0                    1\n",
      "50                     1                    0                    0\n",
      "51                     1                    0                    0\n",
      "52                     0                    0                    0\n",
      "53                     0                    1                    1\n",
      "54                     0                    0                    0\n",
      "55                     1                    1                    1\n",
      "56                     1                    1                    1\n",
      "57                     0                    0                    0\n",
      "58                     1                    1                    1\n",
      "59                     0                    0                    1\n",
      "60                     0                    0                    1\n",
      "61                     1                    0                    1\n",
      "62                     1                    1                    1\n",
      "63                     1                    1                    1\n",
      "64                     1                    1                    1\n",
      "65                     0                    1                    1\n",
      "66                     0                    1                    1\n",
      "67                     1                    1                    1\n",
      "68                     0                    1                    1\n",
      "69                     0                    1                    1\n",
      "70                     1                    0                    1\n",
      "71                     1                    0                    1\n",
      "72                     0                    0                    0\n",
      "73                     1                    1                    1\n",
      "74                     0                    0                    0\n",
      "75                     1                    0                    0\n",
      "76                     0                    0                    0\n",
      "77                     0                    1                    1\n",
      "78                     0                    0                    0\n",
      "79                     0                    0                    0\n",
      "80                     1                    1                    1\n",
      "81                     0                    0                    1\n",
      "82                     0                    0                    0\n",
      "83                     0                    0                    0\n",
      "84                     1                    0                    1\n",
      "85                     1                    0                    1\n",
      "86                     1                    0                    1\n",
      "87                     0                    0                    1\n",
      "88                     1                    1                    1\n",
      "89                     0                    1                    1\n",
      "90                     0                    0                    1\n",
      "91                     0                    1                    1\n",
      "92                     0                    1                    1\n",
      "93                     1                    1                    1\n",
      "94                     0                    1                    0\n",
      "95                     0                    1                    1\n",
      "96                     1                    1                    1\n",
      "97                     0                    0                    0\n",
      "98                     0                    1                    1\n",
      "99                     0                    0                    0\n",
      "100                    1                    1                    0\n",
      "101                    1                    1                    1\n",
      "102                    1                    1                    1\n",
      "103                    1                    1                    1\n",
      "104                    0                    0                    0\n",
      "105                    0                    0                    1\n",
      "106                    1                    1                    1\n",
      "107                    1                    1                    1\n",
      "108                    0                    0                    1\n",
      "109                    0                    0                    0\n",
      "110                    1                    1                    1\n",
      "111                    1                    1                    1\n",
      "112                    1                    1                    1\n",
      "113                    1                    1                    1\n",
      "114                    1                    0                    1\n",
      "115                    0                    0                    0\n",
      "116                    1                    1                    1\n",
      "117                    1                    1                    1\n",
      "118                    1                    1                    1\n",
      "119                    1                    1                    1\n",
      "120                    0                    0                    1\n",
      "121                    0                    0                    0\n",
      "122                    0                    0                    0\n",
      "123                    0                    0                    0\n",
      "124                    0                    0                    0\n",
      "125                    0                    0                    0\n",
      "126                    0                    0                    1\n",
      "127                    0                    1                    1\n",
      "128                    1                    1                    1\n",
      "129                    1                    1                    1\n",
      "130                    1                    1                    1\n",
      "131                    1                    1                    1\n",
      "132                    0                    0                    0\n",
      "133                    0                    0                    0\n",
      "134                    0                    1                    1\n",
      "135                    1                    1                    1\n",
      "136                    1                    0                    1\n",
      "137                    1                    0                    1\n",
      "138                    0                    0                    1\n",
      "139                    1                    1                    1\n",
      "140                    0                    0                    0\n",
      "141                    1                    1                    1\n",
      "142                    0                    0                    0\n",
      "143                    1                    1                    1\n",
      "144                    0                    1                    1\n",
      "145                    0                    0                    0\n",
      "146                    1                    1                    1\n",
      "147                    0                    1                    1\n",
      "148                    1                    1                    1\n",
      "149                    0                    0                    1\n",
      "150                    0                    1                    1\n",
      "151                    1                    0                    1\n",
      "152                    1                    1                    1\n",
      "153                    1                    0                    1\n",
      "154                    0                    1                    1\n",
      "155                    1                    0                    0\n",
      "156                    1                    0                    1\n",
      "157                    1                    0                    0\n",
      "158                    0                    0                    0\n",
      "159                    0                    0                    1\n",
      "160                    0                    0                    1\n",
      "161                    0                    0                    1\n",
      "162                    0                    0                    0\n",
      "163                    1                    1                    1\n",
      "164                    1                    1                    1\n",
      "165                    1                    1                    1\n",
      "166                    1                    1                    1\n",
      "167                    1                    1                    0\n",
      "168                    0                    0                    0\n",
      "169                    0                    1                    0\n",
      "170                    1                    0                    0\n",
      "171                    1                    1                    0\n",
      "172                    1                    1                    1\n",
      "173                    0                    0                    0\n",
      "174                    0                    0                    0\n",
      "175                    1                    1                    1\n",
      "176                    0                    0                    1\n",
      "177                    1                    0                    1\n",
      "178                    0                    0                    0\n",
      "179                    1                    1                    1\n",
      "180                    0                    1                    1\n",
      "181                    1                    1                    1\n",
      "182                    0                    0                    0\n",
      "183                    0                    1                    1\n",
      "184                    0                    1                    1\n",
      "185                    0                    0                    0\n",
      "186                    0                    0                    0\n",
      "187                    1                    1                    1\n",
      "188                    0                    0                    0\n",
      "189                    1                    0                    1\n",
      "190                    1                    0                    1\n",
      "191                    0                    0                    1\n",
      "192                    0                    1                    1\n",
      "193                    0                    0                    1\n",
      "194                    0                    1                    1\n",
      "195                    0                    1                    1\n",
      "196                    1                    1                    0\n",
      "197                    1                    1                    1\n",
      "198                    0                    0                    1\n",
      "199                    1                    1                    1\n",
      "200                    1                    1                    1\n",
      "201                    0                    0                    0\n",
      "202                    0                    0                    1\n",
      "203                    0                    0                    0\n",
      "204                    1                    0                    1\n",
      "205                    0                    0                    0\n",
      "206                    0                    0                    1\n",
      "207                    0                    1                    1\n",
      "208                    1                    1                    1\n",
      "209                    1                    1                    1\n",
      "210                    0                    1                    1\n",
      "211                    0                    1                    1\n",
      "212                    1                    1                    1\n",
      "    emergency_measures.4 emergency_measures.7 emergency_measures.8\n",
      "0                      0                    0                    0\n",
      "1                      0                    0                    0\n",
      "2                      0                    0                    0\n",
      "3                      0                    0                    0\n",
      "4                      0                    0                    0\n",
      "5                      1                    0                    0\n",
      "6                      1                    0                    0\n",
      "7                      1                    0                    0\n",
      "8                      0                    0                    0\n",
      "9                      1                    0                    0\n",
      "10                     0                    0                    0\n",
      "11                     1                    0                    0\n",
      "12                     0                    0                    0\n",
      "13                     1                    1                    0\n",
      "14                     1                    0                    0\n",
      "15                     1                    0                    0\n",
      "16                     1                    1                    0\n",
      "17                     1                    0                    0\n",
      "18                     0                    0                    0\n",
      "19                     1                    1                    0\n",
      "20                     0                    0                    0\n",
      "21                     0                    0                    0\n",
      "22                     0                    1                    0\n",
      "23                     1                    0                    0\n",
      "24                     1                    0                    0\n",
      "25                     0                    0                    0\n",
      "26                     0                    0                    0\n",
      "27                     1                    1                    0\n",
      "28                     1                    0                    0\n",
      "29                     0                    0                    0\n",
      "30                     0                    0                    0\n",
      "31                     0                    1                    0\n",
      "32                     1                    0                    0\n",
      "33                     0                    0                    0\n",
      "34                     0                    0                    1\n",
      "35                     0                    0                    0\n",
      "36                     1                    1                    0\n",
      "37                     1                    0                    0\n",
      "38                     0                    0                    0\n",
      "39                     1                    0                    0\n",
      "40                     1                    0                    0\n",
      "41                     1                    1                    0\n",
      "42                     1                    1                    0\n",
      "43                     0                    1                    0\n",
      "44                     1                    0                    0\n",
      "45                     1                    0                    0\n",
      "46                     1                    1                    0\n",
      "47                     0                    1                    0\n",
      "48                     0                    0                    0\n",
      "49                     1                    0                    0\n",
      "50                     0                    1                    0\n",
      "51                     0                    1                    0\n",
      "52                     0                    0                    0\n",
      "53                     1                    1                    1\n",
      "54                     0                    0                    0\n",
      "55                     1                    1                    0\n",
      "56                     1                    1                    1\n",
      "57                     0                    0                    0\n",
      "58                     1                    0                    0\n",
      "59                     1                    1                    0\n",
      "60                     0                    0                    0\n",
      "61                     0                    0                    0\n",
      "62                     1                    0                    0\n",
      "63                     1                    0                    0\n",
      "64                     1                    0                    0\n",
      "65                     1                    0                    0\n",
      "66                     1                    0                    0\n",
      "67                     1                    0                    0\n",
      "68                     0                    0                    0\n",
      "69                     1                    0                    0\n",
      "70                     1                    0                    0\n",
      "71                     0                    1                    0\n",
      "72                     0                    0                    0\n",
      "73                     1                    1                    0\n",
      "74                     0                    0                    0\n",
      "75                     1                    0                    0\n",
      "76                     0                    0                    0\n",
      "77                     1                    1                    0\n",
      "78                     0                    0                    0\n",
      "79                     0                    1                    0\n",
      "80                     1                    1                    1\n",
      "81                     1                    0                    0\n",
      "82                     0                    0                    0\n",
      "83                     0                    0                    1\n",
      "84                     1                    1                    0\n",
      "85                     1                    1                    0\n",
      "86                     0                    1                    0\n",
      "87                     1                    1                    0\n",
      "88                     1                    0                    0\n",
      "89                     1                    0                    0\n",
      "90                     1                    1                    0\n",
      "91                     1                    0                    0\n",
      "92                     1                    0                    0\n",
      "93                     1                    1                    0\n",
      "94                     0                    0                    0\n",
      "95                     1                    0                    0\n",
      "96                     1                    0                    0\n",
      "97                     0                    0                    0\n",
      "98                     1                    1                    0\n",
      "99                     0                    1                    0\n",
      "100                    0                    1                    0\n",
      "101                    1                    1                    0\n",
      "102                    1                    1                    0\n",
      "103                    1                    1                    0\n",
      "104                    0                    0                    0\n",
      "105                    1                    0                    0\n",
      "106                    1                    0                    0\n",
      "107                    1                    1                    0\n",
      "108                    1                    1                    0\n",
      "109                    1                    1                    0\n",
      "110                    1                    1                    0\n",
      "111                    1                    1                    0\n",
      "112                    1                    1                    0\n",
      "113                    1                    1                    0\n",
      "114                    1                    1                    0\n",
      "115                    0                    0                    0\n",
      "116                    1                    0                    0\n",
      "117                    1                    1                    0\n",
      "118                    1                    0                    0\n",
      "119                    1                    0                    0\n",
      "120                    1                    1                    0\n",
      "121                    0                    0                    0\n",
      "122                    0                    1                    0\n",
      "123                    0                    1                    0\n",
      "124                    0                    0                    0\n",
      "125                    0                    1                    0\n",
      "126                    1                    1                    0\n",
      "127                    0                    0                    0\n",
      "128                    1                    1                    0\n",
      "129                    1                    1                    0\n",
      "130                    1                    1                    1\n",
      "131                    1                    1                    0\n",
      "132                    0                    1                    0\n",
      "133                    0                    1                    0\n",
      "134                    1                    1                    0\n",
      "135                    1                    1                    0\n",
      "136                    1                    1                    0\n",
      "137                    0                    1                    0\n",
      "138                    0                    0                    0\n",
      "139                    1                    1                    0\n",
      "140                    0                    0                    0\n",
      "141                    0                    0                    0\n",
      "142                    0                    0                    0\n",
      "143                    1                    0                    0\n",
      "144                    1                    0                    0\n",
      "145                    0                    0                    0\n",
      "146                    1                    1                    0\n",
      "147                    1                    0                    0\n",
      "148                    1                    0                    0\n",
      "149                    0                    0                    0\n",
      "150                    1                    0                    0\n",
      "151                    1                    0                    0\n",
      "152                    0                    0                    0\n",
      "153                    0                    0                    0\n",
      "154                    1                    0                    0\n",
      "155                    0                    0                    0\n",
      "156                    0                    0                    1\n",
      "157                    0                    0                    0\n",
      "158                    1                    1                    0\n",
      "159                    1                    0                    0\n",
      "160                    1                    1                    0\n",
      "161                    1                    0                    0\n",
      "162                    1                    1                    0\n",
      "163                    1                    0                    0\n",
      "164                    1                    0                    0\n",
      "165                    1                    0                    0\n",
      "166                    1                    1                    0\n",
      "167                    0                    1                    0\n",
      "168                    0                    0                    0\n",
      "169                    0                    1                    0\n",
      "170                    1                    1                    0\n",
      "171                    0                    1                    0\n",
      "172                    1                    1                    1\n",
      "173                    1                    1                    0\n",
      "174                    0                    0                    0\n",
      "175                    1                    0                    0\n",
      "176                    1                    0                    0\n",
      "177                    0                    0                    0\n",
      "178                    0                    0                    0\n",
      "179                    1                    0                    0\n",
      "180                    1                    0                    0\n",
      "181                    1                    0                    0\n",
      "182                    0                    0                    0\n",
      "183                    0                    0                    0\n",
      "184                    1                    0                    0\n",
      "185                    1                    0                    0\n",
      "186                    0                    0                    0\n",
      "187                    1                    1                    1\n",
      "188                    0                    0                    0\n",
      "189                    1                    1                    1\n",
      "190                    1                    1                    0\n",
      "191                    1                    1                    0\n",
      "192                    1                    0                    0\n",
      "193                    1                    1                    0\n",
      "194                    1                    0                    0\n",
      "195                    1                    0                    0\n",
      "196                    0                    0                    0\n",
      "197                    1                    1                    0\n",
      "198                    1                    1                    0\n",
      "199                    1                    1                    0\n",
      "200                    1                    1                    0\n",
      "201                    0                    0                    0\n",
      "202                    1                    0                    0\n",
      "203                    1                    1                    0\n",
      "204                    1                    1                    0\n",
      "205                    0                    1                    0\n",
      "206                    1                    1                    0\n",
      "207                    0                    0                    0\n",
      "208                    1                    1                    1\n",
      "209                    1                    1                    0\n",
      "210                    1                    1                    0\n",
      "211                    1                    1                    0\n",
      "212                    1                    1                    0\n",
      "    overall_problem_house protect_valuables_impl water_barriers_impl\n",
      "0                       1                   1.00                1.00\n",
      "1                       1                   0.00                1.00\n",
      "2                       1                   1.00                1.00\n",
      "3                       0                   0.00                1.00\n",
      "4                       1                   0.00                1.00\n",
      "5                       1                   1.00                1.00\n",
      "6                       1                   1.00                0.75\n",
      "7                       0                   1.00                0.00\n",
      "8                       1                   1.00                1.00\n",
      "9                       0                   1.00                1.00\n",
      "10                      1                   1.00                1.00\n",
      "11                      1                   1.00                1.00\n",
      "12                      0                   0.00                0.00\n",
      "13                      1                   0.00                0.00\n",
      "14                      0                   0.00                0.00\n",
      "15                      1                   0.00                1.00\n",
      "16                      1                   0.00                1.00\n",
      "17                      1                   0.00                0.00\n",
      "18                      1                   0.75                1.00\n",
      "19                      1                   0.00                1.00\n",
      "20                      1                   0.75                1.00\n",
      "21                      1                   0.00                0.00\n",
      "22                      1                   1.00                0.00\n",
      "23                      1                   1.00                1.00\n",
      "24                      0                   1.00                0.00\n",
      "25                      0                   1.00                1.00\n",
      "26                      1                   1.00                1.00\n",
      "27                      1                   1.00                1.00\n",
      "28                      1                   1.00                1.00\n",
      "29                      1                   1.00                1.00\n",
      "30                      1                   1.00                1.00\n",
      "31                      1                   1.00                1.00\n",
      "32                      1                   1.00                0.00\n",
      "33                      1                   1.00                1.00\n",
      "34                      1                   1.00                1.00\n",
      "35                      1                   1.00                1.00\n",
      "36                      1                   0.00                0.00\n",
      "37                      1                   0.00                0.00\n",
      "38                      1                   0.00                0.75\n",
      "39                      1                   0.00                1.00\n",
      "40                      1                   0.00                1.00\n",
      "41                      1                   0.00                0.00\n",
      "42                      1                   0.00                0.00\n",
      "43                      1                   0.00                0.00\n",
      "44                      1                   0.00                1.00\n",
      "45                      1                   1.00                1.00\n",
      "46                      1                   1.00                0.00\n",
      "47                      1                   1.00                0.00\n",
      "48                      1                   0.75                1.00\n",
      "49                      1                   0.75                1.00\n",
      "50                      1                   0.00                1.00\n",
      "51                      1                   0.00                1.00\n",
      "52                      1                   1.00                1.00\n",
      "53                      1                   0.00                0.00\n",
      "54                      0                   0.00                0.00\n",
      "55                      1                   0.00                0.00\n",
      "56                      1                   1.00                1.00\n",
      "57                      1                   1.00                1.00\n",
      "58                      1                   0.00                0.00\n",
      "59                      1                   0.00                0.00\n",
      "60                      1                   0.00                1.00\n",
      "61                      1                   0.00                1.00\n",
      "62                      0                   0.00                1.00\n",
      "63                      1                   0.00                0.00\n",
      "64                      1                   0.00                0.00\n",
      "65                      1                   0.00                1.00\n",
      "66                      1                   1.00                0.00\n",
      "67                      1                   0.00                0.00\n",
      "68                      1                   1.00                1.00\n",
      "69                      1                   0.00                0.00\n",
      "70                      1                   0.00                1.00\n",
      "71                      1                   0.00                0.75\n",
      "72                      1                   1.00                1.00\n",
      "73                      1                   1.00                0.00\n",
      "74                      1                   1.00                0.00\n",
      "75                      1                   0.00                1.00\n",
      "76                      1                   1.00                0.75\n",
      "77                      1                   1.00                1.00\n",
      "78                      1                   1.00                1.00\n",
      "79                      1                   1.00                0.75\n",
      "80                      0                   0.00                0.00\n",
      "81                      1                   1.00                1.00\n",
      "82                      1                   0.00                1.00\n",
      "83                      1                   1.00                0.00\n",
      "84                      1                   1.00                0.00\n",
      "85                      1                   1.00                0.00\n",
      "86                      1                   1.00                0.75\n",
      "87                      1                   1.00                1.00\n",
      "88                      0                   1.00                1.00\n",
      "89                      1                   0.00                1.00\n",
      "90                      1                   0.00                0.75\n",
      "91                      1                   0.00                0.00\n",
      "92                      1                   0.00                1.00\n",
      "93                      1                   0.00                1.00\n",
      "94                      1                   0.00                0.00\n",
      "95                      1                   0.00                0.00\n",
      "96                      1                   1.00                0.00\n",
      "97                      1                   1.00                1.00\n",
      "98                      1                   0.75                0.75\n",
      "99                      1                   0.00                0.75\n",
      "100                     1                   0.00                0.00\n",
      "101                     1                   0.75                0.75\n",
      "102                     1                   0.75                0.75\n",
      "103                     1                   0.75                0.75\n",
      "104                     0                   0.00                0.00\n",
      "105                     1                   0.00                1.00\n",
      "106                     1                   1.00                1.00\n",
      "107                     1                   1.00                0.00\n",
      "108                     1                   1.00                1.00\n",
      "109                     1                   0.75                1.00\n",
      "110                     1                   0.00                0.00\n",
      "111                     1                   0.00                0.00\n",
      "112                     1                   1.00                0.00\n",
      "113                     1                   1.00                0.00\n",
      "114                     1                   1.00                0.00\n",
      "115                     1                   1.00                0.00\n",
      "116                     1                   1.00                1.00\n",
      "117                     1                   1.00                0.00\n",
      "118                     1                   1.00                1.00\n",
      "119                     1                   1.00                1.00\n",
      "120                     1                   1.00                0.00\n",
      "121                     1                   1.00                0.00\n",
      "122                     1                   0.00                0.00\n",
      "123                     1                   1.00                1.00\n",
      "124                     0                   1.00                0.75\n",
      "125                     1                   0.00                0.00\n",
      "126                     1                   0.00                0.00\n",
      "127                     1                   0.00                0.00\n",
      "128                     1                   0.00                0.00\n",
      "129                     1                   0.00                0.00\n",
      "130                     1                   0.00                0.00\n",
      "131                     1                   0.00                0.00\n",
      "132                     1                   0.00                0.00\n",
      "133                     0                   0.00                0.00\n",
      "134                     1                   0.00                0.00\n",
      "135                     1                   0.00                0.00\n",
      "136                     1                   0.00                0.00\n",
      "137                     1                   1.00                0.00\n",
      "138                     1                   0.00                1.00\n",
      "139                     1                   1.00                0.00\n",
      "140                     1                   1.00                1.00\n",
      "141                     1                   0.00                1.00\n",
      "142                     0                   0.00                1.00\n",
      "143                     1                   1.00                0.75\n",
      "144                     1                   1.00                0.00\n",
      "145                     0                   0.25                0.25\n",
      "146                     1                   0.25                0.25\n",
      "147                     1                   0.00                0.00\n",
      "148                     1                   0.00                0.00\n",
      "149                     1                   0.00                0.00\n",
      "150                     1                   1.00                1.00\n",
      "151                     1                   1.00                0.00\n",
      "152                     0                   1.00                1.00\n",
      "153                     1                   1.00                1.00\n",
      "154                     1                   1.00                0.00\n",
      "155                     1                   1.00                1.00\n",
      "156                     1                   1.00                1.00\n",
      "157                     1                   1.00                1.00\n",
      "158                     1                   0.00                0.00\n",
      "159                     1                   0.00                0.75\n",
      "160                     1                   0.00                1.00\n",
      "161                     1                   0.00                1.00\n",
      "162                     1                   0.00                0.00\n",
      "163                     1                   0.00                0.00\n",
      "164                     1                   0.00                1.00\n",
      "165                     1                   1.00                1.00\n",
      "166                     1                   1.00                0.00\n",
      "167                     1                   1.00                0.00\n",
      "168                     1                   0.75                1.00\n",
      "169                     1                   0.75                1.00\n",
      "170                     1                   0.00                1.00\n",
      "171                     1                   0.00                1.00\n",
      "172                     1                   0.00                0.00\n",
      "173                     0                   0.25                0.25\n",
      "174                     1                   1.00                1.00\n",
      "175                     1                   0.25                0.25\n",
      "176                     1                   0.00                1.00\n",
      "177                     1                   0.25                1.00\n",
      "178                     1                   0.25                1.00\n",
      "179                     1                   0.00                1.00\n",
      "180                     1                   1.00                0.25\n",
      "181                     1                   0.25                0.25\n",
      "182                     1                   1.00                1.00\n",
      "183                     1                   1.00                1.00\n",
      "184                     1                   0.00                0.00\n",
      "185                     1                   0.00                1.00\n",
      "186                     1                   1.00                0.75\n",
      "187                     1                   0.00                0.00\n",
      "188                     1                   0.25                1.00\n",
      "189                     1                   1.00                0.00\n",
      "190                     1                   1.00                0.00\n",
      "191                     1                   1.00                1.00\n",
      "192                     1                   0.00                1.00\n",
      "193                     1                   0.00                0.75\n",
      "194                     1                   0.00                0.00\n",
      "195                     1                   0.00                1.00\n",
      "196                     1                   0.00                0.00\n",
      "197                     1                   0.75                0.75\n",
      "198                     1                   0.00                0.75\n",
      "199                     0                   0.75                0.75\n",
      "200                     1                   0.75                0.75\n",
      "201                     1                   0.00                0.00\n",
      "202                     1                   0.00                1.00\n",
      "203                     1                   0.75                1.00\n",
      "204                     1                   1.00                0.00\n",
      "205                     1                   0.25                0.25\n",
      "206                     1                   0.00                0.00\n",
      "207                     1                   0.00                0.00\n",
      "208                     1                   0.00                0.00\n",
      "209                     1                   0.00                0.00\n",
      "210                     1                   0.00                0.00\n",
      "211                     1                   0.00                0.00\n",
      "212                     1                   0.25                0.00\n",
      "    pumping_equipment_impl elevation_building_impl\n",
      "0                     1.00                    0.75\n",
      "1                     0.00                    0.00\n",
      "2                     1.00                    0.00\n",
      "3                     1.00                    0.00\n",
      "4                     1.00                    0.75\n",
      "5                     0.75                    0.75\n",
      "6                     1.00                    0.00\n",
      "7                     1.00                    0.00\n",
      "8                     1.00                    0.00\n",
      "9                     1.00                    1.00\n",
      "10                    1.00                    0.00\n",
      "11                    1.00                    0.00\n",
      "12                    1.00                    0.00\n",
      "13                    1.00                    0.75\n",
      "14                    0.00                    0.00\n",
      "15                    1.00                    0.00\n",
      "16                    1.00                    0.75\n",
      "17                    1.00                    0.00\n",
      "18                    1.00                    0.75\n",
      "19                    1.00                    0.75\n",
      "20                    1.00                    0.75\n",
      "21                    0.00                    1.00\n",
      "22                    1.00                    0.00\n",
      "23                    1.00                    0.00\n",
      "24                    0.00                    0.00\n",
      "25                    1.00                    0.75\n",
      "26                    1.00                    0.00\n",
      "27                    1.00                    0.75\n",
      "28                    0.00                    0.75\n",
      "29                    1.00                    1.00\n",
      "30                    1.00                    0.00\n",
      "31                    0.00                    0.00\n",
      "32                    0.00                    0.00\n",
      "33                    0.00                    0.00\n",
      "34                    0.00                    0.00\n",
      "35                    1.00                    0.00\n",
      "36                    0.00                    0.00\n",
      "37                    0.00                    0.75\n",
      "38                    1.00                    0.00\n",
      "39                    1.00                    1.00\n",
      "40                    1.00                    1.00\n",
      "41                    0.00                    0.00\n",
      "42                    1.00                    0.00\n",
      "43                    1.00                    0.75\n",
      "44                    0.00                    0.00\n",
      "45                    1.00                    1.00\n",
      "46                    0.00                    0.00\n",
      "47                    0.00                    0.75\n",
      "48                    1.00                    0.00\n",
      "49                    0.00                    0.75\n",
      "50                    0.00                    0.00\n",
      "51                    0.00                    0.00\n",
      "52                    0.75                    0.75\n",
      "53                    0.00                    0.00\n",
      "54                    1.00                    0.00\n",
      "55                    0.00                    1.00\n",
      "56                    1.00                    0.75\n",
      "57                    1.00                    0.75\n",
      "58                    0.00                    0.00\n",
      "59                    1.00                    0.00\n",
      "60                    0.00                    0.75\n",
      "61                    1.00                    0.00\n",
      "62                    0.00                    0.00\n",
      "63                    0.00                    0.75\n",
      "64                    1.00                    0.75\n",
      "65                    0.00                    0.75\n",
      "66                    1.00                    1.00\n",
      "67                    0.00                    1.00\n",
      "68                    1.00                    0.75\n",
      "69                    0.00                    1.00\n",
      "70                    1.00                    0.00\n",
      "71                    0.00                    0.75\n",
      "72                    1.00                    0.75\n",
      "73                    1.00                    0.00\n",
      "74                    1.00                    1.00\n",
      "75                    0.00                    0.00\n",
      "76                    1.00                    1.00\n",
      "77                    1.00                    1.00\n",
      "78                    0.00                    0.75\n",
      "79                    1.00                    0.00\n",
      "80                    1.00                    0.00\n",
      "81                    0.00                    0.00\n",
      "82                    0.00                    1.00\n",
      "83                    1.00                    0.75\n",
      "84                    1.00                    0.00\n",
      "85                    0.00                    0.75\n",
      "86                    0.75                    0.00\n",
      "87                    1.00                    0.75\n",
      "88                    1.00                    1.00\n",
      "89                    1.00                    1.00\n",
      "90                    1.00                    0.75\n",
      "91                    1.00                    0.00\n",
      "92                    1.00                    0.00\n",
      "93                    0.75                    0.75\n",
      "94                    1.00                    0.75\n",
      "95                    0.00                    0.75\n",
      "96                    1.00                    1.00\n",
      "97                    1.00                    1.00\n",
      "98                    0.75                    1.00\n",
      "99                    0.75                    1.00\n",
      "100                   0.00                    0.75\n",
      "101                   1.00                    0.75\n",
      "102                   0.75                    0.75\n",
      "103                   1.00                    0.00\n",
      "104                   1.00                    0.00\n",
      "105                   1.00                    0.00\n",
      "106                   1.00                    0.00\n",
      "107                   0.00                    0.75\n",
      "108                   0.75                    0.75\n",
      "109                   0.00                    0.75\n",
      "110                   1.00                    0.00\n",
      "111                   1.00                    0.75\n",
      "112                   0.00                    0.75\n",
      "113                   0.00                    0.00\n",
      "114                   1.00                    0.00\n",
      "115                   1.00                    0.00\n",
      "116                   1.00                    1.00\n",
      "117                   1.00                    0.75\n",
      "118                   0.00                    0.75\n",
      "119                   1.00                    0.00\n",
      "120                   1.00                    0.75\n",
      "121                   1.00                    0.75\n",
      "122                   0.00                    0.75\n",
      "123                   0.75                    0.00\n",
      "124                   1.00                    1.00\n",
      "125                   0.00                    0.00\n",
      "126                   0.00                    0.00\n",
      "127                   0.00                    0.00\n",
      "128                   0.00                    0.75\n",
      "129                   1.00                    0.75\n",
      "130                   0.00                    0.00\n",
      "131                   0.00                    0.00\n",
      "132                   1.00                    0.00\n",
      "133                   1.00                    0.00\n",
      "134                   1.00                    0.75\n",
      "135                   0.00                    0.00\n",
      "136                   1.00                    0.00\n",
      "137                   1.00                    0.75\n",
      "138                   1.00                    1.00\n",
      "139                   1.00                    0.75\n",
      "140                   0.00                    0.75\n",
      "141                   0.00                    0.25\n",
      "142                   1.00                    0.00\n",
      "143                   1.00                    0.00\n",
      "144                   1.00                    0.00\n",
      "145                   1.00                    0.00\n",
      "146                   1.00                    0.75\n",
      "147                   0.00                    0.25\n",
      "148                   1.00                    0.25\n",
      "149                   0.00                    1.00\n",
      "150                   1.00                    0.00\n",
      "151                   0.00                    0.25\n",
      "152                   1.00                    0.75\n",
      "153                   1.00                    0.25\n",
      "154                   0.00                    0.25\n",
      "155                   0.25                    0.00\n",
      "156                   0.00                    0.00\n",
      "157                   1.00                    0.00\n",
      "158                   0.00                    0.00\n",
      "159                   1.00                    0.25\n",
      "160                   1.00                    1.00\n",
      "161                   1.00                    1.00\n",
      "162                   0.00                    0.00\n",
      "163                   1.00                    0.00\n",
      "164                   0.00                    0.00\n",
      "165                   1.00                    1.00\n",
      "166                   0.00                    0.25\n",
      "167                   0.00                    0.75\n",
      "168                   1.00                    0.25\n",
      "169                   0.25                    0.75\n",
      "170                   0.00                    0.25\n",
      "171                   0.00                    0.25\n",
      "172                   0.25                    0.25\n",
      "173                   1.00                    0.00\n",
      "174                   1.00                    0.75\n",
      "175                   0.25                    0.00\n",
      "176                   0.00                    0.25\n",
      "177                   1.00                    0.00\n",
      "178                   0.25                    0.25\n",
      "179                   0.00                    0.75\n",
      "180                   1.00                    1.00\n",
      "181                   0.25                    1.00\n",
      "182                   0.00                    0.00\n",
      "183                   1.00                    0.75\n",
      "184                   0.00                    1.00\n",
      "185                   0.00                    0.00\n",
      "186                   1.00                    1.00\n",
      "187                   1.00                    0.00\n",
      "188                   0.00                    1.00\n",
      "189                   1.00                    0.75\n",
      "190                   0.00                    0.75\n",
      "191                   1.00                    1.00\n",
      "192                   1.00                    1.00\n",
      "193                   1.00                    0.75\n",
      "194                   1.00                    0.00\n",
      "195                   1.00                    0.00\n",
      "196                   1.00                    0.75\n",
      "197                   0.75                    1.00\n",
      "198                   0.75                    1.00\n",
      "199                   0.75                    0.75\n",
      "200                   1.00                    0.25\n",
      "201                   1.00                    0.00\n",
      "202                   1.00                    0.00\n",
      "203                   0.00                    0.75\n",
      "204                   1.00                    0.25\n",
      "205                   0.00                    0.00\n",
      "206                   0.00                    0.00\n",
      "207                   0.00                    0.25\n",
      "208                   0.00                    0.00\n",
      "209                   0.00                    0.25\n",
      "210                   1.00                    0.25\n",
      "211                   1.00                    0.75\n",
      "212                   0.00                    0.25\n",
      "    resistant_material_building_impl electricity_higher_impl\n",
      "0                               1.00                    1.00\n",
      "1                               1.00                    0.00\n",
      "2                               1.00                    0.00\n",
      "3                               1.00                    0.00\n",
      "4                               1.00                    0.00\n",
      "5                               1.00                    1.00\n",
      "6                               1.00                    1.00\n",
      "7                               1.00                    1.00\n",
      "8                               1.00                    1.00\n",
      "9                               1.00                    1.00\n",
      "10                              1.00                    1.00\n",
      "11                              1.00                    1.00\n",
      "12                              1.00                    0.00\n",
      "13                              1.00                    0.75\n",
      "14                              1.00                    0.00\n",
      "15                              1.00                    0.00\n",
      "16                              1.00                    0.75\n",
      "17                              1.00                    1.00\n",
      "18                              0.75                    0.75\n",
      "19                              1.00                    1.00\n",
      "20                              0.75                    0.75\n",
      "21                              1.00                    1.00\n",
      "22                              1.00                    1.00\n",
      "23                              1.00                    0.00\n",
      "24                              1.00                    1.00\n",
      "25                              0.75                    0.75\n",
      "26                              1.00                    1.00\n",
      "27                              1.00                    1.00\n",
      "28                              1.00                    1.00\n",
      "29                              1.00                    1.00\n",
      "30                              1.00                    1.00\n",
      "31                              1.00                    1.00\n",
      "32                              1.00                    0.00\n",
      "33                              1.00                    1.00\n",
      "34                              1.00                    1.00\n",
      "35                              1.00                    1.00\n",
      "36                              1.00                    1.00\n",
      "37                              1.00                    1.00\n",
      "38                              1.00                    1.00\n",
      "39                              1.00                    1.00\n",
      "40                              1.00                    1.00\n",
      "41                              1.00                    0.00\n",
      "42                              1.00                    0.00\n",
      "43                              1.00                    1.00\n",
      "44                              0.00                    1.00\n",
      "45                              1.00                    1.00\n",
      "46                              0.00                    1.00\n",
      "47                              1.00                    1.00\n",
      "48                              1.00                    0.00\n",
      "49                              1.00                    0.75\n",
      "50                              0.00                    0.00\n",
      "51                              1.00                    1.00\n",
      "52                              1.00                    1.00\n",
      "53                              1.00                    0.00\n",
      "54                              1.00                    1.00\n",
      "55                              1.00                    1.00\n",
      "56                              1.00                    1.00\n",
      "57                              1.00                    1.00\n",
      "58                              1.00                    0.00\n",
      "59                              1.00                    1.00\n",
      "60                              1.00                    1.00\n",
      "61                              1.00                    1.00\n",
      "62                              1.00                    0.00\n",
      "63                              1.00                    0.00\n",
      "64                              1.00                    0.00\n",
      "65                              0.75                    0.75\n",
      "66                              1.00                    0.00\n",
      "67                              1.00                    0.00\n",
      "68                              1.00                    1.00\n",
      "69                              1.00                    0.00\n",
      "70                              1.00                    0.00\n",
      "71                              1.00                    1.00\n",
      "72                              1.00                    1.00\n",
      "73                              1.00                    1.00\n",
      "74                              1.00                    1.00\n",
      "75                              0.75                    1.00\n",
      "76                              1.00                    1.00\n",
      "77                              1.00                    0.00\n",
      "78                              1.00                    0.00\n",
      "79                              1.00                    0.00\n",
      "80                              0.00                    1.00\n",
      "81                              1.00                    1.00\n",
      "82                              1.00                    1.00\n",
      "83                              1.00                    0.75\n",
      "84                              1.00                    1.00\n",
      "85                              1.00                    1.00\n",
      "86                              1.00                    1.00\n",
      "87                              1.00                    0.00\n",
      "88                              1.00                    1.00\n",
      "89                              1.00                    1.00\n",
      "90                              1.00                    1.00\n",
      "91                              1.00                    1.00\n",
      "92                              1.00                    1.00\n",
      "93                              1.00                    1.00\n",
      "94                              1.00                    0.00\n",
      "95                              1.00                    1.00\n",
      "96                              1.00                    1.00\n",
      "97                              1.00                    1.00\n",
      "98                              1.00                    0.00\n",
      "99                              0.75                    0.75\n",
      "100                             1.00                    0.00\n",
      "101                             1.00                    0.75\n",
      "102                             1.00                    0.75\n",
      "103                             1.00                    0.00\n",
      "104                             1.00                    0.00\n",
      "105                             1.00                    1.00\n",
      "106                             1.00                    1.00\n",
      "107                             1.00                    1.00\n",
      "108                             1.00                    1.00\n",
      "109                             0.75                    0.75\n",
      "110                             1.00                    0.00\n",
      "111                             1.00                    0.00\n",
      "112                             1.00                    1.00\n",
      "113                             1.00                    0.00\n",
      "114                             1.00                    1.00\n",
      "115                             1.00                    1.00\n",
      "116                             1.00                    1.00\n",
      "117                             1.00                    1.00\n",
      "118                             1.00                    1.00\n",
      "119                             1.00                    1.00\n",
      "120                             1.00                    1.00\n",
      "121                             1.00                    1.00\n",
      "122                             1.00                    1.00\n",
      "123                             1.00                    1.00\n",
      "124                             1.00                    1.00\n",
      "125                             1.00                    1.00\n",
      "126                             1.00                    0.00\n",
      "127                             1.00                    1.00\n",
      "128                             1.00                    0.00\n",
      "129                             1.00                    1.00\n",
      "130                             1.00                    0.00\n",
      "131                             1.00                    0.00\n",
      "132                             1.00                    0.00\n",
      "133                             1.00                    1.00\n",
      "134                             1.00                    1.00\n",
      "135                             1.00                    0.00\n",
      "136                             1.00                    0.00\n",
      "137                             1.00                    1.00\n",
      "138                             1.00                    1.00\n",
      "139                             1.00                    1.00\n",
      "140                             1.00                    0.75\n",
      "141                             1.00                    0.00\n",
      "142                             1.00                    0.00\n",
      "143                             1.00                    1.00\n",
      "144                             1.00                    1.00\n",
      "145                             1.00                    0.00\n",
      "146                             1.00                    0.75\n",
      "147                             1.00                    0.00\n",
      "148                             1.00                    1.00\n",
      "149                             1.00                    1.00\n",
      "150                             1.00                    0.00\n",
      "151                             1.00                    1.00\n",
      "152                             0.75                    0.75\n",
      "153                             1.00                    1.00\n",
      "154                             1.00                    0.00\n",
      "155                             1.00                    1.00\n",
      "156                             1.00                    1.00\n",
      "157                             1.00                    1.00\n",
      "158                             1.00                    1.00\n",
      "159                             1.00                    1.00\n",
      "160                             1.00                    1.00\n",
      "161                             1.00                    1.00\n",
      "162                             1.00                    0.00\n",
      "163                             1.00                    0.00\n",
      "164                             0.00                    1.00\n",
      "165                             1.00                    1.00\n",
      "166                             0.00                    1.00\n",
      "167                             1.00                    1.00\n",
      "168                             1.00                    0.25\n",
      "169                             1.00                    0.75\n",
      "170                             0.25                    0.25\n",
      "171                             1.00                    1.00\n",
      "172                             1.00                    0.25\n",
      "173                             1.00                    1.00\n",
      "174                             1.00                    1.00\n",
      "175                             1.00                    0.25\n",
      "176                             1.00                    1.00\n",
      "177                             1.00                    1.00\n",
      "178                             1.00                    0.00\n",
      "179                             0.75                    0.75\n",
      "180                             1.00                    0.00\n",
      "181                             1.00                    0.00\n",
      "182                             1.00                    0.00\n",
      "183                             1.00                    1.00\n",
      "184                             1.00                    0.00\n",
      "185                             0.75                    1.00\n",
      "186                             1.00                    1.00\n",
      "187                             0.25                    1.00\n",
      "188                             1.00                    1.00\n",
      "189                             1.00                    0.75\n",
      "190                             1.00                    1.00\n",
      "191                             1.00                    1.00\n",
      "192                             1.00                    1.00\n",
      "193                             1.00                    1.00\n",
      "194                             1.00                    1.00\n",
      "195                             1.00                    1.00\n",
      "196                             1.00                    0.00\n",
      "197                             1.00                    0.00\n",
      "198                             0.75                    0.75\n",
      "199                             1.00                    0.75\n",
      "200                             1.00                    0.25\n",
      "201                             1.00                    0.00\n",
      "202                             1.00                    1.00\n",
      "203                             0.75                    0.75\n",
      "204                             1.00                    1.00\n",
      "205                             1.00                    1.00\n",
      "206                             1.00                    0.00\n",
      "207                             1.00                    1.00\n",
      "208                             1.00                    0.00\n",
      "209                             1.00                    0.00\n",
      "210                             1.00                    0.00\n",
      "211                             1.00                    1.00\n",
      "212                             1.00                    0.00\n",
      "    flood_protections_impl flood_experience       bage      b_area\n",
      "0                     1.00              0.8 0.18181818 0.013157895\n",
      "1                     1.00              0.8 0.31818182 0.038461538\n",
      "2                     1.00              0.4 0.30303030 0.068825911\n",
      "3                     1.00              0.0 0.30303030 0.043522267\n",
      "4                     1.00              0.8 0.30303030 0.033400810\n",
      "5                     1.00              0.6 0.37878788 0.506072874\n",
      "6                     1.00              0.6 0.77272727 0.062753036\n",
      "7                     1.00              0.6 0.33333333 0.033400810\n",
      "8                     1.00              0.0 0.68181818 0.023279352\n",
      "9                     1.00              0.2 0.04545455 0.068825911\n",
      "10                    1.00              0.4 0.34848485 0.099190283\n",
      "11                    1.00              0.2 0.50000000 0.078947368\n",
      "12                    1.00              0.8 0.25757576 0.030364372\n",
      "13                    1.00              0.6 0.00000000 0.033400810\n",
      "14                    1.00              1.0 0.24242424 0.068825911\n",
      "15                    1.00              0.8 0.68181818 0.043522267\n",
      "16                    1.00              0.8 0.68181818 0.033400810\n",
      "17                    1.00              1.0 0.45454545 0.028340081\n",
      "18                    1.00              0.8 0.25757576 0.068825911\n",
      "19                    1.00              0.6 0.25757576 0.038461538\n",
      "20                    1.00              0.8 0.21212121 0.008097166\n",
      "21                    1.00              1.0 0.28787879 0.078947368\n",
      "22                    1.00              1.0 0.30303030 0.012145749\n",
      "23                    1.00              0.8 0.39393939 0.053643725\n",
      "24                    1.00              0.6 0.30303030 0.038461538\n",
      "25                    1.00              0.4 0.43939394 0.086032389\n",
      "26                    1.00              1.0 0.34848485 0.149797571\n",
      "27                    1.00              0.2 0.01515152 0.103238866\n",
      "28                    1.00              0.2 0.09090909 0.129554656\n",
      "29                    1.00              0.6 0.27272727 0.068825911\n",
      "30                    1.00              0.6 0.34848485 0.114372470\n",
      "31                    1.00              0.0 0.66666667 0.085020243\n",
      "32                    1.00              0.8 0.45454545 0.078947368\n",
      "33                    1.00              0.8 0.36363636 0.121862348\n",
      "34                    1.00              0.8 0.45454545 0.044534413\n",
      "35                    1.00              0.8 0.31818182 0.023279352\n",
      "36                    1.00              0.4 0.31818182 0.060728745\n",
      "37                    1.00              0.4 0.28787879 0.109311741\n",
      "38                    1.00              0.6 0.30303030 0.068825911\n",
      "39                    1.00              0.6 0.15151515 0.000000000\n",
      "40                    1.00              0.8 0.45454545 0.012145749\n",
      "41                    1.00              0.8 0.30303030 0.028340081\n",
      "42                    1.00              0.8 0.45454545 0.023279352\n",
      "43                    1.00              0.6 0.15151515 0.068825911\n",
      "44                    1.00              0.6 0.30303030 0.068825911\n",
      "45                    1.00              0.4 0.30303030 0.003036437\n",
      "46                    1.00              0.6 0.31818182 0.080971660\n",
      "47                    1.00              0.8 0.10606061 0.018218623\n",
      "48                    1.00              1.0 0.68181818 0.145748988\n",
      "49                    1.00              0.8 0.31818182 0.087044534\n",
      "50                    1.00              1.0 0.31818182 0.078947368\n",
      "51                    1.00              1.0 0.09090909 0.068825911\n",
      "52                    1.00              1.0 0.25757576 0.068825911\n",
      "53                    1.00              1.0 0.07575758 0.190283401\n",
      "54                    1.00              1.0 0.13636364 0.018218623\n",
      "55                    1.00              1.0 0.37878788 0.190283401\n",
      "56                    1.00              1.0 0.07575758 0.075910931\n",
      "57                    1.00              0.4 0.40909091 0.031376518\n",
      "58                    1.00              0.8 0.36363636 0.044534413\n",
      "59                    1.00              0.4 0.18181818 0.003036437\n",
      "60                    1.00              0.8 0.21212121 0.030364372\n",
      "61                    0.00              1.0 0.40909091 0.038461538\n",
      "62                    1.00              1.0 0.42424242 0.056680162\n",
      "63                    1.00              1.0 0.46969697 0.190283401\n",
      "64                    0.00              1.0 0.37878788 0.028340081\n",
      "65                    1.00              1.0 0.10606061 0.028340081\n",
      "66                    1.00              0.8 0.30303030 0.025303644\n",
      "67                    1.00              0.8 0.15151515 0.119433198\n",
      "68                    1.00              0.8 0.30303030 0.107287449\n",
      "69                    1.00              0.6 0.27272727 0.069838057\n",
      "70                    1.00              1.0 0.04545455 0.008097166\n",
      "71                    1.00              1.0 0.28787879 0.150809717\n",
      "72                    1.00              1.0 0.77272727 0.038461538\n",
      "73                    1.00              0.4 0.42424242 0.037449393\n",
      "74                    1.00              0.4 0.28787879 0.089068826\n",
      "75                    1.00              0.8 0.71212121 0.038461538\n",
      "76                    1.00              1.0 0.24242424 0.048582996\n",
      "77                    1.00              0.8 0.33333333 0.030364372\n",
      "78                    1.00              0.8 0.21212121 1.000000000\n",
      "79                    1.00              0.8 0.25757576 0.068825911\n",
      "80                    1.00              1.0 0.68181818 0.038461538\n",
      "81                    1.00              1.0 0.53030303 0.143623482\n",
      "82                    1.00              0.4 1.00000000 0.101214575\n",
      "83                    1.00              0.6 0.36363636 0.109311741\n",
      "84                    1.00              0.8 0.30303030 0.028340081\n",
      "85                    1.00              0.6 0.24242424 0.038461538\n",
      "86                    1.00              0.6 0.53030303 0.008097166\n",
      "87                    1.00              0.0 0.00000000 0.023279352\n",
      "88                    1.00              1.0 0.24242424 0.031376518\n",
      "89                    1.00              0.4 0.09090909 0.109311741\n",
      "90                    1.00              0.4 0.06060606 0.024291498\n",
      "91                    1.00              1.0 0.18181818 0.031376518\n",
      "92                    1.00              0.8 0.22727273 0.003036437\n",
      "93                    1.00              0.6 0.12121212 0.848178138\n",
      "94                    1.00              0.8 0.18181818 0.028340081\n",
      "95                    1.00              1.0 0.68181818 0.008097166\n",
      "96                    1.00              0.6 0.43939394 0.018218623\n",
      "97                    1.00              0.4 0.31818182 0.060728745\n",
      "98                    1.00              1.0 0.86363636 0.044534413\n",
      "99                    1.00              1.0 0.18181818 0.036437247\n",
      "100                   1.00              0.8 0.36363636 0.022267206\n",
      "101                   0.75              1.0 0.15151515 0.038461538\n",
      "102                   1.00              1.0 0.30303030 0.109311741\n",
      "103                   1.00              0.8 0.00000000 0.016194332\n",
      "104                   1.00              0.8 0.21212121 0.058704453\n",
      "105                   1.00              1.0 0.28787879 0.089068826\n",
      "106                   1.00              0.8 0.28787879 0.190283401\n",
      "107                   1.00              0.6 0.28787879 0.089068826\n",
      "108                   1.00              0.8 0.34848485 0.139676113\n",
      "109                   1.00              1.0 0.28787879 0.038461538\n",
      "110                   1.00              1.0 0.28787879 0.048582996\n",
      "111                   1.00              1.0 0.09090909 0.023279352\n",
      "112                   1.00              0.6 0.42424242 0.230769231\n",
      "113                   1.00              0.8 0.13636364 0.081781377\n",
      "114                   1.00              0.8 0.09090909 0.012145749\n",
      "115                   1.00              0.6 0.25757576 0.068825911\n",
      "116                   1.00              0.2 0.06060606 0.028340081\n",
      "117                   1.00              0.4 0.12121212 0.028340081\n",
      "118                   1.00              0.4 0.16666667 0.056680162\n",
      "119                   1.00              0.4 0.06060606 0.048582996\n",
      "120                   1.00              0.2 0.21212121 0.043522267\n",
      "121                   1.00              0.4 0.39393939 0.052631579\n",
      "122                   1.00              0.8 0.24242424 0.109311741\n",
      "123                   1.00              1.0 0.21212121 0.099190283\n",
      "124                   1.00              0.8 0.15151515 0.018218623\n",
      "125                   1.00              0.8 0.09090909 0.068825911\n",
      "126                   1.00              1.0 0.42424242 0.063765182\n",
      "127                   1.00              1.0 0.21212121 0.033400810\n",
      "128                   1.00              1.0 0.18181818 0.068825911\n",
      "129                   1.00              1.0 0.21212121 0.078947368\n",
      "130                   1.00              1.0 0.04545455 0.175101215\n",
      "131                   1.00              1.0 0.51515152 0.139676113\n",
      "132                   1.00              0.8 0.24242424 0.068825911\n",
      "133                   1.00              0.2 0.36363636 0.109311741\n",
      "134                   1.00              1.0 0.01515152 0.068825911\n",
      "135                   1.00              1.0 0.50000000 0.048582996\n",
      "136                   1.00              1.0 0.50000000 0.109311741\n",
      "137                   1.00              1.0 0.00000000 0.094129555\n",
      "138                   0.00              0.6 0.18181818 0.073886640\n",
      "139                   1.00              0.6 0.07575758 0.048582996\n",
      "140                   1.00              0.6 0.06060606 0.030364372\n",
      "141                   1.00              0.8 0.21212121 0.038461538\n",
      "142                   1.00              0.0 0.30303030 0.043522267\n",
      "143                   1.00              0.6 0.72727273 0.062753036\n",
      "144                   1.00              0.6 0.30303030 0.033400810\n",
      "145                   1.00              0.8 0.25757576 0.030364372\n",
      "146                   1.00              0.6 0.00000000 0.033400810\n",
      "147                   1.00              1.0 0.24242424 0.068825911\n",
      "148                   1.00              1.0 0.40909091 0.028340081\n",
      "149                   1.00              1.0 0.27272727 0.078947368\n",
      "150                   1.00              0.8 0.36363636 0.053643725\n",
      "151                   1.00              0.6 0.25757576 0.038461538\n",
      "152                   1.00              0.4 0.43939394 0.086032389\n",
      "153                   1.00              1.0 0.33333333 0.149797571\n",
      "154                   1.00              0.8 0.39393939 0.078947368\n",
      "155                   1.00              0.8 0.31818182 0.121862348\n",
      "156                   1.00              0.8 0.43939394 0.044534413\n",
      "157                   1.00              0.8 0.27272727 0.023279352\n",
      "158                   1.00              0.4 0.30303030 0.060728745\n",
      "159                   1.00              0.6 0.27272727 0.068825911\n",
      "160                   1.00              0.6 0.13636364 0.000000000\n",
      "161                   1.00              0.8 0.42424242 0.012145749\n",
      "162                   1.00              0.8 0.22727273 0.028340081\n",
      "163                   1.00              0.8 0.42424242 0.023279352\n",
      "164                   1.00              0.6 0.28787879 0.068825911\n",
      "165                   1.00              0.4 0.28787879 0.003036437\n",
      "166                   1.00              0.6 0.28787879 0.080971660\n",
      "167                   1.00              0.8 0.07575758 0.018218623\n",
      "168                   1.00              1.0 0.63636364 0.145748988\n",
      "169                   1.00              0.8 0.30303030 0.087044534\n",
      "170                   1.00              1.0 0.16666667 0.078947368\n",
      "171                   1.00              1.0 0.07575758 0.068825911\n",
      "172                   1.00              1.0 0.01515152 0.190283401\n",
      "173                   1.00              1.0 0.06060606 0.018218623\n",
      "174                   1.00              0.4 0.39393939 0.031376518\n",
      "175                   1.00              0.8 0.34848485 0.044534413\n",
      "176                   1.00              1.0 0.27272727 0.073886640\n",
      "177                   0.00              1.0 0.36363636 0.038461538\n",
      "178                   1.00              1.0 0.27272727 0.056680162\n",
      "179                   1.00              1.0 0.04545455 0.028340081\n",
      "180                   1.00              0.8 0.27272727 0.025303644\n",
      "181                   1.00              0.8 0.12121212 0.119433198\n",
      "182                   1.00              0.8 0.28787879 0.072874494\n",
      "183                   1.00              0.8 0.30303030 0.107287449\n",
      "184                   1.00              0.6 0.22727273 0.069838057\n",
      "185                   1.00              0.8 0.63636364 0.038461538\n",
      "186                   1.00              1.0 0.24242424 0.048582996\n",
      "187                   1.00              1.0 0.66666667 0.038461538\n",
      "188                   1.00              0.4 1.00000000 0.101214575\n",
      "189                   1.00              0.6 0.22727273 0.109311741\n",
      "190                   1.00              0.6 0.24242424 0.038461538\n",
      "191                   1.00              1.0 0.22727273 0.031376518\n",
      "192                   1.00              0.4 0.03030303 0.109311741\n",
      "193                   1.00              0.4 0.10606061 0.024291498\n",
      "194                   1.00              1.0 0.18181818 0.031376518\n",
      "195                   1.00              0.8 0.22727273 0.003036437\n",
      "196                   1.00              0.8 0.18181818 0.028340081\n",
      "197                   1.00              1.0 0.84848485 0.044534413\n",
      "198                   1.00              1.0 0.21212121 0.036437247\n",
      "199                   1.00              1.0 0.30303030 0.109311741\n",
      "200                   1.00              0.8 0.00000000 0.016194332\n",
      "201                   1.00              0.8 0.21212121 0.058704453\n",
      "202                   1.00              1.0 0.28787879 0.089068826\n",
      "203                   1.00              1.0 0.27272727 0.038461538\n",
      "204                   1.00              0.8 0.04545455 0.012145749\n",
      "205                   1.00              0.8 0.04545455 0.068825911\n",
      "206                   1.00              1.0 0.42424242 0.063765182\n",
      "207                   1.00              1.0 0.18181818 0.033400810\n",
      "208                   1.00              1.0 0.03030303 0.175101215\n",
      "209                   1.00              1.0 0.50000000 0.139676113\n",
      "210                   1.00              0.8 0.22727273 0.068825911\n",
      "211                   1.00              1.0 0.01515152 0.068825911\n",
      "212                   1.00              1.0 0.45454545 0.048582996\n",
      "    hh_monthly_income_cat shp_owner shp_sector shp_employees\n",
      "0               0.0000000       1.0 0.07792208    0.00000000\n",
      "1               0.3333333       0.0 0.25974026    0.00000000\n",
      "2               0.1666667       0.0 0.00000000    0.00000000\n",
      "3               0.3333333       0.0 0.00000000    0.00000000\n",
      "4               0.1666667       0.0 0.00000000    0.00000000\n",
      "5               0.3333333       1.0 0.07792208    0.00000000\n",
      "6               0.0000000       0.0 0.01298701    0.03030303\n",
      "7               0.1666667       1.0 0.07792208    0.03030303\n",
      "8               0.1666667       1.0 0.01298701    0.00000000\n",
      "9               0.5000000       0.5 0.25974026    0.06060606\n",
      "10              0.3333333       1.0 0.00000000    0.09090909\n",
      "11              0.3333333       1.0 0.07792208    0.03030303\n",
      "12              0.1666667       1.0 0.07792208    0.03030303\n",
      "13              0.1666667       1.0 0.00000000    0.03030303\n",
      "14              0.1666667       1.0 0.00000000    0.03030303\n",
      "15              0.1666667       1.0 0.25974026    0.06060606\n",
      "16              0.1666667       1.0 0.00000000    0.00000000\n",
      "17              0.1666667       1.0 0.00000000    0.03030303\n",
      "18              0.1666667       1.0 0.00000000    0.03030303\n",
      "19              0.3333333       1.0 0.25974026    0.00000000\n",
      "20              0.1666667       1.0 0.07792208    0.00000000\n",
      "21              0.3333333       1.0 0.07792208    0.00000000\n",
      "22              0.1666667       0.0 0.07792208    0.00000000\n",
      "23              0.3333333       0.0 0.00000000    0.00000000\n",
      "24              0.5000000       0.0 0.00000000    0.00000000\n",
      "25              0.3333333       1.0 0.03896104    0.09090909\n",
      "26              0.8333333       1.0 0.12987013    0.18181818\n",
      "27              0.3333333       1.0 0.02597403    0.09090909\n",
      "28              0.5000000       1.0 0.12987013    0.24242424\n",
      "29              0.3333333       1.0 0.07792208    0.06060606\n",
      "30              0.3333333       1.0 1.00000000    0.09090909\n",
      "31              0.3333333       1.0 0.00000000    0.03030303\n",
      "32              0.0000000       0.0 0.00000000    0.00000000\n",
      "33              0.1666667       1.0 0.07792208    0.03030303\n",
      "34              0.0000000       1.0 0.00000000    0.03030303\n",
      "35              0.1666667       1.0 0.14285714    0.00000000\n",
      "36              0.3333333       0.0 0.00000000    0.06060606\n",
      "37              0.3333333       0.0 0.00000000    0.03030303\n",
      "38              0.1666667       0.0 0.07792208    0.00000000\n",
      "39              0.1666667       0.0 0.14285714    0.03030303\n",
      "40              0.3333333       0.0 0.14285714    0.06060606\n",
      "41              0.1666667       0.0 0.07792208    0.00000000\n",
      "42              0.0000000       0.0 0.00000000    0.00000000\n",
      "43              0.1666667       0.0 1.00000000    0.00000000\n",
      "44              0.3333333       0.0 0.07792208    0.09090909\n",
      "45              0.5000000       0.0 0.14285714    0.00000000\n",
      "46              0.3333333       0.0 0.00000000    0.06060606\n",
      "47              0.3333333       1.0 0.03896104    0.03030303\n",
      "48              0.1666667       1.0 0.00000000    0.09090909\n",
      "49              0.1666667       1.0 0.07792208    0.00000000\n",
      "50              0.1666667       1.0 0.07792208    0.00000000\n",
      "51              0.1666667       1.0 0.07792208    0.00000000\n",
      "52              0.1666667       1.0 1.00000000    0.00000000\n",
      "53              0.1666667       1.0 0.00000000    0.03030303\n",
      "54              0.1666667       1.0 0.07792208    0.00000000\n",
      "55              0.1666667       1.0 0.12987013    0.03030303\n",
      "56              0.5000000       1.0 0.15584416    0.00000000\n",
      "57              0.3333333       1.0 0.07792208    0.00000000\n",
      "58              0.3333333       1.0 0.07792208    0.00000000\n",
      "59              0.1666667       0.0 0.00000000    0.03030303\n",
      "60              0.0000000       0.0 0.00000000    0.00000000\n",
      "61              0.3333333       0.0 0.00000000    0.03030303\n",
      "62              0.1666667       0.0 0.07792208    0.03030303\n",
      "63              0.3333333       0.0 0.00000000    0.00000000\n",
      "64              0.1666667       0.0 0.07792208    0.03030303\n",
      "65              0.1666667       0.0 0.12987013    0.00000000\n",
      "66              0.3333333       1.0 0.00000000    0.00000000\n",
      "67              0.5000000       1.0 0.00000000    0.03030303\n",
      "68              0.3333333       1.0 0.07792208    0.00000000\n",
      "69              0.3333333       0.0 0.12987013    0.00000000\n",
      "70              0.1666667       0.0 0.07792208    0.00000000\n",
      "71              0.1666667       1.0 0.16883117    0.03030303\n",
      "72              0.0000000       0.0 0.16883117    0.00000000\n",
      "73              0.0000000       0.5 0.00000000    0.00000000\n",
      "74              0.1666667       1.0 0.07792208    0.03030303\n",
      "75              0.1666667       1.0 0.00000000    0.03030303\n",
      "76              0.1666667       0.5 0.15584416    0.09090909\n",
      "77              0.3333333       0.0 0.00000000    0.18181818\n",
      "78              1.0000000       0.5 1.00000000    1.00000000\n",
      "79              0.0000000       1.0 0.00000000    0.03030303\n",
      "80              0.1666667       1.0 0.07792208    0.00000000\n",
      "81              0.1666667       1.0 0.00000000    0.03030303\n",
      "82              0.3333333       1.0 0.15584416    0.15151515\n",
      "83              0.1666667       1.0 0.16883117    0.09090909\n",
      "84              0.1666667       1.0 0.03896104    0.03030303\n",
      "85              0.0000000       1.0 0.07792208    0.03030303\n",
      "86              0.0000000       1.0 0.07792208    0.03030303\n",
      "87              0.1666667       1.0 0.00000000    0.03030303\n",
      "88              0.0000000       1.0 0.00000000    0.00000000\n",
      "89              0.1666667       0.0 0.00000000    0.03030303\n",
      "90              0.3333333       0.0 0.07792208    0.00000000\n",
      "91              0.3333333       0.0 0.07792208    0.00000000\n",
      "92              0.1666667       0.0 0.00000000    0.00000000\n",
      "93              0.1666667       0.0 0.00000000    0.03030303\n",
      "94              0.1666667       0.0 0.00000000    0.00000000\n",
      "95              0.0000000       0.0 0.07792208    0.03030303\n",
      "96              0.1666667       0.0 0.14285714    0.00000000\n",
      "97              0.1666667       1.0 1.00000000    0.03030303\n",
      "98              0.1666667       1.0 0.16883117    0.00000000\n",
      "99              0.5000000       1.0 0.07792208    0.00000000\n",
      "100             0.3333333       1.0 0.14285714    0.00000000\n",
      "101             0.5000000       1.0 0.03896104    0.03030303\n",
      "102             0.6666667       1.0 0.00000000    0.03030303\n",
      "103             0.5000000       1.0 0.07792208    0.03030303\n",
      "104             0.0000000       1.0 0.14285714    0.00000000\n",
      "105             0.1666667       0.0 0.00000000    0.00000000\n",
      "106             0.3333333       0.5 0.14285714    0.03030303\n",
      "107             0.1666667       0.0 0.01298701    0.00000000\n",
      "108             0.3333333       0.0 0.07792208    0.03030303\n",
      "109             0.3333333       1.0 0.07792208    0.00000000\n",
      "110             0.3333333       1.0 0.16883117    0.00000000\n",
      "111             0.1666667       1.0 0.07792208    0.00000000\n",
      "112             0.1666667       1.0 0.00000000    0.03030303\n",
      "113             0.1666667       1.0 0.07792208    0.03030303\n",
      "114             0.0000000       1.0 0.07792208    0.00000000\n",
      "115             0.1666667       0.0 0.00000000    0.00000000\n",
      "116             0.3333333       0.0 0.03896104    0.06060606\n",
      "117             0.1666667       0.0 0.07792208    0.00000000\n",
      "118             0.1666667       0.0 1.00000000    0.03030303\n",
      "119             0.1666667       0.0 0.00000000    0.03030303\n",
      "120             0.3333333       0.0 0.00000000    0.00000000\n",
      "121             0.1666667       1.0 0.07792208    0.03030303\n",
      "122             0.0000000       1.0 0.07792208    0.03030303\n",
      "123             0.1666667       0.0 0.00000000    0.00000000\n",
      "124             0.1666667       1.0 0.07792208    0.00000000\n",
      "125             0.1666667       1.0 0.07792208    0.03030303\n",
      "126             0.1666667       1.0 0.16883117    0.00000000\n",
      "127             0.3333333       0.0 0.16883117    0.00000000\n",
      "128             0.1666667       1.0 0.28571429    0.00000000\n",
      "129             0.1666667       1.0 0.00000000    0.03030303\n",
      "130             0.3333333       0.0 0.00000000    0.03030303\n",
      "131             0.0000000       1.0 0.00000000    0.03030303\n",
      "132             0.0000000       0.0 0.00000000    0.00000000\n",
      "133             0.3333333       1.0 0.00000000    0.03030303\n",
      "134             0.1666667       1.0 0.00000000    0.03030303\n",
      "135             0.3333333       0.0 0.00000000    0.03030303\n",
      "136             0.1666667       0.0 0.16883117    0.00000000\n",
      "137             0.0000000       0.0 0.16883117    0.00000000\n",
      "138             0.3333333       1.0 0.00000000    0.12121212\n",
      "139             0.3333333       1.0 0.07792208    0.03030303\n",
      "140             0.1666667       0.5 0.07792208    0.00000000\n",
      "141             0.3333333       0.0 0.25974026    0.00000000\n",
      "142             0.3333333       0.0 0.00000000    0.00000000\n",
      "143             0.0000000       0.0 0.01298701    0.03030303\n",
      "144             0.1666667       1.0 0.07792208    0.03030303\n",
      "145             0.1666667       1.0 0.07792208    0.03030303\n",
      "146             0.1666667       1.0 0.00000000    0.03030303\n",
      "147             0.1666667       1.0 0.00000000    0.03030303\n",
      "148             0.1666667       1.0 0.00000000    0.03030303\n",
      "149             0.3333333       1.0 0.07792208    0.00000000\n",
      "150             0.3333333       0.0 0.00000000    0.00000000\n",
      "151             0.5000000       0.0 0.00000000    0.00000000\n",
      "152             0.3333333       1.0 0.03896104    0.09090909\n",
      "153             0.8333333       1.0 0.12987013    0.18181818\n",
      "154             0.0000000       0.0 0.00000000    0.00000000\n",
      "155             0.1666667       1.0 0.07792208    0.03030303\n",
      "156             0.0000000       1.0 0.00000000    0.03030303\n",
      "157             0.1666667       1.0 0.14285714    0.00000000\n",
      "158             0.3333333       0.0 0.00000000    0.06060606\n",
      "159             0.1666667       0.0 0.07792208    0.00000000\n",
      "160             0.1666667       0.0 0.14285714    0.03030303\n",
      "161             0.3333333       0.0 0.14285714    0.06060606\n",
      "162             0.1666667       0.0 0.07792208    0.00000000\n",
      "163             0.0000000       0.0 0.00000000    0.00000000\n",
      "164             0.3333333       0.0 0.07792208    0.09090909\n",
      "165             0.5000000       0.0 0.14285714    0.00000000\n",
      "166             0.3333333       0.0 0.00000000    0.06060606\n",
      "167             0.3333333       1.0 0.03896104    0.03030303\n",
      "168             0.1666667       1.0 0.00000000    0.09090909\n",
      "169             0.1666667       1.0 0.07792208    0.00000000\n",
      "170             0.1666667       1.0 0.07792208    0.00000000\n",
      "171             0.1666667       1.0 0.07792208    0.00000000\n",
      "172             0.1666667       1.0 0.00000000    0.03030303\n",
      "173             0.1666667       1.0 0.07792208    0.00000000\n",
      "174             0.3333333       1.0 0.07792208    0.00000000\n",
      "175             0.3333333       1.0 0.07792208    0.00000000\n",
      "176             0.1666667       0.0 0.00000000    0.00000000\n",
      "177             0.3333333       0.0 0.00000000    0.03030303\n",
      "178             0.1666667       0.0 0.07792208    0.03030303\n",
      "179             0.1666667       0.0 0.12987013    0.00000000\n",
      "180             0.3333333       1.0 0.00000000    0.00000000\n",
      "181             0.5000000       1.0 0.00000000    0.03030303\n",
      "182             0.1666667       1.0 0.00000000    0.03030303\n",
      "183             0.3333333       1.0 0.07792208    0.00000000\n",
      "184             0.3333333       0.0 0.12987013    0.00000000\n",
      "185             0.1666667       1.0 0.00000000    0.03030303\n",
      "186             0.1666667       0.5 0.15584416    0.09090909\n",
      "187             0.1666667       1.0 0.07792208    0.00000000\n",
      "188             0.3333333       1.0 0.15584416    0.15151515\n",
      "189             0.1666667       1.0 0.16883117    0.09090909\n",
      "190             0.0000000       1.0 0.07792208    0.03030303\n",
      "191             0.0000000       1.0 0.00000000    0.00000000\n",
      "192             0.1666667       0.0 0.00000000    0.03030303\n",
      "193             0.3333333       0.0 0.07792208    0.00000000\n",
      "194             0.3333333       0.0 0.07792208    0.00000000\n",
      "195             0.1666667       0.0 0.00000000    0.00000000\n",
      "196             0.1666667       0.0 0.00000000    0.00000000\n",
      "197             0.1666667       1.0 0.16883117    0.00000000\n",
      "198             0.5000000       1.0 0.07792208    0.00000000\n",
      "199             0.6666667       1.0 0.00000000    0.03030303\n",
      "200             0.5000000       1.0 0.07792208    0.03030303\n",
      "201             0.0000000       1.0 0.14285714    0.00000000\n",
      "202             0.1666667       0.0 0.00000000    0.00000000\n",
      "203             0.3333333       1.0 0.07792208    0.00000000\n",
      "204             0.0000000       1.0 0.07792208    0.00000000\n",
      "205             0.1666667       1.0 0.07792208    0.03030303\n",
      "206             0.1666667       1.0 0.16883117    0.00000000\n",
      "207             0.3333333       0.0 0.16883117    0.00000000\n",
      "208             0.3333333       0.0 0.00000000    0.03030303\n",
      "209             0.0000000       1.0 0.00000000    0.03030303\n",
      "210             0.0000000       0.0 0.00000000    0.00000000\n",
      "211             0.1666667       1.0 0.00000000    0.03030303\n",
      "212             0.3333333       0.0 0.00000000    0.03030303\n",
      "    shp_avgmonthly_sale_cat shp_profits_last5years\n",
      "0                      0.25              1.0000000\n",
      "1                      0.00              0.6666667\n",
      "2                      0.00              0.3333333\n",
      "3                      0.25              0.3333333\n",
      "4                      0.00              0.3333333\n",
      "5                      0.00              0.6666667\n",
      "6                      0.00              0.6666667\n",
      "7                      0.00              0.6666667\n",
      "8                      0.00              0.6666667\n",
      "9                      0.75              0.3333333\n",
      "10                     0.50              0.3333333\n",
      "11                     0.25              0.3333333\n",
      "12                     0.25              0.6666667\n",
      "13                     0.25              0.6666667\n",
      "14                     0.25              0.6666667\n",
      "15                     0.25              1.0000000\n",
      "16                     0.00              0.6666667\n",
      "17                     0.25              1.0000000\n",
      "18                     0.50              0.0000000\n",
      "19                     0.25              0.6666667\n",
      "20                     0.25              1.0000000\n",
      "21                     0.50              0.3333333\n",
      "22                     0.00              0.6666667\n",
      "23                     0.25              0.3333333\n",
      "24                     0.00              0.3333333\n",
      "25                     0.25              0.3333333\n",
      "26                     0.75              0.6666667\n",
      "27                     0.25              0.3333333\n",
      "28                     0.50              0.3333333\n",
      "29                     0.50              0.6666667\n",
      "30                     0.50              0.3333333\n",
      "31                     0.25              0.3333333\n",
      "32                     0.00              0.6666667\n",
      "33                     0.00              0.6666667\n",
      "34                     0.00              0.3333333\n",
      "35                     0.00              0.3333333\n",
      "36                     0.25              1.0000000\n",
      "37                     0.00              1.0000000\n",
      "38                     0.25              1.0000000\n",
      "39                     0.50              1.0000000\n",
      "40                     0.50              0.3333333\n",
      "41                     0.00              1.0000000\n",
      "42                     0.00              1.0000000\n",
      "43                     0.25              0.3333333\n",
      "44                     0.50              0.0000000\n",
      "45                     0.50              0.3333333\n",
      "46                     0.50              1.0000000\n",
      "47                     0.50              0.6666667\n",
      "48                     0.50              0.3333333\n",
      "49                     0.00              0.6666667\n",
      "50                     0.25              0.3333333\n",
      "51                     0.25              0.3333333\n",
      "52                     0.25              1.0000000\n",
      "53                     0.25              0.3333333\n",
      "54                     0.25              0.3333333\n",
      "55                     0.25              1.0000000\n",
      "56                     0.50              0.6666667\n",
      "57                     0.00              0.6666667\n",
      "58                     0.25              0.6666667\n",
      "59                     0.25              1.0000000\n",
      "60                     0.00              0.3333333\n",
      "61                     0.00              1.0000000\n",
      "62                     0.00              1.0000000\n",
      "63                     0.00              0.6666667\n",
      "64                     0.00              0.6666667\n",
      "65                     0.25              0.6666667\n",
      "66                     0.25              0.3333333\n",
      "67                     0.25              0.3333333\n",
      "68                     0.00              0.3333333\n",
      "69                     0.50              0.3333333\n",
      "70                     0.00              0.3333333\n",
      "71                     0.25              0.0000000\n",
      "72                     0.00              0.3333333\n",
      "73                     0.00              0.6666667\n",
      "74                     0.25              0.3333333\n",
      "75                     0.00              1.0000000\n",
      "76                     0.50              1.0000000\n",
      "77                     0.25              1.0000000\n",
      "78                     1.00              1.0000000\n",
      "79                     0.00              0.3333333\n",
      "80                     0.25              0.3333333\n",
      "81                     0.25              1.0000000\n",
      "82                     0.25              0.3333333\n",
      "83                     0.50              0.3333333\n",
      "84                     0.50              0.6666667\n",
      "85                     0.00              0.3333333\n",
      "86                     0.00              0.3333333\n",
      "87                     0.25              0.3333333\n",
      "88                     0.00              1.0000000\n",
      "89                     0.25              0.3333333\n",
      "90                     0.50              1.0000000\n",
      "91                     0.50              1.0000000\n",
      "92                     0.25              0.3333333\n",
      "93                     0.25              0.0000000\n",
      "94                     0.00              0.3333333\n",
      "95                     0.00              0.6666667\n",
      "96                     0.25              0.3333333\n",
      "97                     0.25              0.6666667\n",
      "98                     0.00              0.6666667\n",
      "99                     0.00              0.3333333\n",
      "100                    0.50              0.3333333\n",
      "101                    0.50              0.6666667\n",
      "102                    0.50              0.6666667\n",
      "103                    0.50              0.6666667\n",
      "104                    0.00              1.0000000\n",
      "105                    0.00              1.0000000\n",
      "106                    0.50              0.3333333\n",
      "107                    0.00              1.0000000\n",
      "108                    0.25              0.3333333\n",
      "109                    0.25              0.6666667\n",
      "110                    0.25              0.3333333\n",
      "111                    0.00              1.0000000\n",
      "112                    0.25              0.3333333\n",
      "113                    0.00              0.6666667\n",
      "114                    0.00              0.6666667\n",
      "115                    0.25              0.3333333\n",
      "116                    0.25              1.0000000\n",
      "117                    1.00              1.0000000\n",
      "118                    0.25              0.3333333\n",
      "119                    0.00              1.0000000\n",
      "120                    0.00              0.6666667\n",
      "121                    0.00              0.3333333\n",
      "122                    0.00              0.6666667\n",
      "123                    0.00              0.3333333\n",
      "124                    0.00              0.6666667\n",
      "125                    0.25              0.6666667\n",
      "126                    1.00              0.6666667\n",
      "127                    1.00              0.6666667\n",
      "128                    0.00              0.6666667\n",
      "129                    0.25              0.6666667\n",
      "130                    0.25              0.6666667\n",
      "131                    0.00              0.6666667\n",
      "132                    0.00              0.6666667\n",
      "133                    0.25              0.3333333\n",
      "134                    0.25              1.0000000\n",
      "135                    0.50              0.3333333\n",
      "136                    0.25              1.0000000\n",
      "137                    0.00              1.0000000\n",
      "138                    0.50              0.3333333\n",
      "139                    0.25              0.3333333\n",
      "140                    0.00              0.6666667\n",
      "141                    0.00              0.6666667\n",
      "142                    0.25              0.3333333\n",
      "143                    0.00              0.6666667\n",
      "144                    0.00              0.6666667\n",
      "145                    0.25              0.6666667\n",
      "146                    0.25              0.6666667\n",
      "147                    0.25              0.6666667\n",
      "148                    0.25              1.0000000\n",
      "149                    0.50              0.3333333\n",
      "150                    0.25              0.3333333\n",
      "151                    0.00              0.3333333\n",
      "152                    0.25              0.3333333\n",
      "153                    0.75              0.6666667\n",
      "154                    0.00              0.6666667\n",
      "155                    0.00              0.6666667\n",
      "156                    0.00              0.3333333\n",
      "157                    0.00              0.3333333\n",
      "158                    0.25              1.0000000\n",
      "159                    0.25              1.0000000\n",
      "160                    0.50              1.0000000\n",
      "161                    0.50              0.3333333\n",
      "162                    0.00              1.0000000\n",
      "163                    0.00              1.0000000\n",
      "164                    0.50              0.0000000\n",
      "165                    0.50              0.3333333\n",
      "166                    0.50              1.0000000\n",
      "167                    0.50              0.6666667\n",
      "168                    0.50              0.3333333\n",
      "169                    0.00              0.6666667\n",
      "170                    0.25              0.3333333\n",
      "171                    0.25              0.3333333\n",
      "172                    0.25              0.3333333\n",
      "173                    0.25              0.3333333\n",
      "174                    0.00              0.6666667\n",
      "175                    0.25              0.6666667\n",
      "176                    0.00              0.3333333\n",
      "177                    0.00              1.0000000\n",
      "178                    0.00              1.0000000\n",
      "179                    0.25              0.6666667\n",
      "180                    0.25              0.3333333\n",
      "181                    0.25              0.3333333\n",
      "182                    0.25              0.3333333\n",
      "183                    0.00              0.3333333\n",
      "184                    0.50              0.3333333\n",
      "185                    0.00              1.0000000\n",
      "186                    0.50              1.0000000\n",
      "187                    0.25              0.3333333\n",
      "188                    0.25              0.3333333\n",
      "189                    0.50              0.3333333\n",
      "190                    0.00              0.3333333\n",
      "191                    0.00              1.0000000\n",
      "192                    0.25              0.3333333\n",
      "193                    0.50              1.0000000\n",
      "194                    0.50              1.0000000\n",
      "195                    0.25              0.3333333\n",
      "196                    0.00              0.3333333\n",
      "197                    0.00              0.6666667\n",
      "198                    0.00              0.3333333\n",
      "199                    0.50              0.6666667\n",
      "200                    0.50              0.6666667\n",
      "201                    0.00              1.0000000\n",
      "202                    0.00              1.0000000\n",
      "203                    0.25              0.6666667\n",
      "204                    0.00              0.6666667\n",
      "205                    0.25              0.6666667\n",
      "206                    1.00              0.6666667\n",
      "207                    1.00              0.6666667\n",
      "208                    0.25              0.6666667\n",
      "209                    0.00              0.6666667\n",
      "210                    0.00              0.6666667\n",
      "211                    0.25              1.0000000\n",
      "212                    0.50              0.3333333\n",
      "    resilience_more_future_affected resilience_govern_warnings_helpful\n",
      "0                              0.25                               1.00\n",
      "1                              0.00                               0.25\n",
      "2                              0.50                               0.00\n",
      "3                              0.75                               0.00\n",
      "4                              1.00                               0.00\n",
      "5                              0.25                               0.00\n",
      "6                              0.75                               0.50\n",
      "7                              0.75                               0.25\n",
      "8                              0.75                               0.00\n",
      "9                              1.00                               0.50\n",
      "10                             0.50                               0.00\n",
      "11                             0.50                               0.00\n",
      "12                             0.25                               0.00\n",
      "13                             0.75                               0.00\n",
      "14                             1.00                               0.00\n",
      "15                             0.00                               0.00\n",
      "16                             0.50                               0.00\n",
      "17                             1.00                               0.00\n",
      "18                             0.75                               0.00\n",
      "19                             0.50                               0.00\n",
      "20                             0.75                               0.75\n",
      "21                             1.00                               0.50\n",
      "22                             0.75                               0.00\n",
      "23                             1.00                               0.25\n",
      "24                             1.00                               0.50\n",
      "25                             0.00                               1.00\n",
      "26                             0.50                               0.00\n",
      "27                             0.25                               0.00\n",
      "28                             0.75                               0.00\n",
      "29                             0.75                               0.00\n",
      "30                             0.75                               0.00\n",
      "31                             0.25                               0.25\n",
      "32                             1.00                               0.25\n",
      "33                             1.00                               0.00\n",
      "34                             1.00                               0.00\n",
      "35                             1.00                               0.00\n",
      "36                             0.75                               0.25\n",
      "37                             0.75                               0.25\n",
      "38                             1.00                               0.50\n",
      "39                             0.75                               0.25\n",
      "40                             1.00                               0.75\n",
      "41                             1.00                               0.00\n",
      "42                             1.00                               0.00\n",
      "43                             0.00                               0.00\n",
      "44                             0.75                               0.00\n",
      "45                             0.75                               0.00\n",
      "46                             1.00                               0.00\n",
      "47                             0.50                               0.75\n",
      "48                             0.50                               0.25\n",
      "49                             0.75                               0.75\n",
      "50                             0.75                               0.25\n",
      "51                             1.00                               0.00\n",
      "52                             0.50                               0.00\n",
      "53                             0.75                               0.25\n",
      "54                             0.25                               1.00\n",
      "55                             0.75                               0.25\n",
      "56                             0.50                               0.50\n",
      "57                             0.00                               0.50\n",
      "58                             1.00                               0.50\n",
      "59                             0.75                               0.75\n",
      "60                             1.00                               0.50\n",
      "61                             0.75                               0.75\n",
      "62                             0.75                               0.00\n",
      "63                             0.00                               0.00\n",
      "64                             0.00                               0.00\n",
      "65                             1.00                               0.75\n",
      "66                             1.00                               0.00\n",
      "67                             0.75                               0.00\n",
      "68                             0.00                               0.00\n",
      "69                             1.00                               0.50\n",
      "70                             0.00                               0.75\n",
      "71                             1.00                               0.00\n",
      "72                             0.75                               0.25\n",
      "73                             1.00                               0.00\n",
      "74                             1.00                               0.00\n",
      "75                             0.25                               0.50\n",
      "76                             0.25                               0.25\n",
      "77                             0.25                               0.00\n",
      "78                             0.75                               0.00\n",
      "79                             1.00                               0.00\n",
      "80                             0.50                               0.00\n",
      "81                             1.00                               0.25\n",
      "82                             0.00                               1.00\n",
      "83                             0.25                               0.00\n",
      "84                             0.50                               1.00\n",
      "85                             0.50                               0.75\n",
      "86                             0.75                               0.75\n",
      "87                             0.75                               0.25\n",
      "88                             1.00                               0.00\n",
      "89                             0.25                               0.75\n",
      "90                             0.00                               0.25\n",
      "91                             0.75                               0.50\n",
      "92                             1.00                               0.25\n",
      "93                             0.00                               0.25\n",
      "94                             0.00                               0.00\n",
      "95                             0.25                               0.00\n",
      "96                             1.00                               0.25\n",
      "97                             0.00                               0.00\n",
      "98                             0.75                               0.50\n",
      "99                             0.75                               0.25\n",
      "100                            0.25                               0.75\n",
      "101                            0.25                               0.25\n",
      "102                            1.00                               0.00\n",
      "103                            0.50                               0.00\n",
      "104                            0.25                               0.25\n",
      "105                            1.00                               0.75\n",
      "106                            1.00                               0.25\n",
      "107                            1.00                               0.00\n",
      "108                            0.50                               0.25\n",
      "109                            0.50                               0.00\n",
      "110                            1.00                               0.00\n",
      "111                            0.25                               0.00\n",
      "112                            1.00                               1.00\n",
      "113                            0.75                               0.00\n",
      "114                            1.00                               0.00\n",
      "115                            0.75                               0.00\n",
      "116                            1.00                               0.00\n",
      "117                            1.00                               0.00\n",
      "118                            0.75                               0.00\n",
      "119                            1.00                               0.00\n",
      "120                            0.75                               0.00\n",
      "121                            0.25                               0.75\n",
      "122                            0.75                               0.75\n",
      "123                            1.00                               0.50\n",
      "124                            0.75                               0.75\n",
      "125                            0.50                               0.25\n",
      "126                            0.75                               0.75\n",
      "127                            0.50                               0.50\n",
      "128                            0.25                               0.25\n",
      "129                            1.00                               0.00\n",
      "130                            1.00                               0.00\n",
      "131                            1.00                               0.00\n",
      "132                            0.75                               0.00\n",
      "133                            0.00                               0.75\n",
      "134                            0.75                               0.25\n",
      "135                            1.00                               0.00\n",
      "136                            0.25                               0.25\n",
      "137                            0.00                               1.00\n",
      "138                            1.00                               0.00\n",
      "139                            1.00                               0.00\n",
      "140                            0.50                               0.00\n",
      "141                            0.00                               0.25\n",
      "142                            0.75                               0.00\n",
      "143                            0.75                               0.50\n",
      "144                            0.75                               0.25\n",
      "145                            0.25                               0.00\n",
      "146                            0.75                               0.00\n",
      "147                            1.00                               0.00\n",
      "148                            1.00                               0.00\n",
      "149                            1.00                               0.50\n",
      "150                            1.00                               0.25\n",
      "151                            1.00                               0.50\n",
      "152                            0.00                               1.00\n",
      "153                            0.50                               0.00\n",
      "154                            1.00                               0.25\n",
      "155                            1.00                               0.00\n",
      "156                            1.00                               0.00\n",
      "157                            1.00                               0.00\n",
      "158                            0.75                               0.25\n",
      "159                            1.00                               0.50\n",
      "160                            0.75                               0.25\n",
      "161                            1.00                               0.75\n",
      "162                            1.00                               0.00\n",
      "163                            1.00                               0.00\n",
      "164                            0.75                               0.00\n",
      "165                            0.75                               0.00\n",
      "166                            1.00                               0.00\n",
      "167                            0.50                               0.75\n",
      "168                            0.50                               0.25\n",
      "169                            0.75                               0.75\n",
      "170                            0.75                               0.25\n",
      "171                            1.00                               0.00\n",
      "172                            0.75                               0.25\n",
      "173                            0.25                               1.00\n",
      "174                            0.00                               0.50\n",
      "175                            1.00                               0.50\n",
      "176                            0.50                               0.75\n",
      "177                            0.75                               0.75\n",
      "178                            0.75                               0.00\n",
      "179                            1.00                               0.75\n",
      "180                            1.00                               0.00\n",
      "181                            0.75                               0.00\n",
      "182                            1.00                               0.00\n",
      "183                            0.00                               0.00\n",
      "184                            1.00                               0.50\n",
      "185                            0.25                               0.50\n",
      "186                            0.25                               0.25\n",
      "187                            0.50                               0.00\n",
      "188                            0.00                               1.00\n",
      "189                            0.25                               0.00\n",
      "190                            0.50                               0.75\n",
      "191                            1.00                               0.00\n",
      "192                            0.25                               0.75\n",
      "193                            0.00                               0.25\n",
      "194                            0.75                               0.50\n",
      "195                            1.00                               0.25\n",
      "196                            0.00                               0.00\n",
      "197                            0.75                               0.50\n",
      "198                            0.75                               0.25\n",
      "199                            1.00                               0.00\n",
      "200                            0.50                               0.00\n",
      "201                            0.25                               0.25\n",
      "202                            1.00                               0.75\n",
      "203                            0.50                               0.00\n",
      "204                            1.00                               0.00\n",
      "205                            0.50                               0.25\n",
      "206                            0.75                               0.75\n",
      "207                            0.50                               0.50\n",
      "208                            1.00                               0.00\n",
      "209                            1.00                               0.00\n",
      "210                            0.75                               0.00\n",
      "211                            0.75                               0.25\n",
      "212                            1.00                               0.00\n",
      "    resilience_govern_careing perception_private_economy_future\n",
      "0                        1.00                               1.0\n",
      "1                        0.75                               1.0\n",
      "2                        1.00                               0.5\n",
      "3                        0.75                               1.0\n",
      "4                        1.00                               0.5\n",
      "5                        0.25                               1.0\n",
      "6                        0.50                               1.0\n",
      "7                        0.50                               1.0\n",
      "8                        0.75                               0.5\n",
      "9                        0.50                               1.0\n",
      "10                       0.00                               0.5\n",
      "11                       0.00                               0.5\n",
      "12                       0.00                               0.5\n",
      "13                       0.50                               0.5\n",
      "14                       0.00                               0.5\n",
      "15                       0.00                               0.5\n",
      "16                       0.00                               0.5\n",
      "17                       0.50                               0.5\n",
      "18                       0.25                               0.0\n",
      "19                       0.00                               0.0\n",
      "20                       0.75                               0.0\n",
      "21                       0.75                               0.5\n",
      "22                       0.50                               0.0\n",
      "23                       0.25                               1.0\n",
      "24                       0.50                               0.5\n",
      "25                       0.75                               0.0\n",
      "26                       0.25                               1.0\n",
      "27                       0.25                               1.0\n",
      "28                       0.25                               0.5\n",
      "29                       0.00                               0.5\n",
      "30                       0.00                               0.5\n",
      "31                       0.75                               1.0\n",
      "32                       0.25                               0.5\n",
      "33                       0.00                               0.5\n",
      "34                       0.00                               0.5\n",
      "35                       0.00                               0.5\n",
      "36                       0.25                               1.0\n",
      "37                       0.25                               1.0\n",
      "38                       0.75                               0.0\n",
      "39                       0.25                               1.0\n",
      "40                       1.00                               1.0\n",
      "41                       0.75                               0.5\n",
      "42                       0.50                               0.5\n",
      "43                       0.00                               0.5\n",
      "44                       0.75                               0.5\n",
      "45                       0.75                               0.5\n",
      "46                       0.00                               0.5\n",
      "47                       0.75                               1.0\n",
      "48                       0.75                               1.0\n",
      "49                       1.00                               0.5\n",
      "50                       0.25                               1.0\n",
      "51                       0.50                               0.5\n",
      "52                       0.00                               1.0\n",
      "53                       0.75                               1.0\n",
      "54                       1.00                               1.0\n",
      "55                       0.25                               0.5\n",
      "56                       0.00                               1.0\n",
      "57                       0.75                               1.0\n",
      "58                       0.75                               0.5\n",
      "59                       0.75                               1.0\n",
      "60                       0.50                               1.0\n",
      "61                       0.75                               0.5\n",
      "62                       0.75                               0.5\n",
      "63                       0.75                               1.0\n",
      "64                       0.75                               0.5\n",
      "65                       0.50                               0.5\n",
      "66                       0.00                               0.5\n",
      "67                       0.75                               1.0\n",
      "68                       0.00                               1.0\n",
      "69                       0.50                               1.0\n",
      "70                       1.00                               0.0\n",
      "71                       0.50                               0.5\n",
      "72                       0.25                               1.0\n",
      "73                       0.50                               0.5\n",
      "74                       0.00                               0.5\n",
      "75                       0.75                               1.0\n",
      "76                       0.75                               0.5\n",
      "77                       0.75                               0.0\n",
      "78                       0.75                               0.5\n",
      "79                       0.75                               0.5\n",
      "80                       0.25                               0.5\n",
      "81                       0.25                               0.0\n",
      "82                       1.00                               0.0\n",
      "83                       0.75                               0.0\n",
      "84                       0.50                               1.0\n",
      "85                       0.50                               1.0\n",
      "86                       0.50                               1.0\n",
      "87                       0.25                               1.0\n",
      "88                       0.75                               0.5\n",
      "89                       0.75                               1.0\n",
      "90                       0.75                               1.0\n",
      "91                       0.50                               0.0\n",
      "92                       0.25                               1.0\n",
      "93                       1.00                               1.0\n",
      "94                       0.50                               1.0\n",
      "95                       0.25                               1.0\n",
      "96                       0.25                               0.5\n",
      "97                       1.00                               1.0\n",
      "98                       0.25                               0.5\n",
      "99                       0.25                               1.0\n",
      "100                      0.25                               0.0\n",
      "101                      0.50                               0.5\n",
      "102                      0.00                               0.5\n",
      "103                      0.25                               0.5\n",
      "104                      0.25                               1.0\n",
      "105                      0.75                               1.0\n",
      "106                      0.25                               0.5\n",
      "107                      0.00                               0.5\n",
      "108                      0.25                               1.0\n",
      "109                      0.00                               1.0\n",
      "110                      0.75                               0.5\n",
      "111                      0.75                               1.0\n",
      "112                      1.00                               1.0\n",
      "113                      0.75                               0.5\n",
      "114                      0.00                               0.5\n",
      "115                      0.25                               1.0\n",
      "116                      0.00                               0.5\n",
      "117                      0.75                               0.5\n",
      "118                      0.25                               0.5\n",
      "119                      0.25                               0.5\n",
      "120                      0.25                               0.5\n",
      "121                      0.75                               0.5\n",
      "122                      0.25                               0.0\n",
      "123                      0.50                               1.0\n",
      "124                      0.75                               0.0\n",
      "125                      0.75                               1.0\n",
      "126                      0.75                               0.5\n",
      "127                      0.75                               0.5\n",
      "128                      0.25                               0.5\n",
      "129                      0.00                               0.5\n",
      "130                      0.25                               0.5\n",
      "131                      0.75                               0.5\n",
      "132                      0.75                               0.5\n",
      "133                      0.75                               1.0\n",
      "134                      0.25                               1.0\n",
      "135                      0.00                               1.0\n",
      "136                      0.25                               0.5\n",
      "137                      1.00                               1.0\n",
      "138                      0.00                               1.0\n",
      "139                      0.00                               0.5\n",
      "140                      0.00                               1.0\n",
      "141                      0.75                               1.0\n",
      "142                      0.75                               1.0\n",
      "143                      0.50                               1.0\n",
      "144                      0.50                               1.0\n",
      "145                      0.00                               0.5\n",
      "146                      0.50                               0.5\n",
      "147                      0.00                               0.5\n",
      "148                      0.50                               0.5\n",
      "149                      0.75                               0.5\n",
      "150                      0.25                               1.0\n",
      "151                      0.50                               0.5\n",
      "152                      0.75                               0.0\n",
      "153                      0.25                               1.0\n",
      "154                      0.25                               0.5\n",
      "155                      0.00                               0.5\n",
      "156                      0.00                               0.5\n",
      "157                      0.00                               0.5\n",
      "158                      0.25                               1.0\n",
      "159                      0.75                               0.0\n",
      "160                      0.25                               1.0\n",
      "161                      1.00                               1.0\n",
      "162                      0.75                               0.5\n",
      "163                      0.50                               0.5\n",
      "164                      0.75                               0.5\n",
      "165                      0.75                               0.5\n",
      "166                      0.00                               0.5\n",
      "167                      0.75                               1.0\n",
      "168                      0.75                               1.0\n",
      "169                      1.00                               0.5\n",
      "170                      0.25                               1.0\n",
      "171                      0.50                               0.5\n",
      "172                      0.75                               1.0\n",
      "173                      1.00                               1.0\n",
      "174                      0.75                               1.0\n",
      "175                      0.75                               0.5\n",
      "176                      0.50                               1.0\n",
      "177                      0.75                               0.5\n",
      "178                      0.75                               0.5\n",
      "179                      0.50                               0.5\n",
      "180                      0.00                               0.5\n",
      "181                      0.75                               1.0\n",
      "182                      0.50                               0.5\n",
      "183                      0.00                               1.0\n",
      "184                      0.50                               1.0\n",
      "185                      0.75                               1.0\n",
      "186                      0.75                               0.5\n",
      "187                      0.25                               0.5\n",
      "188                      1.00                               0.0\n",
      "189                      0.75                               0.0\n",
      "190                      0.50                               1.0\n",
      "191                      0.75                               0.5\n",
      "192                      0.75                               1.0\n",
      "193                      0.75                               1.0\n",
      "194                      0.50                               0.0\n",
      "195                      0.25                               1.0\n",
      "196                      0.50                               1.0\n",
      "197                      0.25                               0.5\n",
      "198                      0.25                               1.0\n",
      "199                      0.00                               0.5\n",
      "200                      0.25                               0.5\n",
      "201                      0.25                               1.0\n",
      "202                      0.75                               1.0\n",
      "203                      0.00                               1.0\n",
      "204                      0.00                               0.5\n",
      "205                      0.75                               1.0\n",
      "206                      0.75                               0.5\n",
      "207                      0.75                               0.5\n",
      "208                      0.25                               0.5\n",
      "209                      0.75                               0.5\n",
      "210                      0.75                               0.5\n",
      "211                      0.25                               1.0\n",
      "212                      0.00                               1.0\n",
      "    shp_suppliers_HCMC shp_content_value_euro shp_registered_capital_euro\n",
      "0                    1            0.003656245                2.105338e-04\n",
      "1                    1            0.159049366                4.738082e-04\n",
      "2                    1            0.159049366                0.000000e+00\n",
      "3                    1            0.067641764                4.738082e-04\n",
      "4                    1            0.049360046                2.211105e-04\n",
      "5                    1            0.040219186                4.738082e-04\n",
      "6                    1            0.131626788                4.738082e-04\n",
      "7                    1            0.040219186                5.790036e-04\n",
      "8                    1            0.085922987                4.738082e-04\n",
      "9                    1            0.027970643                5.210890e-03\n",
      "10                   1            0.049360046                2.052740e-03\n",
      "11                   1            0.067641764                2.052740e-03\n",
      "12                   1            0.131626788                2.579146e-03\n",
      "13                   1            0.058500905                2.052740e-03\n",
      "14                   1            0.049360046                1.000071e-03\n",
      "15                   1            0.076782128                1.000071e-03\n",
      "16                   1            0.021937467                1.526477e-03\n",
      "17                   1            0.040219186                7.369397e-04\n",
      "18                   1            0.067641764                4.738082e-04\n",
      "19                   1            0.085922987                1.000071e-03\n",
      "20                   1            0.040219186                3.684698e-04\n",
      "21                   1            0.067641764                2.100121e-02\n",
      "22                   1            0.012797104                4.684484e-03\n",
      "23                   1            0.067641764                4.738082e-04\n",
      "24                   1            0.031078327                2.629886e-05\n",
      "25                   1            0.131626788                5.210890e-03\n",
      "26                   1            0.122485929                1.578505e-01\n",
      "27                   1            0.049360046                3.105409e-03\n",
      "28                   1            0.021937467                2.100121e-02\n",
      "29                   1            0.021937467                2.052740e-03\n",
      "30                   1            0.058500905                1.000071e-03\n",
      "31                   1            0.031078327                3.631815e-03\n",
      "32                   1            0.213894027                2.105338e-04\n",
      "33                   1            0.058500905                1.000071e-03\n",
      "34                   1            0.131626788                2.579146e-03\n",
      "35                   1            0.021937467                4.738082e-04\n",
      "36                   1            0.058500905                2.579146e-03\n",
      "37                   1            0.360146289                5.274064e-05\n",
      "38                   1            0.085922987                4.738082e-04\n",
      "39                   1            0.021937467                7.369397e-04\n",
      "40                   1            0.049360046                1.000071e-03\n",
      "41                   1            0.067641764                2.105338e-04\n",
      "42                   1            0.021937467                2.579146e-03\n",
      "43                   1            0.017367286                1.000071e-03\n",
      "44                   1            0.268738191                1.526477e-03\n",
      "45                   1            0.067641764                8.421351e-04\n",
      "46                   1            0.131626788                4.738082e-04\n",
      "47                   1            0.085922987                5.258170e-02\n",
      "48                   1            0.067641764                2.579146e-03\n",
      "49                   1            0.177330589                2.579146e-03\n",
      "50                   1            0.085922987                2.579146e-03\n",
      "51                   1            0.085922987                1.526477e-03\n",
      "52                   1            0.095063847                6.263559e-03\n",
      "53                   1            0.076782128                4.738082e-04\n",
      "54                   1            0.012797104                2.579146e-03\n",
      "55                   1            0.021937467                4.158221e-03\n",
      "56                   1            0.076782128                2.100121e-02\n",
      "57                   1            0.040219186                1.053384e-04\n",
      "58                   1            0.058500905                2.579146e-03\n",
      "59                   1            0.012797104                4.738082e-04\n",
      "60                   1            0.058500905                2.105338e-04\n",
      "61                   1            0.058500905                1.000071e-03\n",
      "62                   1            0.140767648                7.369397e-04\n",
      "63                   1            0.076782128                4.738082e-04\n",
      "64                   1            0.049360046                1.000071e-03\n",
      "65                   1            0.063071087                4.158221e-03\n",
      "66                   1            0.031078327                1.526477e-03\n",
      "67                   1            0.067641764                4.158221e-03\n",
      "68                   1            0.049360046                3.631815e-03\n",
      "69                   1            0.040219186                1.573772e-02\n",
      "70                   1            0.031078327                5.790036e-04\n",
      "71                   1            0.177330589                1.053384e-04\n",
      "72                   1            0.085922987                1.000071e-03\n",
      "73                   1            0.040219186                7.369397e-04\n",
      "74                   1            0.012797104                2.052740e-03\n",
      "75                   1            0.085922987                4.210676e-04\n",
      "76                   1            0.177330589                1.526477e-03\n",
      "77                   1            0.085922987                1.573772e-02\n",
      "78                   1            1.000000000                1.000000e+00\n",
      "79                   1            0.085922987                2.052740e-03\n",
      "80                   1            0.040219186                2.579146e-03\n",
      "81                   1            0.031078327                5.274064e-05\n",
      "82                   1            0.067641764                1.000071e-03\n",
      "83                   1            0.076782128                1.047423e-02\n",
      "84                   1            0.058500905                4.738082e-04\n",
      "85                   1            0.067641764                1.000071e-03\n",
      "86                   1            0.040219186                4.738082e-04\n",
      "87                   1            0.000000000                2.579146e-03\n",
      "88                   1            0.012797104                2.105338e-04\n",
      "89                   1            0.268738191                7.369397e-04\n",
      "90                   1            0.031078327                6.263559e-03\n",
      "91                   1            0.044789368                2.579146e-03\n",
      "92                   1            0.012797104                1.053384e-04\n",
      "93                   1            0.542961494                1.526477e-03\n",
      "94                   1            0.040219186                2.105338e-04\n",
      "95                   1            0.040219186                1.000071e-03\n",
      "96                   1            0.040219186                1.053384e-04\n",
      "97                   1            0.021937467                1.047423e-02\n",
      "98                   1            0.177330589                7.369397e-04\n",
      "99                   1            0.021937467                4.738082e-04\n",
      "100                  1            0.016453349                1.526477e-03\n",
      "101                  1            0.104204706                3.152804e-02\n",
      "102                  1            0.131626788                3.631815e-03\n",
      "103                  1            0.003656245                2.579146e-03\n",
      "104                  1            0.012797104                4.738082e-04\n",
      "105                  1            0.021937467                1.053384e-04\n",
      "106                  1            0.908592398                1.047423e-02\n",
      "107                  1            0.021937467                1.685128e-04\n",
      "108                  1            0.177330589                1.000071e-03\n",
      "109                  1            0.031078327                2.579146e-03\n",
      "110                  1            0.003656245                1.000071e-03\n",
      "111                  1            0.031078327                2.052740e-03\n",
      "112                  1            0.140767648                5.210890e-03\n",
      "113                  1            0.067641764                5.210890e-03\n",
      "114                  1            0.058500905                2.052740e-03\n",
      "115                  1            0.021937467                0.000000e+00\n",
      "116                  1            0.058500905                5.258170e-02\n",
      "117                  0            0.040219186                4.738082e-04\n",
      "118                  0            0.017367286                4.738082e-04\n",
      "119                  1            0.049360046                7.369397e-04\n",
      "120                  1            0.021937467                1.000071e-03\n",
      "121                  1            0.040219186                1.526477e-03\n",
      "122                  1            0.040219186                2.105338e-04\n",
      "123                  1            0.104204706                1.053384e-04\n",
      "124                  1            0.012797104                4.738082e-04\n",
      "125                  1            0.040219186                1.526477e-03\n",
      "126                  1            0.085922987                5.790036e-04\n",
      "127                  1            0.031078327                2.579146e-03\n",
      "128                  1            0.040219186                1.526477e-03\n",
      "129                  1            0.076782128                2.052740e-03\n",
      "130                  1            0.131626788                8.368896e-03\n",
      "131                  1            0.076782128                2.579146e-03\n",
      "132                  1            0.131626788                4.738082e-04\n",
      "133                  1            0.085922987                3.105409e-03\n",
      "134                  1            0.177330589                5.210890e-03\n",
      "135                  1            0.058500905                5.210890e-03\n",
      "136                  1            0.076782128                2.052740e-03\n",
      "137                  1            0.040219186                1.000071e-03\n",
      "138                  1            0.031078327                1.573772e-02\n",
      "139                  1            0.085922987                5.210890e-03\n",
      "140                  1            0.085922987                3.158721e-04\n",
      "141                  1            0.159049366                4.738082e-04\n",
      "142                  1            0.067641764                4.738082e-04\n",
      "143                  1            0.131626788                4.738082e-04\n",
      "144                  1            0.040219186                5.790036e-04\n",
      "145                  1            0.131626788                2.579146e-03\n",
      "146                  1            0.058500905                2.052740e-03\n",
      "147                  1            0.049360046                1.000071e-03\n",
      "148                  1            0.040219186                7.369397e-04\n",
      "149                  1            0.067641764                2.100121e-02\n",
      "150                  1            0.067641764                4.738082e-04\n",
      "151                  1            0.031078327                2.629886e-05\n",
      "152                  1            0.131626788                5.210890e-03\n",
      "153                  1            0.122485929                1.578505e-01\n",
      "154                  1            0.213894027                2.105338e-04\n",
      "155                  1            0.058500905                1.000071e-03\n",
      "156                  1            0.131626788                2.579146e-03\n",
      "157                  1            0.021937467                4.738082e-04\n",
      "158                  1            0.058500905                2.579146e-03\n",
      "159                  1            0.085922987                4.738082e-04\n",
      "160                  1            0.021937467                7.369397e-04\n",
      "161                  1            0.049360046                1.000071e-03\n",
      "162                  1            0.067641764                2.105338e-04\n",
      "163                  1            0.021937467                2.579146e-03\n",
      "164                  1            0.268738191                1.526477e-03\n",
      "165                  1            0.067641764                8.421351e-04\n",
      "166                  1            0.131626788                4.738082e-04\n",
      "167                  1            0.085922987                5.258170e-02\n",
      "168                  1            0.067641764                2.579146e-03\n",
      "169                  1            0.177330589                2.579146e-03\n",
      "170                  1            0.085922987                2.579146e-03\n",
      "171                  1            0.085922987                1.526477e-03\n",
      "172                  1            0.076782128                4.738082e-04\n",
      "173                  1            0.012797104                2.579146e-03\n",
      "174                  1            0.040219186                1.053384e-04\n",
      "175                  1            0.058500905                2.579146e-03\n",
      "176                  1            0.049360046                1.047423e-02\n",
      "177                  1            0.058500905                1.000071e-03\n",
      "178                  1            0.140767648                7.369397e-04\n",
      "179                  1            0.063071087                4.158221e-03\n",
      "180                  1            0.031078327                1.526477e-03\n",
      "181                  1            0.067641764                4.158221e-03\n",
      "182                  1            0.031078327                3.105409e-03\n",
      "183                  1            0.049360046                3.631815e-03\n",
      "184                  1            0.040219186                1.573772e-02\n",
      "185                  1            0.085922987                4.210676e-04\n",
      "186                  1            0.177330589                1.526477e-03\n",
      "187                  1            0.040219186                2.579146e-03\n",
      "188                  1            0.067641764                1.000071e-03\n",
      "189                  1            0.076782128                1.047423e-02\n",
      "190                  1            0.067641764                1.000071e-03\n",
      "191                  1            0.012797104                2.105338e-04\n",
      "192                  1            0.268738191                7.369397e-04\n",
      "193                  1            0.031078327                6.263559e-03\n",
      "194                  1            0.044789368                2.579146e-03\n",
      "195                  1            0.012797104                1.053384e-04\n",
      "196                  1            0.040219186                2.105338e-04\n",
      "197                  1            0.177330589                7.369397e-04\n",
      "198                  1            0.021937467                4.738082e-04\n",
      "199                  1            0.131626788                3.631815e-03\n",
      "200                  1            0.003656245                2.579146e-03\n",
      "201                  1            0.012797104                4.738082e-04\n",
      "202                  1            0.021937467                1.053384e-04\n",
      "203                  1            0.031078327                2.579146e-03\n",
      "204                  1            0.058500905                2.052740e-03\n",
      "205                  1            0.040219186                1.526477e-03\n",
      "206                  1            0.085922987                5.790036e-04\n",
      "207                  1            0.031078327                2.579146e-03\n",
      "208                  1            0.131626788                8.368896e-03\n",
      "209                  1            0.076782128                2.579146e-03\n",
      "210                  1            0.131626788                4.738082e-04\n",
      "211                  1            0.177330589                5.210890e-03\n",
      "212                  1            0.058500905                5.210890e-03\n",
      "\n",
      "$y\n",
      "  0   2   4   5   6   8   9  10  11  12  19  20  21  22  23  24  25  26  27  28 \n",
      "  0   0   0   0   0  20   0   5  10  30   0   5   0 100  10   5   0   0  30  50 \n",
      " 29  30  32  38  39  44  45  46  47  48  49  50  53  55  56  58  61  62  63  65 \n",
      " 70   0  30  10  20  10   0   0  60  10   5   0  20   0   0   0   0   5   0   0 \n",
      " 66  67  68  69  72  73  74  77  78  79  80  81  84  93  94  95  96 101 102 105 \n",
      "  0   0  10  10   5   0  30  40  10  50  10  50   0   0   0  20  90  50  30  35 \n",
      "109 111 112 113 114 118 125 126 129 130 132 134 136 138 140 143 147 149 151 152 \n",
      "  0   0   0  10   5  50  10   0   5   5   0  60   5  50  50  30   0  45 100  10 \n",
      "153 156 158 162 163 164 165 166 168 171 172 173 175 177 178 181 182 183 184 185 \n",
      " 20   0   0  10   0  20   0  50   0   0   0  80  12 100   0   5  50  50  20  40 \n",
      "192 193 194 195 196 197 199 201 202 203 206 207 209 210 211 216 217 218 219 221 \n",
      "  0 100  20  50   0   0   5  20  30   5  10   0   0   0   0   0   0   5  20   5 \n",
      "222 223 228 229 230 232 233 235 236 237 238 239 240 241 242 243 244 246 249 250 \n",
      "  0   0   7  20  40  20  40  10  40  30  20  20  30  10  30  10  60  30   0   0 \n",
      "251 252 254 256 257 263 264 265 266 267 274 275 279 280 283 285 286 287 289 290 \n",
      "  0   0   0   0  10   0 100  20  20 100  20  20  10  30  30   0   0   1   0  10 \n",
      "292 293 294 295 296 297 298 301 302 303 304 305 313 314 317 318 320 324 325 330 \n",
      "  0  10   0  15   5   5  40  40  20  50  50  60   0   0  50  40   0   0 100  70 \n",
      "337 338 340 341 342 347 350 351 352 354 355 356 359 360 361 363 364 365 366 372 \n",
      " 10  10  10  10  20  15   4 100   0  10  10  20   0   0  80  20  10  60  70  20 \n",
      "373 374 375 376 379 386 387 388 389 390 391 392 393 \n",
      " 50   0   0   5   0 100  40  30  20  20  30  30  10 \n",
      "\n",
      "$yfinal\n",
      "  0   2   4   5   6   8   9  10  11  12  19  20  21  22  23  24  25  26  27  28 \n",
      "  0   0   0   0   0  20   0   5  10  30   0   5   0 100  10   5   0   0  30  50 \n",
      " 29  30  32  38  39  44  45  46  47  48  49  50  53  55  56  58  61  62  63  65 \n",
      " 70   0  30  10  20  10   0   0  60  10   5   0  20   0   0   0   0   5   0   0 \n",
      " 66  67  68  69  72  73  74  77  78  79  80  81  84  93  94  95  96 101 102 105 \n",
      "  0   0  10  10   5   0  30  40  10  50  10  50   0   0   0  20  90  50  30  35 \n",
      "109 111 112 113 114 118 125 126 129 130 132 134 136 138 140 143 147 149 151 152 \n",
      "  0   0   0  10   5  50  10   0   5   5   0  60   5  50  50  30   0  45 100  10 \n",
      "153 156 158 162 163 164 165 166 168 171 172 173 175 177 178 181 182 183 184 185 \n",
      " 20   0   0  10   0  20   0  50   0   0   0  80  12 100   0   5  50  50  20  40 \n",
      "192 193 194 195 196 197 199 201 202 203 206 207 209 210 211 216 217 218 219 221 \n",
      "  0 100  20  50   0   0   5  20  30   5  10   0   0   0   0   0   0   5  20   5 \n",
      "222 223 228 229 230 232 233 235 236 237 238 239 240 241 242 243 244 246 249 250 \n",
      "  0   0   7  20  40  20  40  10  40  30  20  20  30  10  30  10  60  30   0   0 \n",
      "251 252 254 256 257 263 264 265 266 267 274 275 279 280 283 285 286 287 289 290 \n",
      "  0   0   0   0  10   0 100  20  20 100  20  20  10  30  30   0   0   1   0  10 \n",
      "292 293 294 295 296 297 298 301 302 303 304 305 313 314 317 318 320 324 325 330 \n",
      "  0  10   0  15   5   5  40  40  20  50  50  60   0   0  50  40   0   0 100  70 \n",
      "337 338 340 341 342 347 350 351 352 354 355 356 359 360 361 363 364 365 366 372 \n",
      " 10  10  10  10  20  15   4 100   0  10  10  20   0   0  80  20  10  60  70  20 \n",
      "373 374 375 376 379 386 387 388 389 390 391 392 393 \n",
      " 50   0   0   5   0 100  40  30  20  20  30  30  10 \n",
      "\n",
      "$final_fit\n",
      "Conditional Inference Random Forest \n",
      "\n",
      "213 samples\n",
      " 34 predictor\n",
      "\n",
      "No pre-processing\n",
      "Resampling: Cross-Validated (10 fold, repeated 5 times) \n",
      "Summary of sample sizes: 192, 192, 191, 191, 191, 190, ... \n",
      "Resampling results across tuning parameters:\n",
      "\n",
      "  mtry  RMSE      Rsquared   MAE     \n",
      "   2    23.85134  0.2264697  18.43301\n",
      "  18    23.38292  0.2008957  17.79058\n",
      "  34    23.48085  0.1853007  17.80837\n",
      "\n",
      "MAE was used to select the optimal model using the smallest value.\n",
      "The final value used for the model was mtry = 18.\n",
      "\n",
      "$final_vars\n",
      " [1] \"inundation_duration_h\"              \"water_depth_cm\"                    \n",
      " [3] \"contaminations.0\"                   \"flowvelocity\"                      \n",
      " [5] \"emergency_measures.1\"               \"emergency_measures.2\"              \n",
      " [7] \"emergency_measures.3\"               \"emergency_measures.4\"              \n",
      " [9] \"emergency_measures.7\"               \"emergency_measures.8\"              \n",
      "[11] \"overall_problem_house\"              \"protect_valuables_impl\"            \n",
      "[13] \"water_barriers_impl\"                \"pumping_equipment_impl\"            \n",
      "[15] \"elevation_building_impl\"            \"resistant_material_building_impl\"  \n",
      "[17] \"electricity_higher_impl\"            \"flood_protections_impl\"            \n",
      "[19] \"flood_experience\"                   \"bage\"                              \n",
      "[21] \"b_area\"                             \"hh_monthly_income_cat\"             \n",
      "[23] \"shp_owner\"                          \"shp_sector\"                        \n",
      "[25] \"shp_employees\"                      \"shp_avgmonthly_sale_cat\"           \n",
      "[27] \"shp_profits_last5years\"             \"resilience_more_future_affected\"   \n",
      "[29] \"resilience_govern_warnings_helpful\" \"resilience_govern_careing\"         \n",
      "[31] \"perception_private_economy_future\"  \"shp_suppliers_HCMC\"                \n",
      "[33] \"shp_content_value_euro\"             \"shp_registered_capital_euro\"       \n",
      "\n",
      "$roc\n",
      "NULL\n",
      "\n",
      "$trControl\n",
      "$trControl$method\n",
      "[1] \"repeatedcv\"\n",
      "\n",
      "$trControl$number\n",
      "[1] 10\n",
      "\n",
      "$trControl$repeats\n",
      "[1] 5\n",
      "\n",
      "$trControl$search\n",
      "[1] \"grid\"\n",
      "\n",
      "$trControl$p\n",
      "[1] 0.75\n",
      "\n",
      "$trControl$initialWindow\n",
      "NULL\n",
      "\n",
      "$trControl$horizon\n",
      "[1] 1\n",
      "\n",
      "$trControl$fixedWindow\n",
      "[1] TRUE\n",
      "\n",
      "$trControl$skip\n",
      "[1] 0\n",
      "\n",
      "$trControl$verboseIter\n",
      "[1] FALSE\n",
      "\n",
      "$trControl$returnData\n",
      "[1] TRUE\n",
      "\n",
      "$trControl$returnResamp\n",
      "[1] \"final\"\n",
      "\n",
      "$trControl$savePredictions\n",
      "[1] FALSE\n",
      "\n",
      "$trControl$classProbs\n",
      "[1] FALSE\n",
      "\n",
      "$trControl$summaryFunction\n",
      "function (data, lev = NULL, model = NULL) \n",
      "{\n",
      "    if (is.character(data$obs)) \n",
      "        data$obs <- factor(data$obs, levels = lev)\n",
      "    postResample(data[, \"pred\"], data[, \"obs\"])\n",
      "}\n",
      "<bytecode: 0x000001bf3ca11608>\n",
      "<environment: namespace:caret>\n",
      "\n",
      "$trControl$selectionFunction\n",
      "[1] \"best\"\n",
      "\n",
      "$trControl$preProcOptions\n",
      "$trControl$preProcOptions$thresh\n",
      "[1] 0.95\n",
      "\n",
      "$trControl$preProcOptions$ICAcomp\n",
      "[1] 3\n",
      "\n",
      "$trControl$preProcOptions$k\n",
      "[1] 5\n",
      "\n",
      "$trControl$preProcOptions$freqCut\n",
      "[1] 19\n",
      "\n",
      "$trControl$preProcOptions$uniqueCut\n",
      "[1] 10\n",
      "\n",
      "$trControl$preProcOptions$cutoff\n",
      "[1] 0.9\n",
      "\n",
      "\n",
      "$trControl$sampling\n",
      "NULL\n",
      "\n",
      "$trControl$index\n",
      "NULL\n",
      "\n",
      "$trControl$indexOut\n",
      "NULL\n",
      "\n",
      "$trControl$indexFinal\n",
      "NULL\n",
      "\n",
      "$trControl$timingSamps\n",
      "[1] 0\n",
      "\n",
      "$trControl$predictionBounds\n",
      "[1] FALSE FALSE\n",
      "\n",
      "$trControl$seeds\n",
      "[1] NA\n",
      "\n",
      "$trControl$adaptive\n",
      "$trControl$adaptive$min\n",
      "[1] 5\n",
      "\n",
      "$trControl$adaptive$alpha\n",
      "[1] 0.05\n",
      "\n",
      "$trControl$adaptive$method\n",
      "[1] \"gls\"\n",
      "\n",
      "$trControl$adaptive$complete\n",
      "[1] TRUE\n",
      "\n",
      "\n",
      "$trControl$trim\n",
      "[1] FALSE\n",
      "\n",
      "$trControl$allowParallel\n",
      "[1] TRUE\n",
      "\n",
      "\n",
      "$bestTunes\n",
      "        mtry\n",
      "Fold 1    18\n",
      "Fold 2    34\n",
      "Fold 3    34\n",
      "Fold 4    34\n",
      "Fold 5    18\n",
      "Fold 6    18\n",
      "Fold 7    18\n",
      "Fold 8    34\n",
      "Fold 9    34\n",
      "Fold 10   18\n",
      "\n",
      "$finalTune\n",
      "  mtry\n",
      "2   18\n",
      "\n",
      "$summary\n",
      "    RMSE   Rsquared        MAE   \n",
      " 23.7981     0.1602    17.6271   \n",
      "\n",
      "attr(,\"class\")\n",
      "[1] \"nestcv.train\"\n",
      "\n",
      "\n",
      "Workaround Evaluation of CRF\n",
      "Model Performance:\n",
      "        Root Mean Square Error: 20.18\n",
      "        Symmetric Mean Abs. Percentage Error: 104.832\n",
      "        Mean Absolute Error: 14.878\n",
      "        Mean Bias Error: -0.033\n",
      "        R-Score: 0.388\n",
      "    \n",
      "\n",
      "Select features based on permutation feature importance\n",
      "5 most important features: ['water_depth_cm', 'perception_private_economy_future', 'bage', 'shp_profits_last5years', 'resilience_govern_careing']\n",
      "\n",
      "Appling xgb on Target_businessreduction:\n",
      "Dropping 36 records from entire dataset due that these values are nan in target variable\n",
      "Using  361  records, from those have  {149}  cases with zero-loss or zero-reduction\n",
      "outer CV: neg. MAE: -17.777 (2.834)\n",
      "[18:28:09] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:09] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:09] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:09] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:09] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:09] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:09] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:09] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:09] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:09] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:09] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:09] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:09] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:09] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:09] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:09] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:09] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:09] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:10] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:10] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:10] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:10] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:10] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:10] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:10] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:10] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:10] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:10] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:10] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:10] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:10] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:10] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:10] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:10] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:10] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:10] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:10] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:10] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:10] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:10] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:10] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:10] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:10] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:10] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:10] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:10] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:10] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:10] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:10] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:10] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:10] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:10] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:10] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:10] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:10] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:10] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:10] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:10] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:10] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:10] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:10] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:10] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:10] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:10] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:10] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:10] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:10] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:10] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:10] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:10] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:10] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:10] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:10] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:10] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:10] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:10] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:10] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:10] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:10] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:10] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:10] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:10] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:10] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:10] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:10] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:10] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:11] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:11] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:11] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:11] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:11] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:11] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:11] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:11] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:11] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:11] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:11] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:11] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:11] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:11] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:11] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:11] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:11] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:11] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:11] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:11] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:11] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:11] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:11] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:12] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:12] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:12] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:12] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:12] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:12] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:13] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:13] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:13] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:13] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:13] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:13] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:14] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:14] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:14] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:14] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:14] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:14] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:14] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:14] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:14] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:14] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:14] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:14] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:14] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:14] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:15] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:15] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:15] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:15] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:15] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:15] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:15] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:15] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:15] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:15] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:15] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:16] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:16] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:16] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:16] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:16] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:16] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:16] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:16] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:16] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:16] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:16] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:16] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:16] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:16] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:16] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:16] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:16] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:16] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:16] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:16] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:16] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:17] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:17] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:17] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:17] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:17] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:17] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:17] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:17] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:17] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:17] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:17] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:17] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:17] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:17] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:17] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:17] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:17] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:17] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:17] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:17] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:17] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:17] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:17] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:17] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:17] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:17] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:17] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:17] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:17] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:17] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:17] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:17] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:17] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:17] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:17] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:17] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:17] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:17] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:17] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:17] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:17] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:17] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:17] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:17] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:17] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:17] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:17] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:17] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:17] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:17] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:17] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:17] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:18] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:18] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:18] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:18] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:18] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:18] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:18] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:18] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:18] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:18] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:18] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:18] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:18] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:18] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:18] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:18] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:18] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:18] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:18] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:18] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:18] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:18] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:18] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:18] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:18] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:18] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:18] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:18] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:18] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:18] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:18] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:18] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:18] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:18] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:18] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:18] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:18] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:18] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:18] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:18] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:18] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:18] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:19] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:19] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:19] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:19] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:19] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:19] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:19] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:19] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:19] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:19] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:19] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:19] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:19] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:19] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:19] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:19] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:19] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:19] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:19] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:19] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:19] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:19] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:19] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:19] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:19] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:19] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:19] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:20] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:20] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:20] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:20] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:20] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:20] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:20] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:20] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:20] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:20] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:20] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:20] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:20] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:20] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:20] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:20] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:20] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:20] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:20] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:20] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:20] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:20] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:20] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:20] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:20] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:20] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:20] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:20] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:20] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:20] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:20] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:20] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:20] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:20] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:20] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:20] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:20] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:20] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:20] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:20] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:20] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:20] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:20] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:20] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:20] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:20] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:21] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:21] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:21] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:21] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:21] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:21] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:21] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:21] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:21] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:21] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:21] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:21] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:21] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:21] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:21] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:21] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:21] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:21] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:21] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:21] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:21] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:21] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:21] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:21] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:21] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:21] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:21] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:21] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:21] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:21] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:21] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:21] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:21] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:21] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:21] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:21] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:21] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:21] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:21] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:21] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:21] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:21] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:21] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:21] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:21] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:21] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:21] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:21] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:21] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:21] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:21] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:21] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:22] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:22] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:22] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:22] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:22] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:22] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:22] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:22] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:22] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:22] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:22] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:22] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:22] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:22] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:22] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:22] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:22] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:22] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:22] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:22] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:22] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:23] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:23] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:23] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:23] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:23] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:23] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:23] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:23] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:23] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:23] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:23] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:23] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:23] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:23] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:23] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:23] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:23] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:23] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:23] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:23] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:23] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:23] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:23] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:23] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:23] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:23] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:23] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:23] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:23] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:23] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:23] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:23] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:23] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:23] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:24] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:24] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:24] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:24] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:24] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:24] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:24] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:24] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:24] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:24] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:24] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:24] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:24] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:24] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:24] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:24] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:24] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:24] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:24] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:24] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:24] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:24] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:24] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:24] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:24] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:24] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:24] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:24] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:24] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:24] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:24] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:24] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:24] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:25] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:25] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:25] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:25] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:25] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:25] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:25] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:25] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:25] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:25] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:25] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:25] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:25] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:25] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:25] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:25] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:25] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:25] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:25] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:25] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:25] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:25] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:25] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:25] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:25] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:25] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[18:28:25] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "\n",
      "Evaluation of xgb\n",
      "Model Performance:\n",
      "        Root Mean Square Error: 21.82\n",
      "        Symmetric Mean Abs. Percentage Error: 119.511\n",
      "        Mean Absolute Error: 16.241\n",
      "        Mean Bias Error: -0.193\n",
      "        R-Score: 0.25\n",
      "    \n",
      "\n",
      "Select features based on permutation feature importance\n",
      "5 most important features: ['emergency_measures.7', 'water_depth_cm', 'shp_registered_capital_euro', 'emergency_measures.2', 'perception_private_economy_future']\n",
      "\n",
      "Appling en on Target_businessreduction:\n",
      "Dropping 36 records from entire dataset due that these values are nan in target variable\n",
      "Using  213  records, from those have  {73}  cases with zero-loss or zero-reduction\n",
      "outer CV: neg. MAE: -18.222 (3.220)\n",
      "\n",
      "Evaluation of en\n",
      "Model Performance:\n",
      "        Root Mean Square Error: 21.893\n",
      "        Symmetric Mean Abs. Percentage Error: 111.462\n",
      "        Mean Absolute Error: 16.434\n",
      "        Mean Bias Error: 0.0\n",
      "        R-Score: 0.28\n",
      "    \n",
      "\n",
      "Select features based on permutation feature importance\n",
      "5 most important features: ['emergency_measures.7', 'flowvelocity', 'water_depth_cm', 'perception_private_economy_future', 'bage']\n"
     ]
    }
   ],
   "source": [
    "## iterate over piplines. Each piplines contains precrosseing methods and several  classifier\n",
    "pipelines = [\"pipe_crf\", \"pipe_xgb\", \"pipe_en\"]  # TODO impl \"pipe_crf\"\n",
    "#pipelines = [\"pipe_logreg\", \"pipe_xgb\", \"pipe_en\", \"pipe_crf\"]  # TODO impl \"pipe_crf\"\n",
    "eval_set_list = []\n",
    "models_trained = {}\n",
    "df_feature_importances = pd.DataFrame(index=df_candidates.drop(target, axis=1).columns.to_list())\n",
    "models_scores = {}\n",
    "\n",
    "## Load set of hyperparamters\n",
    "hyperparams_set = load_config(\"../../../utils/hyperparameter_sets.json\")\n",
    "\n",
    "\n",
    "for pipe_name in pipelines:\n",
    "\n",
    "    model_name = pipe_name.split('_')[1]\n",
    "    print( f\"\\nAppling {model_name} on {target}:\")\n",
    " \n",
    "    df_candidates_t = df_candidates\n",
    "\n",
    "    if target == \"Target_relative_contentloss_euro\":\n",
    "        print(f\"Removing {df_candidates_t.loc[df_candidates_t[target]==0.0,:].shape[0]} zero loss records\")\n",
    "        df_candidates_t = df_candidates_t.loc[df_candidates_t[target]!=0.0,:]\n",
    "        print(f\"Keeping {df_candidates_t.shape} damage cases for model training and evaluation\")\n",
    "\n",
    "    ## drop samples where target is nan\n",
    "    print(f\"Dropping {df_candidates_t[f'{target}'].isna().sum()} records from entire dataset due that these values are nan in target variable\")\n",
    "    df_candidates_t = df_candidates_t[ ~df_candidates_t[f\"{target}\"].isna()]\n",
    "    \n",
    "    ## EN: drop samples where any value is nan\n",
    "    if (model_name == \"en\") | (model_name == \"crf\"):\n",
    "        df_candidates_t.dropna(inplace=True)\n",
    "\n",
    "    ###############\n",
    "    # ## LogReg: for binary version of relative content loss (chance of loss)\n",
    "    # if (target == \"Target_relative_contentloss_euro\") & (model_name == \"logreg\"):\n",
    "    #     ## set target as binary class\n",
    "    #     df_candidates_t[target][df_candidates_t[target] > 0] = 1\n",
    "    #     df_candidates_t[target] = df_candidates_t[target].astype(\"Int64\")\n",
    "    #     df_candidates_t.dropna(inplace=True)\n",
    "    ###############\n",
    "    print(\n",
    "        \"Using \", df_candidates_t.shape[0], \" records, from those have \", \n",
    "            { (df_candidates_t[target][df_candidates_t[target]==0.0]).count() }, \n",
    "            f\" cases with zero-loss or zero-reduction\"\n",
    "    )\n",
    "\n",
    "    X_unscaled = df_candidates_t.drop(target, axis=1)  # remove  target from X\n",
    "    y = df_candidates_t[target]\n",
    "     \n",
    "    ## normalize data \n",
    "    scaler_for_X = MinMaxScaler()\n",
    "    X = scaler_for_X.fit_transform(X_unscaled)\n",
    "\n",
    "    # ## save evaluation set for later usage in feature importance\n",
    "    # eval_set =  pd.concat([y, X], axis=1) \n",
    "    # eval_set_list.append({pipe_name : eval_set})\n",
    "\n",
    "    ## load pipe for non-transfomred model\n",
    "    pipe = joblib.load(f'./pipelines/{pipe_name}.pkl')\n",
    "\n",
    "    ## Hyperparmater and cv setting       \n",
    "    param_grid = hyperparams_set[f\"{model_name}_hyperparameters\"]\n",
    "\n",
    "    ## EN (test with bagging)\n",
    "    # if model_name == \"en\":\n",
    "    #     ## paramter names when bootstrapping mehtod is applied\n",
    "    #     print(\"Testing Elastic Net with bagging\")\n",
    "    #     param_grid = { k.replace('model', 'bagging__estimator') : v for (k, v) in param_grid.items()}\n",
    "\n",
    "    ## define inner and outer cv\n",
    "    ###############\n",
    "    # if (target == \"Target_relative_contentloss_euro\") & (model_name == \"logreg\"):\n",
    "        # ## set cv for classification task        \n",
    "        # inner_cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=10, random_state=seed)\n",
    "        # outer_cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=10, random_state=seed)\n",
    "        \n",
    "        # ## inner cv with hyperparameter tuning \n",
    "        # score_name = \"f1\"\n",
    "        # model_inner_cv = RandomizedSearchCV(\n",
    "        #     estimator= pipe,\n",
    "        #     param_distributions=param_grid,\n",
    "        #     cv=inner_cv, \n",
    "        #     scoring=score_name,  # accurrarcy\n",
    "        #     ##\"\", #\"neg_mean_squared_error\",#\"r2\" #TODO classifcation: test also e.g \"f1\" or recall or \"f1_micro\", \"neg_mean_absolute_error\",\n",
    "        #     refit=True,   \n",
    "        #     random_state=seed\n",
    "        # )\n",
    "        # # execute the nested cv\n",
    "        # scores = cross_val_score(\n",
    "        #     model_inner_cv, \n",
    "        #     X, y, \n",
    "        #     scoring=score_name, \n",
    "        #     cv=outer_cv, \n",
    "        #     n_jobs=-1\n",
    "        # )\n",
    "        # print(score_name, \" : %.3f (%.3f)\"%(np.mean(scores), np.std(scores)))\n",
    "    ###############\n",
    "    # else:\n",
    "    if model_name != \"crf\":\n",
    "\n",
    "        inner_cv = RepeatedKFold(n_splits=10, n_repeats=5, random_state=seed)  # decrease repeats to 5 due to long processing time\n",
    "        outer_cv = RepeatedKFold(n_splits=10, n_repeats=5, random_state=seed)\n",
    "\n",
    "        ## inner cv with hyperparameter tuning\n",
    "        model = RandomizedSearchCV(\n",
    "            estimator= pipe,\n",
    "            param_distributions=param_grid,\n",
    "            cv=inner_cv, \n",
    "            scoring= \"neg_mean_absolute_error\",\n",
    "            ##\"\", #\"neg_mean_squared_error\",#\"r2\" #TODO classifcation: test also e.g \"f1\" or recall or \"f1_micro\", \"neg_mean_absolute_error\",\n",
    "            refit=True,   \n",
    "            random_state=seed\n",
    "        )\n",
    "\n",
    "         # get generalization performance based on tuned model\n",
    "        scores = cross_validate(   # allows specifying multiple metrics for evaluation comparated to cross_val_score\n",
    "        #cross_val_score(\n",
    "            model, \n",
    "            X, y, \n",
    "            # return_train_score=  # if True: more computanitonal expensive, gives scores of training sets\n",
    "            scoring=score_names_for_performance,  # Strategy to evaluate the performance of the cross-validated model on the test set.\n",
    "            # TODO find out if score metrics in outer have to be the same also in hyperp. tunning -probly not\n",
    "            cv=outer_cv, \n",
    "            n_jobs=-1\n",
    "        ) \n",
    "        #print(scores.keys())\n",
    "        print(\"outer CV: neg. MAE: %.3f (%.3f)\"%(scores[\"test_neg_MAE\"].mean(), np.std(scores[\"test_neg_MAE\"])))\n",
    "        models_scores[f\"{model_name}\"] = scores ## store scores for FI weighting\n",
    "\n",
    "\n",
    "        # if model_name ==\"xgb\":\n",
    "        #     ## Fit best model on training set\n",
    "        #     print(\"Testing early stopping for XGB\")\n",
    "        #     model.fit(\n",
    "        #         X, y,\n",
    "        #         model__early_stopping_rounds=3,\n",
    "        #         model__eval_metric=\"mae\",\n",
    "        #         model__eval_set=[(X, y)],\n",
    "        #         model__verbose=False\n",
    "        #     )\n",
    "        # else:\n",
    "        ## TODO check if fit() is needed for evaluation of outer cv\n",
    "        model.fit(X, y)\n",
    "\n",
    "        ## store best trained model\n",
    "        models_trained[f\"trained_{model_name}\"] = model\n",
    "        \n",
    "        print(f\"\\nEvaluation of {model_name}\")\n",
    "        y_pred = model.predict(X)\n",
    "        e.evaluation_report(y, y_pred)\n",
    "\n",
    "\n",
    "    if model_name == \"crf\":\n",
    "        base.set_seed(seed)\n",
    " \n",
    "        model = nestedcv.nestcv_train(\n",
    "            y=y, \n",
    "            x=pd.DataFrame(X, columns=X_unscaled.columns),\n",
    "            method=\"cforest\",\n",
    "            savePredictions=\"final\",\n",
    "            outer_train_predict=True,\n",
    "            #tuneGrid=tg, #cv_cores=2,  # leads to random errors\n",
    "            metric='MAE',#'RMSE',  # RMSE unit of target or use MAE due that more robust than RMSE further metrics options Rsquared, RMSE, MAE \n",
    "                # RMSE penalizes large gaps more harshly than MAE\n",
    "            # maximize=True,\n",
    "            # #na_action =  stats.na_pass,\n",
    "            controls = #party.cforest_control( \n",
    "                party.cforest_unbiased(\n",
    "                # only mtry gets tuned by grid\n",
    "                mtry=2,  # mtry=0 =Bagging without random input var sampling\n",
    "                ntree = 100,  # didnt improved with 200 or 500 trees\n",
    "                # mincriterion = 0.05,   # the value of the test statistic (for testtype == \"Teststatistic\"), or 1 - p-value (for other values of testtype) that must be exceeded in order to implement a split.\n",
    "                #replace = False,\n",
    "                #fraction = 0.632,   # fraction of number of observations to draw without replacement (only relevant if replace = FALSE).\n",
    "            ),  # cforest_unbiased= subsampling without replacement repalce=False a\n",
    "            trControl = caret.trainControl(\n",
    "                method = \"repeatedcv\",  # \"oob\" - then no repeats are needed\n",
    "                number = 10,   ## = K-folds\n",
    "                repeats = 5,  # number of tried values for mtry\n",
    "                #savePredictions = \"final\"  # saves predictions from optimal tuning parameters\n",
    "            )\n",
    "        )\n",
    "        crf_model = model\n",
    "        print(model) \n",
    "        #base.warnings()\n",
    "        \n",
    "        ## store best trained model\n",
    "        models_trained[f\"trained_{model_name}\"] = model\n",
    "        \n",
    "        ## TODO get MAE score of each Fold for R CRF\n",
    "\n",
    "        # print(score_name, \" : %.3f (%.3f)\"%(np.mean(scores), np.std(scores)))\n",
    "        # ## store scores for FI weighting\n",
    "        # models_scores[f\"{model_name}_{score_name}\"] = np.mean(scores)\n",
    "\n",
    "        print(\"\\nWorkaround Evaluation of CRF\")\n",
    "        #y_pred = stats_r.predict(model, newdata=X_test)#, OOB=True, type=\"response\") #  type = \"prob\" # conditional class probabilities extractPrediction(\n",
    "        y_pred = stats_r.predict(\n",
    "            model, \n",
    "            newdata=pd.concat(\n",
    "                [y.reset_index(), pd.DataFrame(X, columns=X_unscaled.columns)], \n",
    "                axis=1,\n",
    "            ).drop(\"index\", axis=1), #, #  type = \"raw\" or \"prob\" # conditional class probabilities extractPrediction()\n",
    "        )\n",
    "        y_pred = base.round(y_pred)\n",
    "        e.evaluation_report(y, y_pred) \n",
    "\n",
    "        # print(f\"\\nEvaluation of {model_name}\")\n",
    "        # y_pred = stats_r.predict(model, newdata=X)#, OOB=True, type=\"response\") #  type = \"prob\" # conditional class probabilities extractPrediction(\n",
    "        # y_pred = base.round(y_pred)\n",
    "        # e.evaluation_report(y_test, y_pred)\n",
    "\n",
    "    ## Evaluate\n",
    "    ## print evaluation report + check for overfitting \n",
    "    # print(f\"\\nEvaluation of {model_name}\")\n",
    "    # y_pred = model.predict(X)\n",
    "    # e.evaluation_report(y, y_pred)\n",
    "\n",
    "\n",
    "    filename = f'./models_trained/{model_name}_{target}.sav'\n",
    "    #pickle.dump(model_cv.best_estimator_, open(filename, 'wb'))\n",
    "    pickle.dump(model, open(filename, 'wb'))\n",
    "\n",
    "\n",
    "    ## Feature importance\n",
    "    print(\"\\nSelect features based on permutation feature importance\")\n",
    "    \n",
    "    if model_name == \"crf\":\n",
    "        ## party.varimp needs refitted model based on best hyperparameters\n",
    "        best_hyperparameters = fs.r_best_hyperparamters(model)\n",
    "        best_hyperparameters = fs.r_dataframe_to_pandas(best_hyperparameters)\n",
    "        #cit_model = partykit.ctree(Formula(f'{target} ~ .'),  \n",
    "        model = party.cforest(Formula(f'{target} ~ .'),  \n",
    "            data=pd.concat(\n",
    "                    [y.reset_index(), pd.DataFrame(X, columns=X_unscaled.columns)], \n",
    "                    axis=1,\n",
    "                    ).drop(\"index\", axis=1),\n",
    "            #weights=1,\n",
    "            control= party.cforest_control(mtry=best_hyperparameters.mtry, ntree=300)\n",
    "            #control= party.cforest_unbiased(mtry=best_hyperparameters.mtry, ntree=300)\n",
    "            #control = partykit.ctree_control(mincriterion = 0.8)\n",
    "        )\n",
    "        #print(crf_model)\n",
    "        varimp = party.varimp(model, conditional = True )  # compute conditional variable importance scores\n",
    "        df_importance = pd.DataFrame(\n",
    "            {f\"{model_name}_importances\" : varimp},\n",
    "            index=X_unscaled.columns.to_list(),\n",
    "        ) \n",
    "\n",
    "    else:\n",
    "        importances = e.permutation_feature_importance(model, X, y, repeats=5, seed=seed)\n",
    "        df_importance = pd.DataFrame(\n",
    "            {f\"{model_name}_importances\" : importances[0]},\n",
    "            index=X_unscaled.columns.to_list(),\n",
    "        ) \n",
    "    \n",
    "    df_importance = df_importance.sort_values(f\"{model_name}_importances\", ascending=False)  # get most important features to the top\n",
    "    print(\"5 most important features:\", df_importance.iloc[:5].index.to_list())\n",
    "    df_importance = df_importance.loc[df_importance[f\"{model_name}_importances\"] >= 0.000000, : ]\n",
    "    \n",
    "    df_feature_importances = df_feature_importances.merge(\n",
    "        df_importance[f\"{model_name}_importances\"], \n",
    "        left_index=True, right_index=True, how=\"outer\"\n",
    "    )   \n",
    "\n",
    "    #models_feature_importances[f\"{model_name}_feature_importance\"]  = df_importance   # store set of determined features\n",
    "    \n",
    "    #df_importance.head(5)\n",
    "    # ## write selected predictors and response to disk\n",
    "    # fs.save_selected_features(\n",
    "    #     X, \n",
    "    #     pd.DataFrame(y, columns=[target]), \n",
    "    #     df_importance.T.columns, \n",
    "    #     filename=f\"../../../input_survey_data/selected_predictors/fs_xgboost_{target.split('_')[1]}_{pipe_name}.xlsx\"\n",
    "    # )\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate models based on performance on outer loop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 10 x10 rcloss\n",
    "#    RMSE   Rsquared        MAE   \n",
    "#  0.14935    0.09213    0.07177   # mtry=27\n",
    "\n",
    "\n",
    "# 10  x 5 Bred\n",
    "#    RMSE   Rsquared        MAE   \n",
    "# 23.7981     0.1602    17.6271    # mtry=18\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>xgb</th>\n",
       "      <th>crf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>5.954000e+00</td>\n",
       "      <td>1.971900e+01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>8.000000e-03</td>\n",
       "      <td>1.600000e-02</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_MAE</th>\n",
       "      <td>1.822200e+01</td>\n",
       "      <td>1.777700e+01</td>\n",
       "      <td>17.627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_RMSE</th>\n",
       "      <td>2.387200e+01</td>\n",
       "      <td>2.364000e+01</td>\n",
       "      <td>23.798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_R2</th>\n",
       "      <td>7.000000e-03</td>\n",
       "      <td>4.800000e-02</td>\n",
       "      <td>0.160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_MAPE</th>\n",
       "      <td>2.541533e+16</td>\n",
       "      <td>2.883702e+16</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_MBE</th>\n",
       "      <td>7.200000e-02</td>\n",
       "      <td>6.900000e-02</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      en           xgb     crf\n",
       "fit_time    5.954000e+00  1.971900e+01     NaN\n",
       "score_time  8.000000e-03  1.600000e-02     NaN\n",
       "test_MAE    1.822200e+01  1.777700e+01  17.627\n",
       "test_RMSE   2.387200e+01  2.364000e+01  23.798\n",
       "test_R2     7.000000e-03  4.800000e-02   0.160\n",
       "test_MAPE   2.541533e+16  2.883702e+16     NaN\n",
       "test_MBE    7.200000e-02  6.900000e-02     NaN"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#print(models_scores[\"en\"][\"test_neg_mean_absolute_percentage_error\"].mean())\n",
    "\n",
    "#outer CV: neg. MAE: -0.083 (0.035)\n",
    "\n",
    "xgb_model_evaluation = pd.DataFrame(models_scores[\"xgb\"]).mean(axis=0).abs()  # get mean of outer cv metrics (positive)\n",
    "#crf_model_evaluation = pd.DataFrame(models_scores[\"crf\"]).mean(axis=0)\n",
    "en_model_evaluation = pd.DataFrame(models_scores[\"en\"]).mean(axis=0).abs()\n",
    "\n",
    "## TODO replace hard coded metric by variables from crf_model$summary\n",
    "## TODO add/derive MBE, MAPE of CRF\n",
    "crf_model_evaluation = pd.DataFrame({\n",
    "    \"crf\": [None, \n",
    "            None,\n",
    "            17.6271,  # MAE\n",
    "            23.7981,  # RMSE\n",
    "            0.1602,  # R2\n",
    "            None,\n",
    "            None]\n",
    "    }, index=xgb_model_evaluation.index\n",
    ")\n",
    "\n",
    "model_evaluation = pd.concat([en_model_evaluation, xgb_model_evaluation, crf_model_evaluation], axis=1)\n",
    "model_evaluation.columns = [\"en\", \"xgb\", \"crf\"]\n",
    "model_evaluation.index = model_evaluation.index.str.replace(\"neg_\", \"\")\n",
    "model_evaluation.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>xgb</th>\n",
       "      <th>crf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>5.954000e+00</td>\n",
       "      <td>1.971900e+01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>8.000000e-03</td>\n",
       "      <td>1.600000e-02</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_MAE</th>\n",
       "      <td>1.822200e+01</td>\n",
       "      <td>1.777700e+01</td>\n",
       "      <td>17.627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_RMSE</th>\n",
       "      <td>2.387200e+01</td>\n",
       "      <td>2.364000e+01</td>\n",
       "      <td>23.798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_R2</th>\n",
       "      <td>7.000000e-03</td>\n",
       "      <td>4.800000e-02</td>\n",
       "      <td>0.160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_MAPE</th>\n",
       "      <td>2.541533e+16</td>\n",
       "      <td>2.883702e+16</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_MBE</th>\n",
       "      <td>7.200000e-02</td>\n",
       "      <td>6.900000e-02</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      en           xgb     crf\n",
       "fit_time    5.954000e+00  1.971900e+01     NaN\n",
       "score_time  8.000000e-03  1.600000e-02     NaN\n",
       "test_MAE    1.822200e+01  1.777700e+01  17.627\n",
       "test_RMSE   2.387200e+01  2.364000e+01  23.798\n",
       "test_R2     7.000000e-03  4.800000e-02   0.160\n",
       "test_MAPE   2.541533e+16  2.883702e+16     NaN\n",
       "test_MBE    7.200000e-02  6.900000e-02     NaN"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_evaluation.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importances \n",
    "\n",
    "### prepare Feature Importances \n",
    "Have the same feature importance method across all applied ML models\n",
    "Weight Importances by model performance on outer loop (mean MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        crf_importances  xgb_importances  en_importances\n",
      "b_area         1.181684         2.681653        0.851206\n",
      "bage           4.184326         5.861523        3.782271\n"
     ]
    }
   ],
   "source": [
    "## Overall FI ranking (procedure similar to Rzer et al 2019; Brill 2022)\n",
    "\n",
    "## scale importance scores to  same units (non important feautres were removed before)\n",
    "#df_feature_importances = minmax_scale(df_feature_importances, feature_range=(1, 100))\n",
    "#fi = df_feature_importances.copy()\n",
    "#fi = MinMaxScaler(feature_range=(0,100)).fit_transform(fi)\n",
    "df_feature_importances = pd.DataFrame(\n",
    "    MinMaxScaler(feature_range=(0,10)).fit_transform(df_feature_importances), \n",
    "    index=df_feature_importances.index,\n",
    "    columns=df_feature_importances.columns\n",
    ")\n",
    "print(df_feature_importances.head(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.777204588844075"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_feature_importances[\"crf_importances\"] \n",
    "np.abs(models_scores[\"xgb\"][\"test_neg_MAE\"].mean())  # neg MAE:  larger negMAE == better model perfo\n",
    "# 18 \n",
    "# 17.78\n",
    "#models_scores.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crf_importances</th>\n",
       "      <th>xgb_importances</th>\n",
       "      <th>en_importances</th>\n",
       "      <th>xgb_importances_weighted</th>\n",
       "      <th>en_importances_weighted</th>\n",
       "      <th>crf_importances_weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>b_area</th>\n",
       "      <td>1.181684</td>\n",
       "      <td>2.681653</td>\n",
       "      <td>0.851206</td>\n",
       "      <td>0.150848</td>\n",
       "      <td>0.046713</td>\n",
       "      <td>0.067038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bage</th>\n",
       "      <td>4.184326</td>\n",
       "      <td>5.861523</td>\n",
       "      <td>3.782271</td>\n",
       "      <td>0.329721</td>\n",
       "      <td>0.207564</td>\n",
       "      <td>0.237382</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        crf_importances  xgb_importances  en_importances   \n",
       "b_area         1.181684         2.681653        0.851206  \\\n",
       "bage           4.184326         5.861523        3.782271   \n",
       "\n",
       "        xgb_importances_weighted  en_importances_weighted   \n",
       "b_area                  0.150848                 0.046713  \\\n",
       "bage                    0.329721                 0.207564   \n",
       "\n",
       "        crf_importances_weighted  \n",
       "b_area                  0.067038  \n",
       "bage                    0.237382  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## weight FI scores based on performance \n",
    "#models_test_mean_mae = models_trained[f\"{model_name}_neg_mean_absolute_error\"]  # mean MAE on test set\n",
    "# weigth importances from better performed models more\n",
    "df_feature_importances[\"xgb_importances_weighted\"] = df_feature_importances[\"xgb_importances\"] / np.abs(models_scores[\"xgb\"][\"test_neg_MAE\"].mean())  # neg MAE:  larger negMAE == better model performance\n",
    "df_feature_importances[\"en_importances_weighted\"]  = df_feature_importances[\"en_importances\"] / np.abs(models_scores[\"en\"][\"test_neg_MAE\"].mean())       # weigth better models more\n",
    "df_feature_importances[\"crf_importances_weighted\"]  = df_feature_importances[\"crf_importances\"] / 17.627 #np.abs(models_scores[\"en_neg_mean_absolute_error\"])       # weigth better models more\n",
    "\n",
    "## TODO add mean score for CRF\n",
    "df_feature_importances.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 most important features across all models (weighted on mean MAE scores):\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crf_importances</th>\n",
       "      <th>xgb_importances</th>\n",
       "      <th>en_importances</th>\n",
       "      <th>xgb_importances_weighted</th>\n",
       "      <th>en_importances_weighted</th>\n",
       "      <th>crf_importances_weighted</th>\n",
       "      <th>overall_importances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>water_depth_cm</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>8.457650</td>\n",
       "      <td>5.897236</td>\n",
       "      <td>0.475758</td>\n",
       "      <td>0.323630</td>\n",
       "      <td>0.567312</td>\n",
       "      <td>0.455566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emergency_measures.7</th>\n",
       "      <td>1.782103</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.562518</td>\n",
       "      <td>0.548782</td>\n",
       "      <td>0.101101</td>\n",
       "      <td>0.404134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perception_private_economy_future</th>\n",
       "      <td>5.153681</td>\n",
       "      <td>6.051822</td>\n",
       "      <td>4.775570</td>\n",
       "      <td>0.340426</td>\n",
       "      <td>0.262075</td>\n",
       "      <td>0.292374</td>\n",
       "      <td>0.298292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bage</th>\n",
       "      <td>4.184326</td>\n",
       "      <td>5.861523</td>\n",
       "      <td>3.782271</td>\n",
       "      <td>0.329721</td>\n",
       "      <td>0.207564</td>\n",
       "      <td>0.237382</td>\n",
       "      <td>0.258222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flowvelocity</th>\n",
       "      <td>1.087561</td>\n",
       "      <td>3.087554</td>\n",
       "      <td>7.182391</td>\n",
       "      <td>0.173681</td>\n",
       "      <td>0.394157</td>\n",
       "      <td>0.061699</td>\n",
       "      <td>0.209845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shp_registered_capital_euro</th>\n",
       "      <td>1.339645</td>\n",
       "      <td>8.115954</td>\n",
       "      <td>0.377177</td>\n",
       "      <td>0.456537</td>\n",
       "      <td>0.020699</td>\n",
       "      <td>0.076000</td>\n",
       "      <td>0.184412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emergency_measures.2</th>\n",
       "      <td>0.202416</td>\n",
       "      <td>6.324327</td>\n",
       "      <td>2.727824</td>\n",
       "      <td>0.355755</td>\n",
       "      <td>0.149698</td>\n",
       "      <td>0.011483</td>\n",
       "      <td>0.172312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resilience_govern_careing</th>\n",
       "      <td>2.227289</td>\n",
       "      <td>4.182050</td>\n",
       "      <td>1.452929</td>\n",
       "      <td>0.235248</td>\n",
       "      <td>0.079734</td>\n",
       "      <td>0.126357</td>\n",
       "      <td>0.147113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shp_employees</th>\n",
       "      <td>0.416431</td>\n",
       "      <td>4.998469</td>\n",
       "      <td>0.008265</td>\n",
       "      <td>0.281173</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>0.023625</td>\n",
       "      <td>0.101750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>elevation_building_impl</th>\n",
       "      <td>1.421967</td>\n",
       "      <td>1.192793</td>\n",
       "      <td>2.841147</td>\n",
       "      <td>0.067097</td>\n",
       "      <td>0.155917</td>\n",
       "      <td>0.080670</td>\n",
       "      <td>0.101228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   crf_importances  xgb_importances   \n",
       "water_depth_cm                           10.000000         8.457650  \\\n",
       "emergency_measures.7                      1.782103        10.000000   \n",
       "perception_private_economy_future         5.153681         6.051822   \n",
       "bage                                      4.184326         5.861523   \n",
       "flowvelocity                              1.087561         3.087554   \n",
       "shp_registered_capital_euro               1.339645         8.115954   \n",
       "emergency_measures.2                      0.202416         6.324327   \n",
       "resilience_govern_careing                 2.227289         4.182050   \n",
       "shp_employees                             0.416431         4.998469   \n",
       "elevation_building_impl                   1.421967         1.192793   \n",
       "\n",
       "                                   en_importances  xgb_importances_weighted   \n",
       "water_depth_cm                           5.897236                  0.475758  \\\n",
       "emergency_measures.7                    10.000000                  0.562518   \n",
       "perception_private_economy_future        4.775570                  0.340426   \n",
       "bage                                     3.782271                  0.329721   \n",
       "flowvelocity                             7.182391                  0.173681   \n",
       "shp_registered_capital_euro              0.377177                  0.456537   \n",
       "emergency_measures.2                     2.727824                  0.355755   \n",
       "resilience_govern_careing                1.452929                  0.235248   \n",
       "shp_employees                            0.008265                  0.281173   \n",
       "elevation_building_impl                  2.841147                  0.067097   \n",
       "\n",
       "                                   en_importances_weighted   \n",
       "water_depth_cm                                    0.323630  \\\n",
       "emergency_measures.7                              0.548782   \n",
       "perception_private_economy_future                 0.262075   \n",
       "bage                                              0.207564   \n",
       "flowvelocity                                      0.394157   \n",
       "shp_registered_capital_euro                       0.020699   \n",
       "emergency_measures.2                              0.149698   \n",
       "resilience_govern_careing                         0.079734   \n",
       "shp_employees                                     0.000454   \n",
       "elevation_building_impl                           0.155917   \n",
       "\n",
       "                                   crf_importances_weighted   \n",
       "water_depth_cm                                     0.567312  \\\n",
       "emergency_measures.7                               0.101101   \n",
       "perception_private_economy_future                  0.292374   \n",
       "bage                                               0.237382   \n",
       "flowvelocity                                       0.061699   \n",
       "shp_registered_capital_euro                        0.076000   \n",
       "emergency_measures.2                               0.011483   \n",
       "resilience_govern_careing                          0.126357   \n",
       "shp_employees                                      0.023625   \n",
       "elevation_building_impl                            0.080670   \n",
       "\n",
       "                                   overall_importances  \n",
       "water_depth_cm                                0.455566  \n",
       "emergency_measures.7                          0.404134  \n",
       "perception_private_economy_future             0.298292  \n",
       "bage                                          0.258222  \n",
       "flowvelocity                                  0.209845  \n",
       "shp_registered_capital_euro                   0.184412  \n",
       "emergency_measures.2                          0.172312  \n",
       "resilience_govern_careing                     0.147113  \n",
       "shp_employees                                 0.101750  \n",
       "elevation_building_impl                       0.101228  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## overall FI scores\n",
    "df_feature_importances[\"overall_importances\"] = df_feature_importances[[\"xgb_importances_weighted\",\"en_importances_weighted\", \"crf_importances_weighted\"]].mean(axis=1)\n",
    "## drop feautres which are unimportant\n",
    "df_feature_importances = df_feature_importances.loc[df_feature_importances[\"overall_importances\"] > 0.000000, : ]\n",
    "print(\n",
    "    \"10 most important features across all models (weighted on mean MAE scores):\\n\" ,\n",
    "    #df_feature_importances.overall_importances.sort_values(ascending=False).head()\n",
    ")\n",
    "df_feature_importances.sort_values(\"overall_importances\", ascending=False)[:10]#.describe()\n",
    "\n",
    "### TODO clarify/read if xgb_importances_weighted\ten_importances_weighted needs to be scaled again back to [0,10]\n",
    "## ranking is not needed\n",
    "\n",
    "## get median across all importance scores of each feature\n",
    "#df_feature_importances_ranking[\"overall_importance\"] = df_feature_importances_ranking.median(axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_feature_importances.sort_values(\"xgb_importances_weighted\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Plot Feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crf_importances</th>\n",
       "      <th>xgb_importances</th>\n",
       "      <th>en_importances</th>\n",
       "      <th>xgb_importances_weighted</th>\n",
       "      <th>en_importances_weighted</th>\n",
       "      <th>crf_importances_weighted</th>\n",
       "      <th>overall_importances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>31.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>33.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.258490</td>\n",
       "      <td>2.586548</td>\n",
       "      <td>1.838513</td>\n",
       "      <td>0.145498</td>\n",
       "      <td>0.100894</td>\n",
       "      <td>0.071396</td>\n",
       "      <td>0.100662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.003531</td>\n",
       "      <td>2.805646</td>\n",
       "      <td>2.453721</td>\n",
       "      <td>0.157823</td>\n",
       "      <td>0.134656</td>\n",
       "      <td>0.113663</td>\n",
       "      <td>0.112656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.257406</td>\n",
       "      <td>0.443400</td>\n",
       "      <td>0.162505</td>\n",
       "      <td>0.024942</td>\n",
       "      <td>0.008918</td>\n",
       "      <td>0.014603</td>\n",
       "      <td>0.024133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.671076</td>\n",
       "      <td>1.816518</td>\n",
       "      <td>1.006977</td>\n",
       "      <td>0.102182</td>\n",
       "      <td>0.055261</td>\n",
       "      <td>0.038071</td>\n",
       "      <td>0.069689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.260664</td>\n",
       "      <td>3.634802</td>\n",
       "      <td>2.046936</td>\n",
       "      <td>0.204464</td>\n",
       "      <td>0.112332</td>\n",
       "      <td>0.071519</td>\n",
       "      <td>0.101750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.562518</td>\n",
       "      <td>0.548782</td>\n",
       "      <td>0.567312</td>\n",
       "      <td>0.455566</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       crf_importances  xgb_importances  en_importances   \n",
       "count        31.000000        31.000000       28.000000  \\\n",
       "mean          1.258490         2.586548        1.838513   \n",
       "std           2.003531         2.805646        2.453721   \n",
       "min           0.000000         0.000000        0.000000   \n",
       "25%           0.257406         0.443400        0.162505   \n",
       "50%           0.671076         1.816518        1.006977   \n",
       "75%           1.260664         3.634802        2.046936   \n",
       "max          10.000000        10.000000       10.000000   \n",
       "\n",
       "       xgb_importances_weighted  en_importances_weighted   \n",
       "count                 31.000000                28.000000  \\\n",
       "mean                   0.145498                 0.100894   \n",
       "std                    0.157823                 0.134656   \n",
       "min                    0.000000                 0.000000   \n",
       "25%                    0.024942                 0.008918   \n",
       "50%                    0.102182                 0.055261   \n",
       "75%                    0.204464                 0.112332   \n",
       "max                    0.562518                 0.548782   \n",
       "\n",
       "       crf_importances_weighted  overall_importances  \n",
       "count                 31.000000            33.000000  \n",
       "mean                   0.071396             0.100662  \n",
       "std                    0.113663             0.112656  \n",
       "min                    0.000000             0.000209  \n",
       "25%                    0.014603             0.024133  \n",
       "50%                    0.038071             0.069689  \n",
       "75%                    0.071519             0.101750  \n",
       "max                    0.567312             0.455566  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feature_importances.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_feature_importances[[\"xgb_importances_weighted\", \"en_importances_weighted\"]]\n",
    "#df_feature_importances.melt(value_vars=[\"xgb_importances_weighted\", \"en_importances_weighted\"], var_name='model', value_name='importances_weighted')\n",
    "\n",
    "# df_fi_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature_importances = df_feature_importances.sort_values(\"overall_importances\", ascending=False)\n",
    "\n",
    "# ### make long pirvot table with additional column indicating the model for each importance score\n",
    "# df_fi_plot = df_feature_importances.copy()\n",
    "# df_fi_plot[\"feature_names\"] = df_fi_plot.index\n",
    "# df_fi_plot = df_fi_plot.melt(\n",
    "#     id_vars=df_fi_plot.columns.difference([\"xgb_importances_weighted\", \"en_importances_weighted\", \"crf_importances_weighted\"]), var_name=\"model\", value_name=\"importances_weighted\"\n",
    "# )\n",
    "# df_fi_plot.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x1200 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "\n",
    "# drop features which dont reduce the loss\n",
    "# df_importance = df_importance.loc[df_importance.importances > 0.0000, : ] \n",
    "df_feature_importances = df_feature_importances.sort_values(\"overall_importances\", ascending=True)\n",
    "\n",
    "#fig, ax = plt.subplots(figsize=(12,5))\n",
    "plt.figure(figsize=(20, 12))\n",
    "#plt.barh(df_importance.name[-18:], df_importance.importances[-18:])\n",
    "df_feature_importances[[\"crf_importances_weighted\", \"en_importances_weighted\", \"xgb_importances_weighted\"]].plot.barh(\n",
    "    stacked=True, \n",
    "    color=['darkblue', 'steelblue', 'grey'],\n",
    "    width=0.5,\n",
    "    # #errorbar=\"sd\",\n",
    "    # errorbar=(\"pi\", 50), \n",
    "    # capsize=.1, errcolor=\".5\",\n",
    "    # linewidth=3,\n",
    "    )\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.ylabel(\"\")\n",
    "# plt.xticks(rotation = 90)\n",
    "plt.title(f\"Feature Importances for {target.replace('_',' ')}\")\n",
    "\n",
    "# # Add a legend and informative axis label\n",
    "# ax.legend(ncol=2, loc=\"lower right\", frameon=True)\n",
    "# ax.set(xlim=(0, 24), ylabel=\"\",\n",
    "#        xlabel=\"Automobile collisions per billion miles\")\n",
    "\n",
    "# ax.set_ylabel('percentage')\n",
    "# Fix the legend so it's not on top of the bars.\n",
    "# legend = ax.get_legend()\n",
    "# legend.set_bbox_to_anchor((1, 1))\n",
    "\n",
    "top_bar = mpatches.Patch(color=\"darkblue\", label=\"crf\")\n",
    "middle_bar = mpatches.Patch(color=\"steelblue\", label=\"elastic net\")\n",
    "bottom_bar = mpatches.Patch(color=\"grey\", label=\"xgboost\")\n",
    "plt.tick_params(axis='y', which='major', labelsize=8)\n",
    "plt.legend(handles=[top_bar,middle_bar, bottom_bar])\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#sns.despine(left=True, bottom=True)\n",
    "## save importance scores and figure\n",
    "#filepath = f'./models_evaluation/best_xgb_importance_scores_{target}_{pipe_name}'\n",
    "#if not glob(filepath):\n",
    "#    df_importance.to_csv(filename, index = False)\n",
    "#plt.savefig(f'../../../figures/best_en_feature_importance_{target}_{pipe_name}.png', bbox_inches='tight')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crf_importances</th>\n",
       "      <th>xgb_importances</th>\n",
       "      <th>en_importances</th>\n",
       "      <th>xgb_importances_weighted</th>\n",
       "      <th>en_importances_weighted</th>\n",
       "      <th>crf_importances_weighted</th>\n",
       "      <th>overall_importances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>water_depth_cm</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>8.457650</td>\n",
       "      <td>5.897236</td>\n",
       "      <td>0.475758</td>\n",
       "      <td>0.323630</td>\n",
       "      <td>0.567312</td>\n",
       "      <td>0.455566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perception_private_economy_future</th>\n",
       "      <td>5.153681</td>\n",
       "      <td>6.051822</td>\n",
       "      <td>4.775570</td>\n",
       "      <td>0.340426</td>\n",
       "      <td>0.262075</td>\n",
       "      <td>0.292374</td>\n",
       "      <td>0.298292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bage</th>\n",
       "      <td>4.184326</td>\n",
       "      <td>5.861523</td>\n",
       "      <td>3.782271</td>\n",
       "      <td>0.329721</td>\n",
       "      <td>0.207564</td>\n",
       "      <td>0.237382</td>\n",
       "      <td>0.258222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shp_profits_last5years</th>\n",
       "      <td>2.404060</td>\n",
       "      <td>0.471020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.026496</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.136385</td>\n",
       "      <td>0.081440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resilience_govern_careing</th>\n",
       "      <td>2.227289</td>\n",
       "      <td>4.182050</td>\n",
       "      <td>1.452929</td>\n",
       "      <td>0.235248</td>\n",
       "      <td>0.079734</td>\n",
       "      <td>0.126357</td>\n",
       "      <td>0.147113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emergency_measures.7</th>\n",
       "      <td>1.782103</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.562518</td>\n",
       "      <td>0.548782</td>\n",
       "      <td>0.101101</td>\n",
       "      <td>0.404134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>elevation_building_impl</th>\n",
       "      <td>1.421967</td>\n",
       "      <td>1.192793</td>\n",
       "      <td>2.841147</td>\n",
       "      <td>0.067097</td>\n",
       "      <td>0.155917</td>\n",
       "      <td>0.080670</td>\n",
       "      <td>0.101228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shp_registered_capital_euro</th>\n",
       "      <td>1.339645</td>\n",
       "      <td>8.115954</td>\n",
       "      <td>0.377177</td>\n",
       "      <td>0.456537</td>\n",
       "      <td>0.020699</td>\n",
       "      <td>0.076000</td>\n",
       "      <td>0.184412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b_area</th>\n",
       "      <td>1.181684</td>\n",
       "      <td>2.681653</td>\n",
       "      <td>0.851206</td>\n",
       "      <td>0.150848</td>\n",
       "      <td>0.046713</td>\n",
       "      <td>0.067038</td>\n",
       "      <td>0.088200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flood_experience</th>\n",
       "      <td>1.140451</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.064699</td>\n",
       "      <td>0.032350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flowvelocity</th>\n",
       "      <td>1.087561</td>\n",
       "      <td>3.087554</td>\n",
       "      <td>7.182391</td>\n",
       "      <td>0.173681</td>\n",
       "      <td>0.394157</td>\n",
       "      <td>0.061699</td>\n",
       "      <td>0.209845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resilience_more_future_affected</th>\n",
       "      <td>0.791100</td>\n",
       "      <td>0.489210</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027519</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044880</td>\n",
       "      <td>0.024133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resilience_govern_warnings_helpful</th>\n",
       "      <td>0.732646</td>\n",
       "      <td>1.816518</td>\n",
       "      <td>1.190308</td>\n",
       "      <td>0.102182</td>\n",
       "      <td>0.065322</td>\n",
       "      <td>0.041564</td>\n",
       "      <td>0.069689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shp_avgmonthly_sale_cat</th>\n",
       "      <td>0.691215</td>\n",
       "      <td>2.026068</td>\n",
       "      <td>1.819973</td>\n",
       "      <td>0.113970</td>\n",
       "      <td>0.099877</td>\n",
       "      <td>0.039213</td>\n",
       "      <td>0.084353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resistant_material_building_impl</th>\n",
       "      <td>0.672658</td>\n",
       "      <td>1.731878</td>\n",
       "      <td>1.695189</td>\n",
       "      <td>0.097421</td>\n",
       "      <td>0.093029</td>\n",
       "      <td>0.038161</td>\n",
       "      <td>0.076204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pumping_equipment_impl</th>\n",
       "      <td>0.671076</td>\n",
       "      <td>0.028403</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001598</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038071</td>\n",
       "      <td>0.013223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>electricity_higher_impl</th>\n",
       "      <td>0.562741</td>\n",
       "      <td>0.940139</td>\n",
       "      <td>0.237310</td>\n",
       "      <td>0.052885</td>\n",
       "      <td>0.013023</td>\n",
       "      <td>0.031925</td>\n",
       "      <td>0.032611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shp_sector</th>\n",
       "      <td>0.422168</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.162748</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.063810</td>\n",
       "      <td>0.023950</td>\n",
       "      <td>0.043880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shp_employees</th>\n",
       "      <td>0.416431</td>\n",
       "      <td>4.998469</td>\n",
       "      <td>0.008265</td>\n",
       "      <td>0.281173</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>0.023625</td>\n",
       "      <td>0.101750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>water_barriers_impl</th>\n",
       "      <td>0.406859</td>\n",
       "      <td>0.088542</td>\n",
       "      <td>0.062896</td>\n",
       "      <td>0.004981</td>\n",
       "      <td>0.003452</td>\n",
       "      <td>0.023082</td>\n",
       "      <td>0.010505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>overall_problem_house</th>\n",
       "      <td>0.368446</td>\n",
       "      <td>1.979257</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.111337</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.020902</td>\n",
       "      <td>0.066120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>protect_valuables_impl</th>\n",
       "      <td>0.354736</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.020125</td>\n",
       "      <td>0.020125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emergency_measures.1</th>\n",
       "      <td>0.271352</td>\n",
       "      <td>0.415780</td>\n",
       "      <td>1.363443</td>\n",
       "      <td>0.023388</td>\n",
       "      <td>0.074823</td>\n",
       "      <td>0.015394</td>\n",
       "      <td>0.037869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inundation_duration_h</th>\n",
       "      <td>0.243459</td>\n",
       "      <td>0.126163</td>\n",
       "      <td>0.174171</td>\n",
       "      <td>0.007097</td>\n",
       "      <td>0.009558</td>\n",
       "      <td>0.013812</td>\n",
       "      <td>0.010156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emergency_measures.2</th>\n",
       "      <td>0.202416</td>\n",
       "      <td>6.324327</td>\n",
       "      <td>2.727824</td>\n",
       "      <td>0.355755</td>\n",
       "      <td>0.149698</td>\n",
       "      <td>0.011483</td>\n",
       "      <td>0.172312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emergency_measures.4</th>\n",
       "      <td>0.119269</td>\n",
       "      <td>1.030860</td>\n",
       "      <td>0.127506</td>\n",
       "      <td>0.057988</td>\n",
       "      <td>0.006997</td>\n",
       "      <td>0.006766</td>\n",
       "      <td>0.023917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hh_monthly_income_cat</th>\n",
       "      <td>0.082520</td>\n",
       "      <td>0.230796</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012983</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004681</td>\n",
       "      <td>0.005888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shp_owner</th>\n",
       "      <td>0.081341</td>\n",
       "      <td>2.826908</td>\n",
       "      <td>1.711176</td>\n",
       "      <td>0.159019</td>\n",
       "      <td>0.093906</td>\n",
       "      <td>0.004615</td>\n",
       "      <td>0.085847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contaminations.0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.715792</td>\n",
       "      <td>0.747492</td>\n",
       "      <td>0.040265</td>\n",
       "      <td>0.041021</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flood_protections_impl</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.065653</td>\n",
       "      <td>0.076431</td>\n",
       "      <td>0.003693</td>\n",
       "      <td>0.004194</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shp_suppliers_HCMC</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007446</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000419</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shp_content_value_euro</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.926849</td>\n",
       "      <td>0.398071</td>\n",
       "      <td>0.108389</td>\n",
       "      <td>0.021845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.065117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emergency_measures.3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.311916</td>\n",
       "      <td>0.815633</td>\n",
       "      <td>0.130049</td>\n",
       "      <td>0.044760</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.087405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    crf_importances  xgb_importances   \n",
       "water_depth_cm                            10.000000         8.457650  \\\n",
       "perception_private_economy_future          5.153681         6.051822   \n",
       "bage                                       4.184326         5.861523   \n",
       "shp_profits_last5years                     2.404060         0.471020   \n",
       "resilience_govern_careing                  2.227289         4.182050   \n",
       "emergency_measures.7                       1.782103        10.000000   \n",
       "elevation_building_impl                    1.421967         1.192793   \n",
       "shp_registered_capital_euro                1.339645         8.115954   \n",
       "b_area                                     1.181684         2.681653   \n",
       "flood_experience                           1.140451         0.000000   \n",
       "flowvelocity                               1.087561         3.087554   \n",
       "resilience_more_future_affected            0.791100         0.489210   \n",
       "resilience_govern_warnings_helpful         0.732646         1.816518   \n",
       "shp_avgmonthly_sale_cat                    0.691215         2.026068   \n",
       "resistant_material_building_impl           0.672658         1.731878   \n",
       "pumping_equipment_impl                     0.671076         0.028403   \n",
       "electricity_higher_impl                    0.562741         0.940139   \n",
       "shp_sector                                 0.422168              NaN   \n",
       "shp_employees                              0.416431         4.998469   \n",
       "water_barriers_impl                        0.406859         0.088542   \n",
       "overall_problem_house                      0.368446         1.979257   \n",
       "protect_valuables_impl                     0.354736              NaN   \n",
       "emergency_measures.1                       0.271352         0.415780   \n",
       "inundation_duration_h                      0.243459         0.126163   \n",
       "emergency_measures.2                       0.202416         6.324327   \n",
       "emergency_measures.4                       0.119269         1.030860   \n",
       "hh_monthly_income_cat                      0.082520         0.230796   \n",
       "shp_owner                                  0.081341         2.826908   \n",
       "contaminations.0                           0.000000         0.715792   \n",
       "flood_protections_impl                     0.000000         0.065653   \n",
       "shp_suppliers_HCMC                         0.000000         0.007446   \n",
       "shp_content_value_euro                          NaN         1.926849   \n",
       "emergency_measures.3                            NaN         2.311916   \n",
       "\n",
       "                                    en_importances  xgb_importances_weighted   \n",
       "water_depth_cm                            5.897236                  0.475758  \\\n",
       "perception_private_economy_future         4.775570                  0.340426   \n",
       "bage                                      3.782271                  0.329721   \n",
       "shp_profits_last5years                         NaN                  0.026496   \n",
       "resilience_govern_careing                 1.452929                  0.235248   \n",
       "emergency_measures.7                     10.000000                  0.562518   \n",
       "elevation_building_impl                   2.841147                  0.067097   \n",
       "shp_registered_capital_euro               0.377177                  0.456537   \n",
       "b_area                                    0.851206                  0.150848   \n",
       "flood_experience                               NaN                  0.000000   \n",
       "flowvelocity                              7.182391                  0.173681   \n",
       "resilience_more_future_affected           0.000000                  0.027519   \n",
       "resilience_govern_warnings_helpful        1.190308                  0.102182   \n",
       "shp_avgmonthly_sale_cat                   1.819973                  0.113970   \n",
       "resistant_material_building_impl          1.695189                  0.097421   \n",
       "pumping_equipment_impl                    0.000000                  0.001598   \n",
       "electricity_higher_impl                   0.237310                  0.052885   \n",
       "shp_sector                                1.162748                       NaN   \n",
       "shp_employees                             0.008265                  0.281173   \n",
       "water_barriers_impl                       0.062896                  0.004981   \n",
       "overall_problem_house                          NaN                  0.111337   \n",
       "protect_valuables_impl                         NaN                       NaN   \n",
       "emergency_measures.1                      1.363443                  0.023388   \n",
       "inundation_duration_h                     0.174171                  0.007097   \n",
       "emergency_measures.2                      2.727824                  0.355755   \n",
       "emergency_measures.4                      0.127506                  0.057988   \n",
       "hh_monthly_income_cat                     0.000000                  0.012983   \n",
       "shp_owner                                 1.711176                  0.159019   \n",
       "contaminations.0                          0.747492                  0.040265   \n",
       "flood_protections_impl                    0.076431                  0.003693   \n",
       "shp_suppliers_HCMC                             NaN                  0.000419   \n",
       "shp_content_value_euro                    0.398071                  0.108389   \n",
       "emergency_measures.3                      0.815633                  0.130049   \n",
       "\n",
       "                                    en_importances_weighted   \n",
       "water_depth_cm                                     0.323630  \\\n",
       "perception_private_economy_future                  0.262075   \n",
       "bage                                               0.207564   \n",
       "shp_profits_last5years                                  NaN   \n",
       "resilience_govern_careing                          0.079734   \n",
       "emergency_measures.7                               0.548782   \n",
       "elevation_building_impl                            0.155917   \n",
       "shp_registered_capital_euro                        0.020699   \n",
       "b_area                                             0.046713   \n",
       "flood_experience                                        NaN   \n",
       "flowvelocity                                       0.394157   \n",
       "resilience_more_future_affected                    0.000000   \n",
       "resilience_govern_warnings_helpful                 0.065322   \n",
       "shp_avgmonthly_sale_cat                            0.099877   \n",
       "resistant_material_building_impl                   0.093029   \n",
       "pumping_equipment_impl                             0.000000   \n",
       "electricity_higher_impl                            0.013023   \n",
       "shp_sector                                         0.063810   \n",
       "shp_employees                                      0.000454   \n",
       "water_barriers_impl                                0.003452   \n",
       "overall_problem_house                                   NaN   \n",
       "protect_valuables_impl                                  NaN   \n",
       "emergency_measures.1                               0.074823   \n",
       "inundation_duration_h                              0.009558   \n",
       "emergency_measures.2                               0.149698   \n",
       "emergency_measures.4                               0.006997   \n",
       "hh_monthly_income_cat                              0.000000   \n",
       "shp_owner                                          0.093906   \n",
       "contaminations.0                                   0.041021   \n",
       "flood_protections_impl                             0.004194   \n",
       "shp_suppliers_HCMC                                      NaN   \n",
       "shp_content_value_euro                             0.021845   \n",
       "emergency_measures.3                               0.044760   \n",
       "\n",
       "                                    crf_importances_weighted   \n",
       "water_depth_cm                                      0.567312  \\\n",
       "perception_private_economy_future                   0.292374   \n",
       "bage                                                0.237382   \n",
       "shp_profits_last5years                              0.136385   \n",
       "resilience_govern_careing                           0.126357   \n",
       "emergency_measures.7                                0.101101   \n",
       "elevation_building_impl                             0.080670   \n",
       "shp_registered_capital_euro                         0.076000   \n",
       "b_area                                              0.067038   \n",
       "flood_experience                                    0.064699   \n",
       "flowvelocity                                        0.061699   \n",
       "resilience_more_future_affected                     0.044880   \n",
       "resilience_govern_warnings_helpful                  0.041564   \n",
       "shp_avgmonthly_sale_cat                             0.039213   \n",
       "resistant_material_building_impl                    0.038161   \n",
       "pumping_equipment_impl                              0.038071   \n",
       "electricity_higher_impl                             0.031925   \n",
       "shp_sector                                          0.023950   \n",
       "shp_employees                                       0.023625   \n",
       "water_barriers_impl                                 0.023082   \n",
       "overall_problem_house                               0.020902   \n",
       "protect_valuables_impl                              0.020125   \n",
       "emergency_measures.1                                0.015394   \n",
       "inundation_duration_h                               0.013812   \n",
       "emergency_measures.2                                0.011483   \n",
       "emergency_measures.4                                0.006766   \n",
       "hh_monthly_income_cat                               0.004681   \n",
       "shp_owner                                           0.004615   \n",
       "contaminations.0                                    0.000000   \n",
       "flood_protections_impl                              0.000000   \n",
       "shp_suppliers_HCMC                                  0.000000   \n",
       "shp_content_value_euro                                   NaN   \n",
       "emergency_measures.3                                     NaN   \n",
       "\n",
       "                                    overall_importances  \n",
       "water_depth_cm                                 0.455566  \n",
       "perception_private_economy_future              0.298292  \n",
       "bage                                           0.258222  \n",
       "shp_profits_last5years                         0.081440  \n",
       "resilience_govern_careing                      0.147113  \n",
       "emergency_measures.7                           0.404134  \n",
       "elevation_building_impl                        0.101228  \n",
       "shp_registered_capital_euro                    0.184412  \n",
       "b_area                                         0.088200  \n",
       "flood_experience                               0.032350  \n",
       "flowvelocity                                   0.209845  \n",
       "resilience_more_future_affected                0.024133  \n",
       "resilience_govern_warnings_helpful             0.069689  \n",
       "shp_avgmonthly_sale_cat                        0.084353  \n",
       "resistant_material_building_impl               0.076204  \n",
       "pumping_equipment_impl                         0.013223  \n",
       "electricity_higher_impl                        0.032611  \n",
       "shp_sector                                     0.043880  \n",
       "shp_employees                                  0.101750  \n",
       "water_barriers_impl                            0.010505  \n",
       "overall_problem_house                          0.066120  \n",
       "protect_valuables_impl                         0.020125  \n",
       "emergency_measures.1                           0.037869  \n",
       "inundation_duration_h                          0.010156  \n",
       "emergency_measures.2                           0.172312  \n",
       "emergency_measures.4                           0.023917  \n",
       "hh_monthly_income_cat                          0.005888  \n",
       "shp_owner                                      0.085847  \n",
       "contaminations.0                               0.027095  \n",
       "flood_protections_impl                         0.002629  \n",
       "shp_suppliers_HCMC                             0.000209  \n",
       "shp_content_value_euro                         0.065117  \n",
       "emergency_measures.3                           0.087405  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feature_importances.sort_values(\"crf_importances\", ascending=False)#_weighted\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models_trained[\"trained_logreg\"].__init__\n",
    "\n",
    "# # plotting cv results\n",
    "# plt.figure(figsize=(16,6))\n",
    "\n",
    "# plt.plot(cv_results[\"param_n_features_to_select\"], cv_results[\"mean_test_score\"])\n",
    "# plt.plot(cv_results[\"param_n_features_to_select\"], cv_results[\"mean_train_score\"])\n",
    "# plt.xlabel('number of features')\n",
    "# plt.ylabel('r-squared')\n",
    "# plt.title(\"Optimal Number of Features\")\n",
    "# plt.legend(['test score', 'train score'], loc='upper left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'trained_logreg_cv': Pipeline(steps=[('model',\n",
       "                  LogisticRegression(C=8, l1_ratio=0.5, max_iter=4,\n",
       "                                     penalty='elasticnet', random_state=42,\n",
       "                                     solver='saga', tol=0.5))]),\n",
       " 'trained_xgb_cv': Pipeline(steps=[('model',\n",
       "                  XGBRegressor(base_score=None, booster='gblinear',\n",
       "                               callbacks=None, colsample_bylevel=None,\n",
       "                               colsample_bynode=None, colsample_bytree=None,\n",
       "                               early_stopping_rounds=None,\n",
       "                               enable_categorical=False, eval_metric=None,\n",
       "                               feature_types=None, gamma=None, gpu_id=None,\n",
       "                               grow_policy=None, importance_type=None,\n",
       "                               interaction_constraints=None, learning_rate=None,\n",
       "                               max_bin=None, max_cat_threshold=None,\n",
       "                               max_cat_to_onehot=None, max_delta_step=None,\n",
       "                               max_depth=3, max_leaves=None,\n",
       "                               min_child_weight=None, missing=nan,\n",
       "                               monotone_constraints=None, n_estimators=8,\n",
       "                               n_jobs=None, num_parallel_tree=None,\n",
       "                               predictor=None, random_state=None, ...))]),\n",
       " 'trained_en_cv': Pipeline(steps=[('model',\n",
       "                  ElasticNet(alpha=1, l1_ratio=0.0, max_iter=4, random_state=42,\n",
       "                             selection='random', tol=5.0))])}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #print(\"penalty term: L1=lasso, L2= rigde : \" , models_trained[\"trained_logreg_cv\"].penalty)\n",
    "\n",
    "# # cv results\n",
    "# cv_results = pd.DataFrame( models_trained[\"trained_logreg_cv\"].cv_results_)\n",
    "# cv_results\n",
    "\n",
    "models_trained#[\"trained_xgb_cv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing models for :  Target_relative_contentloss_euro\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nobs</th>\n",
       "      <th>median</th>\n",
       "      <th>mean</th>\n",
       "      <th>min max</th>\n",
       "      <th>variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>110</td>\n",
       "      <td>0.011252</td>\n",
       "      <td>0.064507</td>\n",
       "      <td>[0.0002538991165125394, 1.0]</td>\n",
       "      <td>4.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>110</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>-0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>110</td>\n",
       "      <td>0.011252</td>\n",
       "      <td>0.064507</td>\n",
       "      <td>[0.0002538991165125394, 1.0]</td>\n",
       "      <td>4.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>110</td>\n",
       "      <td>0.049998</td>\n",
       "      <td>0.062270</td>\n",
       "      <td>[-0.05086763, 1.0296462]</td>\n",
       "      <td>7.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>110</td>\n",
       "      <td>0.011252</td>\n",
       "      <td>0.064507</td>\n",
       "      <td>[0.0002538991165125394, 1.0]</td>\n",
       "      <td>4.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>110</td>\n",
       "      <td>0.064275</td>\n",
       "      <td>0.064507</td>\n",
       "      <td>[0.04852103834647209, 0.10603273405987478]</td>\n",
       "      <td>1.45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   nobs    median      mean                                     min max   \n",
       "0   110  0.011252  0.064507                [0.0002538991165125394, 1.0]  \\\n",
       "1   110  1.000000  0.600000                                  [0.0, 1.0]   \n",
       "2   110  0.011252  0.064507                [0.0002538991165125394, 1.0]   \n",
       "3   110  0.049998  0.062270                    [-0.05086763, 1.0296462]   \n",
       "4   110  0.011252  0.064507                [0.0002538991165125394, 1.0]   \n",
       "5   110  0.064275  0.064507  [0.04852103834647209, 0.10603273405987478]   \n",
       "\n",
       "   variance  \n",
       "0      4.45  \n",
       "1     -0.41  \n",
       "2      4.45  \n",
       "3      7.58  \n",
       "4      4.45  \n",
       "5      1.45  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Testing models for : \", target)\n",
    "e.empirical_vs_predicted(\n",
    "    X, y,\n",
    "    models_list = [models_trained[\"trained_logreg_cv\"], models_trained[\"trained_xgb_cv\"], models_trained[\"trained_en_cv\"]] \n",
    "    #models_trained#[f\"trained_{model_name}_cv\"]\n",
    "    #models_list=[model, model_log, model_quantile, model_boxcox, model_sqrt]    \n",
    ")\n",
    "\n",
    "## TODO fix y empirical\n",
    "# ## TODO idea: make a median/mean etc of best model as boxplots 8one (3 models for each target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target_relative_contentloss_euro\n",
      "(133, 27)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>shp_registered_capital_euro</th>\n",
       "      <td>0.156041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shp_employees</th>\n",
       "      <td>0.146143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contaminations.0</th>\n",
       "      <td>0.027468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>water_barriers_impl</th>\n",
       "      <td>0.024416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flood_experience</th>\n",
       "      <td>0.024315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emergency_measures.4</th>\n",
       "      <td>0.023024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shp_sector</th>\n",
       "      <td>0.011757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b_area</th>\n",
       "      <td>0.010517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>electricity_higher_impl</th>\n",
       "      <td>0.009988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bage</th>\n",
       "      <td>0.009262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emergency_measures.1</th>\n",
       "      <td>0.009052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flowvelocity</th>\n",
       "      <td>0.008451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hh_monthly_income_cat</th>\n",
       "      <td>0.006689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>overall_problem_house</th>\n",
       "      <td>0.005441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emergency_measures.8</th>\n",
       "      <td>0.003819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>water_depth_cm</th>\n",
       "      <td>0.003475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shp_avgmonthly_sale_cat</th>\n",
       "      <td>0.001954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emergency_measures.3</th>\n",
       "      <td>0.001766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inundation_duration_h</th>\n",
       "      <td>0.001606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emergency_measures.2</th>\n",
       "      <td>0.001092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shp_owner</th>\n",
       "      <td>0.001036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>protect_valuables_impl</th>\n",
       "      <td>0.000996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>elevation_building_impl</th>\n",
       "      <td>0.000757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emergency_measures.7</th>\n",
       "      <td>0.000362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             importances\n",
       "shp_registered_capital_euro     0.156041\n",
       "shp_employees                   0.146143\n",
       "contaminations.0                0.027468\n",
       "water_barriers_impl             0.024416\n",
       "flood_experience                0.024315\n",
       "emergency_measures.4            0.023024\n",
       "shp_sector                      0.011757\n",
       "b_area                          0.010517\n",
       "electricity_higher_impl         0.009988\n",
       "bage                            0.009262\n",
       "emergency_measures.1            0.009052\n",
       "flowvelocity                    0.008451\n",
       "hh_monthly_income_cat           0.006689\n",
       "overall_problem_house           0.005441\n",
       "emergency_measures.8            0.003819\n",
       "water_depth_cm                  0.003475\n",
       "shp_avgmonthly_sale_cat         0.001954\n",
       "emergency_measures.3            0.001766\n",
       "inundation_duration_h           0.001606\n",
       "emergency_measures.2            0.001092\n",
       "shp_owner                       0.001036\n",
       "protect_valuables_impl          0.000996\n",
       "elevation_building_impl         0.000757\n",
       "emergency_measures.7            0.000362"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(target)\n",
    "# print(X.shape)\n",
    "\n",
    "# df_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "median entire ds\n",
      "0.01000119482099409\n",
      "0.04939702\n",
      "mean entire ds\n",
      "0.056081992063753514\n",
      "0.060931973\n"
     ]
    }
   ],
   "source": [
    "print(\"median entire ds\")\n",
    "print(np.median(y))\n",
    "print(np.median(model.predict(X)))\n",
    "\n",
    "print(\"mean entire ds\")\n",
    "print(np.mean(y))\n",
    "print(np.mean(model.predict(X)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Empirical median ~ predicted median\n",
    "\n",
    "And further statitics compared to their empirical counterpart.\n",
    "-  mean /variance / std  compared to empirical distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB:  Target_relative_contentloss_euro\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nobs</th>\n",
       "      <th>median</th>\n",
       "      <th>mean</th>\n",
       "      <th>min max</th>\n",
       "      <th>variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>empirical</th>\n",
       "      <td>20</td>\n",
       "      <td>0.004890</td>\n",
       "      <td>0.022702</td>\n",
       "      <td>[0.0002538991165125394, 0.1454527500740594]</td>\n",
       "      <td>2.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no transform</th>\n",
       "      <td>20</td>\n",
       "      <td>0.020135</td>\n",
       "      <td>0.044268</td>\n",
       "      <td>[0.0029349634, 0.35559636]</td>\n",
       "      <td>3.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>natural log</th>\n",
       "      <td>20</td>\n",
       "      <td>0.030449</td>\n",
       "      <td>0.062297</td>\n",
       "      <td>[0.002778631, 0.33896157]</td>\n",
       "      <td>2.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quantile</th>\n",
       "      <td>20</td>\n",
       "      <td>0.010037</td>\n",
       "      <td>0.012736</td>\n",
       "      <td>[0.004311467, 0.044061705]</td>\n",
       "      <td>2.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>box-cox</th>\n",
       "      <td>20</td>\n",
       "      <td>0.010037</td>\n",
       "      <td>0.012736</td>\n",
       "      <td>[0.004311467, 0.044061705]</td>\n",
       "      <td>2.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sqrt</th>\n",
       "      <td>20</td>\n",
       "      <td>0.020135</td>\n",
       "      <td>0.044268</td>\n",
       "      <td>[0.0029349634, 0.35559636]</td>\n",
       "      <td>3.36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              nobs    median      mean   \n",
       "empirical       20  0.004890  0.022702  \\\n",
       "no transform    20  0.020135  0.044268   \n",
       "natural log     20  0.030449  0.062297   \n",
       "quantile        20  0.010037  0.012736   \n",
       "box-cox         20  0.010037  0.012736   \n",
       "sqrt            20  0.020135  0.044268   \n",
       "\n",
       "                                                  min max  variance  \n",
       "empirical     [0.0002538991165125394, 0.1454527500740594]      2.04  \n",
       "no transform                   [0.0029349634, 0.35559636]      3.36  \n",
       "natural log                     [0.002778631, 0.33896157]      2.38  \n",
       "quantile                       [0.004311467, 0.044061705]      2.43  \n",
       "box-cox                        [0.004311467, 0.044061705]      2.43  \n",
       "sqrt                           [0.0029349634, 0.35559636]      3.36  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"XGB: \", target)\n",
    "e.empirical_vs_predicted(\n",
    "    X_test, y_test,\n",
    "    models_list=[model, model_log, model_quantile, model_quantile, model_sqrt]    \n",
    "    #models_list=[model, model_log, model_quantile, model_boxcox, model_sqrt]    \n",
    ")\n",
    "\n",
    "## TODO idea: make a median/mean etc of best model as boxplots 8one (3 models for each target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:36:04] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:36:04] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:05] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:05] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:05] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:05] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:05] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:05] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:05] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:06] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:06] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:06] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:06] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:06] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:06] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:06] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:06] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:06] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:06] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:06] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:06] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:06] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:07] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:07] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:07] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:07] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:07] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:07] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:07] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:07] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:07] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:07] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:07] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:07] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:07] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:07] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:07] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:07] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:08] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:08] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:08] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:08] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:08] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:08] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:08] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:08] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:08] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:08] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:08] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:08] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:08] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:09] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:09] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:09] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:09] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:09] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:09] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:09] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:09] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:09] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:09] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:09] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:09] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:09] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:09] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:09] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:09] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:09] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:10] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:10] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:10] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:10] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:10] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:10] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:10] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:10] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:10] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:10] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:10] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:10] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:10] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:10] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:10] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:10] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:10] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:10] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:11] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:11] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:11] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:11] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:11] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:11] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:11] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:11] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:11] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:11] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:11] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:11] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:11] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:11] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:11] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:11] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:11] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:11] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:11] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:12] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:12] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:12] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:12] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:12] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:12] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:12] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:12] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:12] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:12] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:12] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:12] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:12] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:12] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:12] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:12] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:12] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:12] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:12] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:12] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:12] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:12] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:12] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:12] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:13] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:13] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:13] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:13] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:13] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:13] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:13] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:13] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:13] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:13] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:13] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:13] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:13] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:13] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:14] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:14] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:14] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:14] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:14] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:14] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:14] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:14] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:14] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:15] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:15] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:15] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:15] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:15] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:15] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:15] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:15] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:15] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:15] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:15] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:15] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:15] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:15] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:15] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:15] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:15] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:15] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:16] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:16] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:16] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:16] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:16] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:16] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:16] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:16] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:16] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:16] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:16] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:16] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:16] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:16] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:16] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:17] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:17] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:17] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:17] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:17] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:17] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:17] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:17] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:17] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:17] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:17] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:17] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:17] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:17] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:17] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:17] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:17] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:17] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:17] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:17] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:18] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:18] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:18] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:18] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:18] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:18] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:18] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:18] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:18] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:18] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:18] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:18] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:18] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:18] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:18] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:18] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:18] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:18] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:18] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:18] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:18] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:18] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:18] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:18] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:19] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:19] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:19] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:19] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:19] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:19] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:19] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:19] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:19] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:19] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:19] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:19] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:19] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:19] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:19] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:19] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:19] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:19] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:19] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:19] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:19] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:19] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:19] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:19] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:20] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:20] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:20] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:20] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:20] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:20] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:20] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:20] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:20] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:20] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:20] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:20] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:20] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:20] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:20] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:20] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:20] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:20] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:20] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:20] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:21] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:21] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:21] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:21] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:21] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:21] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:21] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:21] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:21] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:21] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:21] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:21] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:21] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:21] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:21] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:21] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:21] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:21] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:21] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:22] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:22] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:22] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:22] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:22] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:22] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:22] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:22] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:22] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:22] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:22] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:22] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:22] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:22] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:22] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:22] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:22] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:22] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:22] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:22] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:22] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:22] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:22] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:22] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:22] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:22] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:22] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:22] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:23] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:23] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:23] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:23] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:23] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:23] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:23] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:23] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:23] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:23] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:23] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:23] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:23] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:23] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:23] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:23] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:23] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:23] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:23] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:23] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:23] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:23] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:23] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:23] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:23] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:23] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:23] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:23] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:24] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:24] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:24] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:24] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:24] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:24] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:24] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:24] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:24] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:24] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:24] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:24] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:24] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:24] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:24] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:24] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:24] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:24] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:24] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:24] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:24] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:25] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:25] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:25] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:25] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:25] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:25] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:25] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:25] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:25] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:25] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:25] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:25] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:25] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:26] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:26] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:26] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:26] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:26] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:26] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:26] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:26] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:26] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:26] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:26] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:26] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:26] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:27] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:27] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:27] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:27] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:27] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:27] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:27] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:27] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:27] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:27] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:27] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:27] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:28] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:29] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:29] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:30] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:30] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:30] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:30] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:30] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:30] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:30] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:30] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:31] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:31] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:31] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:32] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:32] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:32] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:32] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:32] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:32] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:32] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:33] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:33] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:33] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:33] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:33] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:33] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:33] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:33] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:33] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:33] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:33] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:34] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:34] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:34] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:34] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:34] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:34] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:34] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:34] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:34] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:34] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:34] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:34] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:34] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:34] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:35] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:35] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:35] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:35] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:35] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:35] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:35] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:35] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:35] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:35] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:35] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:35] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:35] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:35] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:35] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:36] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:36] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:36] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:36] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:36] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:36] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:36] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:36] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:36] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:36] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:36] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:36] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:36] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:36] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:37] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:37] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:37] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:37] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:37] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:44] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:36:59] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:37:18] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:37:49] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:38:14] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:38:25] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:38:49] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:38:57] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:39:00] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:39:00] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:39:02] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:39:03] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:39:04] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[02:39:05] WARNING: D:\\bld\\xgboost-split_1685694922754\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "Model Performance:\n",
      "        Root Mean Square Error: 1200.541\n",
      "        Normalized Root Mean Square Error: 2.28\n",
      "        Mean Absolute Error: 608.294\n",
      "        Mean Bias Error: 438.06\n",
      "        R-Score: -0.242\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "import scipy.special as sc\n",
    "#lam = -0.23\n",
    "#inv_bc = ((np.sign(vector)*np.abs(vector) * lam) + 1) ** (1 / lam)\n",
    "\n",
    "\n",
    "###  Transformation: Box-cox \n",
    "model_boxcox_pipe = Pipeline([\n",
    "            ('model', TransformedTargetRegressor(regressor=XGBRegressor(),\n",
    "                transformer=PowerTransformer(method=\"box-cox\", standardize=False) # def=False:\n",
    "                #transformer=PowerTransformer(method=\"yeo-johnson\", standardize=False) # def=False\n",
    "                #func=sc.boxcox(), inverse_func\n",
    "                )\n",
    "            )])\n",
    "model_boxcox_cv = RandomizedSearchCV(\n",
    "    estimator= model_boxcox_pipe,\n",
    "    param_distributions=param_grid_transform,\n",
    "    cv=cv, \n",
    "    scoring= \"neg_mean_absolute_error\",##\"neg_mean_absolute_error\", #\"neg_mean_squared_error\",#\"r2\" ,#\"neg_mean_absolute_error\",   #TODO classifcation: test also e.g \"f1\" or recall or \"f1_micro\", \"neg_mean_absolute_error\",\n",
    "    refit=True,        \n",
    "    random_state=seed\n",
    ")\n",
    "## Fit model with reciprocal-transformed target\n",
    "model_boxcox_cv.fit(X_train, y_train)   \n",
    "model_boxcox = model_boxcox_cv.best_estimator_\n",
    "\n",
    "\n",
    "y_pred = model_boxcox.predict(X_test)\n",
    "e.evaluation_report(y_test, y_pred)\n",
    "\n",
    "## Note: Boxcox cant be used with nan values and also not with negativ or zero values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importances = e.permutation_feature_importance(model, X_test, y_test, repeats=5, seed=seed)\n",
    "\n",
    "# df_importance = pd.DataFrame(\n",
    "#     {\"importances\" : importances[0]},\n",
    "#     index=X_train.columns.to_list(),\n",
    "#     ) \n",
    "# df_importance = df_importance.sort_values(\"importances\", ascending=False)  # get most important features to the top\n",
    "# print(\"Most important features:\", df_importance.iloc[:5].index.to_list())\n",
    "# #df_importance = df_importance.loc[df_importance.importances >= 0.000000, : ]\n",
    "\n",
    "# df_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95      36.8\n",
       "273    621.3\n",
       "182    186.8\n",
       "152     37.4\n",
       "147    560.5\n",
       "       ...  \n",
       "185     44.7\n",
       "275     39.7\n",
       "40     644.3\n",
       "234    382.7\n",
       "268    223.4\n",
       "Name: Target_contentloss_euro, Length: 132, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cv.best_params_\n",
    "\n",
    "y_train\n",
    "\n",
    "##  MAE: + in target unit +  less likely to be affected by extreme values.\n",
    "## MAPE: r (MAPE) quantifies the average absolute difference between \n",
    "## the anticipated and observed values of the target variable as a percentage of the observed value. \n",
    "## The method works well for assessing models where the target variable spans a broad range of scales\n",
    "\n",
    "# 75 % in train mit 300 trress, subsam0.8, maxdep=3, aber bad teest R2\n",
    "\n",
    "\n",
    "## R-Score: 0.46\n",
    "# {'model__validate_parameters': True,\n",
    "#  'model__n_estimators': 800,\n",
    "#  'model__max_depth': 10,\n",
    "#  'model__eta': 0.2}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## reload models\n",
    "\n",
    "# fi_cols =  df_importance.loc[df_importance.importances >= 0.0000001 , : ].index.to_list()#.shape\n",
    "# print(len(fi_cols))\n",
    "# print(fi_cols)\n",
    "\n",
    "# # model_cv = RandomizedSearchCV(\n",
    "# #     estimator=XGBRegressor(), \n",
    "# #     param_distributions=param_grid, #\n",
    "# #     #param_distributions=param_bag_grid, \n",
    "# #     cv=cv, \n",
    "# #     scoring= \"neg_mean_absolute_error\",##\"neg_mean_absolute_error\", #\"neg_mean_squared_error\",#\"r2\" ,#\"neg_mean_absolute_error\",   #TODO classifcation: test also e.g \"f1\" or recall or \"f1_micro\", \"neg_mean_absolute_error\",\n",
    "# #     refit=False,   ## Refit the best estimator with the entire dataset. If False, it is impossible to make predictions using this GridSearchCV instance after fitting.\n",
    "# #                     ## If refit=False, clf.fit() will have no effect because the GridSearchCV object inside the pipeline will be reinitialized after fit().\n",
    "# #                     ## ! When refit=True, the GridSearchCV will be refitted with the best scoring parameter combination on the whole data that is passed in fit()\n",
    "# #     random_state=seed\n",
    "# # )\n",
    "# # Fit model\n",
    "# #model =XGBRegressor()# model_cv.best_estimator_\n",
    "# model.fit(X_train.loc[:, fi_cols], y_train)   \n",
    "\n",
    "# #print('Train R^2 Score : %.3f'%model_cv.best_estimator_.score(X_train.loc[:, fi_cols], y_train))\n",
    "# #print('Test R^2 Score : %.3f'%model_cv.best_estimator_.score(X_test.loc[:, fi_cols], y_test))\n",
    "# #print(\"CV score: \", model_cv.best_score_ ,  model_cv.best_estimator_.score(X_train, y_train),  model_cv.best_estimator_.score(X_test, y_test))\n",
    "# ## Evaluate\n",
    "# ## print evaluation report + check for overfitting \n",
    "# print(\"\\nTraining set\")\n",
    "# y_pred_train = model.predict(X_train.loc[:, fi_cols])\n",
    "# #y_pred_train = model_cv.best_estimator_.predict(X_train)\n",
    "# e.evaluation_report(y_train, y_pred_train)\n",
    "\n",
    "# print(\"\\nTesting set\")\n",
    "# #y_pred = model_cv.best_estimator_.predict(X_test)\n",
    "# y_pred = model.predict(X_test.loc[:, fi_cols])\n",
    "# e.evaluation_report(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "##pipelines = [\"pipe_bag_en\"]#, \n",
    "pipelines = [\"pipe_en\" ]#\n",
    "pipe_name = pipelines[0]\n",
    "\n",
    "#model_eval = pickle.load(open(f\"./models_trained/best_elasticnet_{target}_{pipe_name}.sav\", 'rb'))\n",
    "#elastic_net_eval.get_params()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 training set 97.9  %\n",
      "R^2 test set -49.21\n"
     ]
    }
   ],
   "source": [
    "print('R^2 training set', round(model.score(X_train, y_train)*100, 2), ' %')\n",
    "print('R^2 test set', round(model.score(X_test, y_test)*100, 2))\n",
    "\n",
    "learning_rate = [0.001, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "\n",
    "\n",
    "\n",
    "## Plot tagret vs its log-transformed version\n",
    "\n",
    "## Plot tagret vs its log-transformed version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    }
   ],
   "source": [
    "## Plot learning rate see if    \n",
    "means = model_cv.cv_results_['mean_test_score']\n",
    "stds = model_cv.cv_results_['std_test_score']\n",
    "params = model_cv.cv_results_['params']\n",
    "\n",
    "# for mean, stdev, param in zip(means, stds, params):\n",
    "#     print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "# plot results\n",
    "# scores = np.array(means).reshape(len(learning_rate), len(n_estimators))\n",
    "# for i, value in enumerate(learning_rate):\n",
    "#     plt.plot(n_estimators, scores[i], label='learning_rate: ' + str(value))\n",
    "# for mean, stdev, param in zip(means, stds, params):\n",
    "# \tprint(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "# plot\n",
    "#plt.use('Agg')\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "\n",
    "plt.errorbar(learning_rate, means, yerr=stds)\n",
    "plt.legend()\n",
    "plt.xlabel('learning_rate')\n",
    "plt.ylabel('Log Loss')\n",
    "plt.savefig('log_loss_vs_learning_rate.png')\n",
    "plt.show()\n",
    "# scores = np.array(means).reshape(len(learning_rate), len(n_estimators))\n",
    "# for i, value in enumerate(learning_rate):\n",
    "#     plt.plot(n_estimators, scores[i], label='learning_rate: ' + str(value))\n",
    "# plt.legend()\n",
    "# plt.xlabel('learning_rate')\n",
    "# plt.ylabel('Log Loss')\n",
    "# plt.savefig('n_estimators_vs_learning_rate.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9790346135872993\n",
      "-0.4921255591097222\n"
     ]
    }
   ],
   "source": [
    "#plt.savefig(f\"./models_trained/FI_{target}.png\", bbox_inches='tight')\n",
    "#sns_plot.figure.savefig(\"output.png\")\n",
    "print(model.score(X_train, y_train))\n",
    "print(model.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot prediction error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x800 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#y_pred_log_train = model_log.predict(X_train)\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_log = model_log.predict(X_test)\n",
    "y_pred_quantile = model_quantile.predict(X_test)\n",
    "#y_pred_boxcox = model_boxcox.predict(X_test)\n",
    "y_pred_sqrt = model_sqrt.predict(X_test)\n",
    "\n",
    "\n",
    "f, (ax0, ax1) = plt.subplots( 2, 4,  sharey=\"row\", figsize=(15, 8)) # \n",
    "\n",
    "PredictionErrorDisplay.from_predictions(\n",
    "    y_test,\n",
    "    y_pred,\n",
    "    kind=\"actual_vs_predicted\",\n",
    "    ax=ax0[0],\n",
    "    scatter_kwargs={\"alpha\": 0.5},\n",
    ")\n",
    "PredictionErrorDisplay.from_predictions(\n",
    "    y_test,\n",
    "    y_pred_log,\n",
    "    kind=\"actual_vs_predicted\",\n",
    "    ax=ax0[1],\n",
    "    scatter_kwargs={\"alpha\": 0.5},\n",
    ")\n",
    "PredictionErrorDisplay.from_predictions(\n",
    "    y_test,\n",
    "    y_pred_quantile,\n",
    "    kind=\"actual_vs_predicted\",\n",
    "    ax=ax0[2],\n",
    "    scatter_kwargs={\"alpha\": 0.5},\n",
    ")\n",
    "# PredictionErrorDisplay.from_predictions(\n",
    "#     y_test,\n",
    "#     y_pred_boxcox,\n",
    "#     kind=\"actual_vs_predicted\",\n",
    "#     ax=ax0[3],\n",
    "#     scatter_kwargs={\"alpha\": 0.5},\n",
    "# )\n",
    "PredictionErrorDisplay.from_predictions(\n",
    "    y_test,\n",
    "    y_pred_sqrt,\n",
    "    kind=\"actual_vs_predicted\",\n",
    "    ax=ax0[3],\n",
    "    scatter_kwargs={\"alpha\": 0.5},\n",
    ")\n",
    "ax0[0].set_title(\"XGBoost regression \\n without target transformation\")\n",
    "ax0[1].set_title(\"XGBoost regression \\n with target log-transformation\")\n",
    "ax0[2].set_title(\"XGBoost regression \\n with target quantile-transformation\")\n",
    "ax0[3].set_title(\"XGBoost regression \\n with target sqrt-transformation\")\n",
    "#ax0[3].set_title(\"XGBoost regression \\n with target boxcox-transformation\")\n",
    "\n",
    "ax0[0].set_ylim(0, 300)\n",
    "\n",
    "\n",
    "# Add the score in the legend of each axis\n",
    "for ax, y_pred in zip([ax0[0], ax0[1], ax0[2],ax0[3]], [y_pred, y_pred_log, y_pred_quantile, y_pred_sqrt]):\n",
    "#for ax, y_pred in zip([ax0[0], ax0[1], ax0[2],ax0[3]], [y_pred, y_pred_log, y_pred_quantile, y_pred_boxcox]):\n",
    "    for name, score in e.compute_score(y_test, y_pred).items():\n",
    "        ax.plot([], [], \" \", label=f\"{name}={score}\")\n",
    "    ax.legend(loc=\"upper left\")\n",
    "\n",
    "\n",
    "# plot the residuals vs the predicted values\n",
    "PredictionErrorDisplay.from_predictions(\n",
    "    y_test,\n",
    "    y_pred,\n",
    "    kind=\"residual_vs_predicted\",\n",
    "    ax=ax1[0],\n",
    "    scatter_kwargs={\"alpha\": 0.5},\n",
    ")\n",
    "PredictionErrorDisplay.from_predictions(\n",
    "    y_test,\n",
    "    y_pred_log,\n",
    "    kind=\"residual_vs_predicted\",\n",
    "    ax=ax1[1],\n",
    "    scatter_kwargs={\"alpha\": 0.5},\n",
    ")\n",
    "PredictionErrorDisplay.from_predictions(\n",
    "    y_test,\n",
    "    y_pred_quantile,\n",
    "    kind=\"residual_vs_predicted\",\n",
    "    ax=ax1[2],\n",
    "    scatter_kwargs={\"alpha\": 0.5},\n",
    ")\n",
    "# PredictionErrorDisplay.from_predictions(\n",
    "#     y_test,\n",
    "#     y_pred_boxcox,\n",
    "#     kind=\"residual_vs_predicted\",\n",
    "#     ax=ax1[3],\n",
    "#     scatter_kwargs={\"alpha\": 0.5},\n",
    "# )\n",
    "PredictionErrorDisplay.from_predictions(\n",
    "    y_test,\n",
    "    y_pred_sqrt,\n",
    "    kind=\"residual_vs_predicted\",\n",
    "    ax=ax1[3],\n",
    "    scatter_kwargs={\"alpha\": 0.5},\n",
    ")\n",
    "ax1[0].set_title(\"XGBoost regression \\n without target transformation\")\n",
    "ax1[1].set_title(\"XGBoost regression \\n with target log-transformation\")\n",
    "ax1[2].set_title(\"XGBoost regression \\n with target quantile-transformation\")\n",
    "#ax1[3].set_title(\"XGBoost regression \\n with target boxcox-transformation\")\n",
    "ax1[3].set_title(\"XGBoost regression \\n with target sqrt-transformation\")\n",
    "\n",
    "#ax1[0].set_ylim(0,200)\n",
    "\n",
    "\n",
    "#f.suptitle(\"Synthetic data\", y=1.05)\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "## reload models\n",
    "\n",
    "\n",
    "#model_eval = pickle.load(open(f\"./models_trained/xgboost_{target}_{pipe_name}.sav\", 'rb'))\n",
    "#model_eval.get_params()\n",
    "#dir(model_eval)#.feature_importances_[model_eval.feature_importances_>0.015].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importance\n",
    "Have the same feature importance method across all applied ML models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df_importance_package = pd.DataFrame({\n",
    "#     \"name\" : X_train.columns.to_list(),\n",
    "#     \"importances\" : model.feature_importances_,\n",
    "#      }) \n",
    "# df_importance_package.sort_values(\"importances\", ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Permuation feature importance\n",
    "# result = e.permutation_feature_importance(model, X_test, y_test, repeats=5, seed=seed)\n",
    "\n",
    "# df_importance = pd.DataFrame({\n",
    "#     \"name\" : X_train.columns.to_list(),\n",
    "#     \"importances\" : result[0],\n",
    "# #    \"importances\" : np.abs(result[0]),\n",
    "#      }) \n",
    "# df_importance = df_importance.sort_values(\"importances\", ascending=True)  # get most important features to the top\n",
    "# df_importance.tail(18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot feature importance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA38AAAHcCAYAAABmoBPmAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAACHTElEQVR4nOzdd1QU19sH8O/SexEBARGsFAXFXgNWrLH3CGisscRefjZssRtb7BGIvcZYMVgwdrGgRokalKAJih1FRYT7/uFhXpfdhUXRRef7OWeP7sydO8/M3N2dh3tnRiGEECAiIiIiIqIvmp6uAyAiIiIiIqKPj8kfERERERGRDDD5IyIiIiIikgEmf0RERERERDLA5I+IiIiIiEgGmPwRERERERHJAJM/IiIiIiIiGWDyR0REREREJANM/oiIiIiIiGSAyR8VOD169ICxsTEuX76sMm/GjBlQKBTYtWuX0vSUlBTMmDED1apVg42NDQwNDeHo6IjGjRtj/fr1SEtLk8omJCRAoVAovaysrFC+fHnMnz8fGRkZH30bc7NkyRKEh4fnaZknT56gcOHC2Lhx48cJKgcnTpxAaGgonjx5ovUy69evx/z58z9aTPlt3LhxKFasGAwMDGBjY6PrcPJNSEgI3N3dpfePHz+GjY0NduzY8UH1hoaGqnzOsl6LFy/+sKA1eJ92+KlER0dDoVBg69atug7lve3duxehoaG6DuOTev36Nfr27QsnJyfo6+ujQoUKH2U9We1Dm1dBo+t2ERAQgICAgPdaVtNvbdZ5Ql5/h78E//33H0JDQxEbG/tJ1sdjoAOCqIB5+vSpKFasmPDz8xOvX7+Wpl+6dEkYGRmJkJAQpfLXr18XJUqUEBYWFmLo0KHit99+E3/88YfYtGmT6NGjhzA2Nhbjxo2Tyt+6dUsAEAMHDhQnT54UJ0+eFPv27RP9+vUTAMTQoUM/2bZqUrZsWeHv75+nZQYPHix8fHxEZmbmxwkqB7NnzxYAxK1bt7ReplmzZsLNze2jxZSfduzYIQCIsWPHimPHjomYmBhdh5RvgoODVY5DaGioKFWqlEhLS3vveidOnCgAiMjISOlzlvW6e/fuB0at3vu0w0/l8OHDAoDYsmWLrkN5b/379xdyO22YP3++ACAWLVokTpw4IS5duvRR1vP06VOVz0mRIkVErVq1VKYXNLpuF/7+/nn+vcyi6bf21atX4uTJkyI5OfnDgvsMxcTECAAiLCzsk6xP0zHIOlf7VHHIiYFuUk4izaysrPDzzz+jUaNGmDp1KiZNmoT09HR069YNjo6OSr1Fb968QatWrfDo0SOcOXMGXl5eSnV16NABEyZMwIULF1TWU6xYMVSvXl1637hxY/z555/YsGED5s6d+9G272N49OgRli9fjh9//PGT/mX45cuXMDEx+ejrycjIwJs3b2BsbPzR16XOn3/+CQAYNGgQHBwc8qXOFy9ewMzMLF/qym99+/bF1KlTsXXrVnTp0uWD6qpUqRIKFy6cT5HpRlY7L4i9Lp9CQW6rH9uff/4JU1NTDBgwIN/qfPnyJUxNTZWmWVlZKf0eAYCxsTFsbGxUpr8PIQRevXqlst6CqCC0N2Nj43zZ70T5Id8/E7rOPok06devnzAwMBBnz54V//vf/wQA8fvvvyuV2bx5swAgZs+erXW9WX9NUrdM8+bNRbFixZSmZWRkiJkzZwoPDw9hZGQk7O3tRbdu3cTt27dVlv/555+Fr6+vMDY2Fra2tqJVq1bi6tWrSmXi4+NFx44dhZOTkzAyMhIODg6iXr164sKFC0IIIdzc3AQApVduPWRz584VhoaG4vHjx3lalxBCvH79WowYMUI4OjoKU1NTUatWLXH69Gnh5uYmgoODpXJhYWECgNi/f7/o3r27KFy4sAAgRo0apRIvAHH48GGN8fr7+6tdRoj/Pz4zZ84UU6ZMEe7u7kJfX1/s27dPvHz5UgwdOlSUL19eWFlZCVtbW1G9enWxY8cOlXUAEP379xe//PKL8PT0FKampsLX11fs2rVLqVxycrLo1auXKFq0qDAyMhKFCxcWNWvWFFFRURqPx8SJE4UQ2rcNf39/UbZsWXHkyBFRo0YNYWpqKjp27Cht66xZs8SMGTOEm5ubMDExEf7+/uLatWvi9evXYtSoUcLJyUlYWVmJVq1aiXv37qls68aNG0X16tWFmZmZMDc3F40aNRLnz59XKRcWFibKlCkjjIyMhKenp4iIiFDb8yeEEE2aNBF16tTReAxzk9Xzd//+fY1lMjMzxU8//STKly8vTExMhI2NjWjbtq2Ij49XKvf777+Lr7/+Wri4uAhjY2NRsmRJ0bt3b6W6s9anqR2+e9zepW07f/nypRBC+32dnbqev6yYL168KNq1aye16SFDhoj09HTx119/icDAQGFhYSHc3NzEzJkz1da5Zs0aMWTIEOHo6ChMTEzEV199pTam3377TVSvXl2YmpoKCwsL0aBBA3HixAmlMlkxnTt3TrRt21bY2NiIIkWKiODgYLX7N6uXdfHixaJOnTrC3t5emJmZiXLlyomZM2cqjd4Q4v8/C2fOnBG1a9cWpqamonjx4mL69OkiIyNDqezjx4/F0KFDRfHixaXPV5MmTURcXJxUJi0tTUyZMkX6DBYuXFiEhISo9NgcPHhQ+Pv7i0KFCgkTExPh6uoq2rRpI1JTUzUeM3Xbm9UL8fLlSzF69Gjh7u4uDA0NhbOzs/juu+9UvoPd3NxEs2bNxLZt20SFChWEsbGxGDVqlMZ1qls2y/t8/y1dulR4enoKQ0NDsXTpUiGEEEePHhXVq1cXxsbGwtnZWYwbN06sXLlSba95bu09t3aRm+DgYGFubi4uXbokGjZsKCwsLET16tWFENofW3U9f6GhoaJq1arC1tZWWFpaCj8/P7Fq1SqlkTE5/dZm73X69ddfBQBx4MABlW1YsmSJ9DnOEhMTI1q0aCFsbW2FsbGxqFChgti0aZNW++RdGRkZYuHChdJ3pLW1tahWrZr47bfflMrk5Xcop89e1neKpt88bbct63v00KFDom/fvsLOzk4UKlRItG7dWvz777/vdQyyHD16VNSrV09YWFgIU1NTUaNGDbF7926lMqmpqWLYsGHC3d1dOh+rVKmSWL9+vVRGm/MjbVy/fl107txZ2NvbS7+tixcvVrs/sn8usvb3u+dLms4XhBDin3/+EV27dlVa15w5c1S+O3PD5I8KrOfPn4sSJUpIJ/99+/ZVKdOrVy8BQFy7dk3ret9NLtLT00V6erp48OCB+Pnnn4WBgYEYO3asUvnevXsLAGLAgAEiMjJSLFu2TNjb2wtXV1elk88ffvhBABCdO3cWe/bsEb/88osoUaKEsLa2FtevX5fKeXh4iFKlSok1a9aII0eOiG3btolhw4ZJH/7z58+LEiVKCD8/P2mYT24nl/Xq1RNVq1ZVmZ7buoR4++OrUCjEiBEjxO+//y7mzZsnXFxchJWVldqTYhcXF9G7d2+xb98+sXXrVpGQkCAGDhwoAIjt27dLMT99+lRjvFeuXBG1atUSRYoUURnOlHV8XFxcRN26dcXWrVvF77//Lm7duiWePHkiQkJCxJo1a8ShQ4dEZGSkGD58uNDT0xMRERFK6wAg3N3dRdWqVcXmzZvF3r17RUBAgDAwMFBKLgIDA4W9vb1YsWKFiI6OFjt27BATJkwQGzdulI7Ht99+qzSEMetHVdu2kXXS6erqKhYtWiQOHz4sjhw5Im2rm5ubaNGihdi9e7dYu3atcHR0FGXKlBHdunUTPXr0EPv27RPLli0TFhYWokWLFkrbOW3aNKFQKESPHj3E7t27xfbt20WNGjWEubm5uHLlisrxa9mypdi1a5dYu3atKFWqlHB1dVWb/M2cOVPo6ekpncxmxftuu9AkK4m4e/eu9DlLT08Xb968kcr06tVLGBoaimHDhonIyEixfv164enpKRwdHZWGhi5dulRMnz5d7Ny5Uxw5ckRERESI8uXLCw8PDym5uH37do7tMK/JX/Z2/ubNG633tTo5JX8eHh5iypQpIioqSowcOVJqU56enmLhwoUiKipKdO/eXQAQ27ZtU6nT1dVV5bhaWVkptfN169YJAKJRo0Zix44dYtOmTaJSpUrCyMhIHD16VCUmNzc3MWrUKBEVFSV27Ngh/v77b9GuXTsBQOkz++rVKyGEEEOGDBFLly4VkZGR4tChQ+LHH38UhQsXFt27d1faD/7+/sLOzk6ULl1aLFu2TERFRYnvvvtOAFD6DKekpIiyZcsKc3NzMXnyZLF//36xbds28f3334tDhw4JId6e9DZu3FiYm5uLSZMmiaioKLFq1Srh4uIivL29xYsXL4QQb9utiYmJaNiwodixY4eIjo4W69atE926dVNJ1t518uRJ0bRpU2Fqaiptb3JyssjMzBSBgYHCwMBAjB8/Xvz+++9izpw5wtzcXPj5+Un7JKt9OTk5iRIlSojVq1eLw4cPizNnzuTYVt5d9t3kL6/ffy4uLsLX11esX79eHDp0SPz555/i4sWLwsTERPj6+oqNGzeKnTt3iqZNmwp3d3eVk1Nt2ntu7SI3wcHBwtDQULi7u4vp06eLgwcPiv3792t9bIVQn/yFhISIn3/+WURFRYmoqCgxZcoUYWpqKiZNmiSVyem3NnvikZ6eLhwcHETXrl1VtqFq1aqiYsWK0vtDhw4JIyMjUadOHbFp0yYRGRkpQkJC3msIY7du3YRCoRA9e/YUv/32m9i3b5+YNm2aWLBggVQmL79DuX32nj59Kn0Hjhs3TtovWb952m5bVh0lSpQQAwcOFPv37xerVq0Stra2om7duu91DIQQIjo6WhgaGopKlSqJTZs2iR07dohGjRoJhUIh/WYLIUSfPn2EmZmZmDdvnjh8+LDYvXu3mDFjhli0aJFURpvzo9xcuXJFWFtbCx8fH/HLL7+I33//XQwbNkzo6emJ0NBQlf2hbfKn7nwhOTlZuLi4CHt7e7Fs2TIRGRkpBgwYIACIfv36aR2zEEz+qIBbv369ACCKFCkinj17pjK/cePGAoDKD01mZqbGE86sLxR1r5CQEKWycXFxAoD47rvvlOo/ffq0ACD+97//CSHe/oXa1NRUNG3aVKlcYmKiMDY2Fl26dBFCCPHgwQMBQMyfPz/H7c7rNX9mZmYqybE268raviFDhihNzzpRVHdSHBQUpFJPfl7zl3V8SpYsqdJrkN2bN29Eenq6+Pbbb4Wfn5/SPADC0dFRpKSkSNPu3r0r9PT0xPTp06VpFhYWYvDgwTmuR10vlrZtQ4j/7+k8ePCg2m0tX7680l/usq4z+vrrr5XKDx48WACQEprExERhYGAgBg4cqFTu2bNnokiRIqJDhw5CiLcnyc7OzqJixYpKf/lOSEgQhoaGao9DVFSUACD27dunVF5fX1/06NEjx/0lhOaeOBcXFyHE2xNrAGLu3LlKy92+fVuYmpqKkSNHqq0367P9zz//CABKfwHPqR3mNfnL3s613dea5JT8Zd8HFSpUkJLYLOnp6cLe3l60adNGpU5Nx7Vnz55CiP8//j4+Pkrt7NmzZ8LBwUHUrFlTJaYJEyaobIO213ZlZGSI9PR08csvvwh9fX3x6NEjaV7WZ+H06dNKy3h7e4vAwEDp/eTJkwUAqQdenQ0bNqgkxEL8/zVLS5YsEUIIsXXrVgFAxMbG5hp7dlk9U++KjIwUwNse+3dt2rRJABArVqyQprm5uQl9ff08/YHy3WXfTf6yy+37z9raWmnfCyFE+/bthbm5udJ3WUZGhvD29lb67OSlvX/INX9ZPYerV69Wmq7tsRUi92v+strj5MmThZ2dndJnJS/Xmw0dOlSYmpqKJ0+eSNOuXr0qACglFZ6ensLPz0+kp6cr1dm8eXPh5OSkdS/NH3/8IQCo/EH6Xe/zO5TbZy+na/603bas79Hscc2aNUsAEElJSdK0vByD6tWrCwcHB6XzwTdv3ohy5cqJokWLSse2XLlyolWrVip1ZtH2XCw3gYGBomjRoip/7B4wYIAwMTGRPn95Tf7UnS+MHj1a7fHr16+fUCgUefqO4d0+qcDKzMzEokWLoKenh+TkZFy8eFHrZRcsWABDQ0PpVb58eZUy33//PWJiYhATE4PDhw/jhx9+wObNm9G5c2epzOHDhwG8vSPiu6pWrQovLy8cPHgQAHDy5Em8fPlSpZyrqyvq1asnlStUqBBKliyJ2bNnY968ebhw4QIyMzO13i51njx5ghcvXqhci6bNurK2r2vXrkrTO3ToAAMD9ZcEt23bVuvYMjMz8ebNG+mVlzupfv311zA0NFSZvmXLFtSqVQsWFhYwMDCAoaEhfv75Z8TFxamUrVu3LiwtLaX3jo6OcHBwwD///CNNq1q1KsLDwzF16lScOnUK6enpWsWnbdvIYmtri3r16qmtq2nTptDT+/+v46xrV5s1a6ZULmt6YmIiAGD//v148+YNgoKClPaziYkJ/P39ER0dDQC4du0a/vvvP3Tp0kXpujU3NzfUrFlTbUxZ7enff/9VKv/mzRv8/PPPapdR58CBA9LnLCYmBnv37gUA7N69GwqFAt98841S7EWKFEH58uWl2AEgOTkZffv2haurq3TM3dzcAEDtcc8P2du5tvv6fTRv3lzpvZeXFxQKBZo0aSJNMzAwQKlSpZTabhZNxzWrjWYd/27duim1MwsLC7Rt2xanTp3Cixcvctz+3Fy4cAFff/017OzsoK+vD0NDQwQFBSEjIwPXr19XKlukSBFUrVpVaZqvr6/Stu3btw9lypRBgwYNNK5z9+7dsLGxQYsWLZSOSYUKFVCkSBHpmFSoUAFGRkbo3bs3IiIicPPmzTxtW3aHDh0CoPrZb9++PczNzVU++76+vihTpswHrTNLXr7/6tWrB1tbW6VpR44cQb169ZSuw9XT00OHDh2Uyn3M9q5O9vam7bHV5NChQ2jQoAGsra2l9jhhwgQ8fPgQycnJ7xVjjx498PLlS2zatEmaFhYWBmNjY+na6L///ht//fWX9Jv6buxNmzZFUlISrl27ptX69u3bBwDo37+/xjJ5/R3S5rOnyfts29dff62yLgBarS+71NRUnD59Gu3atYOFhYU0XV9fH926dcOdO3ek9VetWhX79u3D6NGjER0djZcvXyrVlR/nYq9evcLBgwfRunVrmJmZqeyPV69e4dSpU3neTkD9+cKhQ4fg7e2tcvxCQkIghJC+l7TB5I8KrDlz5uDkyZNYv349SpcuLX3xvqtYsWIAVL9IunTpIp1sVqxYUW39RYsWReXKlVG5cmUEBARgzJgxGD9+PLZs2YL9+/cDAB4+fAgAcHJyUlne2dlZmq9tOYVCgYMHDyIwMBCzZs1CxYoVYW9vj0GDBuHZs2da75t3Ze2T7Dde0WZdWXEVKVJEaVkDAwPY2dmpXZ+6bdRk8uTJSkl4yZIltV5W3Xq2b9+ODh06wMXFBWvXrsXJkycRExODHj164NWrVyrl1W2DsbGxUjvatGkTgoODsWrVKtSoUQOFChVCUFAQ7t69m2N82h7znLYnS6FChZTeGxkZ5Tg9a1vv3bsHAKhSpYrSfjY0NMSmTZvw4MEDpVizH2dN04D/b0/ZP3N5Vb58eelzVrlyZenH/969exBCwNHRUSX2U6dOSbFnZmaiUaNG2L59O0aOHImDBw/izJkz0o/qh8anSfbjpe2+fh/qjrOZmZnKZ9rIyEhtO9d0XLX9fsrMzMTjx4+Vpuflc56YmIg6derg33//xYIFC3D06FHExMTgp59+AqB6jLT5XN6/fx9FixbNcb337t3DkydPYGRkpHJM7t69Kx2TkiVL4sCBA3BwcED//v1RsmRJlCxZEgsWLNB6G9/18OFDGBgYwN7eXmm6QqFQ2u9Z8rIvc5LX7z9163348CEcHR1Vpmef9jHbe3ZmZmawsrJSWb82x1adM2fOoFGjRgCAlStX4vjx44iJicHYsWMBvP93RtmyZVGlShWEhYUBeHsjsrVr16Jly5bSZzhrvw0fPlwl7u+++w4AtN539+/fh76+vsbvaCDvv0PafPY0eZ9ty76+rJu2vc8xePz4MYQQGrcV+P/9sXDhQowaNQo7duxA3bp1UahQIbRq1Qo3btwAkD/nYg8fPsSbN2+waNEilf3RtGlTANof6+w0fXa12XZt8G6fVCBdvXoVEyZMQFBQEDp27Ag3NzfUqlULY8eOxbx586RyDRs2xIoVK7Bz504MHz5cmu7g4CD1XFhaWio95y8nWSemFy9eRGBgoPTFlZSUpHIi8t9//0l/PX23XHbvlgPe/lU+q+fk+vXr2Lx5M0JDQ/H69WssW7ZMqzjflbXuR48eqczLbV1Zy969excuLi7Scm/evNH4RZKXOx727t1bqVcjL3frVLeetWvXonjx4ti0aZPSfG2PrzqFCxfG/PnzMX/+fCQmJmLnzp0YPXo0kpOTERkZqXE5bdtGTtvzobLWsXXrVqknTJ13j3N2mpLcrPb0se7UWbhwYSgUChw9elRtu8ia9ueff+LixYsIDw9HcHCwNP/vv//O0/qMjY3VthNt27m2+1oXNB3XrOOe2/eTnp6eSg9RXtrrjh07kJqaiu3btyvtmw95Tpi9vT3u3LmTY5nChQvDzs5O4+f03V7/OnXqoE6dOsjIyMDZs2exaNEiDB48GI6OjujUqVOeYrOzs8ObN29w//59pQRQCIG7d++iSpUqSuXz67Of1+8/deu1s7OTTuLflb0Nfcr2ri7OvBzb7DZu3AhDQ0Ps3r1b6Q8oH/rsUgDo3r07vvvuO8TFxeHmzZtISkpC9+7dleIGgDFjxqBNmzZq6/Dw8NBqXfb29sjIyMDdu3c1/gEhr79DHyI/t+192NraQk9PT+P32LsxmpubY9KkSZg0aRLu3bsn9QK2aNECf/31F4APPxeztbWVeh019c4WL14cwP//MTX7Z1VTcqjps6vNtmuDPX9U4Lx58wbBwcEoXLiw9JfZ6tWrY+jQoViwYAGOHz8ulW3dujW8vb3xww8/SB/oD5F1spKVOGZ1u69du1apXExMDOLi4lC/fn0AQI0aNWBqaqpS7s6dOzh06JBULrsyZcpg3Lhx8PHxwfnz56Xp2v4lDnjbG1CiRAnEx8fnWE7durIejLtu3Tqlsps3b8abN2+0Wn9WvIDqX/OcnZ2Ven18fHyUlsnrX/8UCgWMjIyUvhjv3r2L3377LU/1aFKsWDEMGDAADRs2VDoe6mjbNj6mwMBAGBgYID4+Xmk/v/sC3v4gOzk5YcOGDRBCSMv/888/OHHihNq6s4bGeXt7f5TYmzdvDiEE/v33X7VxZ7WVrGOdPUFcvny5Sp05/VXZ3d0dly5dUpp26NAhPH/+XKt4td3XuqDpuGZ9vj08PODi4oL169crlUtNTcW2bdtQo0YNrW4jrmn/qjtGQgisXLnyvbepSZMmuH79eo5DmZo3b46HDx8iIyND7fFQdyKqr6+PatWqSb2SuX3O1cn6bGf/7G/btg2pqakf7bOfH99//v7+OHTokNJJZ2ZmJrZs2aJULi/t/UN6czR5n2ObRaFQwMDAAPr6+tK0ly9fYs2aNSpl8/o71LlzZ5iYmCA8PBzh4eFwcXGRehmBt5+10qVL4+LFixr3W06J67uyhn0vXbpUY5mP8Tuk6Xjm57ZlX582x8Dc3BzVqlXD9u3blcpnZmZi7dq1KFq0qNrh1Y6OjggJCUHnzp1x7do1lSHugOZzsZyYmZmhbt26uHDhAnx9fdXuj6zk3N3dHQBUfoN27typ1bqAt987V69eVYnvl19+gUKhQN26dbWuiz1/VOBMnz4dZ8+exb59+2BjYyNNnzJlCnbt2oUePXogNjYWpqam0NfXx44dOxAYGIiqVauiV69eCAgIgK2tLZ48eYLTp0/j4sWLKs//A94OVcoaOpaamoqTJ09i+vTpcHNzk/6q5eHhgd69e0vXHjZp0gQJCQkYP348XF1dMWTIEACAjY0Nxo8fj//9738ICgpC586d8fDhQ0yaNAkmJiaYOHEigLcf/AEDBqB9+/YoXbo0jIyMcOjQIVy6dAmjR4+WYvPx8cHGjRuxadMmlChRAiYmJkqJU3YBAQHS9QFZtFmXl5cXvvnmG8yfPx+GhoZo0KAB/vzzT8yZM0dlGE5OsmJbsGABgoODYWhoCA8Pjxx/CHx8fLB9+3YsXboUlSpVgp6eXq4n0M2bN8f27dvx3XffoV27drh9+zamTJkCJycnaThHXjx9+hR169ZFly5d4OnpCUtLS8TExCAyMlLjXzazaNs2PiZ3d3dMnjwZY8eOxc2bN9G4cWPY2tri3r17OHPmjPTXTz09PUyZMgU9e/ZE69at0atXLzx58gShoaEahxSdOnUKdnZ2Su3un3/+QcmSJREcHJyn6/7UqVWrFnr37o3u3bvj7Nmz+Oqrr2Bubo6kpCQcO3YMPj4+6NevHzw9PVGyZEmMHj0aQggUKlQIu3btQlRUlEqdObXDbt26Yfz48ZgwYQL8/f1x9epVLF68GNbW1lrFq+2+1oXk5GTpuD59+hQTJ06EiYkJxowZA+DtNV2zZs1C165d0bx5c/Tp0wdpaWmYPXs2njx5ghkzZmi1nqz9O3PmTDRp0gT6+vrw9fVFw4YNYWRkhM6dO2PkyJF49eoVli5dqjKUNC8GDx6MTZs2oWXLlhg9ejSqVq2Kly9f4siRI2jevDnq1q2LTp06Yd26dWjatCm+//57VK1aFYaGhrhz5w4OHz6Mli1bonXr1li2bBkOHTqEZs2aoVixYnj16hVWr14NADleU6hJw4YNERgYiFGjRiElJQW1atXCpUuXMHHiRPj5+aFbt27vvd05yY/vv7Fjx2LXrl2oX78+xo4dC1NTUyxbtgypqakAIF0Tmpf2rqldZA1Tfx/aHlt1mjVrhnnz5qFLly7o3bs3Hj58iDlz5qgdYZDX31obGxu0bt0a4eHhePLkCYYPH650HS3w9g9TTZo0QWBgIEJCQuDi4oJHjx4hLi4O58+fV0m0NalTpw66deuGqVOn4t69e2jevDmMjY1x4cIFmJmZYeDAgR/ld6hkyZIwNTXFunXr4OXlBQsLCzg7O8PZ2Tnftu1deTkG06dPR8OGDVG3bl0MHz4cRkZGWLJkifSM5qw/jFSrVg3NmzeHr68vbG1tERcXhzVr1kh/6NL2XCw3CxYsQO3atVGnTh3069cP7u7uePbsGf7++2/s2rVL+uNVlSpV4OHhgeHDh+PNmzewtbXFr7/+imPHjmm9riFDhuCXX35Bs2bNMHnyZLi5uWHPnj1YsmQJ+vXrl7frirW+NQzRJxAbGysMDQ1Fr1691M4/efKk0NPTU7k75dOnT8UPP/wgqlSpIqysrISBgYFwcHAQDRs2FD/99JPSs5zU3e3TxMRElClTRgwePFjpLlRC/P8zdMqUKSMMDQ1F4cKFxTfffKP2OX+rVq0Svr6+wsjISFhbW4uWLVsq3QL+3r17IiQkRHh6egpzc3NhYWEhfH19xY8//qh0l9GEhATRqFEjYWlpKd12PScHDx4UAJRuIa7tutLS0sSwYcOEg4ODMDExEdWrVxcnT57UeBfEmJgYtTGMGTNGODs7Cz09PZW7V6nz6NEj0a5dO2FjYyMUCoV0t7icnsMohBAzZsyQnt3j5eUlVq5cKd2h8F3A2+dcZffudr169Ur07dtX+Pr6CisrK2Fqaio8PDzExIkTldqMpmfWads2sp7bk52mbVV3Z0ghNB+DHTt2iLp16worKythbGws3NzcRLt27VSeSbVq1SpRunRpYWRkJMqUKSNWr16t9jl/mZmZws3NTeVOf+/zqIecnvMnhBCrV68W1apVE+bm5sLU1FSULFlSBAUFibNnz0plrl69Kho2bCgsLS2Fra2taN++vUhMTFR7B09N7TAtLU2MHDlSuLq6ClNTU+Hv7y9iY2Pz3M613dfZ5XS3z+z7SN0dJoVQbUfvPudv0KBBwt7eXhgbG4s6deoo7b93Y69WrZowMTER5ubmon79+uL48eNKZXI6bmlpaaJnz57C3t5e+sxm3b1u165d0rPIXFxcxIgRI8S+ffvU3slO3WdBXTt8/Pix+P7770WxYsWEoaGhcHBwEM2aNRN//fWXVCY9PV3MmTNHWreFhYXw9PQUffr0ETdu3BBCvP3daN26tXBzcxPGxsbCzs5O+Pv7i507d6rEoS4udcfi5cuXYtSoUcLNzU0YGhoKJycn0a9fP43P+Xsf6pb90O8/Id4+J61atWrC2NhYFClSRIwYMULMnDlTAFC6k6UQ2rX3nNpFbjTtXyG0O7ZCqL/b5+rVq4WHh4cwNjYWJUqUENOnTxc///yzSmyafms1PWNOiLfPHc06d3j3MU7vunjxoujQoYNwcHAQhoaGokiRIqJevXpi2bJlWu2XLBkZGeLHH38U5cqVk84ratSoofS82g/9HVL32duwYYP0fMjs37PabJum71F1d7fM6zHIes5f1m9G9erVVZ7fO3r0aFG5cmXpWYQlSpQQQ4YMEQ8ePBBCaH9+pI1bt26JHj16CBcXF2FoaCjs7e1FzZo1xdSpU5XKXb9+XTRq1EhYWVkJe3t7MXDgQLFnzx6tvyOFePucvy5dugg7OzthaGgoPDw8xOzZs/P8nD+FEO+MASGiz5avry9q1aqV4xCRvHB3d0dAQADCw8PzpT76fBw8eBCNGjXClStX4OnpqetwSIPo6GjUrVsXW7ZsQbt27XQdDn3GGjVqhISEBJU7sxLRl4fDPom+ELNmzULr1q0xduzYXO+SR5STqVOnokePHkz8iL5AQ4cOhZ+fH1xdXfHo0SOsW7cOUVFRHzyUm4g+D0z+iL4QjRs3xuzZs3Hr1i0mf/TeHj9+DH9/f+nW3UT0ZcnIyMCECRNw9+5dKBQKeHt7Y82aNfjmm2/ybR2ZmZm5PjdN07Nk5SC3G6rp6empXEtIn86X3n457JOIiIiI8k1ISAgiIiJyLCPn08/cHv8RHBzMSy50KDQ0NNcbeN26dUu6i+fnhskfEREREeWbhISEXB9wrcvHo+ja2bNnc5xfuHDhzzax+BL8999/0vPzNPnQO9rqEpM/IiIiIiIiGeCAYiIiIiIiIhn4fK9WJCqgMjMz8d9//8HS0jLXcf1ERERE9OkJIfDs2TM4OzvL6gY7TP6I8tl///0HV1dXXYdBRERERLm4ffu2rO6SzuSPKJ9ZWloCePtlYmVlpeNoiIiIiCi7lJQUuLq6SudtcsHkjyifZQ31tLKyYvJHREREVIDJ7RId+QxwJSIiIiIikjEmf0RERERERDLA5I+IiIiIiEgGmPwRERERERHJAJM/IiIiIiIiGWDyR0REREREJANM/oiIiIiIiGSAyR8REREREZEMMPkjIiIiIiKSASZ/REREREREMsDkj4iIiIiISAYMdB0A0ZcqaMYWGJqY6ToMIiIiogJvy4TOug5BFtjzR0REREREJANM/oiIiIiIiGSAyR8REREREZEMMPkjIiIiIiKSASZ/MiKEQO/evVGoUCEoFArY2Nhg8ODBug5Lo+joaCgUCjx58qRA1kdERERE9Dlh8icjkZGRCA8Px+7du5GUlIRy5crpOqRPqmbNmkhKSoK1tTUAIDw8HDY2NroNioiIiIjoE+GjHmQkPj4eTk5OqFmzJgDAwEBeh9/IyAhFihTRdRhERERERDrBnj+ZCAkJwcCBA5GYmAiFQgF3d3eVMo8fP0ZQUBBsbW1hZmaGJk2a4MaNGwDeDhm1t7fHtm3bpPIVKlSAg4OD9P7kyZMwNDTE8+fP0blzZ3Tq1Emp/vT0dBQuXBhhYWFSnbNmzUKJEiVgamqK8uXLY+vWrTlux7Zt21C2bFkYGxvD3d0dc+fOVZqflpaGkSNHwtXVFcbGxihdujR+/vlnAMrDPqOjo9G9e3c8ffoUCoUCCoUCoaGhmDx5Mnx8fFTWW6lSJUyYMCHH2IiIiIiICjImfzKxYMECTJ48GUWLFkVSUhJiYmJUyoSEhODs2bPYuXMnTp48CSEEmjZtivT0dCgUCnz11VeIjo4G8DZRvHr1KtLT03H16lUAb5OrSpUqwcLCAl27dsXOnTvx/Plzqf79+/cjNTUVbdu2BQCMGzcOYWFhWLp0Ka5cuYIhQ4bgm2++wZEjR9Ruw7lz59ChQwd06tQJly9fRmhoKMaPH4/w8HCpTFBQEDZu3IiFCxciLi4Oy5Ytg4WFhUpdNWvWxPz582FlZYWkpCQkJSVh+PDh6NGjB65evaq0fy5duoQLFy4gJCREbVxpaWlISUlRehERERERFTTyGvcnY9bW1rC0tIS+vr7aoY83btzAzp07cfz4cWlY6Lp16+Dq6oodO3agffv2CAgIwIoVKwAAf/zxB8qXL49ixYohOjoa3t7eiI6ORkBAAAAgMDAQ5ubm+PXXX9GtWzcAwPr169GiRQtYWVkhNTUV8+bNw6FDh1CjRg0AQIkSJXDs2DEsX74c/v7+KjHOmzcP9evXx/jx4wEAZcqUwdWrVzF79myEhITg+vXr2Lx5M6KiotCgQQOpTnWMjIxgbW0NhUKhtD8sLCwQGBiIsLAwVKlSBQAQFhYGf39/jXVNnz4dkyZNyvkAEBERERHpGHv+CAAQFxcHAwMDVKtWTZpmZ2cHDw8PxMXFAQACAgJw5coVPHjwAEeOHEFAQAACAgJw5MgRvHnzBidOnJCSNkNDQ7Rv3x7r1q0DAKSmpuK3335D165dAQBXr17Fq1ev0LBhQ1hYWEivX375BfHx8RpjrFWrltK0WrVq4caNG8jIyEBsbCz09fXVJo550atXL2zYsAGvXr1Ceno61q1bhx49emgsP2bMGDx9+lR63b59+4PWT0RERET0MbDnjwC8vf5O03SFQgEAKFeuHOzs7HDkyBEcOXIEkydPhqurK6ZNm4aYmBi8fPkStWvXlpbt2rUr/P39kZycjKioKJiYmKBJkyYAgMzMTADAnj174OLiorROY2PjXGNRF7epqWket1q9Fi1awNjYGL/++iuMjY2RlpYmDVVVx9jYWGPMREREREQFBZM/AgB4e3vjzZs3OH36tDTs8+HDh7h+/Tq8vLwAQLru77fffsOff/6JOnXqwNLSEunp6Vi2bBkqVqwIS0tLqc6aNWvC1dUVmzZtwr59+9C+fXsYGRlJ6zM2NkZiYqLWPXXe3t44duyY0rQTJ06gTJky0NfXh4+PDzIzM3HkyBFp2GdOjIyMkJGRoTLdwMAAwcHBCAsLg7GxMTp16gQzMzOtYiQiIiIiKqiY/BEAoHTp0mjZsiV69eqF5cuXw9LSEqNHj4aLiwtatmwplQsICMCQIUPg5+cHKysrAMBXX32FdevWYejQoUp1KhQKdOnSBcuWLcP169dx+PBhaZ6lpSWGDx+OIUOGIDMzE7Vr10ZKSgpOnDgBCwsLBAcHq8Q4bNgwVKlSBVOmTEHHjh1x8uRJLF68GEuWLAEAuLu7Izg4GD169MDChQtRvnx5/PPPP0hOTkaHDh1U6nN3d8fz589x8OBBlC9fHmZmZlKS17NnTynpPX78+AfuXSIiIiIi3eM1fyQJCwtDpUqV0Lx5c9SoUQNCCOzduxeGhoZSmbp16yIjI0O6sQsA+Pv7IyMjQ20PXteuXXH16lW4uLioXK83ZcoUTJgwAdOnT4eXlxcCAwOxa9cuFC9eXG18FStWxObNm7Fx40aUK1cOEyZMwOTJk5Xuwrl06VK0a9cO3333HTw9PdGrVy+kpqaqra9mzZro27cvOnbsCHt7e8yaNUuaV7p0adSsWRMeHh5K10ESEREREX2uFELTxV5EMiaEgKenJ/r06aPSo5mblJQUWFtbo+WYVTA04XBRIiIiotxsmdD5k64v63zt6dOn0mg2OeCwT6JskpOTsWbNGvz777/o3r27rsMhIiIiIsoXTP6IsnF0dEThwoWxYsUK2Nra6jocIiIiIqJ8weSPKJv8Ggn9y+j2shpGQEREREQFG2/4QkREREREJANM/oiIiIiIiGSAyR8REREREZEMMPkjIiIiIiKSASZ/REREREREMsDkj4iIiIiISAaY/BEREREREckAkz8iIiIiIiIZYPJHREREREQkA0z+iIiIiIiIZIDJHxERERERkQww+SMiIiIiIpIBJn9EREREREQywOSPiIiIiIhIBpj8ERERERERyQCTPyIiIiIiIhlg8kdERERERCQDTP6IiIiIiIhkgMkfERERERGRDDD5IyIiIiIikgEmf0RERERERDLA5I+IiIiIiEgGmPwRERERERHJAJM/IiIiIiIiGWDyR0REREREJANM/oiIiIiIiGSAyR8REREREZEMMPkjIiIiIiKSAQNdB0D0pQqasQWGJma6DoOIiIg+gS0TOus6BKJcseePiIiIiIhIBpj8ERERERERyQCTPyIiIiIiIhlg8kdERERERCQDBTb5CwgIwODBgzXOVygU2LFjxyeL52PLbXuio6OhUCjw5MmTD15XQkICFAoFYmNjP7guIiIiIiL6PBTY5O9LFRoaigoVKug0BldXVyQlJaFcuXI6jaOgY5JMRERERF8SPupBhvT19VGkSBFdh0FERERERJ9Qge75y8zMxMiRI1GoUCEUKVIEoaGhSvMfPHiA1q1bw8zMDKVLl8bOnTu1qjdrCOX+/fvh5+cHU1NT1KtXD8nJydi3bx+8vLxgZWWFzp0748WLF9JyaWlpGDRoEBwcHGBiYoLatWsjJiZGpd6DBw+icuXKMDMzQ82aNXHt2jUAQHh4OCZNmoSLFy9CoVBAoVAgPDw8z9uTmpoKKysrbN26VWn6rl27YG5ujmfPnuW4/dl7tHKLO8vOnTtRuXJlmJiYoHDhwmjTpo007/HjxwgKCoKtrS3MzMzQpEkT3LhxQ5ofHh4OGxsb7N69Gx4eHjAzM0O7du2QmpqKiIgIuLu7w9bWFgMHDkRGRoa03OvXrzFy5Ei4uLjA3Nwc1apVQ3R0dI7b967jx4/D398fZmZmsLW1RWBgIB4/fgwAiIyMRO3atWFjYwM7Ozs0b94c8fHx0rLFixcHAPj5+UGhUCAgIEDr9RIRERERFTQFOvmLiIiAubk5Tp8+jVmzZmHy5MmIioqS5k+aNAkdOnTApUuX0LRpU3Tt2hWPHj3Suv7Q0FAsXrwYJ06cwO3bt9GhQwfMnz8f69evx549exAVFYVFixZJ5UeOHIlt27YhIiIC58+fR6lSpRAYGKiyzrFjx2Lu3Lk4e/YsDAwM0KNHDwBAx44dMWzYMJQtWxZJSUlISkpCx44d87w95ubm6NSpE8LCwpSmh4WFoV27drC0tNR6H2gTNwDs2bMHbdq0QbNmzXDhwgUpUcwSEhKCs2fPYufOnTh58iSEEGjatCnS09OlMi9evMDChQuxceNGREZGIjo6Gm3atMHevXuxd+9erFmzBitWrFBKart3747jx49j48aNuHTpEtq3b4/GjRsrJZaaxMbGon79+ihbtixOnjyJY8eOoUWLFlJymZqaiqFDhyImJgYHDx6Enp4eWrdujczMTADAmTNnAAAHDhxAUlIStm/frnY9aWlpSElJUXoRERERERU0CiGE0HUQ6gQEBCAjIwNHjx6VplWtWhX16tXDjBkzoFAoMG7cOEyZMgXA2xN5S0tL7N27F40bN86x7ujoaNStWxcHDhxA/fr1AQAzZszAmDFjEB8fjxIlSgAA+vbti4SEBERGRiI1NRW2trYIDw9Hly5dAADp6elwd3fH4MGDMWLECLX17t27F82aNcPLly9hYmKC0NBQ7NixQ+U6sty2J6vux48fw8bGBmfOnEHNmjWRmJgIZ2dnPHjwAM7OzoiKioK/v3+O25+QkIDixYvjwoULqFChglZx16xZEyVKlMDatWtV6rtx4wbKlCmD48ePo2bNmgCAhw8fwtXVFREREWjfvj3Cw8PRvXt3/P333yhZsqS0f9esWYN79+7BwsICANC4cWO4u7tj2bJliI+PR+nSpXHnzh04OztL62vQoAGqVq2KH374Icft7NKlCxITE3Hs2LEcy2W5f/8+HBwccPnyZZQrV05lP2kSGhqKSZMmqUxvOWYVDE3MtFo3ERERfd62TOis6xAoD1JSUmBtbY2nT5/CyspK1+F8MgW658/X11fpvZOTE5KTk9XONzc3h6WlpdL8vNTv6OgIMzMzKfHLmpZVX3x8PNLT01GrVi1pvqGhIapWrYq4uDiN9To5OQGAVnHlZXuqVq2KsmXL4pdffgEArFmzBsWKFcNXX32V63q0WX/2uLN60dSJi4uDgYEBqlWrJk2zs7ODh4eH0r4xMzOTEj/g7f51d3eXEr+saVnrPH/+PIQQKFOmDCwsLKTXkSNHlIZnapJTzMDbY9qlSxeUKFECVlZW0jDPxMTEXOt+15gxY/D06VPpdfv27TwtT0RERET0KRToG74YGhoqvVcoFNKQPG3m56V+hUKRY31ZHaQKhUKpjBBCZVr2egFoFVdet6dnz55YvHgxRo8ejbCwMHTv3l0llrzIKW5TU1ONy2nqPM6+b9RtX07bnJmZCX19fZw7dw76+vpK5d5NGDXJKWYAaNGiBVxdXbFy5Uo4OzsjMzMT5cqVw+vXr3Ot+13GxsYwNjbO0zJERERERJ9age75K0hKlSoFIyMjpSGE6enpOHv2LLy8vLSux8jISOmGJh/im2++QWJiIhYuXIgrV64gODg4X+pVx9fXFwcPHlQ7z9vbG2/evMHp06elaQ8fPsT169fztG+y8/PzQ0ZGBpKTk1GqVCmllzZ3K80p5ocPHyIuLg7jxo1D/fr14eXlJd0IJouRkREA5NvxIiIiIiLSpQLd81eQmJubo1+/fhgxYgQKFSqEYsWKYdasWXjx4gW+/fZbretxd3fHrVu3EBsbi6JFi8LS0vK9e41sbW3Rpk0bjBgxAo0aNULRokXfqx5tTJw4EfXr10fJkiXRqVMnvHnzBvv27cPIkSNRunRptGzZEr169cLy5cthaWmJ0aNHw8XFBS1btnzvdZYpUwZdu3ZFUFAQ5s6dCz8/Pzx48ACHDh2Cj48PmjZtmuPyY8aMgY+PD7777jv07dsXRkZGOHz4MNq3b49ChQrBzs4OK1asgJOTExITEzF69Gil5R0cHGBqaorIyEgULVoUJiYmsLa2fu/tISIiIiLSJfb85cGMGTPQtm1bdOvWDRUrVsTff/+N/fv3w9bWVus62rZti8aNG6Nu3bqwt7fHhg0bPiimb7/9Fq9fv1a6M+fHEBAQgC1btmDnzp2oUKEC6tWrp9TTFxYWhkqVKqF58+aoUaMGhBDYu3evyrDOvAoLC0NQUBCGDRsGDw8PfP311zh9+jRcXV1zXbZMmTL4/fffcfHiRVStWhU1atTAb7/9BgMDA+jp6WHjxo04d+4cypUrhyFDhmD27NlKyxsYGGDhwoVYvnw5nJ2dPyiRJSIiIiLStQJ7t0/Szrp16/D999/jv//+k4Ypkm5l3T2Kd/skIiKSD97t8/Mi17t9ctjnZ+rFixe4desWpk+fjj59+jDxIyIiIiKiHH2Rwz779u2r9GiAd199+/bVdXj5YtasWahQoQIcHR0xZswYpXk//PCDxu1v0qSJjiLOf02aNNG4nbk9A5CIiIiISG6+yGGfycnJSElJUTvPysoKDg4OnziiT+vRo0d49OiR2nmmpqZwcXH5xBF9HP/++y9evnypdl6hQoVQqFChTxzRW3IdRkBERET0uZDr+doXOezTwcHhi0/wcqLLxOdT+lKSWCIiIiKiT+GLHPZJREREREREypj8ERERERERyQCTPyIiIiIiIhlg8kdERERERCQDTP6IiIiIiIhkgMkfERERERGRDDD5IyIiIiIikgEmf0RERERERDLA5I+IiIiIiEgGmPwRERERERHJAJM/IiIiIiIiGWDyR0REREREJANM/oiIiIiIiGSAyR8REREREZEMMPkjIiIiIiKSASZ/REREREREMsDkj4iIiIiISAaY/BEREREREckAkz8iIiIiIiIZYPJHREREREQkA0z+iIiIiIiIZIDJHxERERERkQww+SMiIiIiIpIBJn9EREREREQywOSPiIiIiIhIBpj8ERERERERyQCTPyIiIiIiIhkw0HUARF+qoBlbYGhipuswiIiI8mzLhM66DoGIPgL2/BEREREREckAkz8iIiIiIiIZYPJHREREREQkA0z+iIiIiIiIZIDJHxERERERkQww+SPKxt3dHQqFQuXVv39/XYdGRERERPTe+KgHLQkhkJGRAQMD7rKC4mMdk5iYGGRkZEjv//zzTzRs2BDt27fP1/UQEREREX1Kn0XPnxACs2bNQokSJWBqaory5ctj69atAIDo6GgoFArs378ffn5+MDU1Rb169ZCcnIx9+/bBy8sLVlZW6Ny5M168eKFVndnrrVy5MoyNjXH06FE8e/YMXbt2hbm5OZycnPDjjz8iICAAgwcPlpZ9/fo1Ro4cCRcXF5ibm6NatWqIjo6W5oeHh8PGxgb79++Hl5cXLCws0LhxYyQlJSlt9+rVq1G2bFkYGxvDyckJAwYMAAD06NEDzZs3Vyr75s0bFClSBKtXr851fwYEBGDgwIEYPHgwbG1t4ejoiBUrViA1NRXdu3eHpaUlSpYsiX379iktd/XqVTRt2hQWFhZwdHREt27d8ODBA2l+ZGQkateuDRsbG9jZ2aF58+aIj49X2i8DBgyAk5MTTExM4O7ujunTpwMAEhISoFAoEBsbK5V/8uQJFAqFtO80HZPcjuXjx4/RtWtX2Nvbw9TUFKVLl0ZYWJjG/WNvb48iRYpIr927d6NkyZLw9/fPdd8SERERERVUn0XyN27cOISFhWHp0qW4cuUKhgwZgm+++QZHjhyRyoSGhmLx4sU4ceIEbt++jQ4dOmD+/PlYv3499uzZg6ioKCxatChPdQLAyJEjMX36dMTFxcHX1xdDhw7F8ePHsXPnTkRFReHo0aM4f/680jLdu3fH8ePHsXHjRly6dAnt27dH48aNcePGDanMixcvMGfOHKxZswZ//PEHEhMTMXz4cGn+0qVL0b9/f/Tu3RuXL1/Gzp07UapUKQBAz549ERkZqZQs7t27F8+fP0eHDh202qcREREoXLgwzpw5g4EDB6Jfv35o3749atasifPnzyMwMBDdunWTEuakpCT4+/ujQoUKOHv2LCIjI3Hv3j2l9aWmpmLo0KGIiYnBwYMHoaenh9atWyMzMxMAsHDhQuzcuRObN2/GtWvXsHbtWri7u2sV77uyH5PcjuX48eNx9epV7Nu3D3FxcVi6dCkKFy6s1bpev36NtWvXokePHlAoFGrLpKWlISUlRelFRERERFTQKIQQQtdB5CQ1NRWFCxfGoUOHUKNGDWl6z5498eLFC/Tu3Rt169bFgQMHUL9+fQDAjBkzMGbMGMTHx6NEiRIAgL59+yIhIQGRkZG51rl+/XpER0ejbt262LFjB1q2bAkAePbsGezs7LB+/Xq0a9cOAPD06VM4OzujV69emD9/PuLj41G6dGncuXMHzs7OUt0NGjRA1apV8cMPPyA8PBzdu3fH33//jZIlSwIAlixZgsmTJ+Pu3bsAABcXF3Tv3h1Tp05Vu1/Kli2L4OBgjBw5EgDQunVr2NjY5NijlSUgIAAZGRk4evQoACAjIwPW1tZo06YNfvnlFwDA3bt34eTkhJMnT6J69eqYMGECTp8+jf3790v13LlzB66urrh27RrKlCmjsp779+/DwcEBly9fRrly5TBo0CBcuXIFBw4cUEmkEhISULx4cVy4cAEVKlQA8Lbnz9bWFocPH0ZAQIDaY6LNsfz6669RuHBhrXpFs9u8eTO6dOmCxMREpeP5rtDQUEyaNEllessxq2BoYpbndRIREenalgmddR0C0UeVkpICa2trPH36FFZWVroO55Mp8BewXb16Fa9evULDhg2Vpr9+/Rp+fn7Se19fX+n/jo6OMDMzkxK/rGlnzpzJU50AULlyZen/N2/eRHp6OqpWrSpNs7a2hoeHh/T+/PnzEEKoJENpaWmws7OT3puZmUmJHwA4OTkhOTkZAJCcnIz//vtPSmbV6dmzJ1asWIGRI0ciOTkZe/bswcGDBzWWz+7d/aWvrw87Ozv4+PhI0xwdHaVYAODcuXM4fPgwLCwsVOqKj49HmTJlEB8fj/Hjx+PUqVN48OCB1OOXmJiIcuXKISQkBA0bNoSHhwcaN26M5s2bo1GjRlrHnOXdY6LNsezXrx/atm2L8+fPo1GjRmjVqhVq1qyp1bp+/vlnNGnSRGPiBwBjxozB0KFDpfcpKSlwdXXNyyYREREREX10BT75y0og9uzZAxcXF6V5xsbG0jVlhoaG0nSFQqH0PmtaVl251fkuc3Nz6f9ZnaTZe63e7TzNzMyEvr4+zp07B319faVy7yZO6uLLqsfU1BS5CQoKwujRo3Hy5EmcPHkS7u7uqFOnTq7L5bT+7Pswa3uy/m3RogVmzpypUpeTkxMAoEWLFnB1dcXKlSvh7OyMzMxMlCtXDq9fvwYAVKxYEbdu3cK+fftw4MABdOjQAQ0aNMDWrVuhp/d2BPK7+zI9PV1t7O8eE22OZZMmTfDPP/9gz549Ug9x//79MWfOnBz30T///IMDBw5g+/btOZYzNjZWaTdERERERAVNgU/+vL29YWxsjMTERLU33Hj3hiL5VacmJUuWhKGhIc6cOSP17KSkpODGjRtSPX5+fsjIyEBycnKekrF3WVpawt3dHQcPHkTdunXVlrGzs0OrVq0QFhaGkydPonv37u+1Lm1VrFgR27Ztg7u7u9q7az58+BBxcXFYvny5tN3Hjh1TKWdlZYWOHTuiY8eOaNeuHRo3boxHjx7B3t4ewNtrC7N67N69+Ysm2h5Le3t7hISEICQkBHXq1MGIESNyTf7CwsLg4OCAZs2a5RoHEREREVFBV+CTP0tLSwwfPhxDhgxBZmYmateujZSUFJw4cQIWFhZwc3PL9zqDg4M1LhccHIwRI0agUKFCcHBwwMSJE6Gnpyf1lJUpUwZdu3ZFUFAQ5s6dCz8/Pzx48ACHDh2Cj48PmjZtqlWMoaGh6Nu3LxwcHNCkSRM8e/YMx48fx8CBA6UyPXv2RPPmzZGRkaEx5vzSv39/rFy5Ep07d8aIESNQuHBh/P3339i4cSNWrlwJW1tb2NnZYcWKFXByckJiYiJGjx6tVMePP/4IJycnVKhQAXp6etiyZQuKFCkCGxsb6OnpoXr16pgxYwbc3d3x4MEDjBs3Lte4tDmWEyZMQKVKlVC2bFmkpaVh9+7d8PLykuqoX78+WrduLd1NFXjboxgWFobg4GA+3oOIiIiIvgifxVntlClT4ODggOnTp+PmzZuwsbFBxYoV8b///U8a9pefdeZk3rx56Nu3L5o3bw4rKyuMHDkSt2/fhomJiVQmLCwMU6dOxbBhw/Dvv//Czs4ONWrU0DrxA4Dg4GC8evUKP/74I4YPH47ChQtLN5nJ0qBBAzg5OaFs2bI5XpOWH5ydnXH8+HGMGjUKgYGBSEtLg5ubGxo3biwlvxs3bsSgQYNQrlw5eHh4YOHChQgICJDqsLCwwMyZM3Hjxg3o6+ujSpUq2Lt3rzTkc/Xq1ejRowcqV64MDw8PzJo1S6trAnM7lkZGRhgzZgwSEhJgamqKOnXqYOPGjdLy8fHxSo+sAIADBw4gMTERPXr0yIe9R0RERESkewX+bp8FXWpqKlxcXDB37lx8++23n3TdL168gLOzM1avXo02bdp80nWTZll3j+LdPomI6HPFu33Sl453+yStXLhwAX/99ReqVq2Kp0+fYvLkyQAgPXrgU8jMzMTdu3cxd+5cWFtb4+uvv/5k6yYiIiIios8Tk7/3MGfOHFy7dg1GRkaoVKkSjh49qvVDw/NDYmIiihcvjqJFiyI8PFzpmrTExER4e3trXPbq1asoVqzYpwiTiIiIiIgKECZ/eeTn54dz587pNAZ3d3doGq3r7Oyc410yP/a1gUREREREVDDxmj+ifCbXMeREREREnwu5nq/p6ToAIiIiIiIi+viY/BEREREREckAkz8iIiIiIiIZYPJHREREREQkA0z+iIiIiIiIZIDJHxERERERkQww+SMiIiIiIpIBJn9EREREREQywOSPiIiIiIhIBpj8ERERERERyQCTPyIiIiIiIhlg8kdERERERCQDTP6IiIiIiIhkgMkfERERERGRDDD5IyIiIiIikgEmf0RERERERDLA5I+IiIiIiEgGmPwRERERERHJAJM/IiIiIiIiGWDyR0REREREJANM/oiIiIiIiGSAyR8REREREZEMMPkjIiIiIiKSASZ/REREREREMsDkj4iIiIiISAaY/BEREREREckAkz8iIiIiIiIZMNB1AERfqqAZW2BoYqbrMIiIProtEzrrOgQiItICe/6IiIiIiIhkgMkfERERERGRDDD5IyIiIiIikgEmf0RERERERDLwxSd/0dHRUCgUePLkiU7Wr1AosGPHDq3KhoaGokKFCh81Hnd3d8yfP1/j/ISEBCgUCsTGxmpdZ3h4OGxsbD44trz6VOt9n31CRERERFTQfPHJX37LazKZlJSEJk2aaFV2+PDhOHjwoPQ+JCQErVq1eo8o35+rqyuSkpJQrly5T7re99GxY0dcv35d12EQEREREX0W+KiHj+T169cwMjJCkSJFtF7GwsICFhYWHzGq3Onr6+cp5o8pPT0dhoaGGuebmprC1NT0E0ZERERERPT5+iJ6/oQQmDVrFkqUKAFTU1OUL18eW7du1Vj+xIkT+Oqrr2BqagpXV1cMGjQIqamp0vy0tDSMHDkSrq6uMDY2RunSpfHzzz8jISEBdevWBQDY2tpCoVAgJCQEABAQEIABAwZg6NChKFy4MBo2bAhAddjnnTt30KlTJxQqVAjm5uaoXLkyTp8+DUB52GdoaCgiIiLw22+/QaFQQKFQIDo6GvXq1cOAAQOUtufhw4cwNjbGoUOHtNpfL168QI8ePWBpaYlixYphxYoV0jx1Qxx37tyJ0qVLw9TUFHXr1kVERITa3s/9+/fDy8sLFhYWaNy4MZKSkpTmh4WFwcvLCyYmJvD09MSSJUtU1rt582YEBATAxMQEa9euzXE7sg/7zNp/q1evRrFixWBhYYF+/fohIyMDs2bNQpEiReDg4IBp06Yp1aNQKLB06VI0adIEpqamKF68OLZs2aLVviQiIiIi+lx8EcnfuHHjEBYWhqVLl+LKlSsYMmQIvvnmGxw5ckSl7OXLlxEYGIg2bdrg0qVL2LRpE44dO6aUUAUFBWHjxo1YuHAh4uLisGzZMlhYWMDV1RXbtm0DAFy7dg1JSUlYsGCBtFxERAQMDAxw/PhxLF++XGXdz58/h7+/P/777z/s3LkTFy9exMiRI5GZmalSdvjw4ejQoYOURCUlJaFmzZro2bMn1q9fj7S0NKnsunXr4OzsLCWmuZk7dy4qV66MCxcu4LvvvkO/fv3w119/qS2bkJCAdu3aoVWrVoiNjUWfPn0wduxYlXIvXrzAnDlzsGbNGvzxxx9ITEzE8OHDpfkrV67E2LFjMW3aNMTFxeGHH37A+PHjERERoVTPqFGjMGjQIMTFxSEwMFCr7XlXfHw89u3bh8jISGzYsAGrV69Gs2bNcOfOHRw5cgQzZ87EuHHjcOrUKaXlxo8fj7Zt2+LixYv45ptv0LlzZ8TFxWm1zrS0NKSkpCi9iIiIiIgKms9+2GdqairmzZuHQ4cOoUaNGgCAEiVK4NixY1i+fDl69+6tVH727Nno0qULBg8eDAAoXbo0Fi5cCH9/fyxduhSJiYnYvHkzoqKi0KBBA6m+LIUKFQIAODg4qNxspFSpUpg1a5bGWNevX4/79+8jJiZGqqdUqVJqy1pYWMDU1BRpaWlKwzDbtm2LgQMH4rfffkOHDh0AvO1RCwkJgUKhyG13AQCaNm2K7777DsDbZOvHH39EdHQ0PD09VcouW7YMHh4emD17NgDAw8MDf/75p0rvWXp6OpYtW4aSJUsCAAYMGIDJkydL86dMmYK5c+eiTZs2AIDixYvj6tWrWL58OYKDg6VygwcPlsq8j8zMTKxevRqWlpbw9vZG3bp1ce3aNezduxd6enrw8PDAzJkzER0djerVq0vLtW/fHj179pRijYqKwqJFi5R6JzWZPn06Jk2a9N4xExERERF9Cp998nf16lW8evVKGmaZ5fXr1/Dz81Mpf+7cOfz9999Yt26dNE0IgczMTNy6dQuXL1+Gvr4+/P398xxL5cqVc5wfGxsLPz8/KfF7H8bGxvjmm2+wevVqdOjQAbGxsbh48aLWdxQFAF9fX+n/CoUCRYoUQXJystqy165dQ5UqVZSmVa1aVaWcmZmZlPgBgJOTk1Tn/fv3cfv2bXz77bfo1auXVObNmzewtrZWqie3fZgbd3d3WFpaSu8dHR2hr68PPT09pWnZtzfrDwfvvtf27p5jxozB0KFDpfcpKSlwdXV9j+iJiIiIiD6ezz75yxoyuWfPHri4uCjNMzY2Rnx8vEr5Pn36YNCgQSp1FStWDH///fd7x2Jubp7j/Py6OUnPnj1RoUIF3LlzB6tXr0b9+vXh5uam9fLZb6KiUCjUDj0F3ibG2XsUhRBa1ZlVLqvulStXolq1akrl9PX1ld7ntg9zoy6OvGxv9nLaMDY2hrGxsfZBEhERERHpwGef/Hl7e8PY2BiJiYlqe+uyJ38VK1bElStXNA639PHxQWZmJo4cOSIN+3yXkZERACAjIyPPsfr6+mLVqlV49OiRVr1/RkZGatfj4+ODypUrY+XKlVi/fj0WLVqU51i05enpib179ypNO3v2bJ7qcHR0hIuLC27evImuXbvmZ3j55tSpUwgKClJ6r67nmIiIiIjoc/XZ3/DF0tISw4cPx5AhQxAREYH4+HhcuHABP/30k8rNRIC317idPHkS/fv3R2xsLG7cuIGdO3di4MCBAN4OGwwODkaPHj2wY8cO3Lp1C9HR0di8eTMAwM3NDQqFArt378b9+/fx/PlzrWPt3LkzihQpglatWuH48eO4efMmtm3bhpMnT6ot7+7ujkuXLuHatWt48OAB0tPTpXk9e/bEjBkzkJGRgdatW+dll+VJnz598Ndff2HUqFG4fv06Nm/ejPDwcADa94wBb+/EOX36dCxYsADXr1/H5cuXERYWhnnz5n2kyPNmy5YtWL16Na5fv46JEyfizJkzKndVJSIiIiL6nH32yR/w9gYdEyZMwPTp0+Hl5YXAwEDs2rULxYsXVynr6+uLI0eO4MaNG6hTpw78/Pwwfvx4ODk5SWWWLl2Kdu3a4bvvvoOnpyd69eolPQrCxcUFkyZNwujRo+Ho6JinBMHIyAi///47HBwc0LRpU/j4+GDGjBkqQx+z9OrVCx4eHqhcuTLs7e1x/PhxaV7nzp1hYGCALl26wMTEROsY8qp48eLYunUrtm/fDl9fXyxdulS622dehjr27NkTq1atQnh4OHx8fODv74/w8HC1x0gXJk2ahI0bN8LX1xcRERFYt24dvL29dR0WEREREVG+UQh1F3BRgXf79m24u7sjJiYGFStW/KTrnjZtGpYtW4bbt29/0vV+LAqFAr/++itatWqVL/WlpKTA2toaLcesgqGJWb7USURUkG2Z0FnXIRAR5UnW+drTp09hZWWl63A+mc/+mj+5SU9PR1JSEkaPHo3q1at/ksRvyZIlqFKlCuzs7HD8+HHMnj2bQyKJiIiIiD4zX8SwTzk5fvw43NzccO7cOSxbtkxp3tGjR2FhYaHx9b5u3LiBli1bwtvbG1OmTMGwYcMQGhr6gVuSuyZNmmjclh9++OGjr5+IiIiI6EvCYZ9fkJcvX+Lff//VOF/THU4Lqn///RcvX75UO69QoUIf9LzEj4nDPolIbjjsk4g+N3Id9snkjyifyfXLhIiIiOhzIdfzNQ77JCIiIiIikgEmf0RERERERDLA5I+IiIiIiEgGmPwRERERERHJAJM/IiIiIiIiGWDyR0REREREJANM/oiIiIiIiGSAyR8REREREZEMMPkjIiIiIiKSASZ/REREREREMsDkj4iIiIiISAaY/BEREREREckAkz8iIiIiIiIZYPJHREREREQkA0z+iIiIiIiIZIDJHxERERERkQww+SMiIiIiIpIBJn9EREREREQywOSPiIiIiIhIBpj8ERERERERyQCTPyIiIiIiIhlg8kdERERERCQDTP6IiIiIiIhkgMkfERERERGRDDD5IyIiIiIikgEmf0RERERERDLA5I+IiIiIiEgGmPwRERERERHJgIGuAyD6UgXN2AJDEzNdh0H0RdkyobOuQyAiIvpsseePiIiIiIhIBpj8ERERERERyQCTPyIiIiIiIhlg8kdERERERCQD+Zb8hYSEoFWrVvlV3SeVkJAAhUKB2NhYXYeilYIWb37FU9C2i4iIiIjoS8KePwCurq5ISkpCuXLlci3LBEVV9v0XHR0NhUKBJ0+e6DYwIiIiIiKSfNbJX3p6er7Uo6+vjyJFisDA4NM++SK/4tc1Xe2/j+FLOSZERERERNnlOfnbunUrfHx8YGpqCjs7OzRo0ACpqanS/Dlz5sDJyQl2dnbo37+/0sm0u7s7pkyZgi5dusDCwgLOzs5YtGiR1utWKBRYtmwZWrZsCXNzc0ydOhUAsGvXLlSqVAkmJiYoUaIEJk2ahDdv3kjL/fXXX6hduzZMTEzg7e2NAwcOQKFQYMeOHQBUe/MeP36Mrl27wt7eHqampihdujTCwsIAAMWLFwcA+Pn5QaFQICAgQFpPWFgYvLy8YGJiAk9PTyxZskSal7WOzZs3IyAgACYmJli7dm2uywHAmTNn4OfnBxMTE1SuXBkXLlzQep8BwJUrV9CsWTNYWVnB0tISderUQXx8PAAgJiYGDRs2ROHChWFtbQ1/f3+cP39eZb8vXboUTZo0gampKYoXL44tW7aobFtsbCwSEhJQt25dAICtrS0UCgVCQkIAAJGRkahduzZsbGxgZ2eH5s2bS3G8j6tXr6Jp06awsLCAo6MjunXrhgcPHkjz3d3dMX/+fKVlKlSogNDQUKVtU9emli5dipIlS8LIyAgeHh5Ys2aNxjjS0tKQkpKi9CIiIiIiKmjylPwlJSWhc+fO6NGjB+Li4hAdHY02bdpACAEAOHz4MOLj43H48GFEREQgPDwc4eHhSnXMnj0bvr6+OH/+PMaMGYMhQ4YgKipK6xgmTpyIli1b4vLly+jRowf279+Pb775BoMGDcLVq1exfPlyhIeHY9q0aQCAzMxMtGrVCmZmZjh9+jRWrFiBsWPH5riO8ePH4+rVq9i3bx/i4uKwdOlSFC5cGMDbRAwADhw4gKSkJGzfvh0AsHLlSowdOxbTpk1DXFwcfvjhB4wfPx4RERFKdY8aNQqDBg1CXFwcAgMDc10uNTUVzZs3h4eHB86dO4fQ0FAMHz5c6/3177//4quvvoKJiQkOHTqEc+fOoUePHlJy/OzZMwQHB+Po0aM4deoUSpcujaZNm+LZs2cq+6Rt27a4ePEivvnmG3Tu3BlxcXEq63N1dcW2bdsAANeuXUNSUhIWLFggbcvQoUMRExODgwcPQk9PD61bt0ZmZqbW25MlKSkJ/v7+qFChAs6ePYvIyEjcu3cPHTp0yHNd2dvUr7/+iu+//x7Dhg3Dn3/+iT59+qB79+44fPiw2uWnT58Oa2tr6eXq6prnGIiIiIiIPrY8jdNLSkrCmzdv0KZNG7i5uQEAfHx8pPm2trZYvHgx9PX14enpiWbNmuHgwYPo1auXVKZWrVoYPXo0AKBMmTI4fvw4fvzxRzRs2FCrGLp06YIePXpI77t164bRo0cjODgYAFCiRAlMmTIFI0eOxMSJE/H7778jPj4e0dHRKFKkCABg2rRpOa4vMTERfn5+qFy5MoC3PUhZ7O3tAQB2dnZSfQAwZcoUzJ07F23atAHwtocwKxnNig0ABg8eLJXRZrl169YhIyMDq1evhpmZGcqWLYs7d+6gX79+Wu2vn376CdbW1ti4cSMMDQ0BvN3vWerVq6dUfvny5bC1tcWRI0fQvHlzaXr79u3Rs2dPKeaoqCgsWrRIpZdSX18fhQoVAgA4ODjAxsZGmte2bVulsj///DMcHBxw9epVra63fNfSpUtRsWJF/PDDD9K01atXw9XVFdevX1faxtxkb1NdunRBSEgIvvvuOwDA0KFDcerUKcyZM0fq1XzXmDFjMHToUOl9SkoKE0AiIiIiKnDy1PNXvnx51K9fHz4+Pmjfvj1WrlyJx48fS/PLli0LfX196b2TkxOSk5OV6qhRo4bKe3U9SJpkJWRZzp07h8mTJ8PCwkJ69erVC0lJSXjx4gWuXbsGV1dXpUStatWqOa6jX79+2LhxIypUqICRI0fixIkTOZa/f/8+bt++jW+//VYpjqlTp6oMa3w3fm2Wi4uLQ/ny5WFmZiYtl30f5iQ2NhZ16tSREr/skpOT0bdvX5QpU0bquXr+/DkSExOVyn3ocQOA+Ph4dOnSBSVKlICVlZU0hDb7urRx7tw5HD58WGm/eXp6SuvJi+xtKi4uDrVq1VKaVqtWLY3ba2xsDCsrK6UXEREREVFBk6eeP319fURFReHEiRP4/fffsWjRIowdOxanT58GAJUEQ6FQaDWkT6FQaB2Dubm50vvMzExMmjRJqTcti4mJCYQQeaofAJo0aYJ//vkHe/bswYEDB1C/fn30798fc+bMUVs+axtXrlyJatWqKc17NxnOHr82y2UNqX1fpqamOc4PCQnB/fv3MX/+fLi5ucHY2Bg1atTA69evc607r/u1RYsWcHV1xcqVK+Hs7IzMzEyUK1dOq3Vll5mZiRYtWmDmzJkq85ycnAAAenp6KvtP3Q1dsrcpQHXb3qcdEREREREVJHm+PaNCoUCtWrVQq1YtTJgwAW5ubvj111+1Xv7UqVMq77N6bN5HxYoVce3aNZQqVUrtfE9PTyQmJuLevXtwdHQE8PYmJ7mxt7dHSEgIQkJCUKdOHYwYMQJz5syBkZERACAjI0Mq6+joCBcXF9y8eRNdu3bVOnZtlvP29saaNWvw8uVLKZHLvg9z4uvri4iICKSnp6vt/Tt69CiWLFmCpk2bAgBu376tdNOULKdOnUJQUJDSez8/P7XrVLePHj58iLi4OCxfvhx16tQBABw7dkzr7ciuYsWK2LZtG9zd3TXeZdTe3h5JSUnS+5SUFNy6dSvXur28vHDs2DGl7T1x4gS8vLzeO14iIiIiIl3LU/J3+vRpHDx4EI0aNYKDgwNOnz6N+/fvw8vLC5cuXdKqjuPHj2PWrFlo1aoVoqKisGXLFuzZs+e9ggeACRMmoHnz5nB1dUX79u2hp6eHS5cu4fLly5g6dSoaNmyIkiVLIjg4GLNmzcKzZ8+kG75o6smZMGECKlWqhLJlyyItLQ27d++WTvwdHBxgamqKyMhIFC1aFCYmJrC2tkZoaCgGDRoEKysrNGnSBGlpaTh79iweP36sdD1Ydrkt16VLF4wdOxbffvstxo0bh4SEBI09kOoMGDAAixYtQqdOnTBmzBhYW1vj1KlTqFq1Kjw8PFCqVCmsWbMGlStXRkpKCkaMGKG2t3DLli2oXLkyateujXXr1uHMmTP4+eef1a7Tzc0NCoUCu3fvRtOmTWFqagpbW1vY2dlhxYoVcHJyQmJionTt5/vo378/Vq5cic6dO2PEiBEoXLgw/v77b2zcuBErV66Evr4+6tWrh/DwcLRo0QK2trYYP368Sk+sOiNGjECHDh1QsWJF1K9fH7t27cL27dtx4MCB946XiIiIiEjX8nTNn5WVFf744w80bdoUZcqUwbhx4zB37lw0adJE6zqGDRuGc+fOwc/PT7rZSWBgYJ4DzxIYGIjdu3cjKioKVapUQfXq1TFv3jzphjT6+vrYsWMHnj9/jipVqqBnz54YN24cgLfDQtUxMjLCmDFj4Ovri6+++gr6+vrYuHEjAMDAwAALFy7E8uXL4ezsjJYtWwIAevbsiVWrViE8PBw+Pj7w9/dHeHi4dF2bJrktZ2FhgV27duHq1avw8/PD2LFj1Q511MTOzg6HDh3C8+fP4e/vj0qVKmHlypVSL+Dq1avx+PFj+Pn5oVu3bhg0aBAcHBxU6pk0aRI2btwo9SSuW7cO3t7eatfp4uKCSZMmYfTo0XB0dMSAAQOgp6eHjRs34ty5cyhXrhyGDBmC2bNna70d2Tk7O+P48ePIyMhAYGAgypUrh++//x7W1tbQ03vbrMeMGYOvvvoKzZs3R9OmTdGqVSuULFky17pbtWqFBQsWYPbs2ShbtiyWL1+OsLAwpcd6EBERERF9bhTiQy8qywN3d3cMHjwYgwcP/lSrVOv48eOoXbs2/v77b62SAblTKBT49ddf0apVK12H8llISUmBtbU1Wo5ZBUMTs9wXICKtbZnQWdchEBHRFyDrfO3p06eyullfnq/5+xz9+uuvsLCwQOnSpfH333/j+++/R61atZj4ERERERGRbORp2OfHtG7dOqXb9r/7Klu27AfV/ezZM3z33Xfw9PRESEgIqlSpgt9++y2fItetvn37atxvffv21XV47+1L3S4iIiIiIl35pMM+c/Ls2TPcu3dP7TxDQ0PpGj5SlpycjJSUFLXzrKys1F6/9zn4nLdLrsMIiIiIiD4Xcj1fKzDDPi0tLWFpaanrMD47Dg4OBToRel9f6nYREREREelKgRn2SURERERERB8Pkz8iIiIiIiIZYPJHREREREQkA0z+iIiIiIiIZIDJHxERERERkQww+SMiIiIiIpIBJn9EREREREQywOSPiIiIiIhIBpj8ERERERERyQCTPyIiIiIiIhlg8kdERERERCQDTP6IiIiIiIhkgMkfERERERGRDDD5IyIiIiIikgEmf0RERERERDLA5I+IiIiIiEgGmPwRERERERHJAJM/IiIiIiIiGWDyR0REREREJANM/oiIiIiIiGSAyR8REREREZEMMPkjIiIiIiKSASZ/REREREREMsDkj4iIiIiISAaY/BEREREREckAkz8iIiIiIiIZYPJHREREREQkAwa6DoDoSxU0YwsMTcx0HQblgy0TOus6BCIiIqIPxp4/IiIiIiIiGWDyR0REREREJANM/oiIiIiIiGSAyR8REREREZEMMPmjz0ZAQAAGDx6s6zCIiIiIiD5LTP6IiIiIiIhkgMkfERERERGRDDD5o8/KmzdvMGDAANjY2MDOzg7jxo2DEAIAsHbtWlSuXBmWlpYoUqQIunTpguTkZKXld+7cidKlS8PU1BR169ZFREQEFAoFnjx5IpU5ceIEvvrqK5iamsLV1RWDBg1CamqqxpjS0tKQkpKi9CIiIiIiKmiY/NFnJSIiAgYGBjh9+jQWLlyIH3/8EatWrQIAvH79GlOmTMHFixexY8cO3Lp1CyEhIdKyCQkJaNeuHVq1aoXY2Fj06dMHY8eOVar/8uXLCAwMRJs2bXDp0iVs2rQJx44dw4ABAzTGNH36dFhbW0svV1fXj7LtREREREQfQiGyuk2ICriAgAAkJyfjypUrUCgUAIDRo0dj586duHr1qkr5mJgYVK1aFc+ePYOFhQVGjx6NPXv24PLly1KZcePGYdq0aXj8+DFsbGwQFBQEU1NTLF++XCpz7Ngx+Pv7IzU1FSYmJirrSUtLQ1pamvQ+JSUFrq6uaDlmFQxNzPJzF5CObJnQWdchEBERUT5KSUmBtbU1nj59CisrK12H88mw548+K9WrV5cSPwCoUaMGbty4gYyMDFy4cAEtW7aEm5sbLC0tERAQAABITEwEAFy7dg1VqlRRqq9q1apK78+dO4fw8HBYWFhIr8DAQGRmZuLWrVtqYzI2NoaVlZXSi4iIiIiooDHQdQBE+eHVq1do1KgRGjVqhLVr18Le3h6JiYkIDAzE69evAQBCCKXEMWvauzIzM9GnTx8MGjRIZR3FihX7eBtARERERPSRMfmjz8qpU6dU3pcuXRp//fUXHjx4gBkzZkjX3J09e1aprKenJ/bu3as0LXuZihUr4sqVKyhVqtRHiJ6IiIiISHc47JM+K7dv38bQoUNx7do1bNiwAYsWLcL333+PYsWKwcjICIsWLcLNmzexc+dOTJkyRWnZPn364K+//sKoUaNw/fp1bN68GeHh4QAg9QiOGjUKJ0+eRP/+/REbG4sbN25g586dGDhw4KfeVCIiIiKifMXkjz4rQUFBePnyJapWrYr+/ftj4MCB6N27N+zt7REeHo4tW7bA29sbM2bMwJw5c5SWLV68OLZu3Yrt27fD19cXS5cule72aWxsDADw9fXFkSNHcOPGDdSpUwd+fn4YP348nJycPvm2EhERERHlJ97tk2Rt2rRpWLZsGW7fvp1vdWbdPYp3+/xy8G6fREREXxa53u2T1/yRrCxZsgRVqlSBnZ0djh8/jtmzZ+f4DD8iIiIioi8Fkz+SlRs3bmDq1Kl49OgRihUrhmHDhmHMmDG6DouIiIiI6KPjsE+ifCbXYQREREREnwu5nq/xhi9EREREREQywOSPiIiIiIhIBpj8ERERERERyQCTPyIiIiIiIhlg8kdERERERCQDTP6IiIiIiIhkgMkfERERERGRDDD5IyIiIiIikgEmf0RERERERDLA5I+IiIiIiEgGmPwRERERERHJAJM/IiIiIiIiGWDyR0REREREJANM/oiIiIiIiGSAyR8REREREZEMMPkjIiIiIiKSASZ/REREREREMsDkj4iIiIiISAaY/BEREREREckAkz8iIiIiIiIZYPJHREREREQkA0z+iIiIiIiIZIDJHxERERERkQww+SMiIiIiIpIBJn9EREREREQywOSPiIiIiIhIBpj8ERERERERyQCTPyIiIiIiIhkw0HUARF+qoBlbYGhipusw3suWCZ11HQIRERER5TP2/BEREREREckAkz8iIiIiIiIZYPJHREREREQkA0z+iIiIiIiIZOCLSP6EEOjduzcKFSoEhUIBGxsbDB48+KOv193dHfPnz//o6ylIFAoFduzYoeswAAABAQGf5DiHhoaiQoUKH309REREREQf0xeR/EVGRiI8PBy7d+9GUlISypUrp+uQPpmEhAQoFArExsbma72aEp6kpCQ0adIkX9f1vrZv344pU6boOgwiIiIios/CF/Goh/j4eDg5OaFmzZoAAAODL2KzkJ6eDkNDQ12HoaRIkSK6DkFSqFAhXYdARERERPTZ+Ox7/kJCQjBw4EAkJiZCoVDA3d1dpczjx48RFBQEW1tbmJmZoUmTJrhx44ZSmW3btqFs2bIwNjaGu7s75s6dqzQ/OTkZLVq0gKmpKYoXL45169blKU6FQoGlS5eiSZMmUh1btmyR5mf14G3evBkBAQEwMTHB2rVrkZmZicmTJ6No0aIwNjZGhQoVEBkZKS1XvHhxAICfnx8UCgUCAgKkeWFhYfDy8oKJiQk8PT2xZMkSpZju3LmDTp06oVChQjA3N0flypVx+vRphIeHY9KkSbh48SIUCgUUCgXCw8Ol7Xh32Ofly5dRr149mJqaws7ODr1798bz58+l+SEhIWjVqhXmzJkDJycn2NnZoX///khPT5fKLFmyBKVLl4aJiQkcHR3Rrl07rfZp9mGf7u7umDp1KoKCgmBhYQE3Nzf89ttvuH//Plq2bAkLCwv4+Pjg7Nmz0jLh4eGwsbHBjh07UKZMGZiYmKBhw4a4ffu2VjEAQFpaGlJSUpReREREREQFzWef/C1YsEBKjpKSkhATE6NSJiQkBGfPnsXOnTtx8uRJCCHQtGlTKQE5d+4cOnTogE6dOuHy5csIDQ3F+PHjpYQnq46EhAQcOnQIW7duxZIlS5CcnJynWMePH4+2bdvi4sWL+Oabb9C5c2fExcUplRk1ahQGDRqEuLg4BAYGYsGCBZg7dy7mzJmDS5cuITAwEF9//bWUvJ45cwYAcODAASQlJWH79u0AgJUrV2Ls2LGYNm0a4uLi8MMPP2D8+PGIiIgAADx//hz+/v7477//sHPnTly8eBEjR45EZmYmOnbsiGHDhqFs2bJISkpCUlISOnbsqLI9L168QOPGjWFra4uYmBhs2bIFBw4cwIABA5TKHT58GPHx8Th8+DAiIiIQHh4u7duzZ89i0KBBmDx5Mq5du4bIyEh89dVXedqv7/rxxx9Rq1YtXLhwAc2aNUO3bt0QFBSEb775BufPn0epUqUQFBQEIYTSdkybNg0RERE4fvw4UlJS0KlTJ63XOX36dFhbW0svV1fX946fiIiIiOhj+ezHR1pbW8PS0hL6+vpqhyTeuHEDO3fuxPHjx6VhoevWrYOrqyt27NiB9u3bY968eahfvz7Gjx8PAChTpgyuXr2K2bNnIyQkBNevX8e+fftw6tQpVKtWDQDw888/w8vLK0+xtm/fHj179gQATJkyBVFRUVi0aJFSj9zgwYPRpk0b6f2cOXMwatQoKRmZOXMmDh8+jPnz5+Onn36Cvb09AMDOzk5p+6dMmYK5c+dKdRUvXhxXr17F8uXLERwcjPXr1+P+/fuIiYmRhk+WKlVKWt7CwgIGBgY5DvNct24dXr58iV9++QXm5uYAgMWLF6NFixaYOXMmHB0dAQC2trZYvHgx9PX14enpiWbNmuHgwYPo1asXEhMTYW5ujubNm8PS0hJubm7w8/PL0359V9OmTdGnTx8AwIQJE7B06VJUqVIF7du3B/A2ua5Rowbu3bsnbVt6ejoWL14sHduIiAh4eXnhzJkzqFq1aq7rHDNmDIYOHSq9T0lJYQJIRERERAXOZ9/zl5u4uDgYGBhIJ/bA20TJw8ND6nWLi4tDrVq1lJarVasWbty4gYyMDKmOypUrS/M9PT1hY2OTp1hq1Kih8j57z9+760hJScF///2nNrbsy73r/v37uH37Nr799ltYWFhIr6lTpyI+Ph4AEBsbCz8/vw+6bi4uLg7ly5eXEr+s2DIzM3Ht2jVpWtmyZaGvry+9d3JyknpNGzZsCDc3N5QoUQLdunXDunXr8OLFi/eOydfXV/p/VvLp4+OjMu3dXltNxzanffwuY2NjWFlZKb2IiIiIiAqaz77nLzfvDu/LPl2hUKj8X91yWf/PXiY/ZK/z3URKUxl18b4rMzMTwNuhn+8mvQCkJMzU1PS94tU2jnenZ79pjUKhkGK0tLTE+fPnER0djd9//x0TJkxAaGgoYmJi8pxcZ19XVgzqpmWtX128OU0jIiIiIvpcffE9f97e3njz5g1Onz4tTXv48CGuX78uDdv09vbGsWPHlJY7ceIEypQpA319fXh5eeHNmzdKNwq5du0anjx5kqdYTp06pfLe09NTY3krKys4OzurjS0rdiMjIwBARkaGNN/R0REuLi64efMmSpUqpfTKukGMr68vYmNj8ejRI7XrNjIyUqpTHW9vb8TGxiI1NVWadvz4cejp6aFMmTI5LvsuAwMDNGjQALNmzcKlS5ekays/FU3HNqdjQ0RERET0ufnik7/SpUujZcuW6NWrF44dOybdbMXFxQUtW7YEAAwbNgwHDx7ElClTcP36dURERGDx4sUYPnw4AMDDwwONGzdGr169cPr0aZw7dw49e/bMc+/Zli1bsHr1aly/fh0TJ07EmTNnVG6Okt2IESMwc+ZMbNq0CdeuXcPo0aMRGxuL77//HgDg4OAAU1NTREZG4t69e3j69CmAt8/pmz59OhYsWIDr16/j8uXLCAsLw7x58wAAnTt3RpEiRdCqVSscP34cN2/exLZt23Dy5EkAb++ceevWLcTGxuLBgwdIS0tTia1r164wMTFBcHAw/vzzTxw+fBgDBw5Et27dpOGVudm9ezcWLlyI2NhY/PPPP/jll1+QmZkJDw8PrffrhzI0NMTAgQNx+vRpnD9/Ht27d0f16tW1ut6PiIiIiOhz8cUnf8DbRx5UqlQJzZs3R40aNSCEwN69e6XhgBUrVsTmzZuxceNGlCtXDhMmTMDkyZMREhKiVIerqyv8/f3Rpk0b9O7dGw4ODnmKY9KkSdi4cSN8fX0RERGBdevWwdvbO8dlBg0ahGHDhmHYsGHw8fFBZGQkdu7cidKlSwN422u2cOFCLF++HM7OzlJC27NnT6xatQrh4eHw8fGBv78/wsPDpZ4/IyMj/P7773BwcEDTpk3h4+ODGTNmSMNC27Zti8aNG6Nu3bqwt7fHhg0bVGIzMzPD/v378ejRI1SpUgXt2rVD/fr1sXjxYq33iY2NDbZv34569erBy8sLy5Ytw4YNG1C2bFmt6/hQZmZmGDVqFLp06YIaNWrA1NQUGzdu/GTrJyIiIiL6FBRC00VxlK8UCgV+/fVXtGrVSteh0DvCw8MxePDgPA/hzUlKSgqsra3RcswqGJqY5Vu9n9KWCZ11HQIRERHRR5N1vvb06VNZ3axPFj1/REREREREcsfkLx+sW7dO6ZEK774+5fDFL0liYqLGfWphYYHExERdh0hERERE9FnhsM988OzZM9y7d0/tPENDQ7i5uX3iiD5/b968QUJCgsb57u7uMDAomE8qkeswAiIiIqLPhVzP1wrm2fNnxtLSEpaWlroO44tiYGCAUqVK6ToMIiIiIqIvBod9EhERERERyQCTPyIiIiIiIhlg8kdERERERCQDTP6IiIiIiIhkgMkfERERERGRDDD5IyIiIiIikgEmf0RERERERDLA5I+IiIiIiEgGmPwRERERERHJAJM/IiIiIiIiGWDyR0REREREJANM/oiIiIiIiGSAyR8REREREZEMMPkjIiIiIiKSASZ/REREREREMsDkj4iIiIiISAaY/BEREREREckAkz8iIiIiIiIZYPJHREREREQkA0z+iIiIiIiIZIDJHxERERERkQww+SMiIiIiIpIBJn9EREREREQywOSPiIiIiIhIBpj8ERERERERyQCTPyIiIiIiIhlg8kdERERERCQDBroOgOhLFTRjCwxNzKT3WyZ01mE0RERERCR37PkjIiIiIiKSASZ/REREREREMsDkj4iIiIiISAaY/BEREREREckAkz/SSkhICFq1aqXrMIiIiIiI6D0x+SMiIiIiIpIBJn9EefD69Wtdh0BERERE9F6Y/JGSrVu3wsfHB6amprCzs0ODBg2QmpoqzZ8zZw6cnJxgZ2eH/v37Iz09XZrn7u6OKVOmoEuXLrCwsICzszMWLVqk9boTExPRsmVLWFhYwMrKCh06dMC9e/cAAE+fPoW+vj7OnTsHABBCoFChQqhSpYq0/IYNG+Dk5AQASEhIgEKhwPbt21G3bl2YmZmhfPnyOHnypNI6T5w4ga+++gqmpqZwdXXFoEGDlLbX3d0dU6dORUhICKytrdGrV6887E0iIiIiooKDyR9JkpKS0LlzZ/To0QNxcXGIjo5GmzZtIIQAABw+fBjx8fE4fPgwIiIiEB4ejvDwcKU6Zs+eDV9fX5w/fx5jxozBkCFDEBUVleu6hRBo1aoVHj16hCNHjiAqKgrx8fHo2LEjAMDa2hoVKlRAdHQ0AODSpUvSvykpKQCA6Oho+Pv7K9U7duxYDB8+HLGxsShTpgw6d+6MN2/eAAAuX76MwMBAtGnTBpcuXcKmTZtw7NgxDBgwQGWbypUrh3PnzmH8+PEqsaelpSElJUXpRURERERU0ChE1pk9yd758+dRqVIlJCQkwM3NTWleSEgIoqOjER8fD319fQBAhw4doKenh40bNwJ420vm5eWFffv2Sct16tQJKSkp2Lt3b47rjoqKQpMmTXDr1i24uroCAK5evYqyZcvizJkzqFKlCoYNG4br169j165dWLBgAY4dO4abN29iypQpaNq0KTw8PDBkyBD07dsXCQkJKF68OFatWoVvv/1Wqb64uDh4enoiKCgIpqamWL58uRTHsWPH4O/vj9TUVJiYmMDd3R1+fn749ddfNcYeGhqKSZMmqUxvOWYVDE3MpPdbJnTOcR8QERER0aeRkpICa2trPH36FFZWVroO55Nhzx9Jypcvj/r168PHxwft27fHypUr8fjxY2l+2bJlpcQPAJycnJCcnKxUR40aNVTex8XF5bruuLg4uLq6SokfAHh7e8PGxkZaPiAgAEePHkVmZiaOHDmCgIAABAQE4MiRI7h79y6uX7+u0vPn6+urFC8AKeZz584hPDwcFhYW0iswMBCZmZm4deuWtFzlypVzjH3MmDF4+vSp9Lp9+3au20tERERE9Kkx+SOJvr4+oqKisG/fPnh7e2PRokXw8PCQEiFDQ0Ol8gqFApmZmbnWq1Aoci0jhFBb7t3pX331FZ49e4bz58/j6NGjCAgIgL+/P44cOYLDhw/DwcEBXl5eSsu/G3NWPVkxZ2Zmok+fPoiNjZVeFy9exI0bN1CyZElpOXNz8xxjNzY2hpWVldKLiIiIiKigMdB1AFSwKBQK1KpVC7Vq1cKECRPg5uaW45DH7E6dOqXy3tPTM9flvL29kZiYiNu3bysN+3z69KmU0GVd97d48WIoFAp4e3vD2dkZFy5cwO7du1V6/XJTsWJFXLlyBaVKlcrTckREREREnyP2/JHk9OnT+OGHH3D27FkkJiZi+/btuH//vkpvWk6OHz+OWbNm4fr16/jpp5+wZcsWfP/997ku16BBA/j6+qJr1644f/48zpw5g6CgIPj7+ysNuwwICMDatWvh7+8PhUIBW1tbeHt7Y9OmTQgICMjT9o4aNQonT55E//79ERsbixs3bmDnzp0YOHBgnuohIiIiIvocMPkjiZWVFf744w80bdoUZcqUwbhx4zB37lw0adJE6zqGDRuGc+fOwc/PD1OmTMHcuXMRGBiY63IKhQI7duyAra0tvvrqKzRo0AAlSpTApk2blMrVrVsXGRkZSomev78/MjIy8tzz5+vriyNHjuDGjRuoU6cO/Pz8MH78eOnaQCIiIiKiLwnv9kn5xt3dHYMHD8bgwYN1HYpOZd09inf7JCIiIiqYeLdPIiIiIiIi+mIx+aNPYt26dUqPVHj3VbZsWV2HR0RERET0xeOwT/oknj17hnv37qmdZ2hoqPJQ+c+ZXIcREBEREX0u5Hq+xkc90CdhaWkJS0tLXYdBRERERCRbHPZJREREREQkA0z+iIiIiIiIZIDJHxERERERkQww+SMiIiIiIpIBJn9EREREREQywOSPiIiIiIhIBpj8ERERERERyQCTPyIiIiIiIhlg8kdERERERCQDTP6IiIiIiIhkgMkfERERERGRDDD5IyIiIiIikgEDXQdA9KURQgAAUlJSdBwJEREREamTdZ6Wdd4mF0z+iPLZw4cPAQCurq46joSIiIiIcvLs2TNYW1vrOoxPhskfUT4rVKgQACAxMVFWXyaknZSUFLi6uuL27duwsrLSdThUgLBtkCZsG6QJ28b7E0Lg2bNncHZ21nUonxSTP6J8pqf39lJaa2trfhGTRlZWVmwfpBbbBmnCtkGasG28Hzn+kZ43fCEiIiIiIpIBJn9EREREREQywOSPKJ8ZGxtj4sSJMDY21nUoVACxfZAmbBukCdsGacK2QXmlEHK7vykREREREZEMseePiIiIiIhIBpj8ERERERERyQCTPyIiIiIiIhlg8kdERERERCQDTP6IiIiIiIhkgMkfUT7JyMjAvXv3kJycjIyMDF2HQ0SfoejoaLx8+VLXYVABk5aWhvj4eKSlpek6FCqA7t27h7t37+o6DPpMMPkj+kC//voratWqBTMzMzg7O8PJyQlmZmaoVasWduzYoevwSMcuXryIqVOnYsmSJXjw4IHSvJSUFPTo0UNHkVFB1KhRIyQkJOg6DNKh8PBwnDp1CgDw6tUr9OzZE+bm5ihTpgwsLCzQt29fJoEy9ejRI7Rt2xZubm7o378/MjIy0LNnTzg5OcHFxQU1a9ZEUlKSrsOkAo7P+SP6AMuXL8egQYPQo0cPBAYGwtHREUIIJCcnY//+/QgLC8OiRYvQq1cvXYdKOvD777+jRYsWKF26NJ49e4YXL15g8+bNqFu3LoC3f611dnZmT7EMVaxYUe302NhYeHp6wsTEBABw/vz5TxkWFQClS5fGhg0bULlyZYwYMQJbt27FvHnz4OXlhWvXrmHkyJFo2bIlZs2apetQ6RPr0aMHYmJi0KdPH2zduhW2tra4efMmlixZAj09PXz//ffw8vJCRESErkOlAozJH9EHKFWqFMaMGYNvv/1W7fzVq1dj2rRpiI+P/8SRUUFQs2ZN1K1bF9OmTYMQAnPmzMHkyZOxZcsWNG7cmMmfjBkaGqJBgwaoXr26NE0IgSlTpqBv375wcHAAAEycOFFXIZKOmJiY4Pr16yhWrBg8PDywYMECNG7cWJr/xx9/oFu3bvjnn390GCXpgrOzM7Zu3YqaNWvi3r17cHJywv79+9GwYUMAwPHjx9GxY0fcuXNHx5FSQWag6wCIPmf//vsvateurXF+zZo18d9//33CiKgguXLlCtasWQMAUCgUGDFiBIoWLYp27dphw4YNqFq1qo4jJF2Jjo5GcHAwqlatiokTJ0JP7+1VGNOmTUP//v3h7e2t4whJV4oUKYL4+HgUK1YMqampKFy4sNJ8e3t7PHz4UEfRkS49ffoULi4uAABHR0cYGBjAyclJmu/s7IwnT57oKDr6XPCaP6IPULZsWaxYsULj/JUrV6Js2bKfMCIqSIyNjVV+iDt37oyff/4ZnTp1wq+//qqbwEjnatWqhfPnz+P69euoUaMGRweQpGvXrhg7diyePHmCbt26YfLkyXj+/DkA4MWLFwgNDUWtWrV0HCXpQunSpbF7924AwL59+2BiYoLff/9dmr9//34UL15cV+HRZ4I9f0QfYO7cuWjWrBkiIyPRqFEjODo6QqFQ4O7du4iKisI///yDvXv36jpM0pEKFSrg8OHDqFSpktL0jh07IjMzE8HBwTqKjAoCKysrbNiwAWFhYahduzYmTZoEhUKh67BIxyZOnIg///wTJUqUQOXKlXH06FE4OjrCxcUF//33H+zs7BAVFaXrMEkHRowYgeDgYMyfPx937tzB2rVrMWjQIJw+fRp6enrYvn075s2bp+swqYDjNX9EHyghIQFLly7FqVOnpFstFylSBDVq1EDfvn3h7u6u2wBJZ3799Vf88ccf+PHHH9XO37BhA1asWIHDhw9/4siooLlx4wa6du2Ks2fP4s8//+SwT0JkZCR27dqFmzdvIjMzE05OTqhVqxa6dOkCc3NzXYdHOnLs2DGcPn0aNWvWRI0aNXD16lXMmDEDL168QIsWLfhHRcoVkz8iIqICIDMzE8+ePYOVlRV7AImI6KNg8kdERERERCQDvOEL0UcUHByMevXq6ToMKqDYPkgTtg3ShG2DNGHbIG3whi9EH5Gzs7N0C3ei7Ng+SBO2DdKEbYM0YdsgbXDYJxERERERkQyw54/oA925cwdLly7FiRMncPfuXSgUCjg6OqJmzZro168fihYtqusQSYfYPkgTtg3ShG2DNGHboA/Fnj+iD3Ds2DE0adIErq6u0nP+hBBITk5GVFQUbt++jX379vGBvDLF9kGasG2QJmwbpAnbBuUHJn9EH6BKlSqoXbu2xue4DRkyBMeOHUNMTMwnjowKArYP0oRtgzRh2yBN2DYoPzD5I/oApqamiI2NhYeHh9r5f/31F/z8/PDy5ctPHBkVBGwfpAnbBmnCtkGasG1QfuAtgYg+gJOTE06cOKFx/smTJ+Hk5PQJI6KChO2DNGHbIE3YNkgTtg3KD7zhC9EHGD58OPr27Ytz586hYcOGcHR0hEKhwN27dxEVFYVVq1Zh/vz5ug6TdITtgzRh2yBN2DZIE7YNyg8c9kn0gTZt2oQff/wR586dQ0ZGBgBAX18flSpVwtChQ9GhQwcdR0i6xPZBmrBtkCZsG6QJ2wZ9KCZ/RPkkPT0dDx48AAAULlwYhoaGOo6IChK2D9KEbYM0YdsgTdg26H0x+SMiIiIiIpIB3vCFiIiIiIhIBpj8ERERERERyQCTPyIiIiIiIhlg8kdERERERCQDTP6IiIh0KCAgAIMHD9Z1GEREJAO82ycREZEOPXr0CIaGhrC0tNR1KCqio6NRt25dPH78GDY2NroOh4iIPpCBrgMgIiKSs0KFCuk6BLXS09N1HQIREeUzDvskIiLSoXeHfbq7u2Pq1KkICgqChYUF3Nzc8Ntvv+H+/fto2bIlLCws4OPjg7Nnz0rLh4eHw8bGBjt27ECZMmVgYmKChg0b4vbt20rrWbp0KUqWLAkjIyN4eHhgzZo1SvMVCgWWLVuGli1bwvz/2rm/kKi2No7j37HUxiQUEzERSUyc/BcVko1kMoRkSXVhpJkpFf0z1LJSUqMiggzKbiQLpqILL8oIlSIUCXQsojJMBy+k8kYQQpGKCnO9Fy8Nzak8xfvCqTO/D2yY/ay113oW++qZtfeeO5edO3eSlZUFQGhoKBaLheLiYgDu3btHRkYGISEhhIWFsX79eoaHhz1jvXr1CovFQktLC1lZWQQFBZGamkpvb6/XnD09PWRmZhIUFERoaCjZ2dmMj48DYIzh7NmzxMbGYrVaSU1N5ebNm55rx8fH2bp1K+Hh4VitVhYtWoTT6fzfboaIyL+cij8REZHfyPnz57Hb7Tx79ox169axbds2ioqKKCws5OnTp8TFxVFUVMTXb228f/+e06dPc+3aNXp6epicnGTLli2e9tu3b1NWVsahQ4d48eIFu3fvpqSkhK6uLq+5jx8/zoYNG+jv7+fkyZPcunULgKGhIUZHR2loaADg3bt3HDx4kMePH9PZ2Ymfnx+bNm1ienraa7xjx45RWVlJX18f8fHx5OfnMzU1BUBfXx8Oh4PExER6e3vp7u4mNzeXz58/A1BTU4PT6aSxsZGBgQEqKiooLCzkwYMHANTW1jI4OMjdu3dxu900NjYyf/78//PdEBH5lzEiIiLyj8nMzDRlZWXGGGNiYmJMYWGhp210dNQApra21hPr7e01gBkdHTXGGON0Og1gHj586OnjdrsNYB49emSMMWblypVm165dXvPm5eWZnJwczzlgysvLvfp0dXUZwIyPj8+4hrGxMQOY/v5+Y4wxL1++NIC5cuWKp8/AwIABjNvtNsYYk5+fb+x2+3fHe/v2rZkzZ45xuVxe8R07dpj8/HxjjDG5ubmmpKRkxrxERMSbdv5ERER+IykpKZ7fERERACQnJ38TGxsb88Rmz57N8uXLPecJCQmEhITgdrsBcLvd2O12r3nsdrun/Yuvx5jJ8PAwBQUFxMbGMm/ePBYuXAjAyMjID9cSGRnplfeXnb/vGRwc5MOHD6xZs4bg4GDPcf36dc/jpXv37qW5uZklS5Zw5MgRXC7XT+UuIuLL9MEXERGR34i/v7/nt8Vi+WHsr49Yfon/KPbXdmPMN7G5c+f+VI65ublER0dz+fJlFixYwPT0NElJSXz69Olv1/Ilb6vV+sPxv/Rpb28nKirKqy0wMBCAtWvX8vr1a9rb2+no6MDhcLB//37OnTv3U2sQEfFF2vkTERH5w01NTXl9BGZoaIiJiQkSEhIAsNlsdHd3e13jcrmw2WwzjhsQEADgeQ8P4M2bN7jdbmpqanA4HNhsNs9HWn5FSkoKnZ2d321bvHgxgYGBjIyMEBcX53VER0d7+oWHh1NcXMyNGze4cOECTU1Nv5yHiIgv0c6fiIjIH87f358DBw5w8eJF/P39KS0tZcWKFaSlpQFw+PBhNm/ezNKlS3E4HLS2ttLS0kJHR8eM48bExGCxWGhrayMnJwer1UpoaChhYWE0NTURGRnJyMgIVVVVv5xzdXU1ycnJ7Nu3jz179hAQEEBXVxd5eXnMnz+fyspKKioqmJ6eJiMjg8nJSVwuF8HBwWzfvp26ujqWLVtGYmIiHz9+pK2t7W+LWRERX6edPxERkT9cUFAQR48epaCggPT0dKxWK83NzZ72jRs30tDQQH19PYmJiVy6dAmn08nq1atnHDcqKooTJ05QVVVFREQEpaWl+Pn50dzczJMnT0hKSqKiooL6+vpfzjk+Pp779+/z/Plz0tLSSE9P586dO8ye/d//pU+dOkVdXR1nzpzBZrORnZ1Na2ur5/3CgIAAqqurSUlJYdWqVcyaNctrzSIi8i2LMV99K1pERET+KFevXqW8vJyJiYl/OhUREfnNaedPRERERETEB6j4ExERERER8QF67FNERERERMQHaOdPRERERETEB6j4ExERERER8QEq/kRERERERHyAij8REREREREfoOJPRERERETEB6j4ExERERER8QEq/kRERERERHyAij8REREREREf8B/pM8EgLZzViwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# reload evalation set\n",
    "eval_set = eval_set_list[0]#[pipe_name]\n",
    "\n",
    "\n",
    "importances = e.permutation_feature_importance(model_sqrt, \n",
    "#importances = e.permutation_feature_importance(model, \n",
    "                                               X_test,\n",
    "                                               y_test,\n",
    "                                               #eval_set.drop(target, axis=1), \n",
    "                                               #eval_set[target], \n",
    "                                               repeats=5, seed=seed\n",
    "                                               )\n",
    "\n",
    "## feature importance scores\n",
    "df_importance = pd.DataFrame({\n",
    "    \"name\" : X_unscaled.columns.to_list(),\n",
    "    \"importances\" : importances[0],\n",
    "     }) \n",
    "\n",
    "# drop features which dont reduce the loss\n",
    "df_importance = df_importance.loc[df_importance.importances > 0.0000, : ] \n",
    "df_importance = df_importance.sort_values(\"importances\", ascending=False)\n",
    "\n",
    "\n",
    "#fig, ax = plt.subplots(figsize=(12,5))\n",
    "plt.figure(figsize=(8, 5))\n",
    "#plt.barh(df_importance.name, df_importance.importances)\n",
    "#plt.barh(df_importance.name[-18:], df_importance.importances[-18:])\n",
    "\n",
    "sns.barplot(\n",
    "    data=df_importance, \n",
    "    x=\"importances\", y=\"name\",\n",
    "    width=0.4,\n",
    "    color='steelblue',\n",
    "    #errorbar=\"sd\",\n",
    "    errorbar=(\"pi\", 50), \n",
    "    capsize=.1, errcolor=\".5\",\n",
    "    linewidth=3, #edgecolor=\".3\", #facecolor=(0,0,0,0),\n",
    ")\n",
    "plt.ylabel(\"\")\n",
    "plt.xticks(\n",
    "    rotation = 90\n",
    "    )\n",
    "plt.title(f\"XGBoost (sqrt-transformed): Feature Importances for {target}\")\n",
    "plt.show()\n",
    "\n",
    "## save importnace scores  and figure\n",
    "#filepath = f'./models_evaluation/best_xgb_importance_scores_{target}_{pipe_name}'\n",
    "#if not glob(filepath):\n",
    "#    df_importance.to_csv(filename, index = False)\n",
    "\n",
    "\n",
    "#plt.savefig(f'../../../figures/best_en_feature_importance_{target}_{pipe_name}.png', bbox_inches='tight')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## left overs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hierarchical clustering on Spearman rank correlation\n",
    "\n",
    "Select only feautres with low collienarity to solve disadvantage of perumation feature importance.\n",
    "Randomizing one feature would lead to only small importance score - the model performance wouldnt be move influenced - due that the information is included in other correlated features. Removing one feature keeps the similar inforamtion in the other feautres unchanged and the model learns from the correlated feature. Therefore apply hierachical clustering to select less correlated features\n",
    "\n",
    "See also:\n",
    "- Brill 2020 (dissertation)\n",
    "- https://scikit-learn.org/stable/auto_examples/inspection/plot_permutation_importance_multicollinear.html # code example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scipy.cluster.hierarchy as shc\n",
    "\n",
    "# plt.figure(figsize=(15, 10))\n",
    "# plt.title(\"Customers Dendrogram\")\n",
    "\n",
    "# # Selecting Annual Income and Spending Scores by index\n",
    "# selected_data = X_train.dropna()\n",
    "# selected_data = selected_data.T # only possible with out nan\n",
    "# clusters = shc.linkage(selected_data, \n",
    "#             method='ward', optimal_ordering=False,\n",
    "#             metric=\"euclidean\")\n",
    "# shc.dendrogram(Z=clusters, \n",
    "#                #p=20, # p -> value for truncation mode\n",
    "#                orientation=\"right\",\n",
    "#                labels=X_train.columns\n",
    "#                ) \n",
    "# plt.show()\n",
    "\n",
    "# ## TODO adapt with spearman rank order\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from scipy.stats import spearmanr\n",
    "# from scipy.spatial.distance import squareform\n",
    "# from scipy.cluster.hierarchy import ward, dendrogram\n",
    "\n",
    "# fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 8))\n",
    "# corr = spearmanr(X_unscaled_no_nan).correlation\n",
    "\n",
    "# # Ensure the correlation matrix is symmetric\n",
    "# corr = (corr + corr.T) / 2\n",
    "# np.fill_diagonal(corr, 1)\n",
    "\n",
    "# # We convert the correlation matrix to a distance matrix before performing\n",
    "# # hierarchical clustering using Ward's linkage.\n",
    "# distance_matrix = 1 - np.abs(corr)\n",
    "# dist_linkage = ward(distance_matrix, checks=False )\n",
    "# dendro = dendrogram(\n",
    "#     dist_linkage, labels=X_unscaled_no_nan.columns.tolist(), ax=ax1, leaf_rotation=90\n",
    "# )\n",
    "# dendro_idx = np.arange(0, len(dendro[\"ivl\"]))\n",
    "\n",
    "# ax2.imshow(corr[dendro[\"leaves\"], :][:, dendro[\"leaves\"]])\n",
    "# ax2.set_xticks(dendro_idx)\n",
    "# ax2.set_yticks(dendro_idx)\n",
    "# ax2.set_xticklabels(dendro[\"ivl\"], rotation=\"vertical\")\n",
    "# ax2.set_yticklabels(dendro[\"ivl\"])\n",
    "# fig.tight_layout()\n",
    "\n",
    "# cluster_ids = shc.fcluster(dist_linkage, 1, criterion=\"distance\")\n",
    "# cluster_id_to_feature_ids = defaultdict(list)\n",
    "# for idx, cluster_id in enumerate(cluster_ids):\n",
    "#     cluster_id_to_feature_ids[cluster_id].append(idx)\n",
    "# selected_features = [v[0] for v in cluster_id_to_feature_ids.values()]\n",
    "\n",
    "# X_train_sel = X_train[:, selected_features]\n",
    "# X_test_sel = X_test[:, selected_features]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# closs hyperapram , no model__early_stopping_rounds, repeatedcv wit h10 folds\n",
    "## best train R2: ntree=30, max_depth =1, no furhter params\n",
    "\n",
    "# learning_rate = [ 0.00001, 0.0001, 0.001, 0.1, 0.2]#, 0.3, 0.4, 0.5, 0.6, 0.8, 0.9] # store outside, for plotting\n",
    "# n_estimators = [ 50, 100, 200, 300, 500, 800]\n",
    "\n",
    "# param_grid = {'model__n_estimators': n_estimators,\n",
    "#     #'model__n_estimators': [ 3, 5, 10, 20], # get only low train scores with this\n",
    "#               'model__max_depth': [1, 2, 3, 5, 7, 8, 10, 15],\n",
    "#               #'model__max_leaves': [0, 3, 5],\n",
    "#              # 'model__colsample_bytree': [ 0.3, 0.5, 0.7, 1.0 ], # Percentage of columns to be randomly samples for each tree\n",
    "#              # 'model__colsample_bynode': [ 0.3, 0.5, 0.7, 1.0], # nbr of feautres for each split point\n",
    "#              # 'model__eta': learning_rate,  # == eta\n",
    "#             #   'model__gamma': [0.2, 0.3, 0.5, 0.8, 1, 3] , # min_split_loss -  larger gamma is, the more conservative the algorithm is\n",
    "#               'model__subsample': [0.0, 0.2, 0.5, 0.6, 0.8, 0.9],  # define subsample of train st prior to growing trees, prevent overfitting\n",
    "#             #  'model__reg_alpha': [0.5, 1.0, 2.0, 4.0, 5.0, 6.0 ,7.0],   # Lasso Regularization term on weights , higher values = more consrvative \n",
    "#             #  'model__reg_lambda': [0.0, 0.1, 0.5, 1.0, 2.0, 3.0, 4.0, 5.0],  # Ridge Regularization term on weights ,  higher values = more consrvative\n",
    "#             #   'model__min_child_weight': [0, 1, 2, 3, 4,],\n",
    "#             #   \"model__max_delta_step\":  [0, 3, 5, 6, 7],           # for LogisticReg good to solve imbalance \n",
    "#           #   'model__objective': [None, 'reg:absoluteerror'],#'multi:softprob,'reg:squarederror','reg:models_trained'],\n",
    "#           #  # 'model__tree_method': [\"hist\", \"gpu_hist\"],\n",
    "#           #   'model__booster': [None, \"gblinear\", \"gbtree\"],\n",
    "#             \"model__validate_parameters\":[True],\n",
    "#               }\n",
    "\n",
    "# # 'model__scale_pos_weight': [0.0, 0.3, 0.5, 0.7, 0.9, 1.0],  # only  for clasifcation: handle imbalance, ratio between negative and positive examples\n",
    "\n",
    "# # Objective candidate: multi:softmax\n",
    "# # Objective candidate: multi:softprob\n",
    "# # Objective candidate: reg:squarederror\n",
    "# # Objective candidate: reg:squaredlogerror\n",
    "# # Objective candidate: reg:logistic\n",
    "# ## Objective candidate: reg:linear\n",
    "# # Objective candidate: reg:pseudohubererror\n",
    "# # Objective candidate: reg:gamma\n",
    "# # Objective candidate: reg:absoluteerror\n",
    "\n",
    "# ## DOC: https://xgboost.readthedocs.io/en/stable/parameter.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py396_c3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
