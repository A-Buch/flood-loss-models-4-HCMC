{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"Data preprocessing for HCMC survey dataset\"\"\"\n",
    "\n",
    "__author__ = \"Anna Buch, Heidelberg University\"\n",
    "__email__ = \"a.buch@stud.uni-heidelberg.de\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection done by eXtreme Gradient Boosting (XGBoost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import copy as cp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, train_test_split, StratifiedKFold, RepeatedStratifiedKFold, RepeatedKFold, cross_val_score, cross_validate\n",
    "from sklearn.impute import SimpleImputer\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import pickle\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "sys.path.insert(0, \"../../../\")\n",
    "import utils.utils_feature_selection as fs\n",
    "import utils.utils_evaluation as e\n",
    "import utils.utils_figures as f\n",
    "import utils.settings as s\n",
    "import utils.pipelines_continous as p\n",
    "\n",
    "s.init()\n",
    "seed = s.seed\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target_contentloss_euro</th>\n",
       "      <th>inundation_duration_h</th>\n",
       "      <th>water_depth_cm</th>\n",
       "      <th>contaminations.0</th>\n",
       "      <th>flowvelocity</th>\n",
       "      <th>warning_time_h</th>\n",
       "      <th>emergency_measures.1</th>\n",
       "      <th>emergency_measures.2</th>\n",
       "      <th>emergency_measures.3</th>\n",
       "      <th>emergency_measures.4</th>\n",
       "      <th>emergency_measures.6</th>\n",
       "      <th>emergency_measures.7</th>\n",
       "      <th>emergency_measures.8</th>\n",
       "      <th>emergency_measures.9</th>\n",
       "      <th>overall_problem_house</th>\n",
       "      <th>protect_valuables_impl</th>\n",
       "      <th>water_barriers_impl</th>\n",
       "      <th>pumping_equipment_impl</th>\n",
       "      <th>elevation_building_impl</th>\n",
       "      <th>resistant_material_building_impl</th>\n",
       "      <th>electricity_higher_impl</th>\n",
       "      <th>flood_protections_impl</th>\n",
       "      <th>flood_experience</th>\n",
       "      <th>elevation_building_height_cm</th>\n",
       "      <th>elevation_rel2surrounding_cat</th>\n",
       "      <th>bage</th>\n",
       "      <th>b_area</th>\n",
       "      <th>hh_monthly_income_cat</th>\n",
       "      <th>shp_owner</th>\n",
       "      <th>shp_sector</th>\n",
       "      <th>shp_employees</th>\n",
       "      <th>shp_avgmonthly_sale_cat</th>\n",
       "      <th>shp_finance_investments</th>\n",
       "      <th>shp_risk_tolerance</th>\n",
       "      <th>shp_monetary_resources4prevention</th>\n",
       "      <th>resilience_city_protection</th>\n",
       "      <th>resilience_left_alone</th>\n",
       "      <th>resilience_neighbor_management</th>\n",
       "      <th>perception_who_responsible4protection.Rank1</th>\n",
       "      <th>contaminations_light</th>\n",
       "      <th>contaminations_heavy</th>\n",
       "      <th>shp_content_value_euro</th>\n",
       "      <th>elevation_m</th>\n",
       "      <th>shp_registered_capital_euro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>130.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.83886</td>\n",
       "      <td>11047.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.87277</td>\n",
       "      <td>736.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Target_contentloss_euro  inundation_duration_h  water_depth_cm   \n",
       "395                      0.0                    4.0            70.0  \\\n",
       "396                      0.0                    3.0           100.0   \n",
       "\n",
       "     contaminations.0  flowvelocity  warning_time_h  emergency_measures.1   \n",
       "395                 0             1             NaN                     1  \\\n",
       "396                 0             1             NaN                     1   \n",
       "\n",
       "     emergency_measures.2  emergency_measures.3  emergency_measures.4   \n",
       "395                     0                     1                     0  \\\n",
       "396                     0                     1                     0   \n",
       "\n",
       "     emergency_measures.6  emergency_measures.7  emergency_measures.8   \n",
       "395                     1                     0                     0  \\\n",
       "396                     0                     0                     0   \n",
       "\n",
       "     emergency_measures.9  overall_problem_house  protect_valuables_impl   \n",
       "395                     0                      1                       1  \\\n",
       "396                     0                      0                       1   \n",
       "\n",
       "     water_barriers_impl  pumping_equipment_impl  elevation_building_impl   \n",
       "395                    5                       1                        1  \\\n",
       "396                    5                       5                        5   \n",
       "\n",
       "     resistant_material_building_impl  electricity_higher_impl   \n",
       "395                                 5                        5  \\\n",
       "396                                 5                        5   \n",
       "\n",
       "     flood_protections_impl  flood_experience  elevation_building_height_cm   \n",
       "395                       5                 5                          70.0  \\\n",
       "396                       5                 4                           NaN   \n",
       "\n",
       "     elevation_rel2surrounding_cat  bage  b_area  hh_monthly_income_cat   \n",
       "395                              1   NaN   130.0                    NaN  \\\n",
       "396                              0   5.0    33.0                    1.0   \n",
       "\n",
       "     shp_owner  shp_sector  shp_employees  shp_avgmonthly_sale_cat   \n",
       "395          1          17              2                        3  \\\n",
       "396          1          11              2                        3   \n",
       "\n",
       "     shp_finance_investments  shp_risk_tolerance   \n",
       "395                        1                 3.0  \\\n",
       "396                        1                 3.0   \n",
       "\n",
       "     shp_monetary_resources4prevention  resilience_city_protection   \n",
       "395                                3.0                         1.0  \\\n",
       "396                                4.0                         NaN   \n",
       "\n",
       "     resilience_left_alone  resilience_neighbor_management   \n",
       "395                      5                             1.0  \\\n",
       "396                      5                             NaN   \n",
       "\n",
       "     perception_who_responsible4protection.Rank1  contaminations_light   \n",
       "395                                          2.0                     1  \\\n",
       "396                                          3.0                     1   \n",
       "\n",
       "     contaminations_heavy  shp_content_value_euro  elevation_m   \n",
       "395                     0                     NaN      1.83886  \\\n",
       "396                     0                     NaN      1.87277   \n",
       "\n",
       "     shp_registered_capital_euro  \n",
       "395                      11047.7  \n",
       "396                        736.5  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_candidates = pd.read_excel(\"../../../input_survey_data/input_data_contentloss.xlsx\")\n",
    "df_candidates.tail(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of missing valeus per feature\n",
      " warning_time_h                                 0.775819\n",
      "elevation_building_height_cm                   0.158690\n",
      "shp_content_value_euro                         0.158690\n",
      "shp_registered_capital_euro                    0.118388\n",
      "perception_who_responsible4protection.Rank1    0.070529\n",
      "shp_risk_tolerance                             0.070529\n",
      "bage                                           0.068010\n",
      "hh_monthly_income_cat                          0.060453\n",
      "shp_monetary_resources4prevention              0.045340\n",
      "resilience_city_protection                     0.037783\n",
      "Target_contentloss_euro                        0.037783\n",
      "resilience_neighbor_management                 0.027708\n",
      "inundation_duration_h                          0.022670\n",
      "elevation_m                                    0.010076\n",
      "b_area                                         0.005038\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "## delete features with more than 10% missing values\n",
    "\n",
    "print(\"Percentage of missing valeus per feature\\n\", df_candidates.isna().mean().sort_values(ascending=False)[:15] ) \n",
    "## --> kepp threshold by 15% less would delete important features e.g. content values, registerd capitaletc.\n",
    "\n",
    "# drop warning time due to 77% nan\n",
    "df_candidates = df_candidates.drop(\"warning_time_h\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## select only damage cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = [\"Target_contentloss_euro\", \"Target_businessreduction\"]\n",
    "target = targets[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing 226 zero loss records\n",
      "Keeping (171, 43) damage cases for model training and evaluation\n"
     ]
    }
   ],
   "source": [
    "print(f\"Removing {df_candidates.loc[df_candidates[target]==0,:].shape[0]} zero loss records\")\n",
    "df_candidates = df_candidates.loc[df_candidates[target]!=0,:]\n",
    "\n",
    "print(f\"Keeping {df_candidates.shape} damage cases for model training and evaluation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target varibale distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count       156.000000\n",
      "mean       2242.412179\n",
      "std       18219.509814\n",
      "min           7.400000\n",
      "25%          39.700000\n",
      "50%         137.950000\n",
      "75%         382.700000\n",
      "max      224190.400000\n",
      "Name: Target_contentloss_euro, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "print(df_candidates[target].describe())\n",
    "\n",
    "closses = df_candidates[target] #df_candidates[target][df_candidates[target] != 0.0 ]\n",
    "closses.hist(bins=2000, figsize=(8, 8))\n",
    "plt.ylim(1, 20)\n",
    "plt.xlim(1, 20000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = [ 0.001, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5] # store outside, for plotting\n",
    "\n",
    "param_grid = {'model__n_estimators': [ 50, 100, 200, 300, 500, 1000],\n",
    "    #'model__n_estimators': [ 3, 5, 10, 20], # get only low train scores with this\n",
    "              'model__max_depth': [1, 2, 3, 5, 7, 8, 10, 15],\n",
    "              #'model__max_leaves': [0, 3, 5],\n",
    "             # 'model__colsample_bytree': [ 0.3, 0.5, 0.7, 1.0 ], # Percentage of columns to be randomly samples for each tree\n",
    "             # 'model__colsample_bynode': [ 0.3, 0.5, 0.7, 1.0], # nbr of feautres for each split point\n",
    "              'model__eta': learning_rate,  # == eta\n",
    "            #   'model__gamma': [0.2, 0.3, 0.5, 0.8, 1, 3] , # min_split_loss -  larger gamma is, the more conservative the algorithm is\n",
    "              'model__subsample': [0.2, 0.5, 0.6, 0.8, 0.9],  # define subsample of train st prior to growing trees, prevent overfitting\n",
    "             'model__reg_alpha': [0.5, 1.0, 2.0, 4.0, 5.0, 6.0 ],   # Lasso Regularization term on weights , higher values = more consrvative \n",
    "             'model__reg_lambda': [0.0, 0.1, 0.5, 1.0, 2.0, 3.0],  # Ridge Regularization term on weights ,  higher values = more consrvative\n",
    "            #   'model__min_child_weight': [0, 1, 2, 3, 4,],\n",
    "            #   \"model__max_delta_step\":  [0, 3, 5, 6, 7],           # for LogisticReg good to solve imbalance \n",
    "           # 'model__objective': [None, 'reg:absoluteerror'],#'multi:softprob,'reg:squarederror','reg:models_trained'],\n",
    "           # 'model__tree_method': [\"hist\", \"gpu_hist\"],\n",
    "            #   'model__booster': [None, \"gblinear\", \"gbtree\"]\n",
    "            \"model__validate_parameters\":[True],\n",
    "              }\n",
    "# 'model__scale_pos_weight': [0.0, 0.3, 0.5, 0.7, 0.9, 1.0],  # only  for clasifcation: handle imbalance, ratio between negative and positive examples\n",
    "\n",
    "# Objective candidate: multi:softmax\n",
    "# Objective candidate: multi:softprob\n",
    "# Objective candidate: reg:squarederror\n",
    "# Objective candidate: reg:squaredlogerror\n",
    "# Objective candidate: reg:logistic\n",
    "## Objective candidate: reg:linear\n",
    "# Objective candidate: reg:pseudohubererror\n",
    "# Objective candidate: reg:gamma\n",
    "# Objective candidate: reg:absoluteerror\n",
    "\n",
    "## DOC: https://xgboost.readthedocs.io/en/stable/parameter.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Apply XGBoost on Target_contentloss_euro, with pipeline pipe_xgb:\n",
      "Uses  171  records, from those have  {0}  records zero contentloss\n",
      "Dropping 15 records from entire dataset due that these values are nan in target variable\n",
      "Training set size 117\n",
      "Test set size 39\n",
      "Best hyperparams: {'model__validate_parameters': True, 'model__subsample': 0.9, 'model__reg_lambda': 2.0, 'model__reg_alpha': 4.0, 'model__n_estimators': 200, 'model__max_depth': 3, 'model__eta': 0.4}\n",
      "Create new XGBoost model based on best hyperparameters\n",
      "\n",
      "Select features based on permutation feature importance\n",
      "Most important features: ['shp_content_value_euro', 'shp_employees', 'resilience_left_alone', 'elevation_building_impl', 'b_area']\n",
      "total features: 42\n",
      "selected features: 23\n",
      "dropped features: 19\n",
      "selected features: \n",
      "['shp_content_value_euro', 'shp_employees', 'resilience_left_alone', 'elevation_building_impl', 'b_area', 'elevation_m', 'water_barriers_impl', 'emergency_measures.3', 'electricity_higher_impl', 'resilience_neighbor_management', 'contaminations.0', 'emergency_measures.1', 'emergency_measures.6', 'shp_monetary_resources4prevention', 'elevation_rel2surrounding_cat', 'shp_owner', 'shp_finance_investments', 'contaminations_heavy', 'emergency_measures.8', 'resistant_material_building_impl', 'contaminations_light', 'flood_protections_impl', 'emergency_measures.9']\n",
      "\n",
      "Saving model to disk: ../../../input_survey_data/fs_xgboost_contentloss_pipe_xgb_cntn.xlsx\n",
      "\n",
      "Training set\n",
      "\n",
      "    Model Performance:\n",
      "        Mean Squared Error: 10.2\n",
      "        Root Mean Square Error: 3.2\n",
      "        Mean Absolute Error: 1.8\n",
      "        Mean Absolute Percentage Error: 2.4\n",
      "        R²-Score: 1.0\n",
      "        Adjusted R²-Score: 1.0\n",
      "    \n",
      "\n",
      "Testing set\n",
      "\n",
      "    Model Performance:\n",
      "        Mean Squared Error: 16840126.7\n",
      "        Root Mean Square Error: 4103.7\n",
      "        Mean Absolute Error: 1199.8\n",
      "        Mean Absolute Percentage Error: 432.1\n",
      "        R²-Score: -0.08\n",
      "        Adjusted R²-Score: 11.27\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "## iterate over both targets and store results \n",
    "\n",
    "fi_threshold = 0.000\n",
    "eval_set_list = []\n",
    "\n",
    "targets = [\"Target_contentloss_euro\"]# , \"Target_businessreduction\"]\n",
    "#importances_threshold = {\"target_contentloss_euro\": 0.000, \"Target_businessreduction\": 0.000 }\n",
    "\n",
    "plt.ioff()  # Prevent plt showing stuff\n",
    "\n",
    "# def best_ntree_score(estimator, X, y):\n",
    "#     \"\"\"\n",
    "#     This scorer uses the best_ntree_limit to return\n",
    "#     the best AUC ROC score\n",
    "#     \"\"\"\n",
    "#     try:\n",
    "#         y_predict = estimator.predict_proba(X,\n",
    "#                                             ntree_limit=estimator.best_ntree_limit)\n",
    "#     except AttributeError:\n",
    "#         y_predict = estimator.predict_proba(X)\n",
    "#     return roc_auc_score(y, y_predict[:, 1])\n",
    "\n",
    "\n",
    "for target in targets:\n",
    "\n",
    "\n",
    "    ## iterate over piplines. Each piplines contains precrosseing methods and several  classifier\n",
    "    pipelines = [\"pipe_xgb\"]#, \"pipe_ximput_xgb\"]\n",
    "        \n",
    "\n",
    "    for pipe_name in pipelines:\n",
    "\n",
    "        print( f\"\\nApply XGBoost on {target}, with pipeline {pipe_name}:\")\n",
    "\n",
    "        ## load sinlge pipeline\n",
    "        pipe = joblib.load(f'./pipelines/{pipe_name}.pkl')\n",
    "        \n",
    "        \n",
    "        df_candidates_t = df_candidates\n",
    "\n",
    "        ## TEST run xgb with and without nan in X\n",
    "        ## clean df from remaining records containg nan\n",
    "        #df_candidates_t = df_candidates_t.dropna()\n",
    "        #df_candidates_t = df_candidates_t[df_candidates_t[target]!=0.0]\n",
    "\n",
    "        #print(\"Amount of missing target values should be zero: \", df_candidates_t[target].isna().sum())\n",
    "        print(\"Uses \", df_candidates_t.shape[0], \" records, from those have \", \n",
    "            { (df_candidates_t[target][df_candidates_t[target]==0.0]).count() }, f\" records zero {target.split('_')[1]}\")\n",
    "\n",
    "\n",
    "        ## drop samples where target is nan\n",
    "        print(f\"Dropping {df_candidates_t[f'{target}'].isna().sum()} records from entire dataset due that these values are nan in target variable\")\n",
    "        df_candidates_t = df_candidates_t[ ~df_candidates_t[f\"{target}\"].isna()]\n",
    "\n",
    "\n",
    "        if pipe_name != \"pipe_ximput_xgb\":\n",
    "            pass\n",
    "            # ## drop instances where target is nan\n",
    "            # print(\"Before dropping records with nan\", df_candidates_t.shape)\n",
    "            # df_candidates_t = df_candidates_t.dropna()\n",
    "            # print(\"After dropping records with nan\", df_candidates_t.shape)\n",
    "        else:\n",
    "            ##impute nans in X\n",
    "            for c in df_candidates_t.drop(targets, axis=1).columns: \n",
    "                #df_candidates_t[f\"{c}\"].fillna(value=np.nanmedian(df_candidates_t[f\"{c}\"]), inplace=True)\n",
    "                df_candidates_t[c].fillna(df_candidates_t[c].median(), inplace=True)\n",
    "       \n",
    "        # split into predictors and target variable\n",
    "        X_unscaled = df_candidates_t.drop([target] + targets, axis=1)  # remove targets from X\n",
    "        y = df_candidates_t[target]\n",
    "        \n",
    "        ## test train split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X_unscaled, y, test_size=0.25, \n",
    "            random_state=seed, shuffle=True\n",
    "        )\n",
    "        ## save evaluation set for later usage in feature importance\n",
    "        eval_set =  pd.concat([y_test, X_test], axis=1) #[(X_test, y_test)]\n",
    "        eval_set_list.append({pipe_name : eval_set})\n",
    "        \n",
    "        print(\"Training set size\", X_train.shape[0])\n",
    "        print(\"Test set size\", X_test.shape[0])\n",
    "\n",
    "        ## normalize data \n",
    "        X_train, X_test = fs.normalize_X(X_train, X_test)\n",
    "\n",
    "        ## Hyperparmaters and CV\n",
    "        cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=seed) \n",
    "        #cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3)#, random_state=seed)        #  StratifiedKFold = fold contains same percantega of class as in orignal training set, addresees imbalancing\n",
    "        model_cv = RandomizedSearchCV(   #         #GridSearchCV(\n",
    "            estimator=pipe, \n",
    "            #param_grid=param_grid,\n",
    "            param_distributions=param_grid, \n",
    "            random_state=seed,\n",
    "            cv=cv, \n",
    "            scoring= \"neg_mean_absolute_error\",\n",
    "            #best_ntree_score(XGBRegressor, X_train, y_train) , #\"neg_mean_absolute_error\",   #\n",
    "            refit=True,   ## Refit the best estimator with the entire dataset. If “False”, it is impossible to make predictions using this GridSearchCV instance after fitting.\n",
    "                            ## If refit=False, clf.fit() will have no effect because the GridSearchCV object inside the pipeline will be reinitialized after fit().\n",
    "                            ## ! When refit=True, the GridSearchCV will be refitted with the best scoring parameter combination on the whole data that is passed in fit()\n",
    "            verbose=False,\n",
    "        )\n",
    "        ## Fit best model on training set\n",
    "        model_cv.fit(\n",
    "            X_train, y_train,\n",
    "            model__early_stopping_rounds=50,\n",
    "            model__eval_metric=\"mae\",\n",
    "            model__eval_set=[(X_test, y_test)],\n",
    "            model__verbose=False\n",
    "            )\n",
    " \n",
    "        print(f\"Best hyperparams: {model_cv.best_params_}\")\n",
    "        # print(\"Train R^2 Score : %.1f\" %model_cv.best_estimator_.score(X_train, y_train))\n",
    "        #print(\"MAE of best model: %.1f\" %model_cv.best_score_,\" on iteration \", model_cv.best_estimator_.best_iteration)  \n",
    "\n",
    "        # fit model again with best hyperparams\n",
    "        print(\"Create new XGBoost model based on best hyperparameters\")\n",
    "        model = model_cv.best_estimator_\n",
    "         \n",
    "        ## store best trained model for evaluation\n",
    "        filename = f'./models_trained/xgboost_{target}_{pipe_name}.sav'\n",
    "        #pickle.dump(model_cv.best_estimator_, open(filename, 'wb'))\n",
    "        pickle.dump(model, open(filename, 'wb'))\n",
    "\n",
    "        ## Evaluate model\n",
    "        # print(f\"Training set score (R^2): {round(model.score(X_train, y_train), 2)}\")  # how well did the model on the training set\n",
    "        # print(f\"Test set score (R^2): {model_cv.score(X_test, y_test)}\")   # .. compared to the unseen test set for overfitting - acutal not needed\n",
    "        # r2 = variance explained by model / total variance --> higher r2= better fitted model\n",
    "\n",
    "        ## get signifcant features based on absolute coeff values\n",
    "        print(\"\\nSelect features based on permutation feature importance\")\n",
    "\n",
    "        # ## select significant features byPermuation feature importance\n",
    "        importances = e.permutation_feature_importance(model, X_test, y_test, repeats=5, seed=seed)\n",
    "\n",
    "        df_importance = pd.DataFrame(\n",
    "            {\"importances\" : importances[0]},\n",
    "            index=X_train.columns.to_list(),\n",
    "            ) \n",
    "        df_importance = df_importance.sort_values(\"importances\", ascending=False)  # get most important features to the top\n",
    "        print(\"Most important features:\", df_importance.iloc[:5].index.to_list())\n",
    "        df_importance = df_importance.loc[df_importance.importances >= fi_threshold, : ]\n",
    "        #df_importance.head(5)\n",
    "        # ## write selected predictors and response to disk\n",
    "        fs.save_selected_features(\n",
    "            X_train, \n",
    "            pd.DataFrame(y_train, columns=[target]), \n",
    "            df_importance.T.columns, \n",
    "            filename=f\"../../../input_survey_data/fs_xgboost_{target.split('_')[1]}_{pipe_name}_cntn.xlsx\"\n",
    "        )\n",
    "\n",
    "        ## Evaluate\n",
    "        ## print evaluation report + check for overfitting \n",
    "        print(\"\\nTraining set\")\n",
    "        y_pred_train = model.predict(X_train)\n",
    "        #y_pred_train = model_cv.best_estimator_.predict(X_train)\n",
    "        e.evaluation_report(y_train, y_pred_train,\n",
    "                            X_unscaled.shape[1], \n",
    "                            filepath=f\"./models_evaluation/elastic_net/eval_train_{target.split('_')[1]}_{pipe_name}.csv\")\n",
    "\n",
    "        print(\"\\nTesting set\")\n",
    "        #y_pred = model_cv.best_estimator_.predict(X_test)\n",
    "        y_pred = model.predict(X_test)\n",
    "        e.evaluation_report(y_test, y_pred, \n",
    "                            X_unscaled.shape[1], \n",
    "                            filepath=f\"./models_evaluation/elastic_net/eval_test_{target.split('_')[1]}_{pipe_name}.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model__validate_parameters': True,\n",
       " 'model__subsample': 0.9,\n",
       " 'model__reg_lambda': 2.0,\n",
       " 'model__reg_alpha': 4.0,\n",
       " 'model__n_estimators': 200,\n",
       " 'model__max_depth': 3,\n",
       " 'model__eta': 0.4}"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cv.best_params_\n",
    "\n",
    "# 75 % in train mit 300 trress, subsam0.8, maxdep=3, aber bad teest R2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot learning rate see if    \n",
    "means = model_cv.cv_results_['mean_test_score']\n",
    "stds = model_cv.cv_results_['std_test_score']\n",
    "params = model_cv.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "    # plot\n",
    "    plt.errorbar(learning_rate, means, yerr=stds)\n",
    "    plt.title(\"XGBoost learning_rate vs Log Loss\")\n",
    "    plt.xlabel('learning_rate')\n",
    "    plt.ylabel('Log Loss')\n",
    "    plt.savefig('learning_rate.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -4130.67856349,  -2910.09700882, -14928.96795907,  -5097.28830228,\n",
       "        -3342.94989408,  -3859.81378931,  -4047.15437388,  -3714.01854439,\n",
       "        -4462.63498374,  -3566.7385018 ])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model_cv.cv_results_.get(\"rank_test_score\")\n",
    "model_cv.cv_results_.get(\"mean_test_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Pipeline' object has no attribute 'evals_result'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Anna\\Documents\\UNI\\MA_topic\\flood-loss-models-4-HCMC\\feature-selection-from-remote-fs\\model_preprocessing\\Feature_selection\\xgboost_feature_selection.ipynb Cell 17\u001b[0m in \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Anna/Documents/UNI/MA_topic/flood-loss-models-4-HCMC/feature-selection-from-remote-fs/model_preprocessing/Feature_selection/xgboost_feature_selection.ipynb#X60sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m results \u001b[39m=\u001b[39m model_eval\u001b[39m.\u001b[39;49mevals_result()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Anna/Documents/UNI/MA_topic/flood-loss-models-4-HCMC/feature-selection-from-remote-fs/model_preprocessing/Feature_selection/xgboost_feature_selection.ipynb#X60sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m10\u001b[39m,\u001b[39m7\u001b[39m))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Anna/Documents/UNI/MA_topic/flood-loss-models-4-HCMC/feature-selection-from-remote-fs/model_preprocessing/Feature_selection/xgboost_feature_selection.ipynb#X60sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(results[\u001b[39m\"\u001b[39m\u001b[39mvalidation_0\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mrmse\u001b[39m\u001b[39m\"\u001b[39m], label\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTraining loss\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Pipeline' object has no attribute 'evals_result'"
     ]
    }
   ],
   "source": [
    "# results = model_eval.evals_result()\n",
    "\n",
    "# plt.figure(figsize=(10,7))\n",
    "# plt.plot(results[\"validation_0\"][\"rmse\"], label=\"Training loss\")\n",
    "# plt.plot(results[\"validation_1\"][\"rmse\"], label=\"Validation loss\")\n",
    "# plt.axvline(21, color=\"gray\", label=\"Optimal tree number\")\n",
    "# plt.xlabel(\"Number of trees\")\n",
    "# plt.ylabel(\"Loss\")\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model =   XGBRegressor(n_estimators=30)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "model.best_ntree_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_booster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('running cross validation, with preprocessing function')\n",
    "# # define the preprocessing function\n",
    "# # used to return the preprocessed training, test data, and parameter\n",
    "# # we can use this to do weight rescale, etc.\n",
    "# # as a example, we try to set scale_pos_weight\n",
    "# def fpreproc(dtrain, dtest, param):\n",
    "#     label = dtrain.get_label()\n",
    "#     ratio = float(np.sum(label == 0)) / np.sum(label == 1)\n",
    "#     param['scale_pos_weight'] = ratio  #  ratio of number of negative class to the positive class\n",
    "#     return (dtrain, dtest, param)\n",
    "\n",
    "# # do cross validation, for each fold\n",
    "# # the dtrain, dtest, param will be passed into fpreproc\n",
    "# # then the return value of fpreproc will be used to generate\n",
    "# # results of that fold\n",
    "# xgb.cv(param, dtrain, num_round, nfold=5,\n",
    "#        metrics={'auc'}, seed=0, fpreproc=fpreproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7651809450669104\n",
      "-0.05914785305530312\n"
     ]
    }
   ],
   "source": [
    "#plt.savefig(f\"./models_trained/FI_{target}.png\", bbox_inches='tight')\n",
    "#sns_plot.figure.savefig(\"output.png\")\n",
    "print(model.score(X_train, y_train))\n",
    "print(model.score(X_test, y_test))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reload model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target_contentloss_euro\n"
     ]
    }
   ],
   "source": [
    "## reload models\n",
    "\n",
    "target = targets[0]\n",
    "print(target)\n",
    "\n",
    "model_eval = pickle.load(open(f\"./models_trained/xgboost_{target}_{pipe_name}.sav\", 'rb'))\n",
    "#model_eval.get_params()\n",
    "#dir(model_eval)#.feature_importances_[model_eval.feature_importances_>0.015].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importance\n",
    "Have the same feature importance method across all applied ML models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Permuation feature importance\n",
    "# result = e.permutation_feature_importance(model_eval, X_test, y_test, repeats=5, seed=seed)\n",
    "\n",
    "# df_importance = pd.DataFrame({\n",
    "#     \"name\" : X_train.columns.to_list(),\n",
    "#     \"importances\" : result[0],\n",
    "#      }) \n",
    "# df_importance = df_importance.sort_values(\"importances\", ascending=False)  # get most important features to the top\n",
    "# df_importance.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot feature importance\n",
    "\n",
    "# f.plot_feature_importance(df_importance.importances, n=10, figure_size=(20, 15), target=target)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,10))\n",
    "\n",
    "# drop features which dont reduce the loss\n",
    "df_importance = df_importance.loc[df_importance.importances >= 0.001, : ] \n",
    "#sorted_idx = model_eval.feature_importances_.argsort()\n",
    "#plt.barh(df_importance.name[-5:], df_importance.importances[-5:])\n",
    "plt.bar(df_importance.name, df_importance.importances)\n",
    "#plt.bar(X_train.columns[sorted_idx[:15]], model_eval.feature_importances_[sorted_idx[:15]])\n",
    "plt.xticks(\n",
    "   # ticks = range(len(X_train.columns[sorted_idx[:15]])),\n",
    "   # labels =X_train.columns[sorted_idx[:15],],\n",
    "    rotation = 90\n",
    "    )\n",
    "plt.title(f\"Feature Importances for {target}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hierarchical clustering on Spearman rank correlation\n",
    "\n",
    "Select only feautres with low collienarity to solve disadvantage of perumation feature importance.\n",
    "Randomizing one feature would lead to only small importance score - the model performance wouldnt be move influenced - due that the information is included in other correlated features. Removing one feature keeps the similar inforamtion in the other feautres unchanged and the model learns from the correlated feature. Therefore apply hierachical clustering to select less correlated features\n",
    "\n",
    "See also:\n",
    "- Brill 2020 (dissertation)\n",
    "- https://scikit-learn.org/stable/auto_examples/inspection/plot_permutation_importance_multicollinear.html # code example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scipy.cluster.hierarchy as shc\n",
    "\n",
    "# plt.figure(figsize=(15, 10))\n",
    "# plt.title(\"Customers Dendrogram\")\n",
    "\n",
    "# # Selecting Annual Income and Spending Scores by index\n",
    "# selected_data = X_train.dropna()\n",
    "# selected_data = selected_data.T # only possible with out nan\n",
    "# clusters = shc.linkage(selected_data, \n",
    "#             method='ward', optimal_ordering=False,\n",
    "#             metric=\"euclidean\")\n",
    "# shc.dendrogram(Z=clusters, \n",
    "#                #p=20, # p -> value for truncation mode\n",
    "#                orientation=\"right\",\n",
    "#                labels=X_train.columns\n",
    "#                ) \n",
    "# plt.show()\n",
    "\n",
    "# ## TODO adapt with spearman rank order\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from scipy.stats import spearmanr\n",
    "# from scipy.spatial.distance import squareform\n",
    "# from scipy.cluster.hierarchy import ward, dendrogram\n",
    "\n",
    "# fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 8))\n",
    "# corr = spearmanr(X_unscaled_no_nan).correlation\n",
    "\n",
    "# # Ensure the correlation matrix is symmetric\n",
    "# corr = (corr + corr.T) / 2\n",
    "# np.fill_diagonal(corr, 1)\n",
    "\n",
    "# # We convert the correlation matrix to a distance matrix before performing\n",
    "# # hierarchical clustering using Ward's linkage.\n",
    "# distance_matrix = 1 - np.abs(corr)\n",
    "# dist_linkage = ward(distance_matrix, checks=False )\n",
    "# dendro = dendrogram(\n",
    "#     dist_linkage, labels=X_unscaled_no_nan.columns.tolist(), ax=ax1, leaf_rotation=90\n",
    "# )\n",
    "# dendro_idx = np.arange(0, len(dendro[\"ivl\"]))\n",
    "\n",
    "# ax2.imshow(corr[dendro[\"leaves\"], :][:, dendro[\"leaves\"]])\n",
    "# ax2.set_xticks(dendro_idx)\n",
    "# ax2.set_yticks(dendro_idx)\n",
    "# ax2.set_xticklabels(dendro[\"ivl\"], rotation=\"vertical\")\n",
    "# ax2.set_yticklabels(dendro[\"ivl\"])\n",
    "# fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_ids = shc.fcluster(dist_linkage, 1, criterion=\"distance\")\n",
    "cluster_id_to_feature_ids = defaultdict(list)\n",
    "for idx, cluster_id in enumerate(cluster_ids):\n",
    "    cluster_id_to_feature_ids[cluster_id].append(idx)\n",
    "selected_features = [v[0] for v in cluster_id_to_feature_ids.values()]\n",
    "\n",
    "X_train_sel = X_train[:, selected_features]\n",
    "X_test_sel = X_test[:, selected_features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## permutation based FI (build in func from skilearn)\n",
    "\n",
    "# perm_importance = permutation_importance(xgb, X_test, y_test)\n",
    "# The visualization of the importance:\n",
    "\n",
    "# sorted_idx = perm_importance.importances_mean.argsort()\n",
    "# plt.barh(boston.feature_names[sorted_idx], perm_importance.importances_mean[sorted_idx])\n",
    "# plt.xlabel(\"Permutation Importance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py396_c3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
