{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocessing of Can Tho Dataset and compariosn with HCMC dataset\n",
    "AIm: Valdiate that both datasets dont differ too much from each other, so that they can be compared with each other\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x1000 with 0 Axes>"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"Data preprocessing for Can Tho survey dataset\"\"\"\n",
    "\n",
    "__author__ = \"Anna Buch, Heidelberg University\"\n",
    "__email__ = \"a.buch@stud.uni-heidelberg.de\"\n",
    "\n",
    "\n",
    "import sys\n",
    "import re\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# sys.path.insert(0, \"../\")\n",
    "# import utils.settings as s\n",
    "\n",
    "# #s.init()\n",
    "# seed = s.seed\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('use_inf_as_na', True)\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load DS for flood event from 2011 in CanTHo\n",
    "#df_cantho = pd.read_excel(\"../input_survey_data/input_data_cantho_2013_quicktest.xlsx\", header=0) # only pre-selected features\n",
    "df_cantho_raw = pd.read_excel(\"../input_survey_data/input_data_cantho_2013_raw_no_multiheader.xlsx\") # removed mulitple header rows\n",
    "\n",
    "# ## load HCMC DS for flood events between 2010-2020\n",
    "df_hcmc_rloss = pd.read_excel(\"../input_survey_data/input_data_contentloss_tueb.xlsx\")\n",
    "df_hcmc_bred = pd.read_excel(\"../input_survey_data/input_data_businessreduction_tueb.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cantho = df_cantho_raw\n",
    "\n",
    "## missing values\n",
    "df_cantho = df_cantho.replace({99.0: np.nan, 88.0: np.nan})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rename columns \n",
    "rename cols to the ones used in HCMC ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Target_eloss_VND', 'Target_gloss_VND', 'Target_contentloss_euro',\n",
       "       'Target_relative_contentloss_euro', 'Target_businessreduction',\n",
       "       'shp_sector', 'flood_experience', 'flood_type', 'warning_time_day',\n",
       "       'emergency_measures1', 'emergency_measures2', 'emergency_measures3',\n",
       "       'emergency_measures4', 'emergency_measures5', 'emergency_measures6',\n",
       "       'emergency_measures7', 'emergency_measures8', 'emergency_measures9',\n",
       "       'effect_emergency_measures', 'water_depth_cm',\n",
       "       'inundation_duration_day/month', 'inundation_duration_hour/day',\n",
       "       'contaminations', 'flowvelocity', 'overall_problem_house1',\n",
       "       'overall_problem_house2', 'overall_problem_house3',\n",
       "       'overall_problem_house4', 'replaced_cost_e', 'precautionary_measures1',\n",
       "       'precautionary_measures2', 'precautionary_measures3',\n",
       "       'precautionary_measures4', 'precautionary_measures5',\n",
       "       'precautionary_measures6', 'precautionary_measures7',\n",
       "       'precautionary_measures8', 'precautionary_measures9',\n",
       "       'precautionary_measures10', 'perception_too_destructive_floods',\n",
       "       'risk_future_flood', 'risk_consequents_future_flood', 'ownership',\n",
       "       'bage', 'building_value_cat', 'hh_monthly_income_cat', 'shp_employees',\n",
       "       'shp_avgmonthly_sale_VND', 'shp_registered_capital_VND_cat',\n",
       "       'content_value_g_VND', 'content_value_e_VND', 'b_area', 'floors',\n",
       "       'builing_elevation', 'builing_type', 'Direct_damage'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "## assigne new columns which have to be created in this script, eg relative contnet loss\n",
    "df_cantho[\"Target_relative_contentloss_euro\"] = None\n",
    "df_cantho[\"Target_contentloss_euro\"] = None\n",
    "\n",
    "\n",
    "\n",
    "col_names = {\n",
    "       r'3.31$' : 'Target_eloss_VND', \n",
    "       r'^3.34$' : 'Target_gloss_VND', \n",
    "       r'3.40$' : 'Target_businessreduction',\n",
    "\n",
    "       r'3.13.b$' : 'inundation_duration_day/month',\n",
    "       r'3.13.c$' :'inundation_duration_hour/day',\n",
    "       r'^3.12$' : 'water_depth_cm', \n",
    "       r'3.16$' : 'flowvelocity', \n",
    "       r'3.14$' : 'contaminations', \n",
    "       r'^2.2$' : 'flood_experience', \n",
    "\n",
    "       '3.7.' : 'emergency_measures', \n",
    "       '4.1.' : 'precautionary_measures',  \n",
    "       # not incl pumping euqipmentn and saving of valuables, \n",
    "       # but incl cheap funriture and low-value usage\n",
    "\n",
    "       r'7.3$' : 'bage', \n",
    "       r'11.8$' : 'b_area',\n",
    "       r'11.9$' : 'floors',\n",
    "       r'7.4$' : 'building_value_cat',\n",
    "       '3.18.' : 'overall_problem_house',\n",
    "       r'11.6$' : 'content_value_g_VND',\n",
    "       r'11.7$' : 'content_value_e_VND',\n",
    "\n",
    "       r'11.2$' : 'shp_employees', \n",
    "       r'11.3.1$' : 'shp_avgmonthly_sale_VND', \n",
    "       r'10.5$' : 'hh_monthly_income_cat',\n",
    "       r'11.5$' : 'shp_registered_capital_VND_cat', # 11.5.\tHow much did you pay for opening your shop\n",
    "\n",
    "       # '6.1' : 'perception_govern_management',\n",
    "       # '6.2' : 'perception_govern_increase_management',\n",
    "       #'6.3' : 'perception_govern_protection', # is scaled 1-6\n",
    "       #'resilience', \n",
    "       #'resilienceLeftAlone',\n",
    "\n",
    "       ## further variables which might be intresting but not needed for feature selection\n",
    "       r'^1.4$' : 'shp_sector',\n",
    "       r'^3.2$' : 'flood_type',\n",
    "       r'^3.5$' : 'warning_time_day',  # for HCMC Q1P2.9 wanring_time_hours\n",
    "       r'3.9$' : 'effect_emergency_measures',\n",
    "       r'3.32$' : 'replaced_cost_e',\n",
    "       r'3.34$' : 'replaced_cost_g',\n",
    "       r'^5.1$' : 'risk_future_flood',\n",
    "       r'^5.2$' : 'risk_consequents_future_flood',\n",
    "       r'4.9.1$' : 'perception_too_destructive_floods',\n",
    "       r'6.1.$' : 'flood_management',\n",
    "       r'7.2$' : 'ownership',\n",
    "       r'11.15$' : 'builing_elevation',\n",
    "       'Type of house' : 'builing_type',\n",
    "}\n",
    "\n",
    "for k, v in col_names.items():\n",
    "    df_cantho.rename(columns ={ i: re.sub(k, v, i) for i in  df_cantho.columns }, inplace=True )\n",
    "\n",
    "## drop unneeded columns \n",
    "df_cantho = df_cantho[df_cantho.columns[ ~df_cantho.columns.str.match('^\\d')]]\n",
    "\n",
    "\n",
    "# target vars for relative and absolute costs on content loss [VND]\n",
    "df_cantho.insert(0, \"Target_eloss_VND\", df_cantho.pop(\"Target_eloss_VND\")) \n",
    "df_cantho.insert(1, \"Target_gloss_VND\", df_cantho.pop(\"Target_gloss_VND\"))\n",
    "df_cantho.insert(2, \"Target_contentloss_euro\", df_cantho.pop(\"Target_contentloss_euro\"))\n",
    "df_cantho.insert(3, \"Target_relative_contentloss_euro\", df_cantho.pop(\"Target_relative_contentloss_euro\"))\n",
    "\n",
    "# explanatory var: monthly reduction of business [%] \n",
    "df_cantho.insert(4, \"Target_businessreduction\", df_cantho.pop(\"Target_businessreduction\"))  \n",
    "\n",
    "\n",
    "df_cantho.columns[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Absolute content loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "## merge both absolute content loss targets\n",
    "df_cantho[\"Target_contentloss_VND\"]  = df_cantho.Target_eloss_VND + df_cantho.Target_gloss_VND\n",
    "np.round(df_cantho[\"Target_contentloss_VND\"], 2).describe()\n",
    "\n",
    "## merge content values \n",
    "df_cantho[\"shp_content_value_VND\"]  = df_cantho.content_value_g_VND + df_cantho.content_value_e_VND\n",
    "\n",
    "df_cantho.drop([\"Target_eloss_VND\", \"Target_gloss_VND\", \"content_value_g_VND\", \"content_value_e_VND\"], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hydrological variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CanTHo count   378.00\n",
      "mean      4.33\n",
      "std       3.40\n",
      "min       1.00\n",
      "25%       2.00\n",
      "50%       4.00\n",
      "75%       6.00\n",
      "max      24.00\n",
      "Name: inundation_duration_h, dtype: float64 \n",
      " HCMC count   380.00\n",
      "mean     12.68\n",
      "std      40.85\n",
      "min       0.20\n",
      "25%       2.00\n",
      "50%       3.00\n",
      "75%       6.00\n",
      "max     600.00\n",
      "Name: inundation_duration_h, dtype: float64\n",
      "CanTHo count   378.00\n",
      "mean     26.34\n",
      "std      16.50\n",
      "min       0.00\n",
      "25%      12.75\n",
      "50%      20.00\n",
      "75%      40.00\n",
      "max      80.00\n",
      "Name: water_depth_cm, dtype: float64 \n",
      " HCMC count   388.00\n",
      "mean     34.00\n",
      "std      25.70\n",
      "min       1.00\n",
      "25%      15.00\n",
      "50%      30.00\n",
      "75%      50.00\n",
      "max     150.00\n",
      "Name: water_depth_cm, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df_cantho[\"inundation_duration_h\"] =  df_cantho[\"inundation_duration_hour/day\"] # <<-- more similar to HCMC, than df_cantho[\"inundation_duration_day/month\"] * inundation_duration_hour/day\n",
    "\n",
    "\n",
    "## verify with HCMC\n",
    "print(\"CanTHo\", df_cantho.inundation_duration_h.describe(), \"\\n\", \"HCMC\", df_hcmc_rloss.inundation_duration_h.describe())\n",
    "\n",
    "# # water depth [cm]\n",
    "print(\"CanTHo\", df_cantho.water_depth_cm.describe(), \"\\n\", \"HCMC\", df_hcmc_rloss.water_depth_cm.describe())\n",
    "# median: 0.20cm, mean: 0.25m, max: 0.80m\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "contaminations\n",
       "1.00    270\n",
       "0.00    105\n",
       "2.00      3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## contamination\n",
    "## rank contamination according to their occurence and damage potential: 0:no contamination, 1:light contamination and 2:heavy contamination\n",
    "\n",
    "df_contaminations = df_cantho.filter(like=\"contaminations\", axis=1)\n",
    "\n",
    "df_cantho[\"contaminations\"] = df_cantho[\"contaminations\"].replace(\n",
    "    {\n",
    "    0.00 : 0, #  no contamination\n",
    "    4.00 : 0, # no contamination  \n",
    "    1.00 : 1, # light\n",
    "    2.00 : 2,  # heavy\n",
    "    3.00 : 2,  # heavy\n",
    "    }\n",
    ")\n",
    "df_cantho.contaminations.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "flood_experience\n",
       "5.00    194\n",
       "1.00    132\n",
       "2.00     18\n",
       "4.00     18\n",
       "3.00     16\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assign according to HCMC distribution\n",
    "\n",
    "df_cantho.flowvelocity = df_cantho.flowvelocity.replace(\n",
    "    {\n",
    "        1.0 : 8,    # once a year\n",
    "        2.0 : 16,   # twice a year\n",
    "        3.0 : 26,    # three times a year (doent exist for HCMC)\n",
    "        4.0 : 36,   # 4 times a year\n",
    "        5.0 : 76, \n",
    "    }\n",
    ")\n",
    "df_cantho.flood_experience.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count   378.00\n",
       "mean     40.79\n",
       "std      30.46\n",
       "min       0.00\n",
       "25%      16.00\n",
       "50%      36.00\n",
       "75%      76.00\n",
       "max      76.00\n",
       "Name: flowvelocity, dtype: float64"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## flowvelo\n",
    "\n",
    "## Paprotny 2021:  As for flow velocity, the respondents assessed i based on a qualitative scale, \n",
    "# providing a value from 1 to 6, with half-points possible (Thieken et al. 2005). \n",
    "# A value of 0.1 m/s was assigned to each full step of this qualitative scale. \n",
    "\n",
    "\n",
    "## flowvelocity high depends on the exepience and Einschätzung of the intrviewee\n",
    "## e.g. has the interviewee ever seen turbulent water\n",
    "## still the variable shows the general characteristics, if flood water is fast or not\n",
    "## Extrapolation: use fv as input and also for damage-funs(due that maybe most important var in FI) \n",
    "## - flowvelo is highly related to inundation duration --> from inundation duration possible to derive flovelo \n",
    "\n",
    "\n",
    "df_cantho.flowvelocity = df_cantho.flowvelocity.replace(        # 1 - 6 # calm - torrential\n",
    "    {\n",
    "        1 : 0.1, \n",
    "        2 : 0.2, \n",
    "        3 : 0.3, \n",
    "        4 : 0.4, \n",
    "        5 : 0.5,\n",
    "        6 : 0.6\n",
    "    }\n",
    ")\n",
    "\n",
    "#df_cantho.flowvelocity.value_counts()\n",
    "df_cantho.flowvelocity.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cantho[\"building_value_mVND\"] = df_cantho[\"building_value_cat\"].replace(\n",
    "    {\n",
    "        1.0 : 2.5,\n",
    "        2.0 : 7.5,\n",
    "        3.0 : 15,\n",
    "        4.0 : 35,\n",
    "        5.0 : 75,\n",
    "        6.0 : 150,\n",
    "        7.0 : 350,\n",
    "        8.0 : 750,\n",
    "        9.0 : 1500,\n",
    "        10.0 : 3500,\n",
    "    }\n",
    ")\n",
    "df_cantho = df_cantho.drop(\"building_value_cat\", axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count   376.00\n",
      "mean      0.61\n",
      "std       0.90\n",
      "min       0.00\n",
      "25%       0.00\n",
      "50%       0.00\n",
      "75%       1.00\n",
      "max       4.00\n",
      "Name: floors, dtype: float64\n",
      "CanTHo count   355.00\n",
      "mean      1.46\n",
      "std       0.68\n",
      "min       1.00\n",
      "25%       1.00\n",
      "50%       1.00\n",
      "75%       2.00\n",
      "max       3.00\n",
      "Name: floors, dtype: float64 \n",
      " HCMC: median and mean are at 2 floors \n"
     ]
    }
   ],
   "source": [
    "## bv\n",
    "# median: 75 mVND, mean: 75 mVND, max 3500 mVND\n",
    "print(df_cantho.floors.describe() ) # meaningless or only flat buildings (or count ground floor = 0, first level = 1 ?)\n",
    "    \n",
    "## fix floors :\n",
    "## problably 0 : bungalow with only ground floor --> in HCMC would be this 1 floor\n",
    "df_cantho[\"floors\"] = df_cantho[\"floors\"] +1 \n",
    "\n",
    "## remove records with more than 3 floors\n",
    "df_cantho = df_cantho.loc[df_cantho[\"floors\"] <= 3, :]  # rm ~ 20 records\n",
    "\n",
    "\n",
    "\n",
    "## verify with HCMC\n",
    "print(\"CanTHo\", df_cantho.floors.describe(), \"\\n\", \"HCMC: median and mean are at 2 floors \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### socio economic status\n",
    "check if income , monthly sale etc is similar to the HCMC shophouses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cantho[\"hh_monthly_income_mVND\"]  = df_cantho[\"hh_monthly_income_cat\"].replace(\n",
    "    {\n",
    "        1.0 : 0.25,  # in mVND\n",
    "        2.0 : 0.75,\n",
    "        3.0 : 1.5,\n",
    "        4.0 : 3.5,\n",
    "        5.0 : 7.5,\n",
    "        6.0 : 15,\n",
    "        7.0 : 35,\n",
    "        8.0 : 50,\n",
    "    }\n",
    ")\n",
    "\n",
    "df_cantho.drop(\"hh_monthly_income_cat\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shp_registered_capital_VND\n",
    "\n",
    "df_cantho[\"shp_registered_capital_mVND\"]  = df_cantho[\"shp_registered_capital_VND_cat\"].replace(\n",
    "    {\n",
    "        1.0 : 25,  # in mVND\n",
    "        2.0 : 75,\n",
    "        3.0 : 150,\n",
    "        4.0 : 350,\n",
    "        5.0 : 750,\n",
    "        6.0 : 1500,\n",
    "        7.0 : 3500,\n",
    "    }\n",
    ")\n",
    "\n",
    "df_cantho.drop(\"shp_registered_capital_VND_cat\", axis=1, inplace=True)\n",
    "# df_cantho[\"shp_registered_capital_mVND\"].describe()\n",
    "\n",
    "## compared to HCMC\n",
    "##  --> medians are similar, 1. and 3.Q: are also more or less similar when considering the categrical sturcutre for CanTho\n",
    "## a bit too high values for CanTHo probably due to the categorical intervals were smallest registed captial value caputres most cases ,\n",
    "# ## while for HCMC a continous scale was used in the questionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hh_monthly_income_mVND</th>\n",
       "      <th>shp_employees</th>\n",
       "      <th>shp_avgmonthly_sale_VND</th>\n",
       "      <th>shp_registered_capital_mVND</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>353.00</td>\n",
       "      <td>353.00</td>\n",
       "      <td>324.00</td>\n",
       "      <td>353.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.73</td>\n",
       "      <td>2.05</td>\n",
       "      <td>14175925.93</td>\n",
       "      <td>77.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.44</td>\n",
       "      <td>3.14</td>\n",
       "      <td>48451182.93</td>\n",
       "      <td>296.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.00</td>\n",
       "      <td>300000.00</td>\n",
       "      <td>25.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2000000.00</td>\n",
       "      <td>25.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4000000.00</td>\n",
       "      <td>25.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.50</td>\n",
       "      <td>2.00</td>\n",
       "      <td>10000000.00</td>\n",
       "      <td>25.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>50.00</td>\n",
       "      <td>37.00</td>\n",
       "      <td>600000000.00</td>\n",
       "      <td>3500.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       hh_monthly_income_mVND  shp_employees  shp_avgmonthly_sale_VND   \n",
       "count                  353.00         353.00                   324.00  \\\n",
       "mean                     6.73           2.05              14175925.93   \n",
       "std                      7.44           3.14              48451182.93   \n",
       "min                      0.25           1.00                300000.00   \n",
       "25%                      3.50           1.00               2000000.00   \n",
       "50%                      3.50           1.00               4000000.00   \n",
       "75%                      7.50           2.00              10000000.00   \n",
       "max                     50.00          37.00             600000000.00   \n",
       "\n",
       "       shp_registered_capital_mVND  \n",
       "count                       353.00  \n",
       "mean                         77.05  \n",
       "std                         296.99  \n",
       "min                          25.00  \n",
       "25%                          25.00  \n",
       "50%                          25.00  \n",
       "75%                          25.00  \n",
       "max                        3500.00  "
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_cantho[[\"hh_monthly_income_mVND\", \"shp_employees\", \"shp_avgmonthly_sale_VND\", \"shp_registered_capital_mVND\"]].describe()\n",
    "# df_cantho[df_cantho.number_employees>=20]  # 5 businesses with more than 20 employees\n",
    "\n",
    "## --> first keep also larger shops due that their absolute losses ae similar high aas for HCMC around 2500 €\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_cantho[df_cantho.number_employees>=20]  # 5 businesses with more than 20 employees\n",
    "\n",
    "## --> first keep also larger shops due that their absolute losses ae similar high aas for HCMC around 2500 €"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business-characteristics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "## HCMC\n",
    "# hh_income\t[category]\n",
    "# median 300 €, mean: 425 €, max: 3320 €\n",
    "\n",
    "# number_employees\t\n",
    "# median: 2,  mean: 2,  max: 10\n",
    "\n",
    "# shp_avg_monthly_sale\n",
    "# median: 290 €, mean: 370 €, max: 2760 €\n",
    "\n",
    "\n",
    "\n",
    "## Can Tho\n",
    "# hh_income\t[category]\n",
    "# median: ~ 140€, mean 140€-380€, max > 2000€\n",
    "\n",
    "# number_employees\t\n",
    "# median: 1 mean: 1,  max: 37\n",
    "\n",
    "# shp_avg_monthly_sale [mVND]\n",
    "# median: 192 €, mean: 1670 €, max: 346500 €\n",
    "\n",
    "## --> surveyed people in CanTHo have smaller income than in HCMC --> TODO check ownership (more employee stauts than in HCMC ? )\n",
    "## --> maybe remove shop in CanTho with many employees and high sale\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "## reset idnex to avoid problem when re-merging with indicators \n",
    "df_cantho = df_cantho.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count   355.00\n",
       "mean      0.29\n",
       "std       0.19\n",
       "min       0.00\n",
       "25%       0.11\n",
       "50%       0.33\n",
       "75%       0.44\n",
       "max       0.89\n",
       "Name: emergency_measures, dtype: float64"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## emergency\n",
    "\n",
    "# df_cantho.emergency_measures1 - 9\n",
    "\n",
    "## emergency measures as indicator : range: 0:no measures - 6: applied all measures \n",
    "\n",
    "pattern = [r\"^emergency_measures.?\"] \n",
    "pattern_cols = re.compile('|'.join(pattern))\n",
    "df_emergency = df_cantho.filter(regex=pattern_cols, axis=1)\n",
    "df_emergency\n",
    "\n",
    "## create indicator as ratio between implemented and potentially implemented emergency measures\n",
    "df_cantho[\"emergency_measures\"] = None\n",
    "df_cantho[\"emergency_measures\"] = df_emergency.eq(1).sum(axis=1) / len(df_emergency.columns)\n",
    "\n",
    "# keep only indicator in final df\n",
    "df_cantho.drop(\n",
    "    df_emergency.filter(\n",
    "        regex=r\"^(?:.+\\d)$\"\n",
    "        ).columns, \n",
    "    axis=1, inplace=True\n",
    ")\n",
    "df_cantho.emergency_measures.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Target_contentloss_euro', 'Target_relative_contentloss_euro',\n",
      "       'Target_businessreduction', 'shp_sector', 'flood_experience',\n",
      "       'flood_type', 'warning_time_day', 'effect_emergency_measures',\n",
      "       'water_depth_cm', 'inundation_duration_day/month',\n",
      "       'inundation_duration_hour/day', 'contaminations', 'flowvelocity',\n",
      "       'replaced_cost_e', 'precautionary_measures1', 'precautionary_measures2',\n",
      "       'precautionary_measures3', 'precautionary_measures4',\n",
      "       'precautionary_measures5', 'precautionary_measures6',\n",
      "       'precautionary_measures7', 'precautionary_measures8',\n",
      "       'precautionary_measures9', 'precautionary_measures10',\n",
      "       'perception_too_destructive_floods', 'risk_future_flood',\n",
      "       'risk_consequents_future_flood', 'ownership', 'bage', 'shp_employees',\n",
      "       'shp_avgmonthly_sale_VND', 'b_area', 'floors', 'builing_elevation',\n",
      "       'builing_type', 'Direct_damage', 'Target_contentloss_VND',\n",
      "       'shp_content_value_VND', 'inundation_duration_h', 'building_value_mVND',\n",
      "       'hh_monthly_income_mVND', 'shp_registered_capital_mVND',\n",
      "       'emergency_measures', 'overall_problem_house'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "## overall_problem_house\n",
    "\n",
    "## Cantho survey question\n",
    "# 1: My house was collapsed or washed away \n",
    "# 2: My house was damage partly (specify)\n",
    "# 3: My house was full of water which caused damage to the floor, walls, etc.\n",
    "\n",
    "\n",
    "pattern = [r\"overall_problem_house.(?<!4)$\"] # get all columns but not overall_problem_house_r4: no problem/ problem \n",
    "pattern_cols = re.compile('|'.join(pattern))\n",
    "df_problem_house = df_cantho.filter(regex=pattern_cols, axis=1)\n",
    "df_problem_house.describe()\n",
    "\n",
    "# ## create indicator (based on ranking scheme from HCMC)\n",
    "df_cantho[\"overall_problem_house\"] = None\n",
    "\n",
    "idx = np.where(df_problem_house[\"overall_problem_house1\"]==1)\n",
    "df_cantho.overall_problem_house[idx[0].tolist()] = 6  # heavy building damage\n",
    "\n",
    "\n",
    "idx = np.where(df_problem_house[\"overall_problem_house2\"]==1)\n",
    "df_cantho.overall_problem_house[idx[0].tolist()] = 4  # partly building damage\n",
    "\n",
    "## fix typos in overall_problem_house3\n",
    "df_problem_house[\"overall_problem_house3\"] = df_problem_house[\"overall_problem_house3\"].replace({10:1, 3:1})\n",
    "\n",
    "idx = np.where(df_problem_house[\"overall_problem_house3\"]==1)\n",
    "df_cantho.overall_problem_house[idx[0].tolist()] = 3  # floor and wall damage\n",
    "\n",
    "\n",
    "## keep only indicator in final df\n",
    "df_cantho.drop(\n",
    "    df_cantho.filter(regex=r\"^overall_problem_house.$\").columns,\n",
    "    axis=1, inplace=True\n",
    ")\n",
    "print(df_cantho.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # df_cantho.precautionary_measures1 - 10\n",
    "# # #df_cantho.precautionary_measures1.value_counts()\n",
    "# # df_precautionary.describe()\n",
    "\n",
    "# pattern = [r\"^precautionary_measures.*(?<![2,3])$\"] # exclude information measures\n",
    "# pattern_cols = re.compile('|'.join(pattern))\n",
    "# df_precautionary = df_cantho.filter(regex=pattern_cols, axis=1)\n",
    "# print(df_precautionary.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Target_contentloss_euro', 'Target_relative_contentloss_euro',\n",
      "       'Target_businessreduction', 'shp_sector', 'flood_experience',\n",
      "       'flood_type', 'warning_time_day', 'effect_emergency_measures',\n",
      "       'water_depth_cm', 'inundation_duration_day/month',\n",
      "       'inundation_duration_hour/day', 'contaminations', 'flowvelocity',\n",
      "       'replaced_cost_e', 'perception_too_destructive_floods',\n",
      "       'risk_future_flood', 'risk_consequents_future_flood', 'ownership',\n",
      "       'bage', 'shp_employees', 'shp_avgmonthly_sale_VND', 'b_area', 'floors',\n",
      "       'builing_elevation', 'builing_type', 'Direct_damage',\n",
      "       'Target_contentloss_VND', 'shp_content_value_VND',\n",
      "       'inundation_duration_h', 'building_value_mVND',\n",
      "       'hh_monthly_income_mVND', 'shp_registered_capital_mVND',\n",
      "       'emergency_measures', 'overall_problem_house',\n",
      "       'precautionary_measures_lowcost', 'precautionary_measures_expensive'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "## precaution measures \n",
    "# ## --> test first as seperate features to keep as much information as possible\n",
    "\n",
    "pattern = [r\"^precautionary_measures.*(?<![2,3])$\"] # exclude information measures\n",
    "pattern_cols = re.compile('|'.join(pattern))\n",
    "df_precautionary = df_cantho.filter(regex=pattern_cols, axis=1)\n",
    "# print(df_precautionary.columns)\n",
    "df_precautionary.drop(\"precautionary_measures1\", axis=1, inplace=True)\n",
    "\n",
    "\n",
    "## fix typo\n",
    "df_precautionary = df_precautionary.replace({40.00:np.nan})\n",
    "\n",
    "# ## create ratio: \n",
    "df_precautionary = df_precautionary.replace(\n",
    "    {\n",
    "        4:1,\n",
    "        3:1,    # impl before \n",
    "        2:1,    \n",
    "        1:1,     \n",
    "        0:0     # not at all  \n",
    "    }\n",
    ")\n",
    "# ## devide into expensive and low cost precautionary measures due that expensive meausres seems to be better in flood-loss-reduction\n",
    "df_precautionary_expensive = df_precautionary[[\"precautionary_measures9\", \"precautionary_measures10\", \"precautionary_measures7\"]]\n",
    "df_precautionary_low = df_precautionary.drop([\"precautionary_measures9\", \"precautionary_measures10\", \"precautionary_measures7\"], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# create indicator as ratio between implemented and potentially implemented measures (in total 7 measures exist)\n",
    "# range: 0.0: none measure were implemented before the flood event - 1.0: all potential measures were implemented before the reported flood\n",
    "# --> splitting in low and expensive precaution measures reduces the importance of the feautres for the models remarkable\n",
    "df_cantho[\"precautionary_measures_lowcost\"] = None\n",
    "df_cantho[\"precautionary_measures_lowcost\"] = df_precautionary_low.sum(axis=1) / len(df_precautionary_low.columns)\n",
    "df_cantho[\"precautionary_measures_expensive\"] = None\n",
    "df_cantho[\"precautionary_measures_expensive\"] = df_precautionary_expensive.sum(axis=1) / len(df_precautionary_expensive.columns)\n",
    "\n",
    "\n",
    "## keep only indicator in final df\n",
    "df_cantho.drop(\n",
    "    df_cantho.filter(regex=r\"\\d$\").columns,\n",
    "    # df_cantho.filter(regex=r\"^precautionary_measures.$\").columns,  # not caputere precuation_10\n",
    "    axis=1, inplace=True\n",
    ")\n",
    "print(df_cantho.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precautionary_measures_lowcost</th>\n",
       "      <th>precautionary_measures_expensive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>355.00</td>\n",
       "      <td>355.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       precautionary_measures_lowcost  precautionary_measures_expensive\n",
       "count                          355.00                            355.00\n",
       "mean                             0.30                              0.22\n",
       "std                              0.25                              0.21\n",
       "min                              0.00                              0.00\n",
       "25%                              0.00                              0.00\n",
       "50%                              0.25                              0.33\n",
       "75%                              0.50                              0.33\n",
       "max                              1.00                              0.67"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cantho[[\"precautionary_measures_lowcost\", \"precautionary_measures_expensive\"]].describe()\n",
    "\n",
    "## HCMC for both precautionary indicators\n",
    "# keys stats are similar between both DS (similar mean and median ) \n",
    "## --> for CanTHo it seems that at least lesss often all types of low and expensive meausres were implemented compared to HCMC, but on average more than in HCMC (compare medians between both DS for low and expensive precautions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## shp_registered_capital\n",
    "# df_cantho[\"shp_registered_capital_mVND\"].describe()\n",
    "\n",
    "# ## HCMC\n",
    "# ## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## resilience as indicator:\n",
    "\n",
    "# ## 1 : strong disagree - 5 : strong agree\n",
    "# ## currently would leave at it is and see if its included in final Feature space\n",
    "# ## TEST: as merged indcator and as seperate features\n",
    "# ## o\tOrderer rank okay as long its  quantitative\n",
    "\n",
    "# ## select based on findings from PCA\n",
    "# df_resilience = df[[\"resilience_city_protection\", \"resilience_govern_careing\",\"resilience_neighbor_management\"]]\n",
    "# ## negatives loadings: resilience_govern_careing_increases\n",
    "# print(df_resilience.columns)\n",
    "\n",
    "# df[\"resilience\"] = None\n",
    "# df[\"resilience\"] = df_resilience.sum(axis=1) / len(df_resilience.columns)\n",
    "\n",
    "# ## rather pessimistic resilience variables\n",
    "# df_resilience_leftalone = df[[\"resilience_left_alone\", \"resilience_more_future_affected\"]]\n",
    "# print(df_resilience_leftalone.columns)\n",
    "\n",
    "# df[\"resilienceLeftAlone\"] = None\n",
    "# df[\"resilienceLeftAlone\"] = df_resilience_leftalone.sum(axis=1) / len(df_resilience_leftalone.columns)\n",
    "\n",
    "# ## --> potentiall resilinece_leftalone correlates positvely with target variables, \n",
    "# ## --> while the other resilience indicator may corellates negatively with the targets \n",
    "\n",
    "# ## keep only indicator in final df\n",
    "# df.drop(\n",
    "#     df.filter(like=\"resilience_\").columns,\n",
    "#     axis=1, inplace=True\n",
    "# )\n",
    "# print(df.columns)\n",
    "# ## 1: disagree, 5: agree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## perception as indicator\n",
    "# ## o\tOrderer rank okay as long its  quantitative\n",
    "\n",
    "# # Reduced /Porrer  -> 1\n",
    "# # Maintained /Same  -> 2\n",
    "# # Increased /Richer -> 3\n",
    "\n",
    "\n",
    "# # ## based on findings from PCA\n",
    "# # df_perception = df[[\"perception_govern_support_past\", \"perception_govern_support_future\"]]\n",
    "# # print(df_perception.columns)\n",
    "\n",
    "# # df[\"perception\"] = None\n",
    "# # df[\"perception\"] = df_perception.sum(axis=1) / len(df_perception.columns)\n",
    "\n",
    "# ## keep only indicator in final df\n",
    "# df.drop(\n",
    "#     df.filter(like=\"perception_\").columns, \n",
    "#     axis=1, inplace=True\n",
    "# )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unify monetary values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## check for very small registered capital\n",
    "# vars_money = df_cantho.filter(regex=\"_mVND\", axis=1)\n",
    "# try:\n",
    "#     vars_money[vars_money.shp_registered_capital_mVND <=1.0]  # less than 40 euros\n",
    "# except:\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*list of all monetary vars*\n",
    "\n",
    "**Variables inflation corrected for 2020 (align with HCMC ds)**\n",
    "<!-- - b_value_mVND\t- price level for 2013 (year when survey was done)\n",
    "- shp_building_value_mVND\t- price level for 2013\n",
    "- shp_content_value_mVND\t- price level for 2013\n",
    "- Target_contentloss_mVND\t- price levels based on flood time\n",
    "- shp_registered_capital_mVND  - price level for 2013\n",
    "- hh_monthly_income_mVND     - continous [value ranges in mVND], # price level for 2013\n",
    "- shp_avgmonthly_sale_mVND   - continous [value ranges in mVND], # price level for 2013 -->\n",
    "\n",
    "**Variables inflation corrected for flood year**\n",
    "Damage variables ('Target_eloss_VND', 'Target_gloss_VND') need to be inflation corrected based on flood time which was 2011\n",
    "\n",
    "cpi_2020 = 168.8    ,  2020 = year when the survey was done\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['building_value_VND', 'hh_monthly_income_VND',\n",
      "       'shp_registered_capital_VND'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "## check for very small registered capital\n",
    "vars_money = df_cantho.filter(regex=\"_mVND\", axis=1)\n",
    "\n",
    "\n",
    "## covnert all columns with million VND --> VND\n",
    "\n",
    "vars_money = np.where( (vars_money.values != np.nan),\n",
    "            vars_money.values * 1000000, # convert to VND\n",
    "            vars_money.values)\n",
    "\n",
    "## rename columns\n",
    "new_cols = df_cantho.filter(regex=\"_mVND\", axis=1).columns.str.replace(\"_mVND\", \"_VND\")\n",
    "vars_money = pd.DataFrame(vars_money, columns=new_cols)\n",
    "print(vars_money.columns)\n",
    "\n",
    "df_cantho.drop( df_cantho.filter(regex=\"_mVND\", axis=1).columns, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['building_value_VND', 'hh_monthly_income_VND',\n",
       "       'shp_registered_capital_VND', 'shp_avgmonthly_sale_VND',\n",
       "       'Target_contentloss_VND', 'shp_content_value_VND'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## add remaining monetary variables\n",
    "vars_money = pd.concat(\n",
    "    [vars_money, \n",
    "    df_cantho[df_cantho.filter(regex=\"VND\", axis=1).columns.tolist()]\n",
    "    ], axis=1)\n",
    "vars_money.columns  # sholuld all end with _VND (no _mVND)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Conversion of VND to euro (or US$)*\n",
    "\n",
    "Based on JRC, p.8 and Paprotny2018, eg.p245\n",
    "The reported damage values have been converted to Euro using the the exchange rate for the year 2013 (mean annual value)\n",
    "\n",
    "*Source:* \n",
    "- www.oanda.com/currency/historical-rates\n",
    "-  www.ecb.europa.eu/stats/exchange/eurofxref/html/eurofxref-graph-idr.en.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "# price_index_year_of_issue = {\n",
    "#     2011: 121.41,\n",
    "#     2013: 137.78,\n",
    "#     2014: 142.88,\n",
    "#     2015: 140.43,\n",
    "#     2016: 142.98,\n",
    "#     2017: 149.22,\n",
    "#     2018: 154.63,\n",
    "#     2019: 158.38,\n",
    "#     2020: 160.70\n",
    "# }\n",
    "\n",
    "price_index_2020 = 160.70\n",
    "price_index_year = np.full( vars_money.shape[0], 121.41, dtype=float) # \n",
    "# price_index_year = data_ip2[\"flood_year\"].astype(\"Int64\").map(price_index_year_of_issue)  # series of cpi for each year of flood event\n",
    "\n",
    "exchange_rate = 1 / 27155  #  dong-> euro in 2020 # 3.683e-05\n",
    "# ## (based on eurostat: https://ec.europa.eu/eurostat/databrowser/view/ERT_BIL_EUR_A/default/line?lang=en )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Inflation correction via GDP-deflator*\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{align*}\n",
    "\n",
    "&uninflated_{2020} = losses_y * exchangerate_{2020} \\\\\n",
    "&inflationrate = uninflated_{2020} * pindex_{2020} / pindex_y\\\\\n",
    "\n",
    "\\end{align*}\n",
    "\\end{equation}\n",
    "\n",
    "where:\n",
    "- losses_y : losses in VND for year y\n",
    "- uninflated_{2020} : uninflated losses in euro for 2020\n",
    "- exchangerate_{2020} : exchang erate for VND to euro in year 20202 \n",
    "- pindex_{2020} : price index from GDP-deflator for 2020 \n",
    "- pindex_y : price index from GDP-deflator in year y\n",
    "\n",
    "Given that inflation is the percentage change in the overall price of an item in an economy, we can use the GDP deflator to calculate the inflation rate since its a measure of the price level.\n",
    "\n",
    "\n",
    "*Further sources* \\\n",
    "*Paprotny 2018*: also used country-level GDP deflators for adjusting nominal to real losses in 2011 prices , p153, p244 \\\n",
    "*Sairam et al. 2020*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GDP-deflator\n",
    "\n",
    "vars_money[\"Target_contentloss_VND_gdp\"] = None\n",
    "\n",
    "##  only direct losses needs inflation correction in respect to flood time\n",
    "for r in range(len(vars_money.Target_contentloss_VND)):\n",
    "    ## exchange rate: convert VND in certain year to € in the same year\n",
    "    uninflated_losses = (vars_money.Target_contentloss_VND[r] * exchange_rate) # get uninflated losses in euros for year 2020\n",
    "    ## price index from GDP-deflator\n",
    "    vars_money[\"Target_contentloss_VND_gdp\"][r] = round(uninflated_losses * price_index_2020 / price_index_year[r], 1)\n",
    "\n",
    "\n",
    "\n",
    "# ##  for all other monetary continous vars: only need exchange conversion\n",
    "for c in vars_money.drop([\"Target_contentloss_VND_gdp\",\"Target_contentloss_VND\"], axis=1).columns:\n",
    "    vars_money[c] = vars_money[c].apply(pd.to_numeric)\n",
    "    for r in range(len(vars_money[c])):\n",
    "        ## convert VND_2020 to €_2020\n",
    "        vars_money[c][r] = round((vars_money[c][r] * exchange_rate), 1)#.astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## rename columns\n",
    "new_cols = vars_money.filter(regex=\"_VND\", axis=1).columns.str.replace(\"_VND\", \"_euro\")\n",
    "vars_money.columns = new_cols\n",
    "vars_money = vars_money.apply(pd.to_numeric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Target_relative_contentloss_euro', 'building_value_euro',\n",
       "       'hh_monthly_income_euro', 'shp_registered_capital_euro',\n",
       "       'shp_avgmonthly_sale_euro', 'shp_content_value_euro',\n",
       "       'Target_contentloss_euro'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# update all_input with unified and inflated currencies\n",
    "df_cantho.drop(df_cantho.filter(regex=r\"_mVND|_VND\", axis=1).columns, axis=1, inplace=True) \n",
    "df_cantho = pd.concat([df_cantho, vars_money], axis=1)\n",
    "df_cantho.drop(\"Target_contentloss_euro\", axis=1, inplace=True)\n",
    "df_cantho.rename(columns={\"Target_contentloss_euro_gdp\" : \"Target_contentloss_euro\"}, inplace=True)\n",
    "\n",
    "df_cantho.filter(regex=r\"euro|VND\", axis=1).columns  # should be only euros\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Targets\n",
    "### absolute loss and Target business reduction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*CanTHo* count    354.00\n",
      "mean      89.70\n",
      "std      193.11\n",
      "min        0.00\n",
      "25%        0.00\n",
      "50%        9.70\n",
      "75%       73.10\n",
      "max     1462.30\n",
      "Name: Target_contentloss_euro, dtype: float64 \n",
      " *HCMC*: median: 0€ , mean:131€, 3.Q:78€, max:2600 €\n",
      "*CanTHo* count   355.00\n",
      "mean     40.58\n",
      "std      22.09\n",
      "min       0.00\n",
      "25%      25.00\n",
      "50%      40.00\n",
      "75%      50.00\n",
      "max     100.00\n",
      "Name: Target_businessreduction, dtype: float64 \n",
      " *HCMC* count   353.00\n",
      "mean     17.81\n",
      "std      24.46\n",
      "min       0.00\n",
      "25%       0.00\n",
      "50%      10.00\n",
      "75%      30.00\n",
      "max     100.00\n",
      "Name: Target_businessreduction, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# absolute content loss\n",
    "df_cantho[\"Target_contentloss_euro\"].describe()\n",
    "\n",
    "\n",
    "# Target business reduction\n",
    "df_cantho[\"Target_businessreduction\"].describe()\n",
    "\n",
    "\n",
    "## verify with HCMC\n",
    "print(\"*CanTHo*\", (df_cantho.Target_contentloss_euro).describe(), \"\\n\", \"*HCMC*: median: 0€ , mean:131€, 3.Q:78€, max:2600 €\")\n",
    "## --> abs losses are very similar in both DS\n",
    "## -->  very similar in all keys-statistics  in min-max, median :-) interesting that fraction of zero-loss records is similar high as in HCMC\n",
    "\n",
    "## verify with HCMC\n",
    "print(\"*CanTHo*\", df_cantho.Target_businessreduction.describe(), \"\\n\", \"*HCMC*\", df_hcmc_bred.Target_businessreduction.describe())\n",
    "## --> business reduction differ quite much: between avg < 10% in reduction in HCMC and 40% in Can THo \n",
    "## --> might not good to enrich bred ds with CanTHo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### content value\n",
    "verify cv calculation for HCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count     351.00\n",
      "mean     1853.24\n",
      "std      5569.73\n",
      "min         0.00\n",
      "25%        69.05\n",
      "50%       221.00\n",
      "75%       847.00\n",
      "max     55238.40\n",
      "Name: shp_content_value_euro, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count     354.00\n",
       "mean     1063.56\n",
       "std      2445.13\n",
       "min         0.00\n",
       "25%       138.10\n",
       "50%       322.23\n",
       "75%      1074.08\n",
       "max     32222.42\n",
       "Name: shp_content_value_euro_self, dtype: float64"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## create content value\n",
    "\n",
    "# print(df_cantho[\"shp_content_value_euro\"].describe())\n",
    "\n",
    "\n",
    "## Can Tho\n",
    "# rloss : median: 0.01 , mean: max:\n",
    "# CV: mean 3000 €, median: 300 € , max= 392 600 € (no inflation corrected)\n",
    "print(df_cantho[\"shp_content_value_euro\"].describe())  # in €\n",
    "\n",
    "## make shp_cv as 1/4 of shp_bv\n",
    "df_cantho[\"shp_content_value_euro_self\"] = df_cantho[\"building_value_euro\"] / df_cantho[\"floors\"] * 0.25\n",
    "df_cantho[\"shp_content_value_euro_self\"]  =  df_cantho[\"shp_content_value_euro_self\"] \n",
    "df_cantho[\"shp_content_value_euro_self\"].describe() # in €\n",
    "\n",
    "## cv survey question\n",
    "# median: 260 € , mean: 2000 €, max: 57 000\n",
    "\n",
    "## cv self (bv / floors * 0.25)\n",
    "# median: 330 € , mean: 1100 €, max: 33 250\n",
    "\n",
    "## HCMC euros (inflation corrected) : median: 3203 €,  mean: 4359 €, 1Q:257 €, 3Q: 4603 €, max:46032 €\n",
    "\n",
    "#####################################################################\n",
    "\n",
    "## HCMC after cleaning:\n",
    "# abs closs : median 0, 3.Quantile= 80 €, mean 130 €, max 2600 €\n",
    "# rcloss : median mean = 0.0, max = 0.3\n",
    "# bred [%] : mean: 18%, median: 9 %\n",
    "\n",
    "## Can Tho after cleaning: (no inflation)\n",
    "# rloss : median: 0.0 , mean: 0.05,  max: 0.48\n",
    "# CV: median: 310 € ,  mean 3340 €, max: 392.610 € (no inflation corrected)\n",
    "## Bred : mean 40%, median 40%\n",
    "\n",
    "## TODO \n",
    "# DONE - from can tho remove rloss > 0.8 --> gets similar to HCMC with max=0.3 ?\n",
    "# CURR other method to derive / verify CV for HCMC  --> source why Logitic Regression performed so bad \n",
    "# Bred is quite different between both DS --> idea: apply can tho DS only to estimate closs fraction ?, do extrapoltion only for closs (not for bred)\n",
    " \n",
    "## HCMC\n",
    "# Target_contentloss_euro\tshp_content_value_euro\tTarget_relative_contentloss_euro\tTarget_businessreduction\n",
    "# count\t371.0\t324.0\t315.0\t350.0\n",
    "# mean\t131.6\t4359.2\t0.0\t    17.4\n",
    "# std\t336.1\t4047.6\t0.1\t    24.1\n",
    "# min\t0.0\t    257.8\t0.0\t    0.0\n",
    "# 25%\t0.0\t    1841.3\t0.0\t    0.0\n",
    "# 50%\t0.0\t    3203.8\t0.0\t    8.5\n",
    "# 75%\t77.9\t4603.2\t0.0\t    30.0\n",
    "# max\t2615.6\t46032.0\t1.0\t    100.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     351.00\n",
       "mean     1853.24\n",
       "std      5569.73\n",
       "min         0.00\n",
       "25%        69.05\n",
       "50%       221.00\n",
       "75%       847.00\n",
       "max     55238.40\n",
       "Name: shp_content_value_euro, dtype: float64"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cantho[\"shp_content_value_euro\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target relative closs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "## cv from survey\n",
    "df_cantho[\"Target_relative_contentloss_euro\"] = df_cantho[\"Target_contentloss_euro\"] / df_cantho[\"shp_content_value_euro\"]\n",
    "# set all zero-loss cases to 0\n",
    "df_cantho = df_cantho.apply(pd.to_numeric)\n",
    "df_cantho.Target_relative_contentloss_euro[df_cantho.Target_relative_contentloss_euro.isna()] = 0.0\n",
    "\n",
    "\n",
    "## self calc cv\n",
    "df_cantho[\"Target_relative_contentloss_euro_self\"] = df_cantho[\"Target_contentloss_euro\"] / df_cantho[\"shp_content_value_euro_self\"]\n",
    "# set all zero-loss cases to 0\n",
    "df_cantho = df_cantho.apply(pd.to_numeric)\n",
    "df_cantho.Target_relative_contentloss_euro_self[df_cantho.Target_relative_contentloss_euro_self.isna()] = 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records with relative content loss > total content value : 18\n",
      "Records with self-calc. relative content loss > total content value : 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target_contentloss_euro</th>\n",
       "      <th>Target_relative_contentloss_euro</th>\n",
       "      <th>Target_relative_contentloss_euro_self</th>\n",
       "      <th>shp_content_value_euro</th>\n",
       "      <th>shp_content_value_euro_self</th>\n",
       "      <th>Target_businessreduction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>316.00</td>\n",
       "      <td>317.00</td>\n",
       "      <td>317.00</td>\n",
       "      <td>313.00</td>\n",
       "      <td>316.00</td>\n",
       "      <td>317.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>57.71</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.11</td>\n",
       "      <td>1732.96</td>\n",
       "      <td>1154.96</td>\n",
       "      <td>40.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>130.07</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.20</td>\n",
       "      <td>5536.78</td>\n",
       "      <td>2568.93</td>\n",
       "      <td>21.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>73.70</td>\n",
       "      <td>138.10</td>\n",
       "      <td>25.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>221.00</td>\n",
       "      <td>345.24</td>\n",
       "      <td>40.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>48.70</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.12</td>\n",
       "      <td>810.20</td>\n",
       "      <td>1150.80</td>\n",
       "      <td>50.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>974.90</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.99</td>\n",
       "      <td>55238.40</td>\n",
       "      <td>32222.42</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Target_contentloss_euro  Target_relative_contentloss_euro   \n",
       "count                   316.00                            317.00  \\\n",
       "mean                     57.71                              0.10   \n",
       "std                     130.07                              0.19   \n",
       "min                       0.00                              0.00   \n",
       "25%                       0.00                              0.00   \n",
       "50%                       0.00                              0.00   \n",
       "75%                      48.70                              0.10   \n",
       "max                     974.90                              0.93   \n",
       "\n",
       "       Target_relative_contentloss_euro_self  shp_content_value_euro   \n",
       "count                                 317.00                  313.00  \\\n",
       "mean                                    0.11                 1732.96   \n",
       "std                                     0.20                 5536.78   \n",
       "min                                     0.00                    0.00   \n",
       "25%                                     0.00                   73.70   \n",
       "50%                                     0.00                  221.00   \n",
       "75%                                     0.12                  810.20   \n",
       "max                                     0.99                55238.40   \n",
       "\n",
       "       shp_content_value_euro_self  Target_businessreduction  \n",
       "count                       316.00                    317.00  \n",
       "mean                       1154.96                     40.47  \n",
       "std                        2568.93                     21.54  \n",
       "min                           0.00                      0.00  \n",
       "25%                         138.10                     25.00  \n",
       "50%                         345.24                     40.00  \n",
       "75%                        1150.80                     50.00  \n",
       "max                       32222.42                    100.00  "
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## rloss > cv\n",
    "print(\"Records with relative content loss > total content value :\", sum(df_cantho.Target_relative_contentloss_euro > 1.0) )\n",
    "print(\"Records with self-calc. relative content loss > total content value :\", sum(df_cantho.Target_relative_contentloss_euro_self > 1.0) )\n",
    "\n",
    "## drop these records where rloss > cv\n",
    "df_cantho = df_cantho.loc[~(df_cantho.Target_relative_contentloss_euro >= 1.0), :]\n",
    "df_cantho = df_cantho.loc[~(df_cantho.Target_relative_contentloss_euro_self >= 1.0), :]\n",
    "\n",
    "\n",
    "# ## drop these records where rloss > cv\n",
    "# df_cantho = df_cantho.loc[~(df_cantho.Target_rcloss >= 0.5), :]\n",
    "\n",
    "df_cantho[[\"Target_contentloss_euro\", \"Target_relative_contentloss_euro\", \"Target_relative_contentloss_euro_self\", \n",
    "           \"shp_content_value_euro\", \"shp_content_value_euro_self\", \"Target_businessreduction\"]].describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**cv self** is similar to the cv from questionary, therefore remove later one and the **respective Target version for loss ratio derived from it**, to have common approach of cv estimation in both DS (HCMC, CanTho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cantho = df_cantho.drop([\"Target_relative_contentloss_euro\", \"shp_content_value_euro\"], axis=1)\n",
    "df_cantho.rename(columns={\n",
    "    \"Target_relative_contentloss_euro_self\" : \"Target_relative_contentloss_euro\",\n",
    "    \"shp_content_value_euro_self\" : \"shp_content_value_euro\",\n",
    "    }, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## remove shp sector # due that no expalnation which category revers to which sector\n",
    "# df_cantho.shp_sector.value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore variable's key statistics - are they similar to HCMC ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Target_businessreduction', 'shp_sector', 'flood_experience',\n",
       "       'flood_type', 'warning_time_day', 'effect_emergency_measures',\n",
       "       'water_depth_cm', 'inundation_duration_day/month',\n",
       "       'inundation_duration_hour/day', 'contaminations', 'flowvelocity',\n",
       "       'replaced_cost_e', 'perception_too_destructive_floods',\n",
       "       'risk_future_flood', 'risk_consequents_future_flood', 'ownership',\n",
       "       'bage', 'shp_employees', 'b_area', 'floors', 'builing_elevation',\n",
       "       'builing_type', 'Direct_damage', 'inundation_duration_h',\n",
       "       'emergency_measures', 'overall_problem_house',\n",
       "       'precautionary_measures_lowcost', 'precautionary_measures_expensive',\n",
       "       'building_value_euro', 'hh_monthly_income_euro',\n",
       "       'shp_registered_capital_euro', 'shp_avgmonthly_sale_euro',\n",
       "       'Target_contentloss_euro', 'shp_content_value_euro',\n",
       "       'Target_relative_contentloss_euro'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cantho.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Major cleaning \n",
    "\n",
    "Drop uneeded variables in final feature space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Target_businessreduction', 'flood_experience', 'warning_time_day',\n",
       "       'effect_emergency_measures', 'water_depth_cm', 'contaminations',\n",
       "       'flowvelocity', 'replaced_cost_e', 'perception_too_destructive_floods',\n",
       "       'risk_future_flood', 'risk_consequents_future_flood', 'bage',\n",
       "       'shp_employees', 'b_area', 'floors', 'builing_elevation',\n",
       "       'builing_type', 'inundation_duration_h', 'emergency_measures',\n",
       "       'overall_problem_house', 'precautionary_measures_lowcost',\n",
       "       'precautionary_measures_expensive', 'building_value_euro',\n",
       "       'hh_monthly_income_euro', 'shp_registered_capital_euro',\n",
       "       'shp_avgmonthly_sale_euro', 'Target_contentloss_euro',\n",
       "       'shp_content_value_euro', 'Target_relative_contentloss_euro'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cantho = df_cantho.drop([\n",
    "    'inundation_duration_day/month', 'inundation_duration_hour/day',\n",
    "    'flood_type', \n",
    "    \"shp_sector\",  # have currently no information about category description\n",
    "    \"ownership\",\n",
    "    \"Direct_damage\", \n",
    "    #\"No\", \"Year\", \"floors\", \"distance_to_river\",\n",
    "    ], axis=1\n",
    ")\n",
    "df_cantho.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_cantho.info()\n",
    "# df_cantho.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of missing values per feature [%]\n",
      " overall_problem_house              30.00\n",
      "shp_avgmonthly_sale_euro            9.00\n",
      "warning_time_day                    4.00\n",
      "b_area                              1.00\n",
      "replaced_cost_e                     1.00\n",
      "shp_employees                       1.00\n",
      "hh_monthly_income_euro              1.00\n",
      "shp_registered_capital_euro         1.00\n",
      "risk_future_flood                   0.00\n",
      "building_value_euro                 0.00\n",
      "bage                                0.00\n",
      "Target_contentloss_euro             0.00\n",
      "shp_content_value_euro              0.00\n",
      "emergency_measures                  0.00\n",
      "precautionary_measures_expensive    0.00\n",
      "dtype: float64 2\n"
     ]
    }
   ],
   "source": [
    "## delete features with more than 10% missing values\n",
    "print(\"Percentage of missing values per feature [%]\\n\", round(df_cantho.isna().mean().sort_values(ascending=False)[:15]  * 100), 2) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### single dataset for bred and rloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(317, 26)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['flood_experience', 'warning_time_day', 'effect_emergency_measures',\n",
       "       'water_depth_cm', 'contaminations', 'flowvelocity', 'replaced_cost_e',\n",
       "       'perception_too_destructive_floods', 'risk_future_flood',\n",
       "       'risk_consequents_future_flood', 'bage', 'shp_employees', 'b_area',\n",
       "       'floors', 'builing_elevation', 'builing_type', 'inundation_duration_h',\n",
       "       'emergency_measures', 'overall_problem_house',\n",
       "       'precautionary_measures_lowcost', 'precautionary_measures_expensive',\n",
       "       'building_value_euro', 'hh_monthly_income_euro',\n",
       "       'shp_registered_capital_euro', 'shp_avgmonthly_sale_euro',\n",
       "       'Target_relative_contentloss_euro'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cantho_rloss = df_cantho\n",
    "df_cantho_rloss = df_cantho_rloss.drop(\n",
    "    [\n",
    "    \"Target_contentloss_euro\",\n",
    "    \"Target_businessreduction\",\n",
    "    \"shp_content_value_euro\",\n",
    "    ]\n",
    "    , axis=1)\n",
    "print(df_cantho_rloss.shape)\n",
    "df_cantho_rloss.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(317, 27)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Target_businessreduction', 'flood_experience', 'warning_time_day',\n",
       "       'effect_emergency_measures', 'water_depth_cm', 'contaminations',\n",
       "       'flowvelocity', 'replaced_cost_e', 'perception_too_destructive_floods',\n",
       "       'risk_future_flood', 'risk_consequents_future_flood', 'bage',\n",
       "       'shp_employees', 'b_area', 'floors', 'builing_elevation',\n",
       "       'builing_type', 'inundation_duration_h', 'emergency_measures',\n",
       "       'overall_problem_house', 'precautionary_measures_lowcost',\n",
       "       'precautionary_measures_expensive', 'building_value_euro',\n",
       "       'hh_monthly_income_euro', 'shp_registered_capital_euro',\n",
       "       'shp_avgmonthly_sale_euro', 'shp_content_value_euro'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_cantho_bred = df_cantho\n",
    "df_cantho_bred = df_cantho_bred.drop(\n",
    "    [\n",
    "    \"Target_contentloss_euro\",\n",
    "    \"Target_relative_contentloss_euro\"\n",
    "    ],\n",
    "    axis=1)\n",
    "\n",
    "print(df_cantho_bred.shape)\n",
    "df_cantho_bred.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge with HCMC dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(393, 20)\n",
      "(393, 18)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Target_relative_contentloss_euro', 'inundation_duration_h',\n",
       "       'water_depth_cm', 'flowvelocity', 'flood_experience', 'bage', 'b_area',\n",
       "       'shp_employees', 'shp_avgmonthly_sale_euro', 'hh_monthly_income_euro',\n",
       "       'emergency_measures', 'precautionary_measures_lowcost',\n",
       "       'precautionary_measures_expensive', 'resilience', 'resilienceLeftAlone',\n",
       "       'contaminations', 'overall_problem_house',\n",
       "       'shp_registered_capital_euro'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## make all DS as floats\n",
    "\n",
    "#.info()\n",
    "print(df_hcmc_bred.shape)\n",
    "\n",
    "df_hcmc_bred.rename(columns={\n",
    "    \"shp_avgmonthly_sale\": \"shp_avgmonthly_sale_euro\",\n",
    "    \"hh_monthly_income\": \"hh_monthly_income_euro\"\n",
    "}, inplace=True)\n",
    "\n",
    "\n",
    "df_hcmc_rloss.rename(columns={\n",
    "    \"shp_avgmonthly_sale\": \"shp_avgmonthly_sale_euro\",\n",
    "    \"hh_monthly_income\": \"hh_monthly_income_euro\"\n",
    "}, inplace=True)\n",
    "\n",
    "print(df_hcmc_rloss.shape)\n",
    "df_hcmc_rloss.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cantho_rloss.columns\n",
    "\n",
    "df_hcmc_rloss.drop(\"overall_problem_house\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(710, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emergency_measures</th>\n",
       "      <th>bage</th>\n",
       "      <th>shp_avgmonthly_sale_euro</th>\n",
       "      <th>shp_registered_capital_euro</th>\n",
       "      <th>hh_monthly_income_euro</th>\n",
       "      <th>Target_relative_contentloss_euro</th>\n",
       "      <th>b_area</th>\n",
       "      <th>precautionary_measures_expensive</th>\n",
       "      <th>inundation_duration_h</th>\n",
       "      <th>flowvelocity</th>\n",
       "      <th>water_depth_cm</th>\n",
       "      <th>precautionary_measures_lowcost</th>\n",
       "      <th>flood_experience</th>\n",
       "      <th>contaminations</th>\n",
       "      <th>shp_employees</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>7.50</td>\n",
       "      <td>184.10</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.20</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>76.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.50</td>\n",
       "      <td>368.30</td>\n",
       "      <td>8.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>21.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.20</td>\n",
       "      <td>15.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>76.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>21.00</td>\n",
       "      <td>2.50</td>\n",
       "      <td>368.30</td>\n",
       "      <td>15.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.20</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>76.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emergency_measures  bage  shp_avgmonthly_sale_euro   \n",
       "0                0.00 12.00                      7.50  \\\n",
       "1                0.00  0.00                      7.50   \n",
       "2                0.00 21.00                      2.50   \n",
       "\n",
       "   shp_registered_capital_euro  hh_monthly_income_euro   \n",
       "0                       184.10                    3.00  \\\n",
       "1                       368.30                    8.00   \n",
       "2                       368.30                   15.00   \n",
       "\n",
       "   Target_relative_contentloss_euro  b_area  precautionary_measures_expensive   \n",
       "0                              0.00   25.00                              0.00  \\\n",
       "1                              0.00   21.00                              0.00   \n",
       "2                              0.00   50.00                              0.33   \n",
       "\n",
       "   inundation_duration_h  flowvelocity  water_depth_cm   \n",
       "0                   2.00          0.20           10.00  \\\n",
       "1                   2.00          0.20           15.00   \n",
       "2                   1.00          0.20            2.00   \n",
       "\n",
       "   precautionary_measures_lowcost  flood_experience  contaminations   \n",
       "0                            0.00             76.00            0.00  \\\n",
       "1                            0.00             76.00            1.00   \n",
       "2                            0.75             76.00            0.00   \n",
       "\n",
       "   shp_employees  \n",
       "0           1.00  \n",
       "1           1.00  \n",
       "2           1.00  "
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_cols = list(set.intersection(*(set(df.columns) for df in [df_hcmc_rloss, df_cantho_rloss])))\n",
    "df_rloss_joined = pd.concat([df[common_cols] for df in [df_hcmc_rloss, df_cantho_rloss]], ignore_index=True)\n",
    "print(df_rloss_joined.shape)\n",
    "df_rloss_joined.head(3)   # not containing HCMCs shp_sector, 'resilience', 'resilienceLeftAlone',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(710, 17)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emergency_measures</th>\n",
       "      <th>bage</th>\n",
       "      <th>shp_content_value_euro</th>\n",
       "      <th>shp_avgmonthly_sale_euro</th>\n",
       "      <th>shp_registered_capital_euro</th>\n",
       "      <th>hh_monthly_income_euro</th>\n",
       "      <th>b_area</th>\n",
       "      <th>precautionary_measures_expensive</th>\n",
       "      <th>inundation_duration_h</th>\n",
       "      <th>flowvelocity</th>\n",
       "      <th>Target_businessreduction</th>\n",
       "      <th>water_depth_cm</th>\n",
       "      <th>overall_problem_house</th>\n",
       "      <th>precautionary_measures_lowcost</th>\n",
       "      <th>flood_experience</th>\n",
       "      <th>contaminations</th>\n",
       "      <th>shp_employees</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>1841.30</td>\n",
       "      <td>7.50</td>\n",
       "      <td>184.10</td>\n",
       "      <td>3.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>76.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1841.30</td>\n",
       "      <td>7.50</td>\n",
       "      <td>368.30</td>\n",
       "      <td>8.00</td>\n",
       "      <td>21.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>76.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>21.00</td>\n",
       "      <td>33143.10</td>\n",
       "      <td>2.50</td>\n",
       "      <td>368.30</td>\n",
       "      <td>15.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>76.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emergency_measures  bage  shp_content_value_euro  shp_avgmonthly_sale_euro   \n",
       "0                0.00 12.00                 1841.30                      7.50  \\\n",
       "1                0.00  0.00                 1841.30                      7.50   \n",
       "2                0.00 21.00                33143.10                      2.50   \n",
       "\n",
       "   shp_registered_capital_euro  hh_monthly_income_euro  b_area   \n",
       "0                       184.10                    3.00   25.00  \\\n",
       "1                       368.30                    8.00   21.00   \n",
       "2                       368.30                   15.00   50.00   \n",
       "\n",
       "   precautionary_measures_expensive  inundation_duration_h  flowvelocity   \n",
       "0                              0.00                   2.00          0.20  \\\n",
       "1                              0.00                   2.00          0.20   \n",
       "2                              0.33                   1.00          0.20   \n",
       "\n",
       "   Target_businessreduction  water_depth_cm  overall_problem_house   \n",
       "0                      0.00           10.00                   5.00  \\\n",
       "1                      0.00           15.00                   6.00   \n",
       "2                      0.00            2.00                   1.00   \n",
       "\n",
       "   precautionary_measures_lowcost  flood_experience  contaminations   \n",
       "0                            0.00             76.00            0.00  \\\n",
       "1                            0.00             76.00            1.00   \n",
       "2                            0.75             76.00            0.00   \n",
       "\n",
       "   shp_employees  \n",
       "0           1.00  \n",
       "1           1.00  \n",
       "2           1.00  "
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_cols = list(set.intersection(*(set(df.columns) for df in [df_hcmc_bred, df_cantho_bred])))\n",
    "df_bred_joined = pd.concat([df[common_cols] for df in [df_hcmc_bred, df_cantho_bred]], ignore_index=True)\n",
    "print(df_bred_joined.shape)\n",
    "df_bred_joined.head(3)   # not containing HCMCs shp_sector, 'resilience', 'resilienceLeftAlone',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Target_relative_contentloss_euro', 'inundation_duration_h',\n",
       "       'water_depth_cm', 'flowvelocity', 'flood_experience', 'bage', 'b_area',\n",
       "       'shp_employees', 'shp_avgmonthly_sale', 'hh_monthly_income',\n",
       "       'emergency_measures', 'precautionary_measures_lowcost',\n",
       "       'precautionary_measures_expensive', 'resilience', 'resilienceLeftAlone',\n",
       "       'contaminations', 'overall_problem_house',\n",
       "       'shp_registered_capital_euro'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hcmc_rloss.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_input_contentloss = all_input_contentloss.drop(\"Target_contentloss_euro\", axis=1)\n",
    "# all_input_contentloss = all_input_contentloss.drop(['shp_sector_1.0', 'shp_sector_2.0', 'shp_sector_3.0'], axis=1)\n",
    "# all_input_contentloss = all_input_contentloss.drop(['flood_type.1', 'flood_type.2','flood_type.3'], axis=1)\n",
    "\n",
    "# all_input_business_reduction = all_input_business_reduction.drop(\"Target_relative_contentloss_euro\", axis=1)\n",
    "# all_input_business_reduction = df_bred_joined.drop(['shp_sector' ,'flood_type.1', 'flood_type.2','flood_type.3'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save to disk\n",
    "df_rloss_joined.to_excel(\"../input_survey_data/input_data_contentloss_tueb_cantho.xlsx\", index=False)\n",
    "df_bred_joined.to_excel(\"../input_survey_data/input_data_businessreduction_tueb_cantho.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relative content loss dataset\n",
      "Number of candidate predictors  15\n",
      "Number of cases  710\n",
      "\n",
      "Business reduction dataset\n",
      "Number of candidate predictors  17\n",
      "Number of cases  710\n"
     ]
    }
   ],
   "source": [
    "print(\"Relative content loss dataset\")\n",
    "print(\"Number of candidate predictors \", df_rloss_joined.shape[1])\n",
    "print(\"Number of cases \", df_rloss_joined.shape[0])\n",
    "\n",
    "print(\"\\nBusiness reduction dataset\")\n",
    "print(\"Number of candidate predictors \", df_bred_joined.shape[1])\n",
    "print(\"Number of cases \", df_bred_joined.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Left overs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'abs_closs_VND'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Anaconda\\envs\\py396_c3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3652\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3651\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3652\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3653\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\py396_c3\\lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\py396_c3\\lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'abs_closs_VND'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Anna\\Documents\\UNI\\MA_topic\\flood-loss-models-4-HCMC\\explorative-data-analysis\\cantho_data_cleaning_and_HCMC_comparison.ipynb Cell 79\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Anna/Documents/UNI/MA_topic/flood-loss-models-4-HCMC/explorative-data-analysis/cantho_data_cleaning_and_HCMC_comparison.ipynb#Y131sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m## Target relative closs\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Anna/Documents/UNI/MA_topic/flood-loss-models-4-HCMC/explorative-data-analysis/cantho_data_cleaning_and_HCMC_comparison.ipynb#Y131sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Anna/Documents/UNI/MA_topic/flood-loss-models-4-HCMC/explorative-data-analysis/cantho_data_cleaning_and_HCMC_comparison.ipynb#Y131sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m#t[[\"abs_closs_VND\", \"shp_content_value_VND\"]] = t[[\"abs_closs_VND\", \"shp_content_value_VND\"]].fillna(0, inplace=True)\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Anna/Documents/UNI/MA_topic/flood-loss-models-4-HCMC/explorative-data-analysis/cantho_data_cleaning_and_HCMC_comparison.ipynb#Y131sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m df_cantho[\u001b[39m\"\u001b[39m\u001b[39mTarget_rcloss\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m df_cantho[\u001b[39m\"\u001b[39;49m\u001b[39mabs_closs_VND\u001b[39;49m\u001b[39m\"\u001b[39;49m] \u001b[39m/\u001b[39m df_cantho[\u001b[39m\"\u001b[39m\u001b[39mshp_content_value_VND\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Anna/Documents/UNI/MA_topic/flood-loss-models-4-HCMC/explorative-data-analysis/cantho_data_cleaning_and_HCMC_comparison.ipynb#Y131sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# set all zero-loss cases to 0\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Anna/Documents/UNI/MA_topic/flood-loss-models-4-HCMC/explorative-data-analysis/cantho_data_cleaning_and_HCMC_comparison.ipynb#Y131sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m df_cantho \u001b[39m=\u001b[39m df_cantho\u001b[39m.\u001b[39mapply(pd\u001b[39m.\u001b[39mto_numeric)\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\py396_c3\\lib\\site-packages\\pandas\\core\\frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3759\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3760\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3761\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3762\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3763\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\py396_c3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3654\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3653\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3654\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3655\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3656\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3657\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'abs_closs_VND'"
     ]
    }
   ],
   "source": [
    "## Target relative closs\n",
    "\n",
    "# #t[[\"abs_closs_VND\", \"shp_content_value_VND\"]] = t[[\"abs_closs_VND\", \"shp_content_value_VND\"]].fillna(0, inplace=True)\n",
    "# df_cantho[\"Target_rcloss\"] = df_cantho[\"abs_closs_VND\"] / df_cantho[\"shp_content_value_VND\"]\n",
    "# # set all zero-loss cases to 0\n",
    "# df_cantho = df_cantho.apply(pd.to_numeric)\n",
    "# df_cantho.Target_rcloss[df_cantho.Target_rcloss.isna()] = 0.0\n",
    "\n",
    "## rloss > cv\n",
    "print(\"Records with relative content loss exceding the content values for businesses:\", sum(df_cantho.Target_rcloss > 1.0) )\n",
    "# t.Target_rcloss[t.Target_rcloss > 1.0]  = 1.0\n",
    "# print(all_input_contentloss[all_input_contentloss.Target_relative_contentloss_euro > 0.99 ])\n",
    "df_cantho[[\"abs_closs_VND\", \"shp_content_value_VND\", \"Target_rcloss\", \"Target_bred\"]].describe()\n",
    "\n",
    "#df_cantho[\"Target_rcloss\"] = df_cantho[\"abs_closs_VND\"] / df_cantho[\"shp_content_value_VND\"]\n",
    "df_cantho[\"Target_rcloss\"] = df_cantho[\"abs_closs_VND\"] / df_cantho[\"shp_content_value_VND_self\"]\n",
    "\n",
    "# set all zero-loss cases to 0\n",
    "df_cantho = df_cantho.apply(pd.to_numeric)\n",
    "df_cantho.Target_rcloss[df_cantho.Target_rcloss.isna()] = 0.0\n",
    "\n",
    "## rloss > cv\n",
    "print(\"Records with relative content loss > total content value :\", sum(df_cantho.Target_rcloss > 1.0) )\n",
    "\n",
    "## drop these records where rloss > cv\n",
    "df_cantho = df_cantho.loc[~(df_cantho.Target_rcloss >= 1.0), :]\n",
    "\n",
    "df_cantho[[\"abs_closs_VND\", \"shp_content_value_VND_self\", \"Target_rcloss\", \"Target_bred\"]].describe()\n",
    "\n",
    "\n",
    "# Overestimation of CV for small businesses \n",
    "# --> businesses with overestimated Cv is charcterized by low number of employees\n",
    "\n",
    "shps_with_overeestimated_cv = df_cantho.loc[df_cantho[\"shp_content_value_VND\"]  <= 2000000.00, :]  # using 25% of busineeses with smallest CV [1.Qunatile]\n",
    "shps_with_overeestimated_cv.number_employees.value_counts()  \n",
    "## --> most of the shops with small cv are indeed very small businesses\n",
    "\n",
    "# ## drop these records where rloss > cv\n",
    "# df_cantho = df_cantho.loc[~(df_cantho.Target_rcloss >= 0.5), :]\n",
    "\n",
    "# df_cantho[[\"abs_closs_VND\", \"shp_content_value_VND_self\", \"Target_rcloss\", \"Target_bred\"]].describe()\n",
    "\n",
    "# df_cantho.abs_closs_VND.describe()  # max abs loss is 2300 €\n",
    "\n",
    "# ## explore cases where rloss > cv\n",
    "# tt = t.loc[t.Target_rcloss > 1.0, :]\n",
    "# tt.sort_values(\"abs_closs_VND\", ascending=False)\n",
    "\n",
    "\n",
    "## get rloss to similar ratio as for HCMC (rloss=0.3)\n",
    "df_cantho =  df_cantho.loc[~(df_cantho.Target_rcloss >= 1.0), :] \n",
    "#df_cantho =  df_cantho.loc[~(df_cantho.Target_rcloss >= .5), :]   # removed ~ 15 records with higher loss ratio than 50%\n",
    "df_cantho[[\"abs_closs_VND\", \"shp_content_value_VND\", \"Target_rcloss\", \"Target_bred\"]].describe()\n",
    "\n",
    "## Can Tho\n",
    "# Abs Closs: median: 1 €, 3.Quantile: 50 €, mean 74 € , max:  2310 €\n",
    "# rloss : median: 0.0 , mean: 0.05,  max: 0.48\n",
    "# CV: mean 3340 €, median: 310 € , max: 392.610 € (no inflation corrected)\n",
    "## Bred : mean 40%, median 40%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py396_c3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
